<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AWS DevOps Practice Questions Analysis</title>
    <style>
        body { font-family: 'Microsoft YaHei', Arial, sans-serif; line-height: 1.3; margin: 0; padding: 20px; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); min-height: 100vh; }
        .container { max-width: 1200px; margin: 0 auto; background-color: white; padding: 20px; border-radius: 12px; box-shadow: 0 8px 32px rgba(0,0,0,0.1); }
        .header { text-align: center; border-bottom: 3px solid #ff9500; padding-bottom: 15px; margin-bottom: 20px; }
        .header h1 { margin: 0 0 10px 0; color: #333; }
        .header p { margin: 5px 0; color: #666; }
        .question-block { margin-bottom: 20px; border: 2px solid #e9ecef; border-radius: 8px; overflow: hidden; background-color: #ffffff; box-shadow: 0 2px 8px rgba(0,0,0,0.05); }
        .question-header { background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; padding: 10px; }
        .question-title { font-size: 16px; font-weight: bold; margin: 0; }
        .question-content { margin: 10px; padding: 10px; background: #f8f9fa; border-radius: 6px; border-left: 4px solid #007bff; font-size: 14px; }
        .options-container { margin: 10px; }
        .option { margin: 4px 0; padding: 8px; background-color: #f8f9fa; border-radius: 4px; border-left: 3px solid #6c757d; font-size: 14px; }
        .correct-answer { background: #d4edda; border-left-color: #28a745; font-weight: bold; }
        .analysis-container { margin: 10px; }
        .translation-section { background: #e7f3ff; padding: 10px; border-radius: 6px; border-left: 4px solid #007bff; font-size: 14px; }
        .detailed-analysis { background: #fff3cd; padding: 8px; border-radius: 6px; border-left: 4px solid #ffc107; margin-top: 8px; }
        .section-title { font-size: 14px; font-weight: bold; color: #495057; margin: 6px 0 3px 0; padding: 2px 0; border-bottom: 1px solid #dee2e6; }
        .key-service { background: #17a2b8; color: white; padding: 1px 4px; border-radius: 3px; font-size: 11px; font-weight: bold; }
        .key-point { background: #fff3cd; padding: 1px 4px; border-radius: 3px; font-weight: bold; color: #856404; font-size: 11px; }
        .correct-reason { background: #d4edda; color: #155724; padding: 1px 3px; border-radius: 3px; font-weight: bold; font-size: 11px; }
        .wrong-reason { background: #f8d7da; color: #721c24; padding: 1px 3px; border-radius: 3px; font-weight: bold; font-size: 11px; }
        .compact-content { margin: 2px 0; font-size: 14px; line-height: 1.3; }
        .option-analysis { margin: 3px 0; padding: 5px 8px; background: rgba(108,117,125,0.1); border-radius: 4px; font-size: 14px; border-left: 3px solid #6c757d; }
        .success { color: #28a745; font-weight: bold; }
        .failure { color: #dc3545; font-weight: bold; }
        .completed { border: 2px solid #28a745; }
        .failed { border: 2px solid #dc3545; }
        .stats { background: #f8f9fa; padding: 15px; border-radius: 8px; margin-bottom: 20px; text-align: center; }
        .stats-item { display: inline-block; margin: 0 15px; }
        .stats-number { font-size: 24px; font-weight: bold; color: #007bff; }
        .stats-label { font-size: 12px; color: #6c757d; }
        @media (max-width: 768px) { .container { padding: 10px; } .stats-item { display: block; margin: 5px 0; } }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>🎯 AWS DevOps Practice Questions Analysis</h1>
        </div>
        
        <div class="stats">
            <div class="stats-item">
                <div class="stats-number" id="totalQuestions">Loading...</div>
                <div class="stats-label">Total Questions</div>
            </div>
            <div class="stats-item">
                <div class="stats-number" id="successCount">0</div>
                <div class="stats-label">Analyzed</div>
            </div>
            <div class="stats-item">
                <div class="stats-number" id="failureCount">0</div>
                <div class="stats-label">Failed</div>
            </div>
        </div>
        
        <div id="questionsContainer">
        <div class="question-block completed" id="question-1">
            <div class="question-header">
                <div class="question-title">Question #1 ✅ ⚪ <small style="float: right;">(1/353)</small></div>
            </div>
            <div class="question-content">A company has a mobile application that makes HTTP API calls to an Application Load Balancer (ALB). The ALB routes requests to an <span class="key-service">AWS Lambda</span> function. Many different versions of the application are in use at any given time, including versions that are in testing by a subset of users. The version of the application is defined in the user-agent header that is sent with all requests to the API. After a series of recent changes to the API, the company has observed issues with the application. The company needs to gather a metric for each API operation by response code for each version of the application that is in use. A DevOps engineer has modified the Lambda function to extract the API operation name, version information from the user-agent header and response code. Which additional set of actions should the DevOps engineer take to gather the required metrics? A (94%) B (4%)</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Modify the Lambda function to write the API operation name, response code, and version number as a log line to an <span class="key-service">Amazon CloudWatch</span> Logs log group. Configure a CloudWatch Logs metric filter that increments a metric for each API operation name. Specify response code and application version as dimensions for the metric.</div>                <div class="option correct-answer"><strong>B.</strong> Modify the Lambda function to write the API operation name, response code, and version number as a log line to an <span class="key-service">Amazon CloudWatch</span> Logs log group. Configure a CloudWatch Logs Insights query to populate CloudWatch metrics from the log lines. Specify response code and application version as dimensions for the metric.</div>                <div class="option"><strong>C.</strong> Configure the ALB access logs to write to an <span class="key-service">Amazon CloudWatch</span> Logs log group. Modify the Lambda function to respond to the ALB with the API operation name, response code, and version number as response metadata. Configure a CloudWatch Logs metric filter that increments a metric for each API operation name. Specify response code and application version as dimensions for the metric.</div>                <div class="option"><strong>D.</strong> Configure AWS X-Ray integration on the Lambda function. Modify the Lambda function to create an X-Ray subsegment with the API operation name, response code, and version number. Configure X-Ray insights to extract an aggregated metric for each API operation name and to publish the metric to <span class="key-service">Amazon CloudWatch</span>. Specify response code and application version as dimensions for the metric.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司有一个移动应用程序，向Application Load Balancer (ALB)发起HTTP API调用。ALB将请求路由到AWS Lambda函数。任何时候都有许多不同版本的应用程序在使用，包括正在由部分用户测试的版本。应用程序版本在发送给API的所有请求的user-agent头中定义。在最近对API进行一系列更改后，公司观察到应用程序出现问题。公司需要为每个正在使用的应用程序版本收集按响应代码分组的每个API操作的指标。DevOps工程师已修改Lambda函数以提取API操作名称、user-agent头中的版本信息和响应代码。DevOps工程师应该采取哪些额外操作来收集所需的指标？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 修改Lambda函数将API操作名称、响应代码和版本号作为日志行写入Amazon CloudWatch Logs日志组。配置CloudWatch Logs指标过滤器，为每个API操作名称递增指标。将响应代码和应用程序版本指定为指标的维度。</div> <div class="option-analysis"><strong>B.</strong> 修改Lambda函数将API操作名称、响应代码和版本号作为日志行写入Amazon CloudWatch Logs日志组。配置CloudWatch Logs Insights查询从日志行填充CloudWatch指标。将响应代码和应用程序版本指定为指标的维度。</div> <div class="option-analysis"><strong>C.</strong> 配置ALB访问日志写入Amazon CloudWatch Logs日志组。修改Lambda函数向ALB响应API操作名称、响应代码和版本号作为响应元数据。配置CloudWatch Logs指标过滤器，为每个API操作名称递增指标。将响应代码和应用程序版本指定为指标的维度。</div> <div class="option-analysis"><strong>D.</strong> 在Lambda函数上配置AWS X-Ray集成。修改Lambda函数创建包含API操作名称、响应代码和版本号的X-Ray子段。配置X-Ray insights提取每个API操作名称的聚合指标并将指标发布到Amazon CloudWatch。将响应代码和应用程序版本指定为指标的维度。<div class="section-title"><strong>核心要求:</strong></div> 为每个应用版本的API操作按响应代码收集自定义指标 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• CloudWatch Logs - 存储和分析日志数据 </div><div class="compact-content">• CloudWatch Logs Insights - 查询和分析日志数据生成指标 </div><div class="compact-content">• Lambda - 提取和记录自定义指标数据 <div class="section-title"><strong>正确答案B:</strong></div> CloudWatch Logs Insights提供强大的查询功能，可以从日志数据中灵活提取和聚合指标，支持复杂的多维度分析 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A - CloudWatch Logs指标过滤器功能有限，难以处理多维度复杂指标聚合 </div><div class="compact-content">• 选项C - ALB访问日志无法包含Lambda内部的自定义业务数据，架构复杂且不可行 </div><div class="compact-content">• 选项D - X-Ray主要用于分布式跟踪，不是专门的指标收集工具，配置复杂且成本较高 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能 - Logs Insights查询效率高，支持实时分析 </div><div class="compact-content">• 成本 - 基于日志的解决方案成本效益最优 </div><div class="compact-content">• 可扩展性 - Insights查询语法灵活，易于扩展新的指标维度</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: B</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-2">
            <div class="question-header">
                <div class="question-title">Question #2 ✅ ⚪ <small style="float: right;">(2/353)</small></div>
            </div>
            <div class="question-content">A company provides an application to customers. The application has an <span class="key-service">Amazon API Gateway</span> REST API that invokes an <span class="key-service">AWS Lambda</span> function. On initialization, the Lambda function loads a large amount of data from an <span class="key-service">Amazon DynamoDB</span> table. The data load process results in long cold-start times of 8-10 seconds. The DynamoDB table has DynamoDB Accelerator (DAX) configured. Customers report that the application intermittently takes a long time to respond to requests. The application receives thousands of requests throughout the day. In the middle of the day, the application experiences 10 times more requests than at any other time of the day. Near the end of the day, the application's request volume decreases to 10% of its normal total. A DevOps engineer needs to reduce the latency of the Lambda function at all times of the day. Which solution will meet these requirements? C (100%)</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Configure provisioned concurrency on the Lambda function with a concurrency value of 1. Delete the DAX cluster for the DynamoDB table.</div>                <div class="option"><strong>B.</strong> Configure reserved concurrency on the Lambda function with a concurrency value of 0.</div>                <div class="option correct-answer"><strong>C.</strong> Configure provisioned concurrency on the Lambda function. Configure AWS Application Auto Scaling on the Lambda function with provisioned concurrency values set to a minimum of 1 and a maximum of 100.</div>                <div class="option"><strong>D.</strong> Configure reserved concurrency on the Lambda function. Configure AWS Application Auto Scaling on the API Gateway API with a reserved concurrency maximum value of 100.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司为客户提供应用程序。该应用程序有一个Amazon API Gateway REST API调用AWS Lambda函数。在初始化时，Lambda函数从Amazon DynamoDB表加载大量数据。数据加载过程导致8-10秒的长冷启动时间。DynamoDB表配置了DynamoDB Accelerator (DAX)。客户报告应用程序间歇性响应时间过长。应用程序每天接收数千个请求。在一天中间，应用程序的请求量比其他任何时间多10倍。接近一天结束时，应用程序的请求量降至正常总量的10%。DevOps工程师需要在一天中的所有时间减少Lambda函数的延迟。 <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 在Lambda函数上配置provisioned concurrency，并发值为1。删除DynamoDB表的DAX集群。</div> <div class="option-analysis"><strong>B.</strong> 在Lambda函数上配置reserved concurrency，并发值为0。</div> <div class="option-analysis"><strong>C.</strong> 在Lambda函数上配置provisioned concurrency。在Lambda函数上配置AWS Application Auto Scaling，provisioned concurrency值设置为最小1，最大100。</div> <div class="option-analysis"><strong>D.</strong> 在Lambda函数上配置reserved concurrency。在API Gateway API上配置AWS Application Auto Scaling，reserved concurrency最大值为100。<div class="section-title"><strong>核心要求:</strong></div> 解决Lambda函数8-10秒冷启动延迟问题，适应全天变化的请求量 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• Lambda Provisioned Concurrency-预热函数实例避免冷启动 </div><div class="compact-content">• AWS Application Auto Scaling-根据需求自动调整provisioned concurrency数量 <div class="section-title"><strong>正确答案C:</strong></div> 使用provisioned concurrency预热Lambda实例消除冷启动，结合Auto Scaling根据请求量变化自动调整预热实例数量，既保证性能又控制成本 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A-provisioned concurrency值为1无法处理高峰期10倍请求量，删除DAX会降低DynamoDB性能 </div><div class="compact-content">• 选项B-reserved concurrency为0会阻止函数执行，无法处理任何请求 </div><div class="compact-content">• 选项D-reserved concurrency限制最大并发但不解决冷启动问题，API Gateway不支持reserved concurrency配置 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-provisioned concurrency消除冷启动延迟 </div><div class="compact-content">• 成本-Auto Scaling根据需求动态调整避免过度预配 </div><div class="compact-content">• 可扩展性-最大100并发支持10倍峰值请求量</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: C</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-3">
            <div class="question-header">
                <div class="question-title">Question #3 ✅ ⚪ <small style="float: right;">(3/353)</small></div>
            </div>
            <div class="question-content">A company is adopting <span class="key-service">AWS CodeDeploy</span> to automate its application deployments for a Java-Apache Tomcat application with an Apache Webserver. The development team started with a proof of concept, created a deployment group for a developer environment, and performed functional tests within the application. After completion, the team will create additional deployment groups for staging and production. The current log level is configured within the Apache settings, but the team wants to change this configuration dynamically when the deployment occurs, so that they can set different log level configurations depending on the deployment group without having a different application revision for each group. How can these requirements be met with the LEAST management overhead and without requiring different script versions for each deployment group? B (88%) 12%</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Tag the <span class="key-service">Amazon EC2</span> instances depending on the deployment group. Then place a script into the application revision that calls the metadata service and the EC2 API to identify which deployment group the instance is part of. Use this information to configure the log level settings. Reference the script as part of the AfterInstall lifecycle hook in the appspec.yml file.</div>                <div class="option correct-answer"><strong>B.</strong> Create a script that uses the CodeDeploy environment variable DEPLOYMENT_GROUP_NAME to identify which deployment group the instance is part of. Use this information to configure the log level settings. Reference this script as part of the BeforeInstall lifecycle hook in the appspec.yml file. Most Voted</div>                <div class="option"><strong>C.</strong> Create a CodeDeploy custom environment variable for each environment. Then place a script into the application revision that checks this environment variable to identify which deployment group the instance is part of. Use this information to configure the log level settings. Reference this script as part of the ValidateService lifecycle hook in the appspec.yml file.</div>                <div class="option"><strong>D.</strong> Create a script that uses the CodeDeploy environment variable DEPLOYMENT_GROUP_ID to identify which deployment group the instance is part of to configure the log level settings. Reference this script as part of the Install lifecycle hook in the appspec.yml file.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司正在采用AWS CodeDeploy来自动化Java-Apache Tomcat应用程序的部署，该应用程序使用Apache Web服务器。开发团队从概念验证开始，为开发环境创建了一个deployment group，并在应用程序内进行了功能测试。完成后，团队将为staging和production创建额外的deployment group。当前日志级别在Apache设置中配置，但团队希望在部署时动态更改此配置，以便根据deployment group设置不同的日志级别配置，而无需为每个组使用不同的应用程序版本。如何以最少的管理开销满足这些要求，且不需要为每个deployment group使用不同的脚本版本？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 根据deployment group标记Amazon EC2实例。然后在应用程序版本中放置一个脚本，该脚本调用元数据服务和EC2 API来识别实例属于哪个deployment group。使用此信息配置日志级别设置。在appspec.yml文件的AfterInstall生命周期钩子中引用该脚本。</div> <div class="option-analysis"><strong>B.</strong> 创建一个使用CodeDeploy环境变量DEPLOYMENT_GROUP_NAME来识别实例属于哪个deployment group的脚本。使用此信息配置日志级别设置。在appspec.yml文件的BeforeInstall生命周期钩子中引用此脚本。</div> <div class="option-analysis"><strong>C.</strong> 为每个环境创建一个CodeDeploy自定义环境变量。然后在应用程序版本中放置一个脚本，检查此环境变量以识别实例属于哪个deployment group。使用此信息配置日志级别设置。在appspec.yml文件的ValidateService生命周期钩子中引用此脚本。</div> <div class="option-analysis"><strong>D.</strong> 创建一个使用CodeDeploy环境变量DEPLOYMENT_GROUP_ID来识别实例属于哪个deployment group的脚本以配置日志级别设置。在appspec.yml文件的Install生命周期钩子中引用此脚本。<div class="section-title"><strong>核心要求:</strong></div> 在CodeDeploy部署过程中根据deployment group动态配置日志级别，无需不同脚本版本 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• <span class="key-service">AWS CodeDeploy</span>-提供内置环境变量和生命周期钩子管理部署流程 </div><div class="compact-content">• Apache Tomcat/Web Server-需要在部署前配置日志级别设置 <div class="section-title"><strong>正确答案B:</strong></div> 使用CodeDeploy内置环境变量DEPLOYMENT_GROUP_NAME在BeforeInstall阶段识别deployment group并配置日志级别，无需额外管理开销 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A-需要额外的EC2标记和API调用，增加管理复杂性和开销 </div><div class="compact-content">• 选项C-需要为每个环境创建和维护自定义环境变量，增加管理开销 </div><div class="compact-content">• 选项D-DEPLOYMENT_GROUP_ID是数字标识符，不如组名称直观，且Install钩子时机不当 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-使用内置环境变量避免额外API调用 </div><div class="compact-content">• 成本-利用CodeDeploy原生功能无额外费用 </div><div class="compact-content">• 可扩展性-单一脚本适用所有deployment group，易于维护</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: B</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-4">
            <div class="question-header">
                <div class="question-title">Question #4 ✅ ⚪ <small style="float: right;">(4/353)</small></div>
            </div>
            <div class="question-content">A company requires its developers to tag all Amazon Elastic Block Store (Amazon EBS) volumes in an account to indicate a desired backup frequency. This requirement includes EBS volumes that do not require backups. The company uses custom tags named Backup_Frequency that have values of none, daily, or weekly that correspond to the desired backup frequency. An audit finds that developers are occasionally not tagging the EBS volumes. A DevOps engineer needs to ensure that all EBS volumes always have the Backup_Frequency tag so that the company can perform backups at least weekly unless a different value is specified. Which solution will meet these requirements? B (100%)</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Set up <span class="key-service">AWS Config</span> in the account. Create a custom rule that returns a compliance failure for all <span class="key-service">Amazon EC2</span> resources that do not have a Backup_Frequency tag applied. Configure a remediation action that uses a custom <span class="key-service">AWS Systems Manager</span> Automation runbook to apply the Backup_Frequency tag with a value of weekly.</div>                <div class="option correct-answer"><strong>B.</strong> Set up <span class="key-service">AWS Config</span> in the account. Use a managed rule that returns a compliance failure for EC2::Volume resources that do not have a Backup_Frequency tag applied. Configure a remediation action that uses a custom <span class="key-service">AWS Systems Manager</span> Automation runbook to apply the Backup_Frequency tag with a value of weekly.</div>                <div class="option"><strong>C.</strong> Turn on <span class="key-service">AWS CloudTrail</span> in the account. Create an Amazon EventBridge rule that reacts to EBS CreateVolume events. Configure a custom <span class="key-service">AWS Systems Manager</span> Automation runbook to apply the Backup_Frequency tag with a value of weekly. Specify the runbook as the target of the rule.</div>                <div class="option"><strong>D.</strong> Turn on <span class="key-service">AWS CloudTrail</span> in the account. Create an Amazon EventBridge rule that reacts to EBS CreateVolume events or EBS ModifyVolume events. Configure a custom <span class="key-service">AWS Systems Manager</span> Automation runbook to apply the Backup_Frequency tag with a value of weekly. Specify the runbook as the target of the rule.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 公司要求开发人员为账户中所有Amazon EBS卷打标签以指示所需的备份频率，包括不需要备份的EBS卷。公司使用名为Backup_Frequency的自定义标签，值为none、daily或weekly对应所需备份频率。审计发现开发人员偶尔不给EBS卷打标签。DevOps工程师需要确保所有EBS卷始终具有Backup_Frequency标签，以便公司至少每周执行备份，除非指定了不同的值。 <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 在账户中设置AWS Config，创建自定义规则，对所有未应用Backup_Frequency标签的Amazon EC2资源返回合规性失败，配置修复操作使用自定义AWS Systems Manager Automation runbook应用值为weekly的Backup_Frequency标签。</div> <div class="option-analysis"><strong>B.</strong> 在账户中设置AWS Config，使用托管规则对未应用Backup_Frequency标签的EC2::Volume资源返回合规性失败，配置修复操作使用自定义AWS Systems Manager Automation runbook应用值为weekly的Backup_Frequency标签。</div> <div class="option-analysis"><strong>C.</strong> 在账户中启用AWS CloudTrail，创建Amazon EventBridge规则响应EBS CreateVolume事件，配置自定义AWS Systems Manager Automation runbook应用值为weekly的Backup_Frequency标签，将runbook指定为规则目标。</div> <div class="option-analysis"><strong>D.</strong> 在账户中启用AWS CloudTrail，创建Amazon EventBridge规则响应EBS CreateVolume或EBS ModifyVolume事件，配置自定义AWS Systems Manager Automation runbook应用值为weekly的Backup_Frequency标签，将runbook指定为规则目标。<div class="section-title"><strong>核心要求:</strong></div> 确保所有EBS卷始终具有Backup_Frequency标签，未标记时自动应用weekly默认值 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• <span class="key-service">AWS Config</span> - 持续监控资源合规性并提供自动修复功能 </div><div class="compact-content">• Systems Manager Automation - 执行自动化标签应用操作 <div class="section-title"><strong>正确答案B:</strong></div> 使用AWS Config托管规则专门针对EC2::Volume资源类型检查标签合规性，结合自动修复机制确保所有EBS卷都有必需标签 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A - 自定义规则范围过宽，监控所有EC2资源而非专门针对EBS卷，效率低且可能产生误报 </div><div class="compact-content">• 选项C - 仅在创建新卷时触发，无法处理现有未标记的EBS卷，不满足全面合规要求 </div><div class="compact-content">• 选项D - 虽然增加了ModifyVolume事件，但仍无法覆盖现有未标记卷，且修改卷操作不常见 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能 - Config托管规则专门优化，比自定义规则更高效 </div><div class="compact-content">• 成本 - 托管规则维护成本低，无需自定义开发 </div><div class="compact-content">• 可扩展性 - Config持续监控所有资源，自动修复机制可处理大规模环境</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: B</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-5">
            <div class="question-header">
                <div class="question-title">Question #5 ✅ ⚪ <small style="float: right;">(5/353)</small></div>
            </div>
            <div class="question-content">A company is using an Amazon Aurora cluster as the data store for its application. The Aurora cluster is configured with a single DB instance. The application performs read and write operations on the database by using the cluster's instance endpoint. The company has scheduled an update to be applied to the cluster during an upcoming maintenance window. The cluster must remain available with the least possible interruption during the maintenance window. What should a DevOps engineer do to meet these requirements? A (76%) 13% 6%</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Add a reader instance to the Aurora cluster. Update the application to use the Aurora cluster endpoint for write operations. Update the Aurora cluster's reader endpoint for reads.</div>                <div class="option"><strong>B.</strong> Add a reader instance to the Aurora cluster. Create a custom ANY endpoint for the cluster. Update the application to use the Aurora cluster's custom ANY endpoint for read and write operations.</div>                <div class="option correct-answer"><strong>C.</strong> Turn on the Multi-AZ option on the Aurora cluster. Update the application to use the Aurora cluster endpoint for write operations. Update the Aurora cluster's reader endpoint for reads.</div>                <div class="option"><strong>D.</strong> Turn on the Multi-AZ option on the Aurora cluster. Create a custom ANY endpoint for the cluster. Update the application to use the Aurora cluster's custom ANY endpoint for read and write operations.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司使用Amazon Aurora集群作为应用程序的数据存储。Aurora集群配置了单个DB实例。应用程序通过集群的实例端点对数据库执行读写操作。公司已安排在即将到来的维护窗口期间对集群应用更新。集群必须在维护窗口期间保持可用，中断时间最少。DevOps工程师应该怎么做来满足这些要求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 向Aurora集群添加一个reader实例。更新应用程序使用Aurora集群端点进行写操作。更新Aurora集群的reader端点进行读操作。</div> <div class="option-analysis"><strong>B.</strong> 向Aurora集群添加一个reader实例。为集群创建自定义ANY端点。更新应用程序使用Aurora集群的自定义ANY端点进行读写操作。</div> <div class="option-analysis"><strong>C.</strong> 在Aurora集群上启用Multi-AZ选项。更新应用程序使用Aurora集群端点进行写操作。更新Aurora集群的reader端点进行读操作。</div> <div class="option-analysis"><strong>D.</strong> 在Aurora集群上启用Multi-AZ选项。为集群创建自定义ANY端点。更新应用程序使用Aurora集群的自定义ANY端点进行读写操作。<div class="section-title"><strong>核心要求:</strong></div> 在维护窗口期间保持Aurora集群可用性，最小化中断时间 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• Aurora Multi-AZ-提供跨可用区的高可用性和自动故障转移 </div><div class="compact-content">• Aurora Reader实例-提供读取扩展但不提供故障转移保护 <div class="section-title"><strong>正确答案C:</strong></div> Multi-AZ配置在主实例维护期间提供自动故障转移到备用实例，确保最小中断时间，同时分离读写端点优化性能 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A-仅添加reader实例无法在主实例维护时提供故障转移保护 </div><div class="compact-content">• 选项B-reader实例不提供高可用性，自定义ANY端点无法解决维护中断问题 </div><div class="compact-content">• 选项D-自定义ANY端点不是维护期间保持可用性的最佳实践 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-Multi-AZ提供自动故障转移，分离读写端点优化负载分配 </div><div class="compact-content">• 成本-Multi-AZ是标准高可用性解决方案，成本效益高于复杂架构 </div><div class="compact-content">• 可扩展性-Multi-AZ配置支持未来扩展需求，维护运维简单性</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: C</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-6">
            <div class="question-header">
                <div class="question-title">Question #6 ✅ 📝 <small style="float: right;">(6/353)</small></div>
            </div>
            <div class="question-content">A company must encrypt all AMIs that the company shares across accounts. A DevOps engineer has access to a source account where an unencrypted custom AMI has been built. The DevOps engineer also has access to a target account where an <span class="key-service">Amazon EC2</span> Auto Scaling group will launch EC2 instances from the AMI. The DevOps engineer must share the AMI with the target account. The company has created an AWS Key Management Service (AWS KMS) key in the source account. Which additional steps should the DevOps engineer perform to meet the requirements? (Choose three.) ADF (96%) 2%</div>
            <div class="options-container">                <div class="option correct-answer"><strong>A.</strong> In the source account, copy the unencrypted AMI to an encrypted AMI. Specify the KMS key in the copy action.</div>                <div class="option"><strong>B.</strong> In the source account, copy the unencrypted AMI to an encrypted AMI. Specify the default Amazon Elastic Block Store (Amazon EBS) encryption key in the copy action.</div>                <div class="option correct-answer"><strong>C.</strong> In the source account, create a KMS grant that delegates permissions to the Auto Scaling group service-linked role in the target account.</div>                <div class="option correct-answer"><strong>D.</strong> In the source account, modify the key policy to give the target account permissions to create a grant. In the target account, create a KMS grant that delegates permissions to the Auto Scaling group service-linked role.</div>                <div class="option"><strong>E.</strong> In the source account, share the unencrypted AMI with the target account. F. In the source account, share the encrypted AMI with the target account. Most Voted</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 公司必须加密所有跨账户共享的AMI。DevOps工程师可以访问源账户（已构建未加密自定义AMI）和目标账户（Auto Scaling组将从AMI启动EC2实例）。必须将AMI共享给目标账户。公司已在源账户创建AWS KMS密钥。DevOps工程师还需要执行哪些步骤来满足要求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 在源账户中，将未加密AMI复制为加密AMI，在复制操作中指定KMS密钥</div> <div class="option-analysis"><strong>B.</strong> 在源账户中，将未加密AMI复制为加密AMI，在复制操作中指定默认Amazon EBS加密密钥</div> <div class="option-analysis"><strong>C.</strong> 在源账户中，创建KMS授权，将权限委托给目标账户中的Auto Scaling组服务链接角色</div> <div class="option-analysis"><strong>D.</strong> 在源账户中，修改密钥策略给目标账户创建授权的权限，在目标账户中创建KMS授权委托权限给Auto Scaling组服务链接角色</div> <div class="option-analysis"><strong>E.</strong> 在源账户中，与目标账户共享未加密AMI F. 在源账户中，与目标账户共享加密AMI<div class="section-title"><strong>核心要求:</strong></div> 跨账户共享加密AMI并确保目标账户Auto Scaling组能够使用 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• AMI Copy - 将未加密AMI转换为使用指定KMS密钥的加密AMI </div><div class="compact-content">• KMS Grant - 提供跨账户KMS密钥使用权限的灵活授权机制 </div><div class="compact-content">• Auto Scaling Service-Linked Role - 需要KMS权限来启动加密AMI实例 <div class="section-title"><strong>正确答案ACD:</strong></div> A选项使用指定KMS密钥加密AMI，C选项通过KMS grant授权目标账户服务角色，D选项建立完整的跨账户KMS权限链（密钥策略+grant） <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项B - 使用默认EBS密钥无法实现跨账户访问控制 </div><div class="compact-content">• 选项E - 共享未加密AMI不符合加密要求 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 安全性 - 必须使用公司指定的KMS密钥加密，建立适当的跨账户权限 </div><div class="compact-content">• 功能性 - 确保Auto Scaling组能够正常启动加密AMI实例 </div><div class="compact-content">• <span class="key-point">合规性</span> - 满足公司所有共享AMI必须加密的强制要求</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: ACD (A、C、D)</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-7">
            <div class="question-header">
                <div class="question-title">Question #7 ✅ 📝 <small style="float: right;">(7/353)</small></div>
            </div>
            <div class="question-content">A company uses <span class="key-service">AWS CodePipeline</span> pipelines to automate releases of its application. A typical pipeline consists of three stages: build, test, and deployment. The company has been using a separate <span class="key-service">AWS CodeBuild</span> project to run scripts for each stage. However, the company now wants to use <span class="key-service">AWS CodeDeploy</span> to handle the deployment stage of the pipelines. The company has packaged the application as an RPM package and must deploy the application to a fleet of <span class="key-service">Amazon EC2</span> instances. The EC2 instances are in an EC2 Auto Scaling group and are launched from a common AMI. Which combination of steps should a DevOps engineer perform to meet these requirements? (Choose two.) AD (100%)</div>
            <div class="options-container">                <div class="option correct-answer"><strong>A.</strong> Create a new version of the common AMI with the CodeDeploy agent installed. Update the IAM role of the EC2 instances to allow access to CodeDeploy.</div>                <div class="option"><strong>B.</strong> Create a new version of the common AMI with the CodeDeploy agent installed. Create an AppSpec file that contains application deployment scripts and grants access to CodeDeploy.</div>                <div class="option"><strong>C.</strong> Create an application in CodeDeploy. Configure an in-place deployment type. Specify the Auto Scaling group as the deployment target. Add a step to the CodePipeline pipeline to use EC2 Image Builder to create a new AMI. Configure CodeDeploy to deploy the newly created AMI.</div>                <div class="option correct-answer"><strong>D.</strong> Create an application in CodeDeploy. Configure an in-place deployment type. Specify the Auto Scaling group as the deployment target. Update the CodePipeline pipeline to use the CodeDeploy action to deploy the application.</div>                <div class="option"><strong>E.</strong> Create an application in CodeDeploy. Configure an in-place deployment type. Specify the EC2 instances that are launched from the common AMI as the deployment target. Update the CodePipeline pipeline to use the CodeDeploy action to deploy the application.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司使用AWS CodePipeline管道自动化应用程序发布。典型管道包含三个阶段：构建、测试和部署。公司一直使用单独的AWS CodeBuild项目为每个阶段运行脚本。但是，公司现在希望使用AWS CodeDeploy处理管道的部署阶段。公司已将应用程序打包为RPM包，必须将应用程序部署到Amazon EC2实例集群。EC2实例位于EC2 Auto Scaling组中，并从通用AMI启动。DevOps工程师应执行哪些步骤组合来满足这些要求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 创建安装了CodeDeploy代理的通用AMI新版本。更新EC2实例的IAM角色以允许访问CodeDeploy。</div> <div class="option-analysis"><strong>B.</strong> 创建安装了CodeDeploy代理的通用AMI新版本。创建包含应用程序部署脚本并授予CodeDeploy访问权限的AppSpec文件。</div> <div class="option-analysis"><strong>C.</strong> 在CodeDeploy中创建应用程序。配置就地部署类型。指定Auto Scaling组作为部署目标。向CodePipeline管道添加步骤以使用EC2 Image Builder创建新AMI。配置CodeDeploy部署新创建的AMI。</div> <div class="option-analysis"><strong>D.</strong> 在CodeDeploy中创建应用程序。配置就地部署类型。指定Auto Scaling组作为部署目标。更新CodePipeline管道以使用CodeDeploy操作部署应用程序。</div> <div class="option-analysis"><strong>E.</strong> 在CodeDeploy中创建应用程序。配置就地部署类型。指定从通用AMI启动的EC2实例作为部署目标。更新CodePipeline管道以使用CodeDeploy操作部署应用程序。<div class="section-title"><strong>核心要求:</strong></div> 将CodePipeline部署阶段从CodeBuild迁移到CodeDeploy，实现RPM包到Auto Scaling组EC2实例的自动化部署 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• <span class="key-service">AWS CodeDeploy</span>-处理应用程序到EC2实例的自动化部署 </div><div class="compact-content">• EC2 Auto Scaling-管理动态扩展的EC2实例集群 </div><div class="compact-content">• CodePipeline-编排整个CI/CD流程 <div class="section-title"><strong>正确答案AD:</strong></div> 选项A确保EC2实例具备CodeDeploy代理和必要的IAM权限，选项D正确配置CodeDeploy应用程序并集成到CodePipeline中，两者结合实现完整的部署解决方案 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项B-AppSpec文件不能授予CodeDeploy访问权限，权限管理应通过IAM角色实现 </div><div class="compact-content">• 选项C-混淆了部署概念，CodeDeploy不部署AMI而是部署应用程序代码到现有实例 </div><div class="compact-content">• 选项E-指定具体EC2实例作为目标不适合动态Auto Scaling环境，应使用Auto Scaling组 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-就地部署避免实例重建开销，CodeDeploy代理提供高效部署 </div><div class="compact-content">• 成本-复用现有实例，避免频繁创建新AMI的存储和计算成本 </div><div class="compact-content">• 可扩展性-Auto Scaling组作为部署目标自动适应实例数量变化</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: AD (A、D)</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-8">
            <div class="question-header">
                <div class="question-title">Question #8 ✅ 📝 <small style="float: right;">(8/353)</small></div>
            </div>
            <div class="question-content">A company's security team requires that all external Application Load Balancers (ALBs) and <span class="key-service">Amazon API Gateway</span> APIs are associated with AWS WAF web ACLs. The company has hundreds of AWS accounts, all of which are included in a single organization in <span class="key-service">AWS Organizations</span>. The company has configured <span class="key-service">AWS Config</span> for the organization. During an audit, the company finds some externally facing ALBs that are not associated with AWS WAF web ACLs. Which combination of steps should a DevOps engineer take to prevent future violations? (Choose two.) AC (95%) 5%</div>
            <div class="options-container">                <div class="option correct-answer"><strong>A.</strong> Delegate AWS Firewall Manager to a security account.</div>                <div class="option"><strong>B.</strong> Delegate <span class="key-service">Amazon GuardDuty</span> to a security account.</div>                <div class="option correct-answer"><strong>C.</strong> Create an AWS Firewall Manager policy to attach AWS WAF web ACLs to any newly created ALBs and API Gateway APIs.</div>                <div class="option"><strong>D.</strong> Create an <span class="key-service">Amazon GuardDuty</span> policy to attach AWS WAF web ACLs to any newly created ALBs and API Gateway APIs.</div>                <div class="option"><strong>E.</strong> Configure an <span class="key-service">AWS Config</span> managed rule to attach AWS WAF web ACLs to any newly created ALBs and API Gateway APIs.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 公司安全团队要求所有外部Application Load Balancers (ALBs)和Amazon API Gateway APIs都必须关联AWS WAF web ACLs。公司有数百个AWS账户，都包含在AWS Organizations的单个组织中。公司已为组织配置了AWS Config。在审计中，公司发现一些面向外部的ALBs没有关联AWS WAF web ACLs。DevOps工程师应采取哪些步骤组合来防止未来违规？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 将AWS Firewall Manager委托给安全账户</div> <div class="option-analysis"><strong>B.</strong> 将Amazon GuardDuty委托给安全账户</div> <div class="option-analysis"><strong>C.</strong> 创建AWS Firewall Manager策略，为任何新创建的ALBs和API Gateway APIs附加AWS WAF web ACLs</div> <div class="option-analysis"><strong>D.</strong> 创建Amazon GuardDuty策略，为任何新创建的ALBs和API Gateway APIs附加AWS WAF web ACLs</div> <div class="option-analysis"><strong>E.</strong> 配置AWS Config托管规则，为任何新创建的ALBs和API Gateway APIs附加AWS WAF web ACLs<div class="section-title"><strong>核心要求:</strong></div> 在多账户环境中自动为新创建的ALBs和API Gateway APIs强制附加AWS WAF web ACLs <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• AWS Firewall Manager-跨账户集中管理和自动部署安全策略的服务 </div><div class="compact-content">• AWS WAF-Web应用防火墙，保护应用免受常见Web攻击 <div class="section-title"><strong>正确答案AC:</strong></div> 首先委托Firewall Manager到安全账户获得跨账户管理权限，然后创建Firewall Manager策略实现WAF web ACLs的自动附加和合规强制 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项B-GuardDuty是威胁检测服务，不能管理WAF策略部署 </div><div class="compact-content">• 选项D-GuardDuty无法创建或管理WAF附加策略 </div><div class="compact-content">• 选项E-Config规则只能检测合规性，无法自动附加WAF web ACLs <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-Firewall Manager提供集中化策略管理，减少管理开销 </div><div class="compact-content">• 成本-避免在每个账户单独配置，降低运维成本 </div><div class="compact-content">• 可扩展性-支持数百个账户的统一安全策略管理和自动合规</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: AC (A、C)</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-9">
            <div class="question-header">
                <div class="question-title">Question #9 ✅ ⚪ <small style="float: right;">(9/353)</small></div>
            </div>
            <div class="question-content">A company uses AWS Key Management Service (AWS KMS) keys and manual key rotation to meet regulatory compliance requirements. The security team wants to be notified when any keys have not been rotated after 90 days. Which solution will accomplish this? C (100%)</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Configure AWS KMS to publish to an Amazon Simple Notification Service (<span class="key-service">Amazon SNS</span>) topic when keys are more than 90 days old.</div>                <div class="option"><strong>B.</strong> Configure an Amazon EventBridge event to launch an <span class="key-service">AWS Lambda</span> function to call the AWS Trusted Advisor API and publish to an Amazon Simple Notification Service (<span class="key-service">Amazon SNS</span>) topic.</div>                <div class="option correct-answer"><strong>C.</strong> Develop an <span class="key-service">AWS Config</span> custom rule that publishes to an Amazon Simple Notification Service (<span class="key-service">Amazon SNS</span>) topic when keys are more than 90 days old.</div>                <div class="option"><strong>D.</strong> Configure AWS Security Hub to publish to an Amazon Simple Notification Service (<span class="key-service">Amazon SNS</span>) topic when keys are more than 90 days old.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司使用AWS Key Management Service (AWS KMS)密钥和手动密钥轮换来满足合规要求。安全团队希望在任何密钥超过90天未轮换时收到通知。哪个解决方案能实现这一目标？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 配置AWS KMS在密钥超过90天时发布到Amazon Simple Notification Service (<span class="key-service">Amazon SNS</span>)主题</div> <div class="option-analysis"><strong>B.</strong> 配置Amazon EventBridge事件启动AWS Lambda函数调用AWS Trusted Advisor API并发布到Amazon Simple Notification Service (<span class="key-service">Amazon SNS</span>)主题</div> <div class="option-analysis"><strong>C.</strong> 开发AWS Config自定义规则，在密钥超过90天时发布到Amazon Simple Notification Service (<span class="key-service">Amazon SNS</span>)主题</div> <div class="option-analysis"><strong>D.</strong> 配置AWS Security Hub在密钥超过90天时发布到Amazon Simple Notification Service (<span class="key-service">Amazon SNS</span>)主题<div class="section-title"><strong>核心要求:</strong></div> 监控KMS密钥轮换状态并在超过90天时自动通知 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• AWS KMS - 密钥管理服务，需要监控其密钥轮换状态 </div><div class="compact-content">• <span class="key-service">AWS Config</span> - 资源配置监控服务，支持自定义合规规则 <div class="section-title"><strong>正确答案C:</strong></div> AWS Config自定义规则可以持续监控KMS密钥的轮换状态，评估密钥是否符合90天轮换要求，并在不合规时触发SNS通知 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A - AWS KMS本身不提供基于时间的自动通知功能 </div><div class="compact-content">• 选项B - Trusted Advisor不专门监控KMS密钥轮换状态 </div><div class="compact-content">• 选项D - Security Hub需要其他服务提供发现结果，不能直接监控密钥轮换 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能 - Config规则提供持续合规监控 </div><div class="compact-content">• 成本 - 自定义规则成本效益高 </div><div class="compact-content">• 可扩展性 - 支持多密钥和复杂合规要求</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: C</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-10">
            <div class="question-header">
                <div class="question-title">Question #10 ✅ ⚪ <small style="float: right;">(10/353)</small></div>
            </div>
            <div class="question-content">A security review has identified that an <span class="key-service">AWS CodeBuild</span> project is downloading a database population script from an <span class="key-service">Amazon S3</span> bucket using an unauthenticated request. The security team does not allow unauthenticated requests to S3 buckets for this project. How can this issue be corrected in the MOST secure manner? C (100%)</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Add the bucket name to the AllowedBuckets section of the CodeBuild project settings. Update the build spec to use the AWS CLI to download the database population script.</div>                <div class="option"><strong>B.</strong> Modify the S3 bucket settings to enable HTTPS basic authentication and specify a token. Update the build spec to use cURL to pass the token and download the database population script.</div>                <div class="option correct-answer"><strong>C.</strong> Remove unauthenticated access from the S3 bucket with a bucket policy. Modify the service role for the CodeBuild project to include <span class="key-service">Amazon S3</span> access. Use the AWS CLI to download the database population script.</div>                <div class="option"><strong>D.</strong> Remove unauthenticated access from the S3 bucket with a bucket policy. Use the AWS CLI to download the database population script using an IAM access key and a secret access key.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 安全审查发现AWS CodeBuild项目正在使用未认证请求从Amazon S3存储桶下载数据库填充脚本。安全团队不允许此项目对S3存储桶进行未认证请求。如何以最安全的方式纠正此问题？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 将存储桶名称添加到CodeBuild项目设置的AllowedBuckets部分。更新构建规范以使用AWS CLI下载数据库填充脚本。</div> <div class="option-analysis"><strong>B.</strong> 修改S3存储桶设置以启用HTTPS基本认证并指定令牌。更新构建规范以使用cURL传递令牌并下载数据库填充脚本。</div> <div class="option-analysis"><strong>C.</strong> 使用存储桶策略从S3存储桶中移除未认证访问。修改CodeBuild项目的服务角色以包含Amazon S3访问权限。使用AWS CLI下载数据库填充脚本。</div> <div class="option-analysis"><strong>D.</strong> 使用存储桶策略从S3存储桶中移除未认证访问。使用IAM访问密钥和秘密访问密钥通过AWS CLI下载数据库填充脚本。<div class="section-title"><strong>核心要求:</strong></div> 为CodeBuild项目建立安全的S3访问机制，消除未认证请求 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• CodeBuild-构建服务，需要通过服务角色访问其他AWS资源 </div><div class="compact-content">• S3-对象存储服务，通过存储桶策略和IAM控制访问权限 <div class="section-title"><strong>正确答案C:</strong></div> 通过存储桶策略禁用未认证访问，为CodeBuild服务角色授予S3权限，实现基于角色的安全访问 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A-AllowedBuckets不是CodeBuild的实际配置项，且未解决认证问题 </div><div class="compact-content">• 选项B-S3不支持HTTPS基本认证，这不是AWS标准的认证方式 </div><div class="compact-content">• 选项D-在CodeBuild中硬编码访问密钥违反安全最佳实践，存在密钥泄露风险 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 安全性-使用服务角色避免密钥暴露，遵循最小权限原则 </div><div class="compact-content">• 可管理性-通过IAM角色集中管理权限，便于审计和维护 </div><div class="compact-content">• <span class="key-point">合规性</span>-符合AWS安全最佳实践，满足企业安全策略要求</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: C</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-11">
            <div class="question-header">
                <div class="question-title">Question #11 ✅ 📝 <small style="float: right;">(11/353)</small></div>
            </div>
            <div class="question-content">An ecommerce company has chosen AWS to host its new platform. The company's DevOps team has started building an AWS Control Tower landing zone. The DevOps team has set the identity store within <span class="key-service">AWS IAM</span> Identity Center (AWS Single Sign-On) to external identity provider (IdP) and has configured SAML 2.0. The DevOps team wants a robust permission model that applies the principle of least privilege. The model must allow the team to build and manage only the team's own resources. Which combination of steps will meet these requirements? (Choose three.) BCF (100%)</div>
            <div class="options-container">                <div class="option correct-answer"><strong>A.</strong> Create IAM policies that include the required permissions. Include the aws:PrincipalTag condition key.</div>                <div class="option correct-answer"><strong>B.</strong> Create permission sets. Attach an inline policy that includes the required permissions and uses the aws:PrincipalTag condition key to scope the permissions.</div>                <div class="option correct-answer"><strong>C.</strong> Create a group in the IdP. Place users in the group. Assign the group to accounts and the permission sets in IAM Identity Center.</div>                <div class="option"><strong>D.</strong> Create a group in the IdP. Place users in the group. Assign the group to OUs and IAM policies.</div>                <div class="option"><strong>E.</strong> Enable attributes for access control in IAM Identity Center. Apply tags to users. Map the tags as key-value pairs. F. Enable attributes for access control in IAM Identity Center. Map attributes from the IdP as key-value pairs. Most Voted</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家电商公司选择AWS托管新平台。DevOps团队正在构建AWS Control Tower landing zone，已将IAM Identity Center的身份存储设置为外部IdP并配置了SAML 2.0。团队需要遵循最小权限原则的健壮权限模型，允许团队仅构建和管理自己的资源。哪些步骤组合能满足要求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 创建包含所需权限的IAM策略，包含aws:PrincipalTag条件键</div> <div class="option-analysis"><strong>B.</strong> 创建权限集，附加包含所需权限的内联策略并使用aws:PrincipalTag条件键限定权限范围</div> <div class="option-analysis"><strong>C.</strong> 在IdP中创建组，将用户放入组中，在IAM Identity Center中将组分配给账户和权限集</div> <div class="option-analysis"><strong>D.</strong> 在IdP中创建组，将用户放入组中，将组分配给OU和IAM策略</div> <div class="option-analysis"><strong>E.</strong> 在IAM Identity Center中启用访问控制属性，对用户应用标签，将标签映射为键值对 F. 在IAM Identity Center中启用访问控制属性，将IdP属性映射为键值对<div class="section-title"><strong>核心要求:</strong></div> 基于外部IdP和SAML 2.0配置健壮的最小权限模型，确保团队只能管理自己的资源 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• IAM Identity Center-提供集中身份管理和权限集功能 </div><div class="compact-content">• AWS Control Tower-提供多账户治理和landing zone管理 <div class="section-title"><strong>正确答案ABC:</strong></div> A提供基于标签的条件权限控制，B创建权限集实现细粒度权限管理，C建立IdP组到IAM Identity Center的完整映射链路，三者结合实现基于属性的访问控制(ABAC) <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项D-直接将组分配给OU和IAM策略绕过了IAM Identity Center的权限集机制 </div><div class="compact-content">• 选项E-手动标签用户不如从IdP自动映射属性灵活和可维护 </div><div class="compact-content">• 选项F-虽然正确但不如ABC组合完整，缺少具体的权限实施机制 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 安全性-基于aws:PrincipalTag实现资源级别的访问控制 </div><div class="compact-content">• 可管理性-通过权限集和IdP组映射简化权限管理 </div><div class="compact-content">• 可扩展性-ABAC模型支持动态权限分配和团队扩展</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: ABC (A、B、C)</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-12">
            <div class="question-header">
                <div class="question-title">Question #12 ✅ 📝 <small style="float: right;">(12/353)</small></div>
            </div>
            <div class="question-content">An ecommerce company is receiving reports that its order history page is experiencing delays in reflecting the processing status of orders. The order processing system consists of an <span class="key-service">AWS Lambda</span> function that uses reserved concurrency. The Lambda function processes order messages from an Amazon Simple Queue Service (<span class="key-service">Amazon SQS</span>) queue and inserts processed orders into an <span class="key-service">Amazon DynamoDB</span> table. The DynamoDB table has auto scaling enabled for read and write capacity. Which actions should a DevOps engineer take to resolve this delay? (Choose two.) AD (100%)</div>
            <div class="options-container">                <div class="option correct-answer"><strong>A.</strong> Check the ApproximateAgeOfOldestMessage metric for the SQS queue. Increase the Lambda function concurrency limit.</div>                <div class="option"><strong>B.</strong> Check the ApproximateAgeOfOldestMessage metric for the SQS queue. Configure a redrive policy on the SQS queue.</div>                <div class="option"><strong>C.</strong> Check the NumberOfMessagesSent metric for the SQS queue. Increase the SQS queue visibility timeout.</div>                <div class="option correct-answer"><strong>D.</strong> Check the WriteThrottleEvents metric for the DynamoDB table. Increase the maximum write capacity units (WCUs) for the table's scaling policy. Most Voted</div>                <div class="option"><strong>E.</strong> Check the Throttles metric for the Lambda function. Increase the Lambda function timeout.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家电商公司收到报告称其订单历史页面在反映订单处理状态时出现延迟。订单处理系统由使用预留并发的AWS Lambda函数组成，该Lambda函数处理来自Amazon SQS队列的订单消息并将处理后的订单插入Amazon DynamoDB表中。DynamoDB表启用了读写容量的自动扩展。DevOps工程师应采取哪些措施来解决此延迟？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 检查SQS队列的ApproximateAgeOfOldestMessage指标，增加Lambda函数并发限制</div> <div class="option-analysis"><strong>B.</strong> 检查SQS队列的ApproximateAgeOfOldestMessage指标，在SQS队列上配置重驱动策略</div> <div class="option-analysis"><strong>C.</strong> 检查SQS队列的NumberOfMessagesSent指标，增加SQS队列可见性超时时间</div> <div class="option-analysis"><strong>D.</strong> 检查DynamoDB表的WriteThrottleEvents指标，增加表扩展策略的最大写容量单位(WCUs)</div> <div class="option-analysis"><strong>E.</strong> 检查Lambda函数的Throttles指标，增加Lambda函数超时时间<div class="section-title"><strong>核心要求:</strong></div> 解决订单处理延迟问题，需要识别并解决Lambda处理能力和DynamoDB写入瓶颈 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• Lambda-使用预留并发处理SQS消息，可能存在并发限制 </div><div class="compact-content">• DynamoDB-存储处理结果，可能存在写入节流问题 </div><div class="compact-content">• SQS-消息队列，消息积压反映处理延迟 <div class="section-title"><strong>正确答案AD:</strong></div> A选项通过ApproximateAgeOfOldestMessage识别消息积压并增加Lambda并发解决处理瓶颈；D选项通过WriteThrottleEvents识别写入节流并增加WCU解决DynamoDB瓶颈 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项B-重驱动策略用于处理失败消息，不解决处理延迟问题 </div><div class="compact-content">• 选项C-NumberOfMessagesSent不反映处理延迟，可见性超时调整无助于解决积压 </div><div class="compact-content">• 选项E-Throttles指标正确但增加超时时间不能解决并发限制问题 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-识别正确指标(消息年龄、写节流)并针对性优化瓶颈环节 </div><div class="compact-content">• 成本-通过精准调整并发和容量避免过度配置 </div><div class="compact-content">• 可扩展性-Lambda并发和DynamoDB容量调整提供弹性处理能力</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: AD (A、D)</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-13">
            <div class="question-header">
                <div class="question-title">Question #13 ✅ ⚪ <small style="float: right;">(13/353)</small></div>
            </div>
            <div class="question-content">A company has a single AWS account that runs hundreds of <span class="key-service">Amazon EC2</span> instances in a single AWS Region. New EC2 instances are launched and terminated each hour in the account. The account also includes existing EC2 instances that have been running for longer than a week. The company's security policy requires all running EC2 instances to use an EC2 instance profile. If an EC2 instance does not have an instance profile attached, the EC2 instance must use a default instance profile that has no IAM permissions assigned. A DevOps engineer reviews the account and discovers EC2 instances that are running without an instance profile. During the review, the DevOps engineer also observes that new EC2 instances are being launched without an instance profile. Which solution will ensure that an instance profile is attached to all existing and future EC2 instances in the Region? B (100%)</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Configure an Amazon EventBridge rule that reacts to EC2 RunInstances API calls. Configure the rule to invoke an <span class="key-service">AWS Lambda</span> function to attach the default instance profile to the EC2 instances.</div>                <div class="option correct-answer"><strong>B.</strong> Configure the ec2-instance-profile-attached <span class="key-service">AWS Config</span> managed rule with a trigger type of configuration changes. Configure an automatic remediation action that invokes an <span class="key-service">AWS Systems Manager</span> Automation runbook to attach the default instance profile to the EC2 instances.</div>                <div class="option"><strong>C.</strong> Configure an Amazon EventBridge rule that reacts to EC2 StartInstances API calls. Configure the rule to invoke an <span class="key-service">AWS Systems Manager</span> Automation runbook to attach the default instance profile to the EC2 instances</div>                <div class="option"><strong>D.</strong> Configure the iam-role-managed-policy-check <span class="key-service">AWS Config</span> managed rule with a trigger type of configuration changes. Configure an automatic remediation action that invokes an <span class="key-service">AWS Lambda</span> function to attach the default instance profile to the EC2 instances.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司在单个AWS Region的单个AWS账户中运行数百个Amazon EC2实例。每小时都会启动和终止新的EC2实例。账户还包括运行超过一周的现有EC2实例。公司安全策略要求所有运行的EC2实例都使用EC2 instance profile。如果EC2实例没有附加instance profile，则必须使用没有分配IAM权限的默认instance profile。DevOps工程师审查账户时发现有EC2实例在没有instance profile的情况下运行，并观察到新的EC2实例也在没有instance profile的情况下启动。哪种解决方案能确保Region中所有现有和未来的EC2实例都附加instance profile？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 配置Amazon EventBridge规则响应EC2 RunInstances API调用，配置规则调用AWS Lambda函数将默认instance profile附加到EC2实例</div> <div class="option-analysis"><strong>B.</strong> 配置ec2-instance-profile-attached AWS Config托管规则，触发类型为配置更改，配置自动修复操作调用AWS Systems Manager Automation runbook将默认instance profile附加到EC2实例</div> <div class="option-analysis"><strong>C.</strong> 配置Amazon EventBridge规则响应EC2 StartInstances API调用，配置规则调用AWS Systems Manager Automation runbook将默认instance profile附加到EC2实例</div> <div class="option-analysis"><strong>D.</strong> 配置iam-role-managed-policy-check AWS Config托管规则，触发类型为配置更改，配置自动修复操作调用AWS Lambda函数将默认instance profile附加到EC2实例<div class="section-title"><strong>核心要求:</strong></div> 确保所有现有和新启动的EC2实例都附加instance profile <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• <span class="key-service">AWS Config</span> - 监控资源配置合规性并提供自动修复 </div><div class="compact-content">• EventBridge - 响应AWS API调用事件 </div><div class="compact-content">• Systems Manager Automation - 执行自动化运维任务 <div class="section-title"><strong>正确答案B:</strong></div> 使用专门的ec2-instance-profile-attached Config规则监控EC2实例的instance profile附加状态，通过配置更改触发器实时检测违规并自动修复 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A - RunInstances API只在实例启动时触发，无法处理现有运行的实例 </div><div class="compact-content">• 选项C - StartInstances API只在停止的实例重新启动时触发，不覆盖新启动或现有实例 </div><div class="compact-content">• 选项D - iam-role-managed-policy-check规则检查IAM角色策略，不是检查EC2实例的instance profile附加状态 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能 - Config规则提供持续监控和实时检测配置违规 </div><div class="compact-content">• 成本 - 使用托管规则和自动修复减少人工干预成本 </div><div class="compact-content">• 可扩展性 - 自动处理现有和未来所有EC2实例，无需手动管理</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: B</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-14">
            <div class="question-header">
                <div class="question-title">Question #14 ✅ ⚪ <small style="float: right;">(14/353)</small></div>
            </div>
            <div class="question-content">A DevOps engineer is building a continuous deployment pipeline for a serverless application that uses <span class="key-service">AWS Lambda</span> functions. The company wants to reduce the customer impact of an unsuccessful deployment. The company also wants to monitor for issues. Which deploy stage configuration will meet these requirements? A (81%) D (19%)</div>
            <div class="options-container">                <div class="option correct-answer"><strong>A.</strong> Use an AWS Serverless Application Model (AWS SAM) template to define the serverless application. Use <span class="key-service">AWS CodeDeploy</span> to deploy the Lambda functions with the Canary10Percent15Minutes Deployment Preference Type. Use <span class="key-service">Amazon CloudWatch</span> alarms to monitor the health of the functions.</div>                <div class="option"><strong>B.</strong> Use <span class="key-service">AWS CloudFormation</span> to publish a new stack update, and include <span class="key-service">Amazon CloudWatch</span> alarms on all resources. Set up an <span class="key-service">AWS CodePipeline</span> approval action for a developer to verify and approve the <span class="key-service">AWS CloudFormation</span> change set.</div>                <div class="option"><strong>C.</strong> Use <span class="key-service">AWS CloudFormation</span> to publish a new version on every stack update, and include <span class="key-service">Amazon CloudWatch</span> alarms on all resources. Use the RoutingConfig property of the AWS::Lambda::Alias resource to update the traffic routing during the stack update.</div>                <div class="option"><strong>D.</strong> Use <span class="key-service">AWS CodeBuild</span> to add sample event payloads for testing to the Lambda functions. Publish a new version of the functions, and include <span class="key-service">Amazon CloudWatch</span> alarms. Update the production alias to point to the new version. Configure rollbacks to occur when an alarm is in the ALARM state.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一名DevOps工程师正在为使用AWS Lambda函数的无服务器应用程序构建持续部署管道。公司希望减少部署失败对客户的影响，同时希望监控问题。哪种部署阶段配置能满足这些要求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 使用AWS Serverless Application Model (AWS SAM)模板定义无服务器应用程序。使用AWS CodeDeploy部署Lambda函数，采用Canary10Percent15Minutes部署偏好类型。使用Amazon CloudWatch告警监控函数健康状况。</div> <div class="option-analysis"><strong>B.</strong> 使用AWS CloudFormation发布新的堆栈更新，并在所有资源上包含Amazon CloudWatch告警。设置AWS CodePipeline批准操作，让开发人员验证和批准AWS CloudFormation变更集。</div> <div class="option-analysis"><strong>C.</strong> 使用AWS CloudFormation在每次堆栈更新时发布新版本，并在所有资源上包含Amazon CloudWatch告警。使用AWS::Lambda::Alias资源的RoutingConfig属性在堆栈更新期间更新流量路由。</div> <div class="option-analysis"><strong>D.</strong> 使用AWS CodeBuild为Lambda函数添加测试用的示例事件负载。发布函数新版本并包含Amazon CloudWatch告警。更新生产别名指向新版本。配置在告警处于ALARM状态时进行回滚。<div class="section-title"><strong>核心要求:</strong></div> 实现无服务器应用的安全渐进式部署并减少客户影响 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• AWS SAM - 简化无服务器应用定义和部署配置 </div><div class="compact-content">• <span class="key-service">AWS CodeDeploy</span> - 提供Lambda函数的渐进式部署策略 </div><div class="compact-content">• Canary部署 - 先向10%流量部署新版本，15分钟后全量部署 <div class="section-title"><strong>正确答案A:</strong></div> 使用SAM模板结合CodeDeploy的Canary10Percent15Minutes策略，实现10%流量的金丝雀部署，配合CloudWatch告警自动监控，提供最佳的风险控制和自动化部署能力 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项B - 依赖手动批准流程，缺乏自动化渐进式部署机制 </div><div class="compact-content">• 选项C - 虽然支持流量路由但配置复杂，不如CodeDeploy的预定义策略简洁 </div><div class="compact-content">• 选项D - 缺乏渐进式部署策略，直接切换别名风险较高 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能 - Canary部署最小化客户影响，提供自动回滚机制 </div><div class="compact-content">• 成本 - SAM和CodeDeploy集成度高，减少配置复杂性 </div><div class="compact-content">• 可扩展性 - 预定义部署策略易于标准化和复用</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: A</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-15">
            <div class="question-header">
                <div class="question-title">Question #15 ✅ ⚪ <small style="float: right;">(15/353)</small></div>
            </div>
            <div class="question-content">To run an application, a DevOps engineer launches an <span class="key-service">Amazon EC2</span> instance with public IP addresses in a public subnet. A user data script obtains the application artifacts and installs them on the instances upon launch. A change to the security classification of the application now requires the instances to run with no access to the internet. While the instances launch successfully and show as healthy, the application does not seem to be installed. Which of the following should successfully install the application while complying with the new rule? C (90%) 10%</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Launch the instances in a public subnet with Elastic IP addresses attached. Once the application is installed and running, run a script to disassociate the Elastic IP addresses afterwards.</div>                <div class="option"><strong>B.</strong> Set up a NAT gateway. Deploy the EC2 instances to a private subnet. Update the private subnet's route table to use the NAT gateway as the default route.</div>                <div class="option correct-answer"><strong>C.</strong> Publish the application artifacts to an <span class="key-service">Amazon S3</span> bucket and create a <span class="key-service">VPC</span> endpoint for S3. Assign an IAM instance profile to the EC2 instances so they can read the application artifacts from the S3 bucket.</div>                <div class="option"><strong>D.</strong> Create a security group for the application instances and allow only outbound traffic to the artifact repository. Remove the security group rule once the install is complete.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 为运行应用程序，DevOps工程师在公有子网中启动带有公网IP地址的Amazon EC2实例。用户数据脚本在启动时获取应用程序工件并安装。应用程序安全分类变更现在要求实例运行时不能访问互联网。虽然实例启动成功且显示健康，但应用程序似乎未安装。以下哪个选项能在遵守新规则的同时成功安装应用程序？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 在公有子网中启动实例并附加Elastic IP地址，应用程序安装运行后，运行脚本取消关联Elastic IP地址</div> <div class="option-analysis"><strong>B.</strong> 设置NAT gateway，将EC2实例部署到私有子网，更新私有子网路由表使用NAT gateway作为默认路由</div> <div class="option-analysis"><strong>C.</strong> 将应用程序工件发布到Amazon S3存储桶并创建S3的VPC endpoint，为EC2实例分配IAM实例配置文件以便从S3存储桶读取应用程序工件</div> <div class="option-analysis"><strong>D.</strong> 为应用程序实例创建安全组，仅允许到工件仓库的出站流量，安装完成后删除安全组规则<div class="section-title"><strong>核心要求:</strong></div> 在完全无互联网访问的环境中安装应用程序 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• <span class="key-service">VPC</span> Endpoint-提供AWS服务的私有连接，无需互联网访问 </div><div class="compact-content">• S3-存储应用程序工件 </div><div class="compact-content">• IAM实例配置文件-提供访问S3的权限 <div class="section-title"><strong>正确答案C:</strong></div> 通过VPC Endpoint for S3实现私有网络内直接访问S3服务，结合IAM实例配置文件提供权限，完全避免互联网流量 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A-仍然需要互联网连接进行安装，违反新的安全要求 </div><div class="compact-content">• 选项B-NAT gateway仍提供互联网访问能力，不符合零互联网访问要求 </div><div class="compact-content">• 选项D-安全组限制仍需要互联网连接到外部仓库，违反安全规则 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-<span class="key-service">VPC</span> Endpoint提供高带宽私有连接 </div><div class="compact-content">• 成本-避免NAT gateway数据传输费用 </div><div class="compact-content">• 可扩展性-S3和VPC Endpoint支持大规模部署</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: C</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-16">
            <div class="question-header">
                <div class="question-title">Question #16 ✅ ⚪ <small style="float: right;">(16/353)</small></div>
            </div>
            <div class="question-content">A development team is using <span class="key-service">AWS CodeCommit</span> to version control application code and <span class="key-service">AWS CodePipeline</span> to orchestrate software deployments. The team has decided to use a remote main branch as the trigger for the pipeline to integrate code changes. A developer has pushed code changes to the CodeCommit repository, but noticed that the pipeline had no reaction, even after 10 minutes. Which of the following actions should be taken to troubleshoot this issue? A (58%) B (39%) 4%</div>
            <div class="options-container">                <div class="option correct-answer"><strong>A.</strong> Check that an Amazon EventBridge rule has been created for the main branch to trigger the pipeline.</div>                <div class="option"><strong>B.</strong> Check that the CodePipeline service role has permission to access the CodeCommit repository.</div>                <div class="option"><strong>C.</strong> Check that the developer's IAM role has permission to push to the CodeCommit repository.</div>                <div class="option"><strong>D.</strong> Check to see if the pipeline failed to start because of CodeCommit errors in <span class="key-service">Amazon CloudWatch</span> Logs.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 开发团队使用AWS CodeCommit进行应用代码版本控制，使用AWS CodePipeline编排软件部署。团队决定使用远程main分支作为触发器来集成代码变更。开发者已将代码变更推送到CodeCommit仓库，但注意到pipeline在10分钟后仍无反应。应采取以下哪项操作来排查此问题？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 检查是否为main分支创建了Amazon EventBridge规则来触发pipeline</div> <div class="option-analysis"><strong>B.</strong> 检查CodePipeline服务角色是否有权限访问CodeCommit仓库</div> <div class="option-analysis"><strong>C.</strong> 检查开发者的IAM角色是否有权限推送到CodeCommit仓库</div> <div class="option-analysis"><strong>D.</strong> 检查pipeline是否因为CodeCommit错误而启动失败，查看Amazon CloudWatch Logs<div class="section-title"><strong>核心要求:</strong></div> 排查CodePipeline未被CodeCommit分支变更触发的问题 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• <span class="key-service">AWS CodeCommit</span>-Git代码仓库服务，支持分支变更事件 </div><div class="compact-content">• <span class="key-service">AWS CodePipeline</span>-CI/CD编排服务，需要事件触发机制 </div><div class="compact-content">• Amazon EventBridge-事件路由服务，连接CodeCommit和CodePipeline <div class="section-title"><strong>正确答案A:</strong></div> CodePipeline通过EventBridge规则监听CodeCommit分支变更事件，缺少EventBridge规则会导致pipeline无法被触发 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项B-权限问题会导致pipeline执行失败而非无反应 </div><div class="compact-content">• 选项C-开发者已成功推送代码，说明推送权限正常 </div><div class="compact-content">• 选项D-pipeline根本未启动，不存在执行失败的日志 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-EventBridge提供实时事件触发机制 </div><div class="compact-content">• 成本-EventBridge按事件数量计费，成本极低 </div><div class="compact-content">• 可扩展性-EventBridge支持多种事件源和目标的灵活配置</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: A</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-17">
            <div class="question-header">
                <div class="question-title">Question #17 ✅ ⚪ <small style="float: right;">(17/353)</small></div>
            </div>
            <div class="question-content">A company's developers use <span class="key-service">Amazon EC2</span> instances as remote workstations. The company is concerned that users can create or modify EC2 security groups to allow unrestricted inbound access. A DevOps engineer needs to develop a solution to detect when users create unrestricted security group rules. The solution must detect changes to security group rules in near real time, remove unrestricted rules, and send email notifications to the security team. The DevOps engineer has created an <span class="key-service">AWS Lambda</span> function that checks for security group ID from input, removes rules that grant unrestricted access, and sends notifications through Amazon Simple Notification Service (<span class="key-service">Amazon SNS</span>). What should the DevOps engineer do next to meet the requirements? C (100%)</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Configure the Lambda function to be invoked by the SNS topic. Create an <span class="key-service">AWS CloudTrail</span> subscription for the SNS topic. Configure a subscription filter for security group modification events.</div>                <div class="option"><strong>B.</strong> Create an Amazon EventBridge scheduled rule to invoke the Lambda function. Define a schedule pattern that runs the Lambda function every hour.</div>                <div class="option correct-answer"><strong>C.</strong> Create an Amazon EventBridge event rule that has the default event bus as the source. Define the rule's event pattern to match EC2 security group creation and modification events. Configure the rule to invoke the Lambda function.</div>                <div class="option"><strong>D.</strong> Create an Amazon EventBridge custom event bus that subscribes to events from all AWS services. Configure the Lambda function to be invoked by the custom event bus.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司的开发人员使用Amazon EC2实例作为远程工作站。公司担心用户可能创建或修改EC2 security groups以允许不受限制的入站访问。DevOps工程师需要开发一个解决方案来检测用户何时创建不受限制的security group规则。该解决方案必须近实时检测security group规则的更改，删除不受限制的规则，并向安全团队发送电子邮件通知。DevOps工程师已创建了一个AWS Lambda函数，该函数检查输入中的security group ID，删除授予不受限制访问的规则，并通过Amazon Simple Notification Service (<span class="key-service">Amazon SNS</span>)发送通知。DevOps工程师接下来应该做什么来满足要求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 配置Lambda函数由SNS主题调用。为SNS主题创建AWS CloudTrail订阅。为security group修改事件配置订阅过滤器。</div> <div class="option-analysis"><strong>B.</strong> 创建Amazon EventBridge计划规则来调用Lambda函数。定义每小时运行Lambda函数的计划模式。</div> <div class="option-analysis"><strong>C.</strong> 创建以默认事件总线为源的Amazon EventBridge事件规则。定义规则的事件模式以匹配EC2 security group创建和修改事件。配置规则调用Lambda函数。</div> <div class="option-analysis"><strong>D.</strong> 创建订阅所有AWS服务事件的Amazon EventBridge自定义事件总线。配置Lambda函数由自定义事件总线调用。<div class="section-title"><strong>核心要求:</strong></div> 近实时检测security group规则变更并自动修复 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• Amazon EventBridge-事件驱动架构，实时捕获AWS服务状态变化 </div><div class="compact-content">• <span class="key-service">AWS Lambda</span>-无服务器计算，执行自动修复逻辑 </div><div class="compact-content">• <span class="key-service">Amazon SNS</span>-消息通知服务 <div class="section-title"><strong>正确答案C:</strong></div> EventBridge默认事件总线可直接捕获EC2 security group的创建和修改事件，通过事件模式匹配实现近实时触发Lambda函数 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A-CloudTrail主要用于审计日志，不是实时事件触发机制，且架构设计错误 </div><div class="compact-content">• 选项B-定时调用无法满足近实时要求，存在检测延迟 </div><div class="compact-content">• 选项D-自定义事件总线增加不必要复杂性，默认事件总线已足够 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-EventBridge提供近实时事件处理能力 </div><div class="compact-content">• 成本-使用默认事件总线避免额外费用 </div><div class="compact-content">• 可扩展性-事件驱动架构自动扩展处理能力</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: C</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-18">
            <div class="question-header">
                <div class="question-title">Question #18 ✅ ⚪ <small style="float: right;">(18/353)</small></div>
            </div>
            <div class="question-content">A DevOps engineer is creating an <span class="key-service">AWS CloudFormation</span> template to deploy a web service. The web service will run on <span class="key-service">Amazon EC2</span> instances in a private subnet behind an Application Load Balancer (ALB). The DevOps engineer must ensure that the service can accept requests from clients that have IPv6 addresses. What should the DevOps engineer do with the CloudFormation template so that IPv6 clients can access the web service? D (100%)</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Add an IPv6 CIDR block to the <span class="key-service">VPC</span> and the private subnet for the EC2 instances. Create route table entries for the IPv6 network, use EC2 instance types that support IPv6, and assign IPv6 addresses to each EC2 instance.</div>                <div class="option correct-answer"><strong>B.</strong> Assign each EC2 instance an IPv6 Elastic IP address. Create a target group, and add the EC2 instances as targets. Create a listener on port 443 of the ALB, and associate the target group with the ALB.</div>                <div class="option"><strong>C.</strong> Replace the ALB with a Network Load Balancer (NLB). Add an IPv6 CIDR block to the <span class="key-service">VPC</span> and subnets for the NLB, and assign the NLB an IPv6 Elastic IP address.</div>                <div class="option"><strong>D.</strong> Add an IPv6 CIDR block to the <span class="key-service">VPC</span> and subnets for the AL<div class="option-analysis"><strong>B.</strong> Create a listener on port 443, and specify the dualstack IP address type on the ALB. Create a target group, and add the EC2 instances as targets. Associate the target group with the ALB.</div></div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一位DevOps工程师正在创建AWS CloudFormation模板来部署Web服务。该Web服务将在Application Load Balancer (ALB)后面的私有子网中的Amazon EC2实例上运行。DevOps工程师必须确保该服务能够接受来自具有IPv6地址的客户端的请求。DevOps工程师应该如何处理CloudFormation模板以便IPv6客户端可以访问Web服务？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 向VPC和EC2实例的私有子网添加IPv6 CIDR块。为IPv6网络创建路由表条目，使用支持IPv6的EC2实例类型，并为每个EC2实例分配IPv6地址。</div> <div class="option-analysis"><strong>B.</strong> 为每个EC2实例分配一个IPv6 Elastic IP地址。创建目标组，并将EC2实例添加为目标。在ALB的443端口上创建监听器，并将目标组与ALB关联。</div> <div class="option-analysis"><strong>C.</strong> 将ALB替换为Network Load Balancer (NLB)。向VPC和NLB的子网添加IPv6 CIDR块，并为NLB分配IPv6 Elastic IP地址。</div> <div class="option-analysis"><strong>D.</strong> 向VPC和ALB的子网添加IPv6 CIDR块。创建443端口监听器，并在ALB上指定双栈IP地址类型。创建目标组，并将EC2实例添加为目标。将目标组与ALB关联。<div class="section-title"><strong>核心要求:</strong></div> 配置ALB支持IPv6客户端访问私有子网中的Web服务 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• Application Load Balancer - 提供Layer 7负载均衡和IPv6支持 </div><div class="compact-content">• <span class="key-service">VPC</span> IPv6 CIDR - 为网络基础设施提供IPv6地址空间 </div><div class="compact-content">• CloudFormation - 基础设施即代码部署 <div class="section-title"><strong>正确答案D:</strong></div> ALB支持双栈模式(IPv4/IPv6)，只需在VPC和ALB子网配置IPv6 CIDR块，设置ALB为dualstack类型即可接受IPv6请求并转发到私有子网的IPv4后端实例 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A - 私有子网中的EC2实例无需IPv6地址，ALB可以进行IPv6到IPv4的转换 </div><div class="compact-content">• 选项B - EC2实例不能直接分配IPv6 Elastic IP，且缺少ALB的IPv6配置 </div><div class="compact-content">• 选项C - 不需要替换为NLB，ALB完全支持IPv6且更适合Web服务 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能 - ALB原生支持IPv6双栈模式，无需额外组件 </div><div class="compact-content">• 成本 - 利用现有ALB架构，无需更换负载均衡器类型 </div><div class="compact-content">• 可扩展性 - 双栈配置同时支持IPv4和IPv6客户端访问</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: B</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-19">
            <div class="question-header">
                <div class="question-title">Question #19 ✅ ⚪ <small style="float: right;">(19/353)</small></div>
            </div>
            <div class="question-content">A company uses <span class="key-service">AWS Organizations</span> and AWS Control Tower to manage all the company's AWS accounts. The company uses the Enterprise Support plan. A DevOps engineer is using Account Factory for Terraform (AFT) to provision new accounts. When new accounts are provisioned, the DevOps engineer notices that the support plan for the new accounts is set to the Basic Support plan. The DevOps engineer needs to implement a solution to provision the new accounts with the Enterprise Support plan. Which solution will meet these requirements? D (100%)</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Use an <span class="key-service">AWS Config</span> conformance pack to deploy the account-part-of-organizations <span class="key-service">AWS Config</span> rule and to automatically remediate any noncompliant accounts.</div>                <div class="option"><strong>B.</strong> Create an <span class="key-service">AWS Lambda</span> function to create a ticket for AWS Support to add the account to the Enterprise Support plan. Grant the Lambda function the support:ResolveCase permission.</div>                <div class="option"><strong>C.</strong> Add an additional value to the control_tower_parameters input to set the AWSEnterpriseSupport parameter as the organization's management account number.</div>                <div class="option correct-answer"><strong>D.</strong> Set the aft_feature_enterprise_support feature flag to True in the AFT deployment input configuration. Redeploy AFT and apply the changes.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司使用AWS Organizations和AWS Control Tower管理所有AWS账户，使用Enterprise Support计划。DevOps工程师使用Account Factory for Terraform (AFT)预置新账户时，发现新账户的支持计划被设置为Basic Support计划。需要实现解决方案让新账户预置时使用Enterprise Support计划。 <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 使用AWS Config conformance pack部署account-part-of-organizations AWS Config规则并自动修复任何不合规账户。</div> <div class="option-analysis"><strong>B.</strong> 创建AWS Lambda函数为AWS Support创建工单以将账户添加到Enterprise Support计划，授予Lambda函数support:ResolveCase权限。</div> <div class="option-analysis"><strong>C.</strong> 在control_tower_parameters输入中添加额外值，将AWSEnterpriseSupport参数设置为组织管理账户号码。</div> <div class="option-analysis"><strong>D.</strong> 在AFT部署输入配置中将aft_feature_enterprise_support功能标志设置为True，重新部署AFT并应用更改。<div class="section-title"><strong>核心要求:</strong></div> 在AFT预置新账户时自动配置Enterprise Support计划 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• AFT-Terraform版本的Account Factory，用于自动化账户预置 </div><div class="compact-content">• <span class="key-service">AWS Organizations</span>-集中管理多个AWS账户的服务 </div><div class="compact-content">• AWS Control Tower-提供多账户环境的治理和合规性 <div class="section-title"><strong>正确答案D:</strong></div> AFT提供内置的aft_feature_enterprise_support功能标志，设置为True后可在账户预置过程中自动配置Enterprise Support计划 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A-AWS Config用于合规性检查，无法直接修改支持计划配置 </div><div class="compact-content">• 选项B-手动创建工单方式效率低且support:ResolveCase权限不适用于添加支持计划 </div><div class="compact-content">• 选项C-control_tower_parameters中没有AWSEnterpriseSupport参数，且管理账户号码不是正确的配置方式 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-使用AFT内置功能标志实现自动化配置，无需额外开发 </div><div class="compact-content">• 成本-利用现有AFT功能，无需额外Lambda函数或Config规则成本 </div><div class="compact-content">• 可扩展性-功能标志配置一次后对所有新预置账户自动生效</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: D</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-20">
            <div class="question-header">
                <div class="question-title">Question #20 ✅ ⚪ <small style="float: right;">(20/353)</small></div>
            </div>
            <div class="question-content">A company's DevOps engineer uses <span class="key-service">AWS Systems Manager</span> to perform maintenance tasks during maintenance windows. The company has a few <span class="key-service">Amazon EC2</span> instances that require a restart after notifications from AWS Health. The DevOps engineer needs to implement an automated solution to remediate these notifications. The DevOps engineer creates an Amazon EventBridge rule. How should the DevOps engineer configure the EventBridge rule to meet these requirements? A (64%) C (32%) 3%</div>
            <div class="options-container">                <div class="option correct-answer"><strong>A.</strong> Configure an event source of AWS Health, a service of EC2, and an event type that indicates instance maintenance. Target a Systems Manager document to restart the EC2 instance.</div>                <div class="option"><strong>B.</strong> Configure an event source of Systems Manager and an event type that indicates a maintenance window. Target a Systems Manager document to restart the EC2 instance.</div>                <div class="option"><strong>C.</strong> Configure an event source of AWS Health, a service of EC2, and an event type that indicates instance maintenance. Target a newly created <span class="key-service">AWS Lambda</span> function that registers an automation task to restart the EC2 instance during a maintenance window.</div>                <div class="option"><strong>D.</strong> Configure an event source of EC2 and an event type that indicates instance maintenance. Target a newly created <span class="key-service">AWS Lambda</span> function that registers an automation task to restart the EC2 instance during a maintenance window.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 公司的DevOps工程师使用AWS Systems Manager在维护窗口期间执行维护任务。公司有一些Amazon EC2实例在收到AWS Health通知后需要重启。DevOps工程师需要实现自动化解决方案来修复这些通知。工程师创建了Amazon EventBridge规则。应该如何配置EventBridge规则来满足这些要求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 配置事件源为AWS Health，服务为EC2，事件类型指示实例维护。目标为Systems Manager文档来重启EC2实例。</div> <div class="option-analysis"><strong>B.</strong> 配置事件源为Systems Manager，事件类型指示维护窗口。目标为Systems Manager文档来重启EC2实例。</div> <div class="option-analysis"><strong>C.</strong> 配置事件源为AWS Health，服务为EC2，事件类型指示实例维护。目标为新创建的AWS Lambda函数，该函数注册自动化任务在维护窗口期间重启EC2实例。</div> <div class="option-analysis"><strong>D.</strong> 配置事件源为EC2，事件类型指示实例维护。目标为新创建的AWS Lambda函数，该函数注册自动化任务在维护窗口期间重启EC2实例。<div class="section-title"><strong>核心要求:</strong></div> 基于AWS Health通知自动重启EC2实例 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• AWS Health - 提供AWS资源健康状态通知和维护事件 </div><div class="compact-content">• EventBridge - 事件驱动架构，监听AWS Health事件并触发自动化响应 </div><div class="compact-content">• Systems Manager - 执行EC2实例重启等运维操作 <div class="section-title"><strong>正确答案A:</strong></div> AWS Health发出维护通知时，EventBridge监听该事件并直接调用Systems Manager文档执行EC2重启，实现最简单直接的自动化修复流程 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项B - 事件源错误，应监听AWS Health而非Systems Manager事件 </div><div class="compact-content">• 选项C - 架构过度复杂，无需Lambda中间层处理简单的重启操作 </div><div class="compact-content">• 选项D - 事件源错误，EC2本身不发出维护通知事件 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能 - 直接调用Systems Manager响应最快，无额外延迟 </div><div class="compact-content">• 成本 - 避免不必要的Lambda函数调用，降低运行成本 </div><div class="compact-content">• 可扩展性 - EventBridge+Systems Manager原生集成，支持大规模实例管理</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: A</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-21">
            <div class="question-header">
                <div class="question-title">Question #21 ✅ ⚪ <small style="float: right;">(21/353)</small></div>
            </div>
            <div class="question-content">A company has containerized all of its in-house quality control applications. The company is running Jenkins on <span class="key-service">Amazon EC2</span> instances, which require patching and upgrading. The compliance officer has requested a DevOps engineer begin encrypting build artifacts since they contain company intellectual property. What should the DevOps engineer do to accomplish this in the MOST maintainable manner? D (83%) B (17%)</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Automate patching and upgrading using <span class="key-service">AWS Systems Manager</span> on EC2 instances and encrypt Amazon EBS volumes by default.</div>                <div class="option"><strong>B.</strong> Deploy Jenkins to an <span class="key-service">Amazon ECS</span> cluster and copy build artifacts to an <span class="key-service">Amazon S3</span> bucket with default encryption enabled.</div>                <div class="option"><strong>C.</strong> Leverage <span class="key-service">AWS CodePipeline</span> with a build action and encrypt the artifacts using AWS Secrets Manager.</div>                <div class="option correct-answer"><strong>D.</strong> Use <span class="key-service">AWS CodeBuild</span> with artifact encryption to replace the Jenkins instance running on EC2 instances.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司已将所有内部质量控制应用程序容器化。公司在Amazon EC2实例上运行Jenkins，需要打补丁和升级。合规官要求DevOps工程师开始加密构建工件，因为它们包含公司知识产权。DevOps工程师应该如何以最可维护的方式完成此任务？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 在EC2实例上使用AWS Systems Manager自动化打补丁和升级，并默认加密Amazon EBS卷</div> <div class="option-analysis"><strong>B.</strong> 将Jenkins部署到Amazon ECS集群，并将构建工件复制到启用默认加密的Amazon S3存储桶</div> <div class="option-analysis"><strong>C.</strong> 利用AWS CodePipeline的构建操作，并使用AWS Secrets Manager加密工件</div> <div class="option-analysis"><strong>D.</strong> 使用带有工件加密功能的AWS CodeBuild替换运行在EC2实例上的Jenkins实例<div class="section-title"><strong>核心要求:</strong></div> 以最可维护的方式实现构建工件加密并解决Jenkins维护问题 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• <span class="key-service">AWS CodeBuild</span>-完全托管的构建服务，内置工件加密功能 </div><div class="compact-content">• <span class="key-service">Amazon S3</span>-对象存储服务，支持默认加密 </div><div class="compact-content">• <span class="key-service">AWS Systems Manager</span>-系统管理和自动化服务 <div class="section-title"><strong>正确答案D:</strong></div> AWS CodeBuild是完全托管的构建服务，消除了EC2实例维护负担，内置工件加密功能直接满足合规要求，可维护性最高 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A-仍需维护EC2实例，EBS加密不能加密构建工件本身 </div><div class="compact-content">• 选项B-仍需管理ECS集群和Jenkins，增加运维复杂度 </div><div class="compact-content">• 选项C-AWS Secrets Manager用于密钥管理而非工件加密，概念混淆 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-CodeBuild提供弹性扩展的构建能力 </div><div class="compact-content">• 成本-无需管理基础设施，按使用量付费 </div><div class="compact-content">• 可扩展性-完全托管服务，自动处理扩展和维护</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: D</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-22">
            <div class="question-header">
                <div class="question-title">Question #22 ✅ ⚪ <small style="float: right;">(22/353)</small></div>
            </div>
            <div class="question-content">An IT team has built an <span class="key-service">AWS CloudFormation</span> template so others in the company can quickly and reliably deploy and terminate an application. The template creates an <span class="key-service">Amazon EC2</span> instance with a user data script to install the application and an <span class="key-service">Amazon S3</span> bucket that the application uses to serve static webpages while it is running. All resources should be removed when the CloudFormation stack is deleted. However, the team observes that CloudFormation reports an error during stack deletion, and the S3 bucket created by the stack is not deleted. How can the team resolve the error in the MOST efficient manner to ensure that all resources are deleted without errors? B (100%)</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Add a DeletionPolicy attribute to the S3 bucket resource, with the value Delete forcing the bucket to be removed when the stack is deleted.</div>                <div class="option correct-answer"><strong>B.</strong> Add a custom resource with an <span class="key-service">AWS Lambda</span> function with the DependsOn attribute specifying the S3 bucket, and an IAM role. Write the Lambda function to delete all objects from the bucket when RequestType is Delete. Most Voted</div>                <div class="option"><strong>C.</strong> Identify the resource that was not deleted. Manually empty the S3 bucket and then delete it.</div>                <div class="option"><strong>D.</strong> Replace the EC2 and S3 bucket resources with a single AWS OpsWorks Stacks resource. Define a custom recipe for the stack to create and delete the EC2 instance and the S3 bucket.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> IT团队构建了AWS CloudFormation模板供公司其他人快速可靠地部署和终止应用程序。模板创建带用户数据脚本的Amazon EC2实例来安装应用程序，以及应用程序用于提供静态网页的Amazon S3存储桶。删除CloudFormation堆栈时应移除所有资源。但团队观察到CloudFormation在堆栈删除期间报告错误，堆栈创建的S3存储桶未被删除。团队如何以最高效的方式解决错误，确保所有资源都能无错误删除？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 向S3存储桶资源添加DeletionPolicy属性，值为Delete，强制在删除堆栈时移除存储桶。</div> <div class="option-analysis"><strong>B.</strong> 添加带AWS Lambda函数的自定义资源，使用DependsOn属性指定S3存储桶和IAM角色。编写Lambda函数在RequestType为Delete时删除存储桶中的所有对象。</div> <div class="option-analysis"><strong>C.</strong> 识别未删除的资源。手动清空S3存储桶然后删除它。</div> <div class="option-analysis"><strong>D.</strong> 用单个AWS OpsWorks Stacks资源替换EC2和S3存储桶资源。为堆栈定义自定义配方来创建和删除EC2实例和S3存储桶。<div class="section-title"><strong>核心要求:</strong></div> 解决CloudFormation删除非空S3存储桶时的错误问题 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• CloudFormation-基础设施即代码服务，管理AWS资源的生命周期 </div><div class="compact-content">• S3-对象存储服务，非空存储桶无法直接删除 </div><div class="compact-content">• Lambda-无服务器计算服务，可执行自定义删除逻辑 <div class="section-title"><strong>正确答案B:</strong></div> 使用Lambda自定义资源在堆栈删除时自动清空S3存储桶内容，然后CloudFormation才能成功删除存储桶，实现完全自动化的清理流程 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A-DeletionPolicy的Delete值无法解决非空存储桶删除失败的根本问题 </div><div class="compact-content">• 选项C-手动操作不符合自动化要求，且不是最高效的解决方案 </div><div class="compact-content">• 选项D-OpsWorks过于复杂，不能解决S3存储桶删除的核心问题 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-自动化执行，无需人工干预 </div><div class="compact-content">• 成本-Lambda按需计费，成本最低 </div><div class="compact-content">• 可扩展性-可重复使用的模板化解决方案</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: B</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-23">
            <div class="question-header">
                <div class="question-title">Question #23 ✅ 📝 <small style="float: right;">(23/353)</small></div>
            </div>
            <div class="question-content">A company has an <span class="key-service">AWS CodePipeline</span> pipeline that is configured with an <span class="key-service">Amazon S3</span> bucket in the eu-west-1 Region. The pipeline deploys an <span class="key-service">AWS Lambda</span> application to the same Region. The pipeline consists of an <span class="key-service">AWS CodeBuild</span> project build action and an <span class="key-service">AWS CloudFormation</span> deploy action. The CodeBuild project uses the <span class="key-service">aws cloudformation</span> package AWS CLI command to build an artifact that contains the Lambda function code's .zip file and the CloudFormation template. The CloudFormation deploy action references the CloudFormation template from the output artifact of the CodeBuild project's build action. The company wants to also deploy the Lambda application to the us-east-1 Region by using the pipeline in eu-west-1. A DevOps engineer has already updated the CodeBuild project to use the <span class="key-service">aws cloudformation</span> package command to produce an additional output artifact for us-east- 1. Which combination of additional steps should the DevOps engineer take to meet these requirements? (Choose two.) CE (68%) AB (17%) Other</div>
            <div class="options-container">                <div class="option correct-answer"><strong>A.</strong> Modify the CloudFormation template to include a parameter for the Lambda function code's zip file location. Create a new CloudFormation deploy action for us-east-1 in the pipeline. Configure the new deploy action to pass in the us-east-1 artifact location as a parameter override. Most Voted</div>                <div class="option correct-answer"><strong>B.</strong> Create a new CloudFormation deploy action for us-east-1 in the pipeline. Configure the new deploy action to use the CloudFormation template from the us-east-1 output artifact. Most Voted</div>                <div class="option"><strong>C.</strong> Create an S3 bucket in us-east-1. Configure the S3 bucket policy to allow CodePipeline to have read and write access.</div>                <div class="option"><strong>D.</strong> Create an S3 bucket in us-east-1. Configure S3 Cross-Region Replication (CRR) from the S3 bucket in eu-west-1 to the S3 bucket in us-east-1.</div>                <div class="option"><strong>E.</strong> Modify the pipeline to include the S3 bucket for us-east-1 as an artifact store. Create a new CloudFormation deploy action for us-east-1 in the pipeline. Configure the new deploy action to use the CloudFormation template from the us-east-1 output artifact.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司有一个配置了eu-west-1区域Amazon S3存储桶的AWS CodePipeline管道。该管道将AWS Lambda应用程序部署到同一区域。管道包含AWS CodeBuild项目构建操作和AWS CloudFormation部署操作。CodeBuild项目使用aws cloudformation package AWS CLI命令构建包含Lambda函数代码.zip文件和CloudFormation模板的构件。CloudFormation部署操作引用CodeBuild项目构建操作输出构件中的CloudFormation模板。公司希望使用eu-west-1中的管道将Lambda应用程序也部署到us-east-1区域。DevOps工程师已更新CodeBuild项目以使用aws cloudformation package命令为us-east-1生成额外的输出构件。DevOps工程师应采取哪些额外步骤组合来满足这些要求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 修改CloudFormation模板以包含Lambda函数代码zip文件位置的参数。在管道中为us-east-1创建新的CloudFormation部署操作。配置新的部署操作以将us-east-1构件位置作为参数覆盖传入。</div> <div class="option-analysis"><strong>B.</strong> 在管道中为us-east-1创建新的CloudFormation部署操作。配置新的部署操作以使用来自us-east-1输出构件的CloudFormation模板。</div> <div class="option-analysis"><strong>C.</strong> 在us-east-1中创建S3存储桶。配置S3存储桶策略以允许CodePipeline具有读写访问权限。</div> <div class="option-analysis"><strong>D.</strong> 在us-east-1中创建S3存储桶。配置从eu-west-1中的S3存储桶到us-east-1中的S3存储桶的S3跨区域复制(CRR)。</div> <div class="option-analysis"><strong>E.</strong> 修改管道以包含us-east-1的S3存储桶作为构件存储。在管道中为us-east-1创建新的CloudFormation部署操作。配置新的部署操作以使用来自us-east-1输出构件的CloudFormation模板。<div class="section-title"><strong>核心要求:</strong></div> 在现有eu-west-1 CodePipeline基础上实现跨区域Lambda应用部署到us-east-1 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• <span class="key-service">AWS CodePipeline</span>-跨区域CI/CD管道编排 </div><div class="compact-content">• <span class="key-service">AWS CloudFormation</span>-基础设施即代码部署 </div><div class="compact-content">• <span class="key-service">AWS CodeBuild</span>-构建和打包Lambda代码 <div class="section-title"><strong>正确答案AB:</strong></div> A选项通过参数化CloudFormation模板实现灵活的构件位置配置，B选项创建专用的us-east-1部署操作使用对应区域的输出构件，两者结合实现跨区域部署 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项C-仅创建S3存储桶不足以实现跨区域部署，缺少构件存储配置 </div><div class="compact-content">• 选项D-S3跨区域复制不是CodePipeline跨区域部署的正确方法 </div><div class="compact-content">• 选项E-虽然提到构件存储但在已有us-east-1输出构件情况下不是必需的 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-利用现有构件输出避免重复构建 </div><div class="compact-content">• 成本-最小化额外基础设施需求 </div><div class="compact-content">• 可扩展性-参数化模板支持多区域扩展</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: AB (A、B)</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-24">
            <div class="question-header">
                <div class="question-title">Question #24 ✅ ⚪ <small style="float: right;">(24/353)</small></div>
            </div>
            <div class="question-content">A company runs an application on one <span class="key-service">Amazon EC2</span> instance. Application metadata is stored in <span class="key-service">Amazon S3</span> and must be retrieved if the instance is restarted. The instance must restart or relaunch automatically if the instance becomes unresponsive. Which solution will meet these requirements? B (96%) 4%</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Create an <span class="key-service">Amazon CloudWatch</span> alarm for the StatusCheckFailed metric. Use the recover action to stop and start the instance. Use an S3 event notification to push the metadata to the instance when the instance is back up and running.</div>                <div class="option correct-answer"><strong>B.</strong> Configure AWS OpsWorks, and use the auto healing feature to stop and start the instance. Use a lifecycle event in OpsWorks to pull the metadata from <span class="key-service">Amazon S3</span> and update it on the instance.</div>                <div class="option"><strong>C.</strong> Use EC2 Auto Recovery to automatically stop and start the instance in case of a failure. Use an S3 event notification to push the metadata to the instance when the instance is back up and running.</div>                <div class="option"><strong>D.</strong> Use <span class="key-service">AWS CloudFormation</span> to create an EC2 instance that includes the UserData property for the EC2 resource. Add a command in UserData to retrieve the application metadata from <span class="key-service">Amazon S3</span>.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司在一个Amazon EC2实例上运行应用程序。应用程序元数据存储在Amazon S3中，如果实例重启必须检索这些数据。如果实例无响应，实例必须自动重启或重新启动。哪个解决方案满足这些要求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 为StatusCheckFailed指标创建Amazon CloudWatch告警。使用恢复操作停止和启动实例。当实例重新运行时，使用S3事件通知将元数据推送到实例。</div> <div class="option-analysis"><strong>B.</strong> 配置AWS OpsWorks，使用自动修复功能停止和启动实例。在OpsWorks中使用生命周期事件从Amazon S3拉取元数据并在实例上更新。</div> <div class="option-analysis"><strong>C.</strong> 使用EC2 Auto Recovery在故障情况下自动停止和启动实例。当实例重新运行时，使用S3事件通知将元数据推送到实例。</div> <div class="option-analysis"><strong>D.</strong> 使用AWS CloudFormation创建包含EC2资源UserData属性的EC2实例。在UserData中添加命令从Amazon S3检索应用程序元数据。<div class="section-title"><strong>核心要求:</strong></div> 实现EC2实例自动故障恢复和启动时自动获取S3元数据 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• AWS OpsWorks-提供应用程序生命周期管理和自动修复功能 </div><div class="compact-content">• <span class="key-service">Amazon S3</span>-存储应用程序元数据 </div><div class="compact-content">• CloudWatch-监控实例状态指标 <div class="section-title"><strong>正确答案B:</strong></div> OpsWorks的auto healing功能可自动检测和恢复故障实例，lifecycle event机制确保实例启动时主动从S3拉取元数据，形成完整的自动化解决方案 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A-S3事件通知无法直接推送数据到EC2实例，需要额外的触发机制 </div><div class="compact-content">• 选项C-EC2 Auto Recovery主要用于硬件故障，且S3事件通知推送方式不可行 </div><div class="compact-content">• 选项D-CloudFormation只负责初始部署，无法提供持续的故障检测和自动恢复能力 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-OpsWorks提供完整的应用程序级监控和快速故障恢复 </div><div class="compact-content">• 成本-利用现有AWS服务集成，无需额外的中间件或Lambda函数 </div><div class="compact-content">• 可扩展性-OpsWorks支持多实例管理和复杂应用程序栈的自动化运维</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: B</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-25">
            <div class="question-header">
                <div class="question-title">Question #25 ✅ ⚪ <small style="float: right;">(25/353)</small></div>
            </div>
            <div class="question-content">A company has multiple AWS accounts. The company uses <span class="key-service">AWS IAM</span> Identity Center (AWS Single Sign-On) that is integrated with AWS Toolkit for Microsoft Azure DevOps. The attributes for access control feature is enabled in IAM Identity Center. The attribute mapping list contains two entries. The department key is mapped to ${path:enterprise.department}. The costCenter key is mapped to ${path:enterprise.costCenter}. All existing <span class="key-service">Amazon EC2</span> instances have a department tag that corresponds to three company departments (d1, d2, d3). A DevOps engineer must create policies based on the matching attributes. The policies must minimize administrative effort and must grant each Azure AD user access to only the EC2 instances that are tagged with the user's respective department name. Which condition key should the DevOps engineer include in the custom permissions policies to meet these requirements? C (100%)</div>
            <div class="options-container">            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司有多个AWS账户，使用与Microsoft Azure DevOps的AWS Toolkit集成的AWS IAM Identity Center，启用了访问控制属性功能，属性映射列表包含两个条目：department键映射到${path:enterprise.department}，costCenter键映射到${path:enterprise.costCenter}，所有现有EC2实例都有对应三个公司部门(d1,d2,d3)的department标签，DevOps工程师必须基于匹配属性创建策略，策略必须最小化管理工作量并仅授予每个Azure AD用户访问标记有用户各自部门名称的EC2实例的权限，DevOps工程师应在自定义权限策略中包含哪个条件键来满足这些要求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> [选项A内容未提供]</div> <div class="option-analysis"><strong>B.</strong> [选项B内容未提供]</div> <div class="option-analysis"><strong>C.</strong> [选项C内容未提供]</div> <div class="option-analysis"><strong>D.</strong> [选项D内容未提供]<div class="section-title"><strong>核心要求:</strong></div> 基于IAM Identity Center属性映射实现部门级别的EC2实例访问控制 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• <span class="key-service">AWS IAM</span> Identity Center - 提供单点登录和属性映射功能 </div><div class="compact-content">• EC2 - 需要基于标签进行访问控制的目标资源 <div class="section-title"><strong>正确答案C:</strong></div> 使用aws:PrincipalTag条件键结合department属性，通过IAM Identity Center的属性映射将Azure AD用户的部门信息作为会话标签传递，实现基于用户部门属性匹配EC2实例department标签的访问控制 <div class="section-title"><strong>错误选项:</strong></div> 其他选项可能使用了不正确的条件键，无法有效利用IAM Identity Center的属性映射功能或无法实现基于用户属性的动态访问控制 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 功能性-必须支持属性映射和动态访问控制 </div><div class="compact-content">• 管理效率-最小化策略维护工作量 </div><div class="compact-content">• 安全性-确保用户只能访问对应部门的资源</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: C</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-26">
            <div class="question-header">
                <div class="question-title">Question #26 ✅ ⚪ <small style="float: right;">(26/353)</small></div>
            </div>
            <div class="question-content">A company hosts a security auditing application in an AWS account. The auditing application uses an IAM role to access other AWS accounts. All the accounts are in the same organization in <span class="key-service">AWS Organizations</span>. A recent security audit revealed that users in the audited AWS accounts could modify or delete the auditing application's IAM role. The company needs to prevent any modification to the auditing application's IAM role by any entity other than a trusted administrator IAM role. Which solution will meet these requirements? A (91%) 9%</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Create an <span class="key-service">SCP</span> that includes a Deny statement for changes to the auditing application's IAM role. Include a condition that allows the trusted administrator IAM role to make changes. Attach the <span class="key-service">SCP</span> to the root of the organization. Most Voted</div>                <div class="option"><strong>B.</strong> Create an <span class="key-service">SCP</span> that includes an Allow statement for changes to the auditing application's IAM role by the trusted administrator IAM role. Include a Deny statement for changes by all other IAM principals. Attach the <span class="key-service">SCP</span> to the IAM service in each AWS account where the auditing application has an IAM role.</div>                <div class="option correct-answer"><strong>C.</strong> Create an IAM permissions boundary that includes a Deny statement for changes to the auditing application's IAM role. Include a condition that allows the trusted administrator IAM role to make changes. Attach the permissions boundary to the audited AWS accounts.</div>                <div class="option"><strong>D.</strong> Create an IAM permissions boundary that includes a Deny statement for changes to the auditing application's IAM role. Include a condition that allows the trusted administrator IAM role to make changes. Attach the permissions boundary to the auditing application's IAM role in the AWS accounts.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司在AWS账户中托管安全审计应用程序。该审计应用程序使用IAM角色访问其他AWS账户。所有账户都在AWS Organizations的同一组织中。最近的安全审计显示，被审计AWS账户中的用户可以修改或删除审计应用程序的IAM角色。公司需要防止除受信任管理员IAM角色之外的任何实体修改审计应用程序的IAM角色。 <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 创建包含拒绝更改审计应用程序IAM角色声明的SCP，包含允许受信任管理员IAM角色进行更改的条件，将SCP附加到组织根部</div> <div class="option-analysis"><strong>B.</strong> 创建包含允许受信任管理员IAM角色更改审计应用程序IAM角色声明的SCP，包含拒绝所有其他IAM主体更改的声明，将SCP附加到每个有审计应用程序IAM角色的AWS账户的IAM服务</div> <div class="option-analysis"><strong>C.</strong> 创建包含拒绝更改审计应用程序IAM角色声明的IAM权限边界，包含允许受信任管理员IAM角色进行更改的条件，将权限边界附加到被审计的AWS账户</div> <div class="option-analysis"><strong>D.</strong> 创建包含拒绝更改审计应用程序IAM角色声明的IAM权限边界，包含允许受信任管理员IAM角色进行更改的条件，将权限边界附加到审计应用程序的IAM角色<div class="section-title"><strong>核心要求:</strong></div> 防止除受信任管理员外的任何实体修改跨账户审计应用程序的IAM角色 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• <span class="key-service">SCP</span>-组织级策略控制，限制账户内所有操作 </div><div class="compact-content">• IAM权限边界-限制IAM实体的最大权限范围 <div class="section-title"><strong>正确答案C:</strong></div> IAM权限边界在账户级别限制所有用户和角色的最大权限，通过拒绝IAM角色修改操作并设置受信任管理员例外条件，有效保护审计角色 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A-SCP附加到组织根部会影响所有账户，过于宽泛且可能影响正常IAM管理 </div><div class="compact-content">• 选项B-SCP不能附加到特定服务，只能附加到组织单元或账户 </div><div class="compact-content">• 选项D-权限边界附加到被保护的角色本身无法防止角色被删除或修改 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-权限边界提供细粒度控制，不影响其他IAM操作 </div><div class="compact-content">• 成本-使用现有IAM功能，无额外成本 </div><div class="compact-content">• 可扩展性-可灵活应用到多个被审计账户，易于管理</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: C</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-27">
            <div class="question-header">
                <div class="question-title">Question #27 ✅ ⚪ <small style="float: right;">(27/353)</small></div>
            </div>
            <div class="question-content">A company has an on-premises application that is written in Go. A DevOps engineer must move the application to AWS. The company's development team wants to enable blue/green deployments and perform A/B testing. Which solution will meet these requirements? D (100%)</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Deploy the application on an <span class="key-service">Amazon EC2</span> instance, and create an AMI of the instance. Use the AMI to create an automatic scaling launch configuration that is used in an Auto Scaling group. Use Elastic Load Balancing to distribute traffic. When changes are made to the application, a new AMI will be created, which will initiate an EC2 instance refresh.</div>                <div class="option"><strong>B.</strong> Use Amazon Lightsail to deploy the application. Store the application in a zipped format in an <span class="key-service">Amazon S3</span> bucket. Use this zipped version to deploy new versions of the application to Lightsail. Use Lightsail deployment options to manage the deployment.</div>                <div class="option"><strong>C.</strong> Use AWS CodeArtifact to store the application code. Use <span class="key-service">AWS CodeDeploy</span> to deploy the application to a fleet of <span class="key-service">Amazon EC2</span> instances. Use Elastic Load Balancing to distribute the traffic to the EC2 instances. When making changes to the application, upload a new version to CodeArtifact and create a new CodeDeploy deployment.</div>                <div class="option correct-answer"><strong>D.</strong> Use AWS Elastic Beanstalk to host the application. Store a zipped version of the application in <span class="key-service">Amazon S3</span>. Use that location to deploy new versions of the application. Use Elastic Beanstalk to manage the deployment options.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司有一个用Go编写的本地应用程序。DevOps工程师必须将应用程序迁移到AWS。公司开发团队希望启用蓝/绿部署并执行A/B测试。哪种解决方案能满足这些要求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 在Amazon EC2实例上部署应用程序，并创建实例的AMI。使用AMI创建Auto Scaling组中使用的自动扩展启动配置。使用Elastic Load Balancing分发流量。当应用程序发生更改时，将创建新的AMI，这将启动EC2实例刷新。</div> <div class="option-analysis"><strong>B.</strong> 使用Amazon Lightsail部署应用程序。将应用程序以压缩格式存储在Amazon S3存储桶中。使用此压缩版本将新版本的应用程序部署到Lightsail。使用Lightsail部署选项管理部署。</div> <div class="option-analysis"><strong>C.</strong> 使用AWS CodeArtifact存储应用程序代码。使用AWS CodeDeploy将应用程序部署到Amazon EC2实例集群。使用Elastic Load Balancing将流量分发到EC2实例。当对应用程序进行更改时，将新版本上传到CodeArtifact并创建新的CodeDeploy部署。</div> <div class="option-analysis"><strong>D.</strong> 使用AWS Elastic Beanstalk托管应用程序。将应用程序的压缩版本存储在Amazon S3中。使用该位置部署应用程序的新版本。使用Elastic Beanstalk管理部署选项。<div class="section-title"><strong>核心要求:</strong></div> 将Go应用程序迁移到AWS并支持蓝/绿部署和A/B测试 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• Elastic Beanstalk-提供内置蓝/绿部署和流量分割功能 </div><div class="compact-content">• S3-存储应用程序版本包 <div class="section-title"><strong>正确答案D:</strong></div> Elastic Beanstalk原生支持蓝/绿部署、滚动部署、不可变部署等多种部署策略，并提供流量分割功能进行A/B测试，完全满足要求 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A-EC2实例刷新不提供真正的蓝/绿部署，缺乏A/B测试的流量控制机制 </div><div class="compact-content">• 选项B-Lightsail是简化服务，不支持高级部署策略如蓝/绿部署和A/B测试 </div><div class="compact-content">• 选项C-CodeDeploy虽然支持蓝/绿部署，但需要额外配置，且CodeArtifact主要用于包管理而非应用程序存储 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-Elastic Beanstalk提供自动扩展和负载均衡 </div><div class="compact-content">• 成本-托管服务减少运维成本，按使用量付费 </div><div class="compact-content">• 可扩展性-支持多种部署策略和环境管理</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: D</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-28">
            <div class="question-header">
                <div class="question-title">Question #28 ✅ ⚪ <small style="float: right;">(28/353)</small></div>
            </div>
            <div class="question-content">A developer is maintaining a fleet of 50 <span class="key-service">Amazon EC2</span> Linux servers. The servers are part of an <span class="key-service">Amazon EC2</span> Auto Scaling group, and also use Elastic Load Balancing for load balancing. Occasionally, some application servers are being terminated after failing ELB HTTP health checks. The developer would like to perform a root cause analysis on the issue, but before being able to access application logs, the server is terminated. How can log collection be automated? D (88%) 12%</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Use Auto Scaling lifecycle hooks to put instances in a Pending:Wait state. Create an <span class="key-service">Amazon CloudWatch</span> alarm for EC2 Instance Terminate Successful and trigger an <span class="key-service">AWS Lambda</span> function that invokes an SSM Run Command script to collect logs, push them to <span class="key-service">Amazon S3</span>, and complete the lifecycle action once logs are collected.</div>                <div class="option"><strong>B.</strong> Use Auto Scaling lifecycle hooks to put instances in a Terminating:Wait state. Create an <span class="key-service">AWS Config</span> rule for EC2 Instance-terminate Lifecycle Action and trigger a step function that invokes a script to collect logs, push them to <span class="key-service">Amazon S3</span>, and complete the lifecycle action once logs are collected.</div>                <div class="option"><strong>C.</strong> Use Auto Scaling lifecycle hooks to put instances in a Terminating:Wait state. Create an <span class="key-service">Amazon CloudWatch</span> subscription filter for EC2 Instance Terminate Successful and trigger a CloudWatch agent that invokes a script to collect logs, push them to <span class="key-service">Amazon S3</span>, and complete the lifecycle action once logs are collected.</div>                <div class="option correct-answer"><strong>D.</strong> Use Auto Scaling lifecycle hooks to put instances in a Terminating:Wait state. Create an Amazon EventBridge rule for EC2 Instance-terminate Lifecycle Action and trigger an <span class="key-service">AWS Lambda</span> function that invokes an SSM Run Command script to collect logs, push them to <span class="key-service">Amazon S3</span>, and complete the lifecycle action once logs are collected.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 开发人员维护着50台Amazon EC2 Linux服务器组成的fleet。这些服务器是Amazon EC2 Auto Scaling组的一部分，并使用Elastic Load Balancing进行负载均衡。偶尔，一些应用服务器在ELB HTTP健康检查失败后被终止。开发人员希望对此问题进行根因分析，但在能够访问应用日志之前，服务器就被终止了。如何自动化日志收集？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 使用Auto Scaling生命周期钩子将实例置于Pending:Wait状态。为EC2 Instance Terminate Successful创建Amazon CloudWatch告警，触发AWS Lambda函数调用SSM Run Command脚本收集日志，推送到Amazon S3，日志收集完成后完成生命周期操作。</div> <div class="option-analysis"><strong>B.</strong> 使用Auto Scaling生命周期钩子将实例置于Terminating:Wait状态。为EC2 Instance-terminate Lifecycle Action创建AWS Config规则，触发step function调用脚本收集日志，推送到Amazon S3，日志收集完成后完成生命周期操作。</div> <div class="option-analysis"><strong>C.</strong> 使用Auto Scaling生命周期钩子将实例置于Terminating:Wait状态。为EC2 Instance Terminate Successful创建Amazon CloudWatch订阅过滤器，触发CloudWatch agent调用脚本收集日志，推送到Amazon S3，日志收集完成后完成生命周期操作。</div> <div class="option-analysis"><strong>D.</strong> 使用Auto Scaling生命周期钩子将实例置于Terminating:Wait状态。为EC2 Instance-terminate Lifecycle Action创建Amazon EventBridge规则，触发AWS Lambda函数调用SSM Run Command脚本收集日志，推送到Amazon S3，日志收集完成后完成生命周期操作。<div class="section-title"><strong>核心要求:</strong></div> 在EC2实例终止前自动收集应用日志进行根因分析 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• Auto Scaling lifecycle hooks-在实例终止前暂停以执行自定义操作 </div><div class="compact-content">• EventBridge-捕获生命周期事件并触发自动化响应 </div><div class="compact-content">• Lambda+SSM Run Command-在目标实例上执行日志收集脚本 <div class="section-title"><strong>正确答案D:</strong></div> 使用Terminating:Wait状态暂停终止过程，EventBridge捕获生命周期事件触发Lambda，通过SSM在实例上执行日志收集，完整的事件驱动自动化流程 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A-使用错误的Pending:Wait状态，应该是Terminating:Wait；CloudWatch告警不是正确的事件触发机制 </div><div class="compact-content">• 选项B-AWS Config用于合规性检查而非事件触发；step function增加不必要复杂性 </div><div class="compact-content">• 选项C-CloudWatch订阅过滤器用于日志流处理；CloudWatch agent无法直接触发脚本执行 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-EventBridge提供实时事件响应，Lambda快速执行 </div><div class="compact-content">• 成本-使用托管服务按需付费，无需额外基础设施 </div><div class="compact-content">• 可扩展性-事件驱动架构自动处理所有实例终止事件</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: D</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-29">
            <div class="question-header">
                <div class="question-title">Question #29 ✅ 📝 <small style="float: right;">(29/353)</small></div>
            </div>
            <div class="question-content">A company has an organization in <span class="key-service">AWS Organizations</span>. The organization includes workload accounts that contain enterprise applications. The company centrally manages users from an operations account. No users can be created in the workload accounts. The company recently added an operations team and must provide the operations team members with administrator access to each workload account. Which combination of actions will provide this access? (Choose three.) BDE (88%) 8%</div>
            <div class="options-container">                <div class="option correct-answer"><strong>A.</strong> Create a SysAdmin role in the operations account. Attach the AdministratorAccess policy to the role. Modify the trust relationship to allow the sts:AssumeRole action from the workload accounts.</div>                <div class="option correct-answer"><strong>B.</strong> Create a SysAdmin role in each workload account. Attach the AdministratorAccess policy to the role. Modify the trust relationship to allow the sts:AssumeRole action from the operations account.</div>                <div class="option"><strong>C.</strong> Create an Amazon Cognito identity pool in the operations account. Attach the SysAdmin role as an authenticated role.</div>                <div class="option"><strong>D.</strong> In the operations account, create an IAM user for each operations team member.</div>                <div class="option correct-answer"><strong>E.</strong> In the operations account, create an IAM user group that is named SysAdmins. Add an IAM policy that allows the sts:AssumeRole action for the SysAdmin role in each workload account. Add all operations team members to the group. F. Create an Amazon Cognito user pool in the operations account. Create an Amazon Cognito user for each operations team member.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司在AWS Organizations中有一个组织，包含企业应用的工作负载账户。公司从运营账户集中管理用户，工作负载账户中不能创建用户。公司最近新增了运营团队，必须为运营团队成员提供对每个工作负载账户的管理员访问权限。哪些操作组合能提供此访问权限？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 在运营账户中创建SysAdmin角色，附加AdministratorAccess策略，修改信任关系允许来自工作负载账户的sts:AssumeRole操作</div> <div class="option-analysis"><strong>B.</strong> 在每个工作负载账户中创建SysAdmin角色，附加AdministratorAccess策略，修改信任关系允许来自运营账户的sts:AssumeRole操作</div> <div class="option-analysis"><strong>C.</strong> 在运营账户中创建Amazon Cognito身份池，将SysAdmin角色附加为已认证角色</div> <div class="option-analysis"><strong>D.</strong> 在运营账户中为每个运营团队成员创建IAM用户</div> <div class="option-analysis"><strong>E.</strong> 在运营账户中创建名为SysAdmins的IAM用户组，添加允许对每个工作负载账户中SysAdmin角色执行sts:AssumeRole操作的IAM策略，将所有运营团队成员添加到组中 F. 在运营账户中创建Amazon Cognito用户池，为每个运营团队成员创建Amazon Cognito用户<div class="section-title"><strong>核心要求:</strong></div> 实现跨账户管理员访问的角色假设机制 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• IAM Cross-Account Role - 实现跨账户访问控制 </div><div class="compact-content">• AWS STS AssumeRole - 提供临时凭证进行角色切换 <div class="section-title"><strong>正确答案ABE:</strong></div> 建立完整的跨账户角色假设链：B在目标账户创建可被假设的角色，E在源账户创建有权限假设角色的用户组，A描述了信任关系的反向配置但在某些场景下也是必要的配置组件 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项C - Cognito身份池用于联合身份访问，不适用于企业内部跨账户管理场景 </div><div class="compact-content">• 选项F - Cognito用户池用于应用程序用户认证，不是企业IAM管理的最佳实践 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 安全性 - 使用临时凭证和最小权限原则 </div><div class="compact-content">• 管理性 - 集中用户管理，分布式权限控制 </div><div class="compact-content">• 可扩展性 - 支持多账户环境的统一访问模式</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: ABE (A、B、E)</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-30">
            <div class="question-header">
                <div class="question-title">Question #30 ✅ ⚪ <small style="float: right;">(30/353)</small></div>
            </div>
            <div class="question-content">A company has multiple accounts in an organization in <span class="key-service">AWS Organizations</span>. The company's SecOps team needs to receive an Amazon Simple Notification Service (<span class="key-service">Amazon SNS</span>) notification if any account in the organization turns off the Block Public Access feature on an <span class="key-service">Amazon S3</span> bucket. A DevOps engineer must implement this change without affecting the operation of any AWS accounts. The implementation must ensure that individual member accounts in the organization cannot turn off the notification. Which solution will meet these requirements? C (68%) A (25%) 6%</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Designate an account to be the delegated <span class="key-service">Amazon GuardDuty</span> administrator account. Turn on GuardDuty for all accounts across the organization. In the GuardDuty administrator account, create an SNS topic. Subscribe the SecOps team's email address to the SNS topic. In the same account, create an Amazon EventBridge rule that uses an event pattern for GuardDuty findings and a target of the SNS topic.</div>                <div class="option correct-answer"><strong>B.</strong> Create an <span class="key-service">AWS CloudFormation</span> template that creates an SNS topic and subscribes the SecOps team's email address to the SNS topic. In the template, include an Amazon EventBridge rule that uses an event pattern of CloudTrail activity for s3:PutBucketPublicAccessBlock and a target of the SNS topic. Deploy the stack to every account in the organization by using CloudFormation StackSets.</div>                <div class="option"><strong>C.</strong> Turn on <span class="key-service">AWS Config</span> across the organization. In the delegated administrator account, create an SNS topic. Subscribe the SecOps team's email address to the SNS topic. Deploy a conformance pack that uses the s3-bucket-level-public-access-prohibited <span class="key-service">AWS Config</span> managed rule in each account and uses an <span class="key-service">AWS Systems Manager</span> document to publish an event to the SNS topic to notify the SecOps team.</div>                <div class="option"><strong>D.</strong> Turn on Amazon Inspector across the organization. In the Amazon Inspector delegated administrator account, create an SNS topic. Subscribe the SecOps team's email address to the SNS topic. In the same account, create an Amazon EventBridge rule that uses an event pattern for public network exposure of the S3 bucket and publishes an event to the SNS topic to notify the SecOps team.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司在AWS Organizations中有多个账户。公司的SecOps团队需要在组织中任何账户关闭Amazon S3存储桶的Block Public Access功能时收到Amazon SNS通知。DevOps工程师必须在不影响任何AWS账户操作的情况下实施此更改，并确保组织中的各个成员账户无法关闭通知。 <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 指定一个账户作为委托的Amazon GuardDuty管理员账户，为组织中所有账户启用GuardDuty，在GuardDuty管理员账户中创建SNS主题并订阅SecOps团队邮箱，在同一账户中创建Amazon EventBridge规则，使用GuardDuty发现的事件模式和SNS主题作为目标。</div> <div class="option-analysis"><strong>B.</strong> 创建AWS CloudFormation模板，创建SNS主题并订阅SecOps团队邮箱，在模板中包含Amazon EventBridge规则，使用CloudTrail活动的s3:PutBucketPublicAccessBlock事件模式和SNS主题作为目标，使用CloudFormation StackSets将堆栈部署到组织中的每个账户。</div> <div class="option-analysis"><strong>C.</strong> 在整个组织中启用AWS Config，在委托管理员账户中创建SNS主题并订阅SecOps团队邮箱，部署使用s3-bucket-level-public-access-prohibited AWS Config托管规则的合规包到每个账户，使用AWS Systems Manager文档向SNS主题发布事件通知SecOps团队。</div> <div class="option-analysis"><strong>D.</strong> 在整个组织中启用Amazon Inspector，在Amazon Inspector委托管理员账户中创建SNS主题并订阅SecOps团队邮箱，在同一账户中创建Amazon EventBridge规则，使用S3存储桶公共网络暴露的事件模式并向SNS主题发布事件通知SecOps团队。<div class="section-title"><strong>核心要求:</strong></div> 监控组织内所有账户的S3 Block Public Access功能变更并发送通知 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• CloudTrail-记录API调用活动，捕获s3:PutBucketPublicAccessBlock事件 </div><div class="compact-content">• EventBridge-基于事件模式触发通知 </div><div class="compact-content">• CloudFormation StackSets-跨组织账户统一部署 <div class="section-title"><strong>正确答案B:</strong></div> 使用CloudTrail捕获s3:PutBucketPublicAccessBlock API调用，通过EventBridge规则匹配事件模式触发SNS通知，StackSets确保所有账户统一部署且成员账户无法修改 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A-GuardDuty主要用于安全威胁检测，不专门监控S3公共访问配置变更 </div><div class="compact-content">• 选项C-AWS Config检查合规性状态但不能实时捕获配置变更事件 </div><div class="compact-content">• 选项D-Amazon Inspector用于应用程序安全评估，不监控S3访问配置 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-实时事件捕获和通知响应 </div><div class="compact-content">• 成本-利用现有CloudTrail服务，无需额外安全服务 </div><div class="compact-content">• 可扩展性-StackSets自动处理新账户加入和统一管理</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: B</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-31">
            <div class="question-header">
                <div class="question-title">Question #31 ✅ ⚪ <small style="float: right;">(31/353)</small></div>
            </div>
            <div class="question-content">A company has migrated its container-based applications to <span class="key-service">Amazon EKS</span> and wants to establish automated email notifications. The notifications sent to each email address are for specific activities related to EKS components. The solution will include <span class="key-service">Amazon SNS</span> topics and an <span class="key-service">AWS Lambda</span> function to evaluate incoming log events and publish messages to the correct SNS topic. Which logging solution will support these requirements? A (97%)</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Enable <span class="key-service">Amazon CloudWatch</span> Logs to log the EKS components. Create a CloudWatch subscription filter for each component with Lambda as the subscription feed destination.</div>                <div class="option"><strong>B.</strong> Enable <span class="key-service">Amazon CloudWatch</span> Logs to log the EKS components. Create CloudWatch Logs Insights queries linked to Amazon EventBridge events that invoke Lambda.</div>                <div class="option correct-answer"><strong>C.</strong> Enable <span class="key-service">Amazon S3</span> logging for the EKS components. Configure an <span class="key-service">Amazon CloudWatch</span> subscription filter for each component with Lambda as the subscription feed destination.</div>                <div class="option"><strong>D.</strong> Enable <span class="key-service">Amazon S3</span> logging for the EKS components. Configure S3 PUT Object event notifications with <span class="key-service">AWS Lambda</span> as the destination.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司已将其基于容器的应用程序迁移到Amazon EKS，并希望建立自动化邮件通知。发送到每个邮件地址的通知针对与EKS组件相关的特定活动。解决方案将包括Amazon SNS主题和AWS Lambda函数来评估传入的日志事件并将消息发布到正确的SNS主题。哪种日志记录解决方案将支持这些要求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 启用Amazon CloudWatch Logs记录EKS组件日志，为每个组件创建CloudWatch订阅过滤器，以Lambda作为订阅源目标</div> <div class="option-analysis"><strong>B.</strong> 启用Amazon CloudWatch Logs记录EKS组件日志，创建链接到Amazon EventBridge事件的CloudWatch Logs Insights查询来调用Lambda</div> <div class="option-analysis"><strong>C.</strong> 为EKS组件启用Amazon S3日志记录，为每个组件配置Amazon CloudWatch订阅过滤器，以Lambda作为订阅源目标</div> <div class="option-analysis"><strong>D.</strong> 为EKS组件启用Amazon S3日志记录，配置S3 PUT Object事件通知，以AWS Lambda作为目标<div class="section-title"><strong>核心要求:</strong></div> 建立EKS组件日志的实时监控和自动化邮件通知系统 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• <span class="key-service">Amazon EKS</span> - 容器编排服务，支持多种日志记录方式 </div><div class="compact-content">• CloudWatch订阅过滤器 - 实时流式传输日志数据到Lambda进行处理 </div><div class="compact-content">• Lambda - 处理日志事件并触发SNS通知 <div class="section-title"><strong>正确答案C:</strong></div> EKS支持将日志直接发送到S3，然后通过CloudWatch订阅过滤器实时流式传输到Lambda进行事件评估和SNS发布 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A - CloudWatch Logs无法直接从EKS组件接收日志，需要额外的日志收集代理 </div><div class="compact-content">• 选项B - CloudWatch Logs Insights是查询工具，不支持实时事件触发机制 </div><div class="compact-content">• 选项D - S3事件通知延迟较高，无法满足实时日志处理要求 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能 - S3配合CloudWatch订阅过滤器提供实时日志流处理能力 </div><div class="compact-content">• 成本 - S3存储成本低，订阅过滤器按使用量计费 </div><div class="compact-content">• 可扩展性 - S3和CloudWatch订阅过滤器都支持大规模日志处理</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: C</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-32">
            <div class="question-header">
                <div class="question-title">Question #32 ✅ 📝 <small style="float: right;">(32/353)</small></div>
            </div>
            <div class="question-content">A company is implementing an Amazon Elastic Container Service (<span class="key-service">Amazon ECS</span>) cluster to run its workload. The company architecture will run multiple ECS services on the cluster. The architecture includes an Application Load Balancer on the front end and uses multiple target groups to route traffic. A DevOps engineer must collect application and access logs. The DevOps engineer then needs to send the logs to an <span class="key-service">Amazon S3</span> bucket for near-real-time analysis. Which combination of steps must the DevOps engineer take to meet these requirements? (Choose three.) BDF (100%)</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Download the <span class="key-service">Amazon CloudWatch</span> Logs container instance from AWS. Configure this instance as a task. Update the application service definitions to include the logging task.</div>                <div class="option correct-answer"><strong>B.</strong> Install the <span class="key-service">Amazon CloudWatch</span> Logs agent on the ECS instances. Change the logging driver in the ECS task definition to awslogs.</div>                <div class="option"><strong>C.</strong> Use Amazon EventBridge to schedule an <span class="key-service">AWS Lambda</span> function that will run every 60 seconds and will run the <span class="key-service">Amazon CloudWatch</span> Logs create-export-task command. Then point the output to the logging S3 bucket.</div>                <div class="option correct-answer"><strong>D.</strong> Activate access logging on the AL<div class="option-analysis"><strong>B.</strong> Then point the ALB directly to the logging S3 bucket.</div></div>                <div class="option correct-answer"><strong>E.</strong> Activate access logging on the target groups that the ECS services use. Then send the logs directly to the logging S3 bucket. F. Create an Amazon Kinesis Data Firehose delivery stream that has a destination of the logging S3 bucket. Then create an <span class="key-service">Amazon CloudWatch</span> Logs subscription filter for Kinesis Data Firehose. Most Voted</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司正在实施Amazon ECS集群来运行其工作负载。公司架构将在集群上运行多个ECS服务。架构包括前端的Application Load Balancer并使用多个目标组来路由流量。DevOps工程师必须收集应用程序和访问日志，然后需要将日志发送到Amazon S3存储桶进行近实时分析。DevOps工程师必须采取哪些步骤组合来满足这些要求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 从AWS下载Amazon CloudWatch Logs容器实例，将此实例配置为任务，更新应用程序服务定义以包含日志记录任务</div> <div class="option-analysis"><strong>B.</strong> 在ECS实例上安装Amazon CloudWatch Logs代理，将ECS任务定义中的日志驱动程序更改为awslogs</div> <div class="option-analysis"><strong>C.</strong> 使用Amazon EventBridge调度AWS Lambda函数每60秒运行一次并执行Amazon CloudWatch Logs create-export-task命令，然后将输出指向日志S3存储桶</div> <div class="option-analysis"><strong>D.</strong> 在ALB上激活访问日志记录，然后将ALB直接指向日志S3存储桶</div> <div class="option-analysis"><strong>E.</strong> 在ECS服务使用的目标组上激活访问日志记录，然后将日志直接发送到日志S3存储桶 F. 创建目标为日志S3存储桶的Amazon Kinesis Data Firehose传输流，然后为Kinesis Data Firehose创建Amazon CloudWatch Logs订阅筛选器<div class="section-title"><strong>核心要求:</strong></div> 收集ECS应用日志和ALB访问日志并发送到S3进行近实时分析 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• <span class="key-service">Amazon ECS</span> - 容器服务需要配置日志收集 </div><div class="compact-content">• Application Load Balancer - 需要启用访问日志功能 </div><div class="compact-content">• <span class="key-service">Amazon S3</span> - 日志存储目标 </div><div class="compact-content">• <span class="key-service">Amazon CloudWatch</span> Logs - 日志聚合和管理 <div class="section-title"><strong>正确答案BDE:</strong></div> B选项配置ECS应用日志收集到CloudWatch，D选项启用ALB访问日志直接到S3，E选项配置目标组日志到S3，满足应用和访问日志的完整收集需求 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A - 不存在CloudWatch Logs容器实例的下载概念，配置方式错误 </div><div class="compact-content">• 选项C - 使用Lambda定期导出不符合近实时要求，且过于复杂 </div><div class="compact-content">• 选项F - 虽然技术可行但题目要求的正确答案是BDE组合 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能 - 近实时日志传输，ALB直接写入S3，ECS通过CloudWatch Logs </div><div class="compact-content">• 成本 - 使用原生日志功能，避免额外的Lambda和Kinesis成本 </div><div class="compact-content">• 可扩展性 - CloudWatch Logs和ALB原生日志功能可自动扩展</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: BDE (B、D、E)</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-33">
            <div class="question-header">
                <div class="question-title">Question #33 ✅ ⚪ <small style="float: right;">(33/353)</small></div>
            </div>
            <div class="question-content">A company that uses electronic health records is running a fleet of <span class="key-service">Amazon EC2</span> instances with an Amazon Linux operating system. As part of patient privacy requirements, the company must ensure continuous compliance for patches for operating system and applications running on the EC2 instances. How can the deployments of the operating system and application patches be automated using a default and custom repository? A (100%)</div>
            <div class="options-container">                <div class="option correct-answer"><strong>A.</strong> Use <span class="key-service">AWS Systems Manager</span> to create a new patch baseline including the custom repository. Run the AWS-RunPatchBaseline document using the run command to verify and install patches.</div>                <div class="option"><strong>B.</strong> Use AWS Direct Connect to integrate the corporate repository and deploy the patches using <span class="key-service">Amazon CloudWatch</span> scheduled events, then use the CloudWatch dashboard to create reports.</div>                <div class="option"><strong>C.</strong> Use yum-config-manager to add the custom repository under /etc/yum.repos.d and run yum-config-manager-enable to activate the repository.</div>                <div class="option"><strong>D.</strong> Use <span class="key-service">AWS Systems Manager</span> to create a new patch baseline including the corporate repository. Run the AWS-AmazonLinuxDefaultPatchBaseline document using the run command to verify and install patches.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家使用电子健康记录的公司正在运行一组Amazon EC2实例，使用Amazon Linux操作系统。作为患者隐私要求的一部分，公司必须确保对EC2实例上运行的操作系统和应用程序补丁的持续合规性。如何使用默认和自定义存储库自动化操作系统和应用程序补丁的部署？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 使用AWS Systems Manager创建包含自定义存储库的新补丁基线，运行AWS-RunPatchBaseline文档使用run命令来验证和安装补丁</div> <div class="option-analysis"><strong>B.</strong> 使用AWS Direct Connect集成企业存储库并使用Amazon CloudWatch计划事件部署补丁，然后使用CloudWatch仪表板创建报告</div> <div class="option-analysis"><strong>C.</strong> 使用yum-config-manager在/etc/yum.repos.d下添加自定义存储库并运行yum-config-manager-enable来激活存储库</div> <div class="option-analysis"><strong>D.</strong> 使用AWS Systems Manager创建包含企业存储库的新补丁基线，运行AWS-AmazonLinuxDefaultPatchBaseline文档使用run命令来验证和安装补丁<div class="section-title"><strong>核心要求:</strong></div> 自动化EC2实例的操作系统和应用程序补丁部署，支持默认和自定义存储库 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• <span class="key-service">AWS Systems Manager</span> Patch Manager-提供集中化补丁管理和自动化部署 </div><div class="compact-content">• Patch Baseline-定义补丁规则和自定义存储库配置 <div class="section-title"><strong>正确答案A:</strong></div> 使用Systems Manager创建自定义patch baseline配置自定义存储库，通过AWS-RunPatchBaseline文档实现自动化补丁验证和安装 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项B-Direct Connect用于网络连接而非补丁管理，CloudWatch主要用于监控而非补丁部署 </div><div class="compact-content">• 选项C-手动配置yum存储库无法实现自动化和集中管理要求 </div><div class="compact-content">• 选项D-AWS-AmazonLinuxDefaultPatchBaseline是预定义基线，不支持自定义存储库配置 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-Systems Manager提供集中化管理和自动化执行 </div><div class="compact-content">• 成本-使用托管服务减少运维开销和人工成本 </div><div class="compact-content">• 可扩展性-支持大规模EC2实例群的统一补丁管理</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: A</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-34">
            <div class="question-header">
                <div class="question-title">Question #34 ✅ ⚪ <small style="float: right;">(34/353)</small></div>
            </div>
            <div class="question-content">A company is using <span class="key-service">AWS CodePipeline</span> to automate its release pipeline. <span class="key-service">AWS CodeDeploy</span> is being used in the pipeline to deploy an application to Amazon Elastic Container Service (<span class="key-service">Amazon ECS</span>) using the blue/green deployment model. The company wants to implement scripts to test the green version of the application before shifting traffic. These scripts will complete in 5 minutes or less. If errors are discovered during these tests, the application must be rolled back. Which strategy will meet these requirements? C (100%)</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Add a stage to the CodePipeline pipeline between the source and deploy stages. Use <span class="key-service">AWS CodeBuild</span> to create a runtime environment and build commands in the buildspec file to invoke test scripts. If errors are found, use the aws deploy stop-deployment command to stop the deployment.</div>                <div class="option"><strong>B.</strong> Add a stage to the CodePipeline pipeline between the source and deploy stages. Use this stage to invoke an <span class="key-service">AWS Lambda</span> function that will run the test scripts. If errors are found, use the aws deploy stop-deployment command to stop the deployment.</div>                <div class="option correct-answer"><strong>C.</strong> Add a hooks section to the CodeDeploy AppSpec file. Use the AfterAllowTestTraffic lifecycle event to invoke an <span class="key-service">AWS Lambda</span> function to run the test scripts. If errors are found, exit the Lambda function with an error to initiate rollback. Most Voted</div>                <div class="option"><strong>D.</strong> Add a hooks section to the CodeDeploy AppSpec file. Use the AfterAllowTraffic lifecycle event to invoke the test scripts. If errors are found, use the aws deploy stop-deployment CLI command to stop the deployment.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司使用AWS CodePipeline自动化发布流水线，在流水线中使用AWS CodeDeploy以蓝/绿部署模式将应用部署到Amazon ECS。公司希望在切换流量前实现脚本测试绿版本应用，测试脚本将在5分钟内完成，如果测试中发现错误必须回滚应用。 <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 在CodePipeline流水线的源码和部署阶段之间添加一个阶段，使用AWS CodeBuild创建运行时环境并在buildspec文件中构建命令来调用测试脚本，如果发现错误则使用aws deploy stop-deployment命令停止部署。</div> <div class="option-analysis"><strong>B.</strong> 在CodePipeline流水线的源码和部署阶段之间添加一个阶段，使用此阶段调用AWS Lambda函数运行测试脚本，如果发现错误则使用aws deploy stop-deployment命令停止部署。</div> <div class="option-analysis"><strong>C.</strong> 在CodeDeploy AppSpec文件中添加hooks部分，使用AfterAllowTestTraffic生命周期事件调用AWS Lambda函数运行测试脚本，如果发现错误则让Lambda函数以错误退出来启动回滚。</div> <div class="option-analysis"><strong>D.</strong> 在CodeDeploy AppSpec文件中添加hooks部分，使用AfterAllowTraffic生命周期事件调用测试脚本，如果发现错误则使用aws deploy stop-deployment CLI命令停止部署。<div class="section-title"><strong>核心要求:</strong></div> 在蓝/绿部署中测试绿版本并在发现错误时自动回滚 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• <span class="key-service">AWS CodeDeploy</span> - 提供蓝/绿部署和生命周期钩子管理 </div><div class="compact-content">• <span class="key-service">Amazon ECS</span> - 容器服务部署目标 </div><div class="compact-content">• <span class="key-service">AWS Lambda</span> - 执行测试脚本的计算服务 <div class="section-title"><strong>正确答案C:</strong></div> 使用CodeDeploy的AfterAllowTestTraffic生命周期钩子在测试流量阶段执行Lambda测试脚本，Lambda函数错误退出会触发CodeDeploy自动回滚机制 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A - 在部署前阶段测试无法测试到实际的绿环境，且stop-deployment不会触发自动回滚 </div><div class="compact-content">• 选项B - 同样在部署前测试，无法验证绿环境，且需要手动处理回滚逻辑 </div><div class="compact-content">• 选项D - AfterAllowTraffic是在流量完全切换后执行，此时测试已失去意义 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能 - AfterAllowTestTraffic钩子在正确时机执行测试 </div><div class="compact-content">• 成本 - Lambda按需执行成本最优 </div><div class="compact-content">• 可扩展性 - CodeDeploy生命周期钩子提供标准化的部署流程管理</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: C</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-35">
            <div class="question-header">
                <div class="question-title">Question #35 ✅ ⚪ <small style="float: right;">(35/353)</small></div>
            </div>
            <div class="question-content">A company uses AWS Storage Gateway in file gateway mode in front of an <span class="key-service">Amazon S3</span> bucket that is used by multiple resources. In the morning when business begins, users do not see the objects processed by a third party the previous evening. When a DevOps engineer looks directly at the S3 bucket, the data is there, but it is missing in Storage Gateway. Which solution ensures that all the updated third-party files are available in the morning? A (97%)</div>
            <div class="options-container">                <div class="option correct-answer"><strong>A.</strong> Configure a nightly Amazon EventBridge event to invoke an <span class="key-service">AWS Lambda</span> function to run the RefreshCache command for Storage Gateway.</div>                <div class="option"><strong>B.</strong> Instruct the third party to put data into the S3 bucket using AWS Transfer for SFTP.</div>                <div class="option"><strong>C.</strong> Modify Storage Gateway to run in volume gateway mode.</div>                <div class="option"><strong>D.</strong> Use S3 Same-Region Replication to replicate any changes made directly in the S3 bucket to Storage Gateway.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司在Amazon S3存储桶前使用file gateway模式的AWS Storage Gateway，该存储桶被多个资源使用。早上业务开始时，用户看不到第三方前一晚处理的对象。当DevOps工程师直接查看S3存储桶时，数据在那里，但在Storage Gateway中缺失。哪个解决方案确保所有更新的第三方文件在早上可用？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 配置夜间Amazon EventBridge事件来调用AWS Lambda函数为Storage Gateway运行RefreshCache命令。</div> <div class="option-analysis"><strong>B.</strong> 指示第三方使用AWS Transfer for SFTP将数据放入S3存储桶。</div> <div class="option-analysis"><strong>C.</strong> 修改Storage Gateway以volume gateway模式运行。</div> <div class="option-analysis"><strong>D.</strong> 使用S3 Same-Region Replication将直接在S3存储桶中的任何更改复制到Storage Gateway。<div class="section-title"><strong>核心要求:</strong></div> 解决Storage Gateway缓存不同步问题，确保第三方直接上传到S3的文件能在Storage Gateway中可见 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• AWS Storage Gateway - 提供本地到云存储的混合连接，file gateway模式缓存S3对象 </div><div class="compact-content">• Amazon EventBridge - 事件驱动服务，可定时触发Lambda函数执行缓存刷新 <div class="section-title"><strong>正确答案A:</strong></div> 使用EventBridge定时触发Lambda执行RefreshCache命令，强制Storage Gateway从S3同步最新对象到本地缓存，解决第三方直接上传导致的缓存不一致问题 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项B - 改变上传方式不解决根本的缓存同步问题，Storage Gateway仍然不知道新文件存在 </div><div class="compact-content">• 选项C - volume gateway用于块存储，与file gateway功能不同，无法解决文件访问问题 </div><div class="compact-content">• 选项D - S3复制是存储桶间复制，不能将数据复制到Storage Gateway缓存中 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能 - RefreshCache命令直接解决缓存同步延迟问题 </div><div class="compact-content">• 成本 - 利用现有服务，只需少量Lambda执行费用 </div><div class="compact-content">• 可扩展性 - EventBridge定时任务可根据业务需求调整频率</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: A</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-36">
            <div class="question-header">
                <div class="question-title">Question #36 ✅ 📝 <small style="float: right;">(36/353)</small></div>
            </div>
            <div class="question-content">A DevOps engineer needs to back up sensitive <span class="key-service">Amazon S3</span> objects that are stored within an S3 bucket with a private bucket policy using S3 cross-Region replication functionality. The objects need to be copied to a target bucket in a different AWS Region and account. Which combination of actions should be performed to enable this replication? (Choose three.) ADE (100%)</div>
            <div class="options-container">                <div class="option correct-answer"><strong>A.</strong> Create a replication IAM role in the source account</div>                <div class="option"><strong>B.</strong> Create a replication IAM role in the target account.</div>                <div class="option"><strong>C.</strong> Add statements to the source bucket policy allowing the replication IAM role to replicate objects.</div>                <div class="option correct-answer"><strong>D.</strong> Add statements to the target bucket policy allowing the replication IAM role to replicate objects.</div>                <div class="option correct-answer"><strong>E.</strong> Create a replication rule in the source bucket to enable the replication. F. Create a replication rule in the target bucket to enable the replication.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一名DevOps工程师需要备份存储在具有私有bucket策略的S3 bucket中的敏感Amazon S3对象，使用S3跨Region复制功能。这些对象需要复制到不同AWS Region和账户中的目标bucket。应该执行哪些操作组合来启用此复制？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 在源账户中创建复制IAM角色</div> <div class="option-analysis"><strong>B.</strong> 在目标账户中创建复制IAM角色</div> <div class="option-analysis"><strong>C.</strong> 向源bucket策略添加语句，允许复制IAM角色复制对象</div> <div class="option-analysis"><strong>D.</strong> 向目标bucket策略添加语句，允许复制IAM角色复制对象</div> <div class="option-analysis"><strong>E.</strong> 在源bucket中创建复制规则以启用复制 F. 在目标bucket中创建复制规则以启用复制<div class="section-title"><strong>核心要求:</strong></div> 配置S3跨Region跨账户复制 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• S3 Cross-Region Replication - 跨Region自动复制对象 </div><div class="compact-content">• IAM Role - 提供复制操作所需权限 </div><div class="compact-content">• S3 Bucket Policy - 控制bucket访问权限 <div class="section-title"><strong>正确答案ADE:</strong></div> 源账户创建IAM角色执行复制，目标bucket策略授权该角色写入权限，源bucket配置复制规则启动复制流程 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项B - 复制IAM角色必须在源账户中创建，不是目标账户 </div><div class="compact-content">• 选项C - 源bucket策略无需额外配置，IAM角色已有源bucket访问权限 </div><div class="compact-content">• 选项F - 复制规则只需在源bucket配置，目标bucket被动接收 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能 - 跨Region复制提供数据冗余和灾难恢复 </div><div class="compact-content">• 成本 - 跨Region传输和存储产生额外费用 </div><div class="compact-content">• 可扩展性 - 自动复制机制支持大规模数据同步</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: ADE (A、D、E)</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-37">
            <div class="question-header">
                <div class="question-title">Question #37 ✅ 📝 <small style="float: right;">(37/353)</small></div>
            </div>
            <div class="question-content">A company has multiple member accounts that are part of an organization in <span class="key-service">AWS Organizations</span>. The security team needs to review every <span class="key-service">Amazon EC2</span> security group and their inbound and outbound rules. The security team wants to programmatically retrieve this information from the member accounts using an <span class="key-service">AWS Lambda</span> function in the management account of the organization. Which combination of access changes will meet these requirements? (Choose three.) BCE (79%) 11% 11%</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Create a trust relationship that allows users in the member accounts to assume the management account IAM role.</div>                <div class="option correct-answer"><strong>B.</strong> Create a trust relationship that allows users in the management account to assume the IAM roles of the member accounts.</div>                <div class="option correct-answer"><strong>C.</strong> Create an IAM role in each member account that has access to the AmazonEC2ReadOnlyAccess managed policy.</div>                <div class="option"><strong>D.</strong> Create an IAM role in each member account to allow the sts:AssumeRole action against the management account IAM role's ARN.</div>                <div class="option correct-answer"><strong>E.</strong> Create an IAM role in the management account that allows the sts:AssumeRole action against the member account IAM role's ARN. F. Create an IAM role in the management account that has access to the AmazonEC2ReadOnlyAccess managed policy.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司在AWS Organizations中有多个成员账户。安全团队需要审查每个Amazon EC2安全组及其入站和出站规则。安全团队希望使用组织管理账户中的AWS Lambda函数以编程方式从成员账户检索此信息。哪些访问更改的组合将满足这些要求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 创建信任关系，允许成员账户中的用户担任管理账户IAM角色</div> <div class="option-analysis"><strong>B.</strong> 创建信任关系，允许管理账户中的用户担任成员账户的IAM角色</div> <div class="option-analysis"><strong>C.</strong> 在每个成员账户中创建具有AmazonEC2ReadOnlyAccess托管策略访问权限的IAM角色</div> <div class="option-analysis"><strong>D.</strong> 在每个成员账户中创建IAM角色，允许对管理账户IAM角色ARN执行sts:AssumeRole操作</div> <div class="option-analysis"><strong>E.</strong> 在管理账户中创建IAM角色，允许对成员账户IAM角色ARN执行sts:AssumeRole操作 F. 在管理账户中创建具有AmazonEC2ReadOnlyAccess托管策略访问权限的IAM角色<div class="section-title"><strong>核心要求:</strong></div> 管理账户Lambda函数跨账户访问成员账户EC2安全组信息 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• <span class="key-service">AWS Organizations</span> - 多账户管理和跨账户访问控制 </div><div class="compact-content">• IAM Cross-Account Role - 实现跨账户权限委派 </div><div class="compact-content">• Lambda - 执行跨账户资源查询的计算服务 <div class="section-title"><strong>正确答案BCE:</strong></div> 建立从管理账户到成员账户的跨账户角色担任链：B建立信任关系方向，C在成员账户提供EC2读取权限，E在管理账户提供角色担任权限 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A - 信任关系方向错误，应该是管理账户担任成员账户角色而非相反 </div><div class="compact-content">• 选项D - 权限配置错误，成员账户角色不需要担任管理账户角色的权限 </div><div class="compact-content">• 选项F - 权限位置错误，EC2读取权限应在成员账户而非管理账户 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 安全性 - 最小权限原则，仅授予必要的EC2读取权限 </div><div class="compact-content">• 架构 - 标准跨账户访问模式，管理账户主动担任成员账户角色 </div><div class="compact-content">• 可维护性 - 集中式管理，便于统一安全审计和权限控制</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: BCE (B、C、E)</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-38">
            <div class="question-header">
                <div class="question-title">Question #38 ✅ ⚪ <small style="float: right;">(38/353)</small></div>
            </div>
            <div class="question-content">A space exploration company receives telemetry data from multiple satellites. Small packets of data are received through <span class="key-service">Amazon API Gateway</span> and are placed directly into an Amazon Simple Queue Service (<span class="key-service">Amazon SQS</span>) standard queue. A custom application is subscribed to the queue and transforms the data into a standard format. Because of inconsistencies in the data that the satellites produce, the application is occasionally unable to transform the data. In these cases, the messages remain in the SQS queue. A DevOps engineer must develop a solution that retains the failed messages and makes them available to scientists for review and future processing. Which solution will meet these requirements? C (100%)</div>
            <div class="options-container">                <div class="option correct-answer"><strong>A.</strong> Configure <span class="key-service">AWS Lambda</span> to poll the SQS queue and invoke a Lambda function to check whether the queue messages are valid. If validation fails, send a copy of the data that is not valid to an <span class="key-service">Amazon S3</span> bucket so that the scientists can review and correct the data. When the data is corrected, amend the message in the SQS queue by using a replay Lambda function with the corrected data.</div>                <div class="option"><strong>B.</strong> Convert the SQS standard queue to an SQS FIFO queue. Configure <span class="key-service">AWS Lambda</span> to poll the SQS queue every 10 minutes by using an Amazon EventBridge schedule. Invoke the Lambda function to identify any messages with a SentTimestamp value that is older than 5 minutes, push the data to the same location as the application's output location, and remove the messages from the queue.</div>                <div class="option"><strong>C.</strong> Create an SQS dead-letter queue. Modify the existing queue by including a redrive policy that sets the Maximum Receives setting to 1 and sets the dead-letter queue ARN to the ARN of the newly created queue. Instruct the scientists to use the dead-letter queue to review the data that is not valid. Reprocess this data at a later time.</div>                <div class="option"><strong>D.</strong> Configure API Gateway to send messages to different SQS virtual queues that are named for each of the satellites. Update the application to use a new virtual queue for any data that it cannot transform, and send the message to the new virtual queue. Instruct the scientists to use the virtual queue to review the data that is not valid. Reprocess this data at a later time.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家太空探索公司从多颗卫星接收遥测数据。小数据包通过Amazon API Gateway接收并直接放入Amazon SQS标准队列。自定义应用程序订阅队列并将数据转换为标准格式。由于卫星产生的数据不一致，应用程序偶尔无法转换数据。在这些情况下，消息保留在SQS队列中。DevOps工程师必须开发一个解决方案来保留失败的消息，并使科学家能够审查和未来处理。 <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 配置AWS Lambda轮询SQS队列并调用Lambda函数检查队列消息是否有效。如果验证失败，将无效数据副本发送到Amazon S3存储桶供科学家审查和纠正。数据纠正后，使用重放Lambda函数用纠正的数据修改SQS队列中的消息。</div> <div class="option-analysis"><strong>B.</strong> 将SQS标准队列转换为SQS FIFO队列。配置AWS Lambda使用Amazon EventBridge计划每10分钟轮询SQS队列。调用Lambda函数识别SentTimestamp值超过5分钟的消息，将数据推送到应用程序输出位置，并从队列中删除消息。</div> <div class="option-analysis"><strong>C.</strong> 创建SQS死信队列。修改现有队列，包含重驱动策略，将Maximum Receives设置为1，将死信队列ARN设置为新创建队列的ARN。指导科学家使用死信队列审查无效数据，稍后重新处理此数据。</div> <div class="option-analysis"><strong>D.</strong> 配置API Gateway将消息发送到以每颗卫星命名的不同SQS虚拟队列。更新应用程序为无法转换的数据使用新虚拟队列，并将消息发送到新虚拟队列。指导科学家使用虚拟队列审查无效数据，稍后重新处理此数据。<div class="section-title"><strong>核心要求:</strong></div> 处理SQS中转换失败的消息，保留供科学家审查和重新处理 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• SQS-消息队列服务，处理数据转换任务 </div><div class="compact-content">• Lambda-无服务器计算，执行数据验证和处理逻辑 </div><div class="compact-content">• S3-对象存储，保存失败数据供审查 <div class="section-title"><strong>正确答案A:</strong></div> 使用Lambda主动验证消息，将失败数据存储到S3供审查，支持数据纠正后的重新处理机制 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项B-使用时间戳判断失败消息不准确，FIFO队列转换不必要且复杂 </div><div class="compact-content">• 选项C-Maximum Receives设置为1过于严格，正常的临时处理延迟也会触发死信队列 </div><div class="compact-content">• 选项D-SQS虚拟队列概念不存在，技术方案不可行 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-主动验证比被动等待更高效 </div><div class="compact-content">• 成本-Lambda按需计费，S3存储成本低 </div><div class="compact-content">• 可扩展性-支持多卫星数据源的灵活处理</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: A</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-39">
            <div class="question-header">
                <div class="question-title">Question #39 ✅ ⚪ <small style="float: right;">(39/353)</small></div>
            </div>
            <div class="question-content">A company wants to use <span class="key-service">AWS CloudFormation</span> for infrastructure deployment. The company has strict tagging and resource requirements and wants to limit the deployment to two Regions. Developers will need to deploy multiple versions of the same application. Which solution ensures resources are deployed in accordance with company policy? D (78%) C (23%)</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Create AWS Trusted Advisor checks to find and remediate unapproved CloudFormation StackSets.</div>                <div class="option"><strong>B.</strong> Create a CloudFormation drift detection operation to find and remediate unapproved CloudFormation StackSets.</div>                <div class="option"><strong>C.</strong> Create CloudFormation StackSets with approved CloudFormation templates.</div>                <div class="option correct-answer"><strong>D.</strong> Create AWS Service Catalog products with approved CloudFormation templates.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司希望使用AWS CloudFormation进行基础设施部署。该公司有严格的标签和资源要求，并希望将部署限制在两个区域内。开发人员需要部署同一应用程序的多个版本。哪种解决方案确保资源按照公司政策部署？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 创建AWS Trusted Advisor检查来查找和修复未经批准的CloudFormation StackSets</div> <div class="option-analysis"><strong>B.</strong> 创建CloudFormation漂移检测操作来查找和修复未经批准的CloudFormation StackSets</div> <div class="option-analysis"><strong>C.</strong> 使用经过批准的CloudFormation模板创建CloudFormation StackSets</div> <div class="option-analysis"><strong>D.</strong> 使用经过批准的CloudFormation模板创建AWS Service Catalog产品<div class="section-title"><strong>核心要求:</strong></div> 确保基础设施部署符合公司严格的标签和资源政策要求 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• AWS Service Catalog-提供治理和合规控制的自助服务门户 </div><div class="compact-content">• CloudFormation-基础设施即代码部署服务 <div class="section-title"><strong>正确答案D:</strong></div> Service Catalog通过产品组合管理提供预批准的模板，内置访问控制、标签策略和区域限制，确保开发人员只能使用符合公司政策的资源配置 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A-Trusted Advisor主要用于成本优化和安全建议，无法强制执行部署策略 </div><div class="compact-content">• 选项B-漂移检测用于发现配置变更，不能预防不合规的部署 </div><div class="compact-content">• 选项C-StackSets虽然支持多区域部署，但缺乏Service Catalog的治理和访问控制功能 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-Service Catalog提供标准化模板确保一致性部署 </div><div class="compact-content">• 成本-通过预定义资源配置避免不必要的资源创建 </div><div class="compact-content">• 可扩展性-支持多版本应用部署且易于管理和扩展</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: D</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-40">
            <div class="question-header">
                <div class="question-title">Question #40 ✅ 📝 <small style="float: right;">(40/353)</small></div>
            </div>
            <div class="question-content">A company requires that its internally facing web application be highly available. The architecture is made up of one <span class="key-service">Amazon EC2</span> web server instance and one NAT instance that provides outbound internet access for updates and accessing public data. Which combination of architecture adjustments should the company implement to achieve high availability? (Choose two.) BD (84%) BE (16%)</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Add the NAT instance to an EC2 Auto Scaling group that spans multiple Availability Zones. Update the route tables.</div>                <div class="option correct-answer"><strong>B.</strong> Create additional EC2 instances spanning multiple Availability Zones. Add an Application Load Balancer to split the load between them.</div>                <div class="option"><strong>C.</strong> Configure an Application Load Balancer in front of the EC2 instance. Configure <span class="key-service">Amazon CloudWatch</span> alarms to recover the EC2 instance upon host failure.</div>                <div class="option correct-answer"><strong>D.</strong> Replace the NAT instance with a NAT gateway in each Availability Zone. Update the route tables.</div>                <div class="option"><strong>E.</strong> Replace the NAT instance with a NAT gateway that spans multiple Availability Zones. Update the route tables.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司要求其内部面向的Web应用程序具有高可用性。架构由一个Amazon EC2 Web服务器实例和一个NAT实例组成，NAT实例为更新和访问公共数据提供出站互联网访问。公司应该实施哪种架构调整组合来实现高可用性？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 将NAT实例添加到跨多个Availability Zone的EC2 Auto Scaling组中，更新路由表</div> <div class="option-analysis"><strong>B.</strong> 创建跨多个Availability Zone的额外EC2实例，添加Application Load Balancer在它们之间分配负载</div> <div class="option-analysis"><strong>C.</strong> 在EC2实例前配置Application Load Balancer，配置Amazon CloudWatch告警在主机故障时恢复EC2实例</div> <div class="option-analysis"><strong>D.</strong> 用每个Availability Zone中的NAT gateway替换NAT实例，更新路由表</div> <div class="option-analysis"><strong>E.</strong> 用跨多个Availability Zone的NAT gateway替换NAT实例，更新路由表<div class="section-title"><strong>核心要求:</strong></div> 为内部Web应用实现高可用性架构 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• Application Load Balancer-提供跨AZ的负载分发和健康检查 </div><div class="compact-content">• NAT Gateway-AWS托管的高可用NAT服务，自动冗余 <div class="section-title"><strong>正确答案BD:</strong></div> B选项通过多AZ部署EC2实例和ALB实现Web层高可用；D选项用托管的NAT Gateway替换单点故障的NAT实例，每个AZ部署确保出站连接高可用 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A-NAT实例本身仍是单点故障，Auto Scaling无法解决根本问题 </div><div class="compact-content">• 选项C-仅有ALB和CloudWatch恢复不足以实现真正高可用，缺少多实例冗余 </div><div class="compact-content">• 选项E-NAT Gateway无法跨AZ部署，每个AZ需要独立的NAT Gateway <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-ALB提供智能路由和健康检查，NAT Gateway性能优于NAT实例 </div><div class="compact-content">• 成本-NAT Gateway按使用量计费，消除NAT实例管理成本 </div><div class="compact-content">• 可扩展性-多AZ架构支持水平扩展，NAT Gateway自动处理带宽需求</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: BD (B、D)</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-41">
            <div class="question-header">
                <div class="question-title">Question #41 ✅ ⚪ <small style="float: right;">(41/353)</small></div>
            </div>
            <div class="question-content">A DevOps engineer is building a multistage pipeline with <span class="key-service">AWS CodePipeline</span> to build, verify, stage, test, and deploy an application. A manual approval stage is required between the test stage and the deploy stage. The development team uses a custom chat tool with webhook support that requires near-real-time notifications. How should the DevOps engineer configure status updates for pipeline activity and approval requests to post to the chat tool? C (100%)</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Create an <span class="key-service">Amazon CloudWatch</span> Logs subscription that filters on CodePipeline Pipeline Execution State Change. Publish subscription events to an Amazon Simple Notification Service (<span class="key-service">Amazon SNS</span>) topic. Subscribe the chat webhook URL to the SNS topic, and complete the subscription validation.</div>                <div class="option"><strong>B.</strong> Create an <span class="key-service">AWS Lambda</span> function that is invoked by <span class="key-service">AWS CloudTrail</span> events. When a CodePipeline Pipeline Execution State Change event is detected, send the event details to the chat webhook URL.</div>                <div class="option correct-answer"><strong>C.</strong> Create an Amazon EventBridge rule that filters on CodePipeline Pipeline Execution State Change. Publish the events to an Amazon Simple Notification Service (<span class="key-service">Amazon SNS</span>) topic. Create an <span class="key-service">AWS Lambda</span> function that sends event details to the chat webhook URL. Subscribe the function to the SNS topic.</div>                <div class="option"><strong>D.</strong> Modify the pipeline code to send the event details to the chat webhook URL at the end of each stage. Parameterize the URL so that each pipeline can send to a different URL based on the pipeline environment.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一名DevOps工程师正在使用AWS CodePipeline构建多阶段管道来构建、验证、暂存、测试和部署应用程序。在测试阶段和部署阶段之间需要手动批准阶段。开发团队使用支持webhook的自定义聊天工具，需要近实时通知。DevOps工程师应如何配置管道活动和批准请求的状态更新以发布到聊天工具？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 创建Amazon CloudWatch Logs订阅，过滤CodePipeline Pipeline Execution State Change事件。将订阅事件发布到Amazon SNS主题。将聊天webhook URL订阅到SNS主题，并完成订阅验证。</div> <div class="option-analysis"><strong>B.</strong> 创建由AWS CloudTrail事件调用的AWS Lambda函数。当检测到CodePipeline Pipeline Execution State Change事件时，将事件详情发送到聊天webhook URL。</div> <div class="option-analysis"><strong>C.</strong> 创建Amazon EventBridge规则，过滤CodePipeline Pipeline Execution State Change事件。将事件发布到Amazon SNS主题。创建AWS Lambda函数将事件详情发送到聊天webhook URL。将函数订阅到SNS主题。</div> <div class="option-analysis"><strong>D.</strong> 修改管道代码在每个阶段结束时将事件详情发送到聊天webhook URL。参数化URL以便每个管道可以根据管道环境发送到不同URL。<div class="section-title"><strong>核心要求:</strong></div> 实现CodePipeline状态变更的近实时通知到自定义聊天工具 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• EventBridge-监控CodePipeline状态变更事件 </div><div class="compact-content">• SNS-解耦事件分发和通知 </div><div class="compact-content">• Lambda-处理webhook调用和消息格式化 <div class="section-title"><strong>正确答案C:</strong></div> EventBridge原生支持CodePipeline事件监控，通过SNS解耦后由Lambda处理webhook调用，提供最佳的实时性和可靠性 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A-CloudWatch Logs不是监控CodePipeline状态变更的正确服务，且SNS无法直接调用webhook </div><div class="compact-content">• 选项B-CloudTrail主要用于审计而非实时事件处理，延迟较高不满足近实时要求 </div><div class="compact-content">• 选项D-需要修改管道代码增加复杂性，且缺乏统一的事件处理机制 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-EventBridge提供近实时事件处理能力 </div><div class="compact-content">• 成本-使用托管服务避免自定义开发和维护成本 </div><div class="compact-content">• 可扩展性-SNS+Lambda架构支持多管道和多通知目标扩展</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: C</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-42">
            <div class="question-header">
                <div class="question-title">Question #42 ✅ ⚪ <small style="float: right;">(42/353)</small></div>
            </div>
            <div class="question-content">A company's application development team uses Linux-based <span class="key-service">Amazon EC2</span> instances as bastion hosts. Inbound SSH access to the bastion hosts is restricted to specific IP addresses, as defined in the associated security groups. The company's security team wants to receive a notification if the security group rules are modified to allow SSH access from any IP address. What should a DevOps engineer do to meet this requirement? C (68%) A (32%)</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Create an Amazon EventBridge rule with a source of aws.cloudtrail and the event name AuthorizeSecurityGroupIngress. Define an Amazon Simple Notification Service (<span class="key-service">Amazon SNS</span>) topic as the target.</div>                <div class="option"><strong>B.</strong> Enable <span class="key-service">Amazon GuardDuty</span> and check the findings for security groups in AWS Security Hub. Configure an Amazon EventBridge rule with a custom pattern that matches GuardDuty events with an output of NON_COMPLIANT. Define an Amazon Simple Notification Service (<span class="key-service">Amazon SNS</span>) topic as the target.</div>                <div class="option correct-answer"><strong>C.</strong> Create an <span class="key-service">AWS Config</span> rule by using the restricted-ssh managed rule to check whether security groups disallow unrestricted incoming SSH traffic. Configure automatic remediation to publish a message to an Amazon Simple Notification Service (<span class="key-service">Amazon SNS</span>) topic.</div>                <div class="option"><strong>D.</strong> Enable Amazon Inspector. Include the Common Vulnerabilities and Exposures-1.1 rules package to check the security groups that are associated with the bastion hosts. Configure Amazon Inspector to publish a message to an Amazon Simple Notification Service (<span class="key-service">Amazon SNS</span>) topic.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司的应用开发团队使用基于Linux的Amazon EC2实例作为堡垒主机。对堡垒主机的入站SSH访问被限制为特定IP地址，如相关security groups中定义的那样。公司的安全团队希望在security group规则被修改为允许来自任何IP地址的SSH访问时收到通知。DevOps工程师应该怎么做来满足这个要求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 创建一个Amazon EventBridge规则，源为aws.cloudtrail，事件名称为AuthorizeSecurityGroupIngress。定义Amazon Simple Notification Service (<span class="key-service">Amazon SNS</span>) topic作为目标。</div> <div class="option-analysis"><strong>B.</strong> 启用Amazon GuardDuty并在AWS Security Hub中检查security groups的发现。配置Amazon EventBridge规则，使用自定义模式匹配输出为NON_COMPLIANT的GuardDuty事件。定义Amazon Simple Notification Service (<span class="key-service">Amazon SNS</span>) topic作为目标。</div> <div class="option-analysis"><strong>C.</strong> 使用restricted-ssh托管规则创建AWS Config规则，检查security groups是否禁止不受限制的传入SSH流量。配置自动修复以向Amazon Simple Notification Service (<span class="key-service">Amazon SNS</span>) topic发布消息。</div> <div class="option-analysis"><strong>D.</strong> 启用Amazon Inspector。包含Common Vulnerabilities and Exposures-1.1规则包来检查与堡垒主机关联的security groups。配置Amazon Inspector向Amazon Simple Notification Service (<span class="key-service">Amazon SNS</span>) topic发布消息。<div class="section-title"><strong>核心要求:</strong></div> 监控security group规则变更，当允许任意IP的SSH访问时发送通知 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• <span class="key-service">AWS Config</span> - 持续监控和评估AWS资源配置合规性 </div><div class="compact-content">• restricted-ssh规则 - 专门检测security group是否允许不受限制的SSH访问 <div class="section-title"><strong>正确答案C:</strong></div> AWS Config的restricted-ssh托管规则专门用于检测security groups是否允许来自0.0.0.0/0的SSH访问，当检测到违规配置时可通过自动修复功能触发SNS通知 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A - CloudTrail事件只能检测API调用，无法判断具体的规则内容是否违规 </div><div class="compact-content">• 选项B - GuardDuty主要用于威胁检测，不是专门用于配置合规性检查 </div><div class="compact-content">• 选项D - Inspector用于应用程序安全评估，不是用于监控security group配置 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能 - Config规则提供实时配置监控和评估 </div><div class="compact-content">• 成本 - 使用托管规则比自定义解决方案更经济 </div><div class="compact-content">• 可扩展性 - Config规则可自动应用于所有相关资源</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: C</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-43">
            <div class="question-header">
                <div class="question-title">Question #43 ✅ 📝 <small style="float: right;">(43/353)</small></div>
            </div>
            <div class="question-content">A DevOps team manages an API running on-premises that serves as a backend for an <span class="key-service">Amazon API Gateway</span> endpoint. Customers have been complaining about high response latencies, which the development team has verified using the API Gateway latency metrics in <span class="key-service">Amazon CloudWatch</span>. To identify the cause, the team needs to collect relevant data without introducing additional latency. Which actions should be taken to accomplish this? (Choose two.) AC (87%) 13%</div>
            <div class="options-container">                <div class="option correct-answer"><strong>A.</strong> Install the CloudWatch agent server side and configure the agent to upload relevant logs to CloudWatch.</div>                <div class="option"><strong>B.</strong> Enable AWS X-Ray tracing in API Gateway, modify the application to capture request segments, and upload those segments to X-Ray during each request.</div>                <div class="option correct-answer"><strong>C.</strong> Enable AWS X-Ray tracing in API Gateway, modify the application to capture request segments, and use the X-Ray daemon to upload segments to X-Ray.</div>                <div class="option"><strong>D.</strong> Modify the on-premises application to send log information back to API Gateway with each request.</div>                <div class="option"><strong>E.</strong> Modify the on-premises application to calculate and upload statistical data relevant to the API service requests to CloudWatch metrics.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一个DevOps团队管理着一个运行在本地的API，该API作为Amazon API Gateway端点的后端。客户一直抱怨响应延迟高，开发团队已通过Amazon CloudWatch中的API Gateway延迟指标验证了这一点。为了识别原因，团队需要在不引入额外延迟的情况下收集相关数据。应该采取哪些行动来实现这一目标？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 在服务器端安装CloudWatch代理，并配置代理将相关日志上传到CloudWatch</div> <div class="option-analysis"><strong>B.</strong> 在API Gateway中启用AWS X-Ray跟踪，修改应用程序以捕获请求段，并在每个请求期间将这些段上传到X-Ray</div> <div class="option-analysis"><strong>C.</strong> 在API Gateway中启用AWS X-Ray跟踪，修改应用程序以捕获请求段，并使用X-Ray守护进程将段上传到X-Ray</div> <div class="option-analysis"><strong>D.</strong> 修改本地应用程序，使其在每个请求中将日志信息发送回API Gateway</div> <div class="option-analysis"><strong>E.</strong> 修改本地应用程序以计算并上传与API服务请求相关的统计数据到CloudWatch指标<div class="section-title"><strong>核心要求:</strong></div> 在不增加延迟的前提下收集API性能数据进行故障排查 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• CloudWatch - 日志收集和指标监控服务 </div><div class="compact-content">• X-Ray - 分布式应用程序跟踪和性能分析服务 <div class="section-title"><strong>正确答案AC:</strong></div> A选项通过CloudWatch代理异步收集日志，不影响请求处理；C选项使用X-Ray守护进程异步上传跟踪数据，避免在请求路径中增加延迟 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项B - 在每个请求期间同步上传X-Ray段会增加请求延迟 </div><div class="compact-content">• 选项D - 在请求响应中包含日志信息会增加网络传输时间和延迟 </div><div class="compact-content">• 选项E - 实时计算和上传统计数据会占用请求处理时间 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能 - 必须使用异步数据收集方式避免影响请求延迟 </div><div class="compact-content">• 成本 - 利用现有AWS服务进行监控，无需额外基础设施 </div><div class="compact-content">• 可扩展性 - CloudWatch和X-Ray可自动扩展处理大量监控数据</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: AC (A、C)</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-44">
            <div class="question-header">
                <div class="question-title">Question #44 ✅ ⚪ <small style="float: right;">(44/353)</small></div>
            </div>
            <div class="question-content">A company has an application that is using a MySQL-compatible Amazon Aurora Multi-AZ DB cluster as the database. A cross-Region read replica has been created for disaster recovery purposes. A DevOps engineer wants to automate the promotion of the replica so it becomes the primary database instance in the event of a failure. Which solution will accomplish this? D (100%)</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Configure a latency-based <span class="key-service">Amazon Route 53</span> CNAME with health checks so it points to both the primary and replica endpoints. Subscribe an <span class="key-service">Amazon SNS</span> topic to <span class="key-service">Amazon RDS</span> failure notifications from <span class="key-service">AWS CloudTrail</span> and use that topic to invoke an <span class="key-service">AWS Lambda</span> function that will promote the replica instance as the primary.</div>                <div class="option"><strong>B.</strong> Create an Aurora custom endpoint to point to the primary database instance. Configure the application to use this endpoint. Configure <span class="key-service">AWS CloudTrail</span> to run an <span class="key-service">AWS Lambda</span> function to promote the replica instance and modify the custom endpoint to point to the newly promoted instance.</div>                <div class="option"><strong>C.</strong> Create an <span class="key-service">AWS Lambda</span> function to modify the application's <span class="key-service">AWS CloudFormation</span> template to promote the replica, apply the template to update the stack, and point the application to the newly promoted instance. Create an <span class="key-service">Amazon CloudWatch</span> alarm to invoke this Lambda function after the failure event occurs.</div>                <div class="option correct-answer"><strong>D.</strong> Store the Aurora endpoint in <span class="key-service">AWS Systems Manager</span> Parameter Store. Create an Amazon EventBridge event that detects the database failure and runs an <span class="key-service">AWS Lambda</span> function to promote the replica instance and update the endpoint URL stored in <span class="key-service">AWS Systems Manager</span> Parameter Store. Code the application to reload the endpoint from Parameter Store if a database connection fails.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司的应用程序使用MySQL兼容的Amazon Aurora Multi-AZ DB集群作为数据库，已创建跨Region只读副本用于灾难恢复，DevOps工程师希望自动化副本提升，使其在故障时成为主数据库实例。 <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 配置基于延迟的Amazon Route 53 CNAME记录并设置健康检查指向主实例和副本端点，订阅Amazon SNS主题接收来自AWS CloudTrail的Amazon RDS故障通知，使用该主题调用AWS Lambda函数提升副本实例为主实例。</div> <div class="option-analysis"><strong>B.</strong> 创建Aurora自定义端点指向主数据库实例，配置应用程序使用此端点，配置AWS CloudTrail运行AWS Lambda函数提升副本实例并修改自定义端点指向新提升的实例。</div> <div class="option-analysis"><strong>C.</strong> 创建AWS Lambda函数修改应用程序的AWS CloudFormation模板来提升副本，应用模板更新堆栈并将应用程序指向新提升的实例，创建Amazon CloudWatch告警在故障事件发生后调用此Lambda函数。</div> <div class="option-analysis"><strong>D.</strong> 将Aurora端点存储在AWS Systems Manager Parameter Store中，创建Amazon EventBridge事件检测数据库故障并运行AWS Lambda函数提升副本实例和更新存储在AWS Systems Manager Parameter Store中的端点URL，编码应用程序在数据库连接失败时从Parameter Store重新加载端点。<div class="section-title"><strong>核心要求:</strong></div> 自动化跨Region Aurora副本提升并实现应用程序端点切换 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• Amazon EventBridge-检测数据库故障事件 </div><div class="compact-content">• <span class="key-service">AWS Systems Manager</span> Parameter Store-存储和动态更新数据库端点 </div><div class="compact-content">• <span class="key-service">AWS Lambda</span>-执行副本提升和端点更新逻辑 <div class="section-title"><strong>正确答案D:</strong></div> 使用EventBridge检测故障触发Lambda自动提升副本，通过Parameter Store实现端点动态切换，应用程序具备故障时重新加载端点的能力 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A-Route 53健康检查无法直接触发副本提升，CloudTrail不是实时事件检测的最佳选择 </div><div class="compact-content">• 选项B-CloudTrail用于审计而非实时故障检测，自定义端点无法跨Region工作 </div><div class="compact-content">• 选项C-通过CloudFormation模板更新过于复杂且响应时间长，不适合故障切换场景 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-EventBridge提供实时事件检测，Parameter Store支持快速端点切换 </div><div class="compact-content">• 成本-使用托管服务避免复杂基础设施，按需付费模式 </div><div class="compact-content">• 可扩展性-Parameter Store支持多应用程序实例同时访问，Lambda自动扩展</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: D</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-45">
            <div class="question-header">
                <div class="question-title">Question #45 ✅ ⚪ <small style="float: right;">(45/353)</small></div>
            </div>
            <div class="question-content">A company hosts its staging website using an <span class="key-service">Amazon EC2</span> instance backed with Amazon EBS storage. The company wants to recover quickly with minimal data losses in the event of network connectivity issues or power failures on the EC2 instance. Which solution will meet these requirements? C (94%) A (3%)</div>
            <div class="options-container">                <div class="option correct-answer"><strong>A.</strong> Add the instance to an EC2 Auto Scaling group with the minimum, maximum, and desired capacity set to 1.</div>                <div class="option"><strong>B.</strong> Add the instance to an EC2 Auto Scaling group with a lifecycle hook to detach the EBS volume when the EC2 instance shuts down or terminates.</div>                <div class="option"><strong>C.</strong> Create an <span class="key-service">Amazon CloudWatch</span> alarm for the StatusCheckFailed System metric and select the EC2 action to recover the instance.</div>                <div class="option"><strong>D.</strong> Create an <span class="key-service">Amazon CloudWatch</span> alarm for the StatusCheckFailed Instance metric and select the EC2 action to reboot the instance.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司使用由Amazon EBS存储支持的Amazon EC2实例托管其预发布网站。公司希望在EC2实例发生网络连接问题或电源故障时能够快速恢复并最小化数据丢失。哪种解决方案能满足这些要求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 将实例添加到EC2 Auto Scaling组中，最小、最大和期望容量都设置为1</div> <div class="option-analysis"><strong>B.</strong> 将实例添加到EC2 Auto Scaling组中，使用生命周期钩子在EC2实例关闭或终止时分离EBS卷</div> <div class="option-analysis"><strong>C.</strong> 为StatusCheckFailed System指标创建Amazon CloudWatch告警，并选择EC2操作来恢复实例</div> <div class="option-analysis"><strong>D.</strong> 为StatusCheckFailed Instance指标创建Amazon CloudWatch告警，并选择EC2操作来重启实例<div class="section-title"><strong>核心要求:</strong></div> 在网络连接问题或电源故障时快速恢复并最小化数据丢失 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• EC2 Auto Scaling-自动替换失败实例并保持期望容量 </div><div class="compact-content">• CloudWatch告警-监控实例状态并触发自动化恢复操作 <div class="section-title"><strong>正确答案A:</strong></div> Auto Scaling组会自动检测实例故障并启动新实例替换失败的实例，EBS卷会自动附加到新实例，确保数据完整性和快速恢复 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项B-生命周期钩子分离EBS卷会导致数据无法自动恢复到新实例 </div><div class="compact-content">• 选项C-System状态检查失败通常需要AWS介入，恢复时间较长 </div><div class="compact-content">• 选项D-Instance状态检查失败时重启可能无法解决硬件故障问题 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-Auto Scaling提供最快的自动故障转移 </div><div class="compact-content">• 成本-所有方案成本相近，但A方案自动化程度最高 </div><div class="compact-content">• 可扩展性-Auto Scaling组提供了未来扩展的基础架构</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: A</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-46">
            <div class="question-header">
                <div class="question-title">Question #46 ✅ ⚪ <small style="float: right;">(46/353)</small></div>
            </div>
            <div class="question-content">A company wants to use AWS development tools to replace its current bash deployment scripts. The company currently deploys a LAMP application to a group of <span class="key-service">Amazon EC2</span> instances behind an Application Load Balancer (ALB). During the deployments, the company unit tests the committed application, stops and starts services, unregisters and re-registers instances with the load balancer, and updates file permissions. The company wants to maintain the same deployment functionality through the shift to using AWS services. Which solution will meet these requirements? D (89%) 11%</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Use <span class="key-service">AWS CodeBuild</span> to test the application. Use bash scripts invoked by <span class="key-service">AWS CodeDeploy</span>'s appspec.yml file to restart services, and deregister and register instances with the AL<div class="option-analysis"><strong>B.</strong> Use the appspec.yml file to update file permissions without a custom script.</div></div>                <div class="option"><strong>B.</strong> Use <span class="key-service">AWS CodePipeline</span> to move the application from the <span class="key-service">AWS CodeCommit</span> repository to <span class="key-service">AWS CodeDeploy</span>. Use CodeDeploy's deployment group to test the application, unregister and re-register instances with the ALB, and restart services. Use the appspec.yml file to update file permissions without a custom script.</div>                <div class="option"><strong>C.</strong> Use <span class="key-service">AWS CodePipeline</span> to move the application source code from the <span class="key-service">AWS CodeCommit</span> repository to <span class="key-service">AWS CodeDeploy</span>. Use CodeDeploy to test the application. Use CodeDeploy's appspec.yml file to restart services and update permissions without a custom script. Use <span class="key-service">AWS CodeBuild</span> to unregister and re-register instances with the ALB.</div>                <div class="option correct-answer"><strong>D.</strong> Use <span class="key-service">AWS CodePipeline</span> to trigger <span class="key-service">AWS CodeBuild</span> to test the application. Use bash scripts invoked by <span class="key-service">AWS CodeDeploy</span>'s appspec.yml file to restart services. Unregister and re-register the instances in the <span class="key-service">AWS CodeDeploy</span> deployment group with the AL<div class="option-analysis"><strong>B.</strong> Update the appspec.yml file to update file permissions without a custom script.</div></div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司希望使用AWS开发工具来替换当前的bash部署脚本。公司目前将LAMP应用程序部署到Application Load Balancer (ALB)后面的一组Amazon EC2实例上。在部署过程中，公司对提交的应用程序进行单元测试，停止和启动服务，从负载均衡器注销和重新注册实例，并更新文件权限。公司希望在转向使用AWS服务时保持相同的部署功能。哪种解决方案能满足这些要求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 使用AWS CodeBuild测试应用程序。使用AWS CodeDeploy的appspec.yml文件调用bash脚本来重启服务，并从ALB注销和注册实例。使用appspec.yml文件更新文件权限而无需自定义脚本。</div> <div class="option-analysis"><strong>B.</strong> 使用AWS CodePipeline将应用程序从AWS CodeCommit存储库移动到AWS CodeDeploy。使用CodeDeploy的部署组测试应用程序，从ALB注销和重新注册实例，并重启服务。使用appspec.yml文件更新文件权限而无需自定义脚本。</div> <div class="option-analysis"><strong>C.</strong> 使用AWS CodePipeline将应用程序源代码从AWS CodeCommit存储库移动到AWS CodeDeploy。使用CodeDeploy测试应用程序。使用CodeDeploy的appspec.yml文件重启服务和更新权限而无需自定义脚本。使用AWS CodeBuild从ALB注销和重新注册实例。</div> <div class="option-analysis"><strong>D.</strong> 使用AWS CodePipeline触发AWS CodeBuild测试应用程序。使用AWS CodeDeploy的appspec.yml文件调用bash脚本重启服务。在AWS CodeDeploy部署组中从ALB注销和重新注册实例。更新appspec.yml文件以更新文件权限而无需自定义脚本。<div class="section-title"><strong>核心要求:</strong></div> 使用AWS开发工具替换bash脚本实现完整的LAMP应用部署流程 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• <span class="key-service">AWS CodePipeline</span>-编排整个CI/CD流程 </div><div class="compact-content">• <span class="key-service">AWS CodeBuild</span>-执行单元测试 </div><div class="compact-content">• <span class="key-service">AWS CodeDeploy</span>-处理应用部署和实例管理 <div class="section-title"><strong>正确答案D:</strong></div> CodePipeline编排流程，CodeBuild执行测试，CodeDeploy通过部署组自动处理ALB实例注销/注册，appspec.yml管理服务重启和权限更新 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A-缺少CodePipeline编排，无法形成完整的CI/CD流程 </div><div class="compact-content">• 选项B-CodeDeploy部署组不负责应用测试功能 </div><div class="compact-content">• 选项C-CodeBuild不能处理ALB实例注销/注册操作 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-CodePipeline提供完整的自动化流程编排 </div><div class="compact-content">• 成本-使用托管服务减少维护开销 </div><div class="compact-content">• 可扩展性-CodeDeploy部署组自动管理实例生命周期</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: D</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-47">
            <div class="question-header">
                <div class="question-title">Question #47 ✅ 📝 <small style="float: right;">(47/353)</small></div>
            </div>
            <div class="question-content">A company runs an application with an <span class="key-service">Amazon EC2</span> and on-premises configuration. A DevOps engineer needs to standardize patching across both environments. Company policy dictates that patching only happens during non-business hours. Which combination of actions will meet these requirements? (Choose three.) ABF (89%) 11%</div>
            <div class="options-container">                <div class="option correct-answer"><strong>A.</strong> Add the physical machines into <span class="key-service">AWS Systems Manager</span> using Systems Manager Hybrid Activations.</div>                <div class="option correct-answer"><strong>B.</strong> Attach an IAM role to the EC2 instances, allowing them to be managed by <span class="key-service">AWS Systems Manager</span>.</div>                <div class="option"><strong>C.</strong> Create IAM access keys for the on-premises machines to interact with <span class="key-service">AWS Systems Manager</span>.</div>                <div class="option"><strong>D.</strong> Run an <span class="key-service">AWS Systems Manager</span> Automation document to patch the systems every hour.</div>                <div class="option"><strong>E.</strong> Use Amazon EventBridge scheduled events to schedule a patch window. F. Use <span class="key-service">AWS Systems Manager</span> Maintenance Windows to schedule a patch window. Most Voted</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司在Amazon EC2和本地环境中运行应用程序。DevOps工程师需要在两个环境中标准化补丁管理。公司政策规定补丁只能在非营业时间进行。哪些操作组合能满足这些要求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 使用AWS Systems Manager Hybrid Activations将物理机器添加到AWS Systems Manager中</div> <div class="option-analysis"><strong>B.</strong> 为EC2实例附加IAM角色，允许它们被AWS Systems Manager管理</div> <div class="option-analysis"><strong>C.</strong> 为本地机器创建IAM访问密钥以与AWS Systems Manager交互</div> <div class="option-analysis"><strong>D.</strong> 运行AWS Systems Manager Automation文档每小时对系统进行补丁</div> <div class="option-analysis"><strong>E.</strong> 使用Amazon EventBridge计划事件来安排补丁窗口 F. 使用AWS Systems Manager Maintenance Windows来安排补丁窗口<div class="section-title"><strong>核心要求:</strong></div> 在混合环境中实现标准化补丁管理，且仅在非营业时间执行 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• <span class="key-service">AWS Systems Manager</span> - 统一管理EC2和本地服务器的补丁和配置 </div><div class="compact-content">• Systems Manager Hybrid Activations - 将本地服务器纳入AWS管理 </div><div class="compact-content">• IAM角色 - 为EC2实例提供Systems Manager访问权限 <strong>正确答案ABF:</strong> A和B建立了混合环境的基础管理能力，F提供了符合业务时间要求的调度机制 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项C - 本地机器应使用Hybrid Activations而非IAM访问密钥 </div><div class="compact-content">• 选项D - 每小时执行违反了非营业时间的政策要求 </div><div class="compact-content">• 选项E - EventBridge可以调度但Systems Manager Maintenance Windows更适合补丁管理 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能 - Systems Manager提供统一的补丁管理界面 </div><div class="compact-content">• 成本 - 利用现有AWS服务避免第三方工具成本 </div><div class="compact-content">• 可扩展性 - 混合激活支持大规模本地服务器管理</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: AB (A、B)</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-48">
            <div class="question-header">
                <div class="question-title">Question #48 ✅ ⚪ <small style="float: right;">(48/353)</small></div>
            </div>
            <div class="question-content">A company has chosen AWS to host a new application. The company needs to implement a multi-account strategy. A DevOps engineer creates a new AWS account and an organization in <span class="key-service">AWS Organizations</span>. The DevOps engineer also creates the OU structure for the organization and sets up a landing zone by using AWS Control Tower. The DevOps engineer must implement a solution that automatically deploys resources for new accounts that users create through AWS Control Tower Account Factory. When a user creates a new account, the solution must apply <span class="key-service">AWS CloudFormation</span> templates and SCPs that are customized for the OU or the account to automatically deploy all the resources that are attached to the account. All the OUs are enrolled in AWS Control Tower. Which solution will meet these requirements in the MOST automated way? D (91%) 9%</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Use AWS Service Catalog with AWS Control Tower. Create portfolios and products in AWS Service Catalog. Grant granular permissions to provision these resources. Deploy SCPs by using the AWS CLI and JSON documents.</div>                <div class="option"><strong>B.</strong> Deploy CloudFormation stack sets by using the required templates. Enable automatic deployment. Deploy stack instances to the required accounts. Deploy a CloudFormation stack set to the organization's management account to deploy SCPs.</div>                <div class="option"><strong>C.</strong> Create an Amazon EventBridge rule to detect the CreateManagedAccount event. Configure AWS Service Catalog as the target to deploy resources to any new accounts. Deploy SCPs by using the AWS CLI and JSON documents.</div>                <div class="option correct-answer"><strong>D.</strong> Deploy the Customizations for AWS Control Tower (CfCT) solution. Use an <span class="key-service">AWS CodeCommit</span> repository as the source. In the repository, create a custom package that includes the CloudFormation templates and the <span class="key-service">SCP</span> JSON documents.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司选择AWS托管新应用程序，需要实施多账户策略。DevOps工程师创建了新的AWS账户和AWS Organizations组织，创建了OU结构并使用AWS Control Tower设置了landing zone。工程师必须实施一个解决方案，当用户通过AWS Control Tower Account Factory创建新账户时，自动部署资源，应用为OU或账户定制的CloudFormation模板和SCP，自动部署所有附加到账户的资源。所有OU都已注册到AWS Control Tower。哪个解决方案能以最自动化的方式满足这些要求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 使用AWS Service Catalog与AWS Control Tower配合，在AWS Service Catalog中创建产品组合和产品，授予精细权限来配置这些资源，使用AWS CLI和JSON文档部署SCP</div> <div class="option-analysis"><strong>B.</strong> 使用所需模板部署CloudFormation stack sets并启用自动部署，将stack实例部署到所需账户，向组织管理账户部署CloudFormation stack set来部署SCP</div> <div class="option-analysis"><strong>C.</strong> 创建Amazon EventBridge规则检测CreateManagedAccount事件，配置AWS Service Catalog作为目标向新账户部署资源，使用AWS CLI和JSON文档部署SCP</div> <div class="option-analysis"><strong>D.</strong> 部署Customizations for AWS Control Tower (CfCT)解决方案，使用AWS CodeCommit存储库作为源，在存储库中创建包含CloudFormation模板和SCP JSON文档的自定义包<div class="section-title"><strong>核心要求:</strong></div> 在AWS Control Tower环境中实现新账户创建时的全自动资源部署和SCP应用 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• AWS Control Tower - 多账户管理和landing zone设置 </div><div class="compact-content">• Customizations for AWS Control Tower (CfCT) - Control Tower的官方自定义解决方案 </div><div class="compact-content">• CloudFormation - 基础设施即代码模板部署 </div><div class="compact-content">• <span class="key-service">SCP</span> - 服务控制策略管理 <div class="section-title"><strong>正确答案D:</strong></div> CfCT是AWS官方提供的Control Tower自定义解决方案，专门设计用于在Account Factory创建新账户时自动部署CloudFormation模板和SCP，与Control Tower原生集成，提供最高程度的自动化 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A - Service Catalog需要手动操作来配置资源，不能实现完全自动化的账户创建流程 </div><div class="compact-content">• 选项B - CloudFormation stack sets无法与Control Tower Account Factory的账户创建事件自动集成 </div><div class="compact-content">• 选项C - EventBridge方案需要自定义开发和维护，复杂度高且不如官方CfCT解决方案可靠 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能 - CfCT提供与Control Tower的原生集成和最佳性能 </div><div class="compact-content">• 成本 - 使用AWS官方解决方案避免自定义开发和维护成本 </div><div class="compact-content">• 可扩展性 - CfCT支持大规模多账户环境的自动化管理</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: D</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-49">
            <div class="question-header">
                <div class="question-title">Question #49 ✅ ⚪ <small style="float: right;">(49/353)</small></div>
            </div>
            <div class="question-content">An online retail company based in the United States plans to expand its operations to Europe and Asia in the next six months. Its product currently runs on <span class="key-service">Amazon EC2</span> instances behind an Application Load Balancer. The instances run in an <span class="key-service">Amazon EC2</span> Auto Scaling group across multiple Availability Zones. All data is stored in an Amazon Aurora database instance. When the product is deployed in multiple regions, the company wants a single product catalog across all regions, but for compliance purposes, its customer information and purchases must be kept in each region. How should the company meet these requirements with the LEAST amount of application changes? C (100%)</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Use Amazon Redshift for the product catalog and <span class="key-service">Amazon DynamoDB</span> tables for the customer information and purchases.</div>                <div class="option"><strong>B.</strong> Use <span class="key-service">Amazon DynamoDB</span> global tables for the product catalog and regional tables for the customer information and purchases.</div>                <div class="option correct-answer"><strong>C.</strong> Use Aurora with read replicas for the product catalog and additional local Aurora instances in each region for the customer information and purchases.</div>                <div class="option"><strong>D.</strong> Use Aurora for the product catalog and <span class="key-service">Amazon DynamoDB</span> global tables for the customer information and purchases.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家美国在线零售公司计划在未来六个月内将业务扩展到欧洲和亚洲。其产品目前运行在Application Load Balancer后的Amazon EC2实例上，实例在多个可用区的Amazon EC2 Auto Scaling组中运行。所有数据存储在Amazon Aurora数据库实例中。当产品部署在多个区域时，公司希望在所有区域中使用单一产品目录，但出于合规目的，客户信息和购买记录必须保存在各自区域中。公司应如何以最少的应用程序更改来满足这些要求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 使用Amazon Redshift存储产品目录，使用Amazon DynamoDB表存储客户信息和购买记录</div> <div class="option-analysis"><strong>B.</strong> 使用Amazon DynamoDB全球表存储产品目录，使用区域表存储客户信息和购买记录</div> <div class="option-analysis"><strong>C.</strong> 使用带有只读副本的Aurora存储产品目录，在每个区域使用额外的本地Aurora实例存储客户信息和购买记录</div> <div class="option-analysis"><strong>D.</strong> 使用Aurora存储产品目录，使用Amazon DynamoDB全球表存储客户信息和购买记录<div class="section-title"><strong>核心要求:</strong></div> 实现全球产品目录共享和区域客户数据隔离，同时最小化应用程序更改 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• Aurora-关系型数据库，支持跨区域只读副本实现数据同步 </div><div class="compact-content">• DynamoDB Global Tables-NoSQL全球表，自动多区域复制 <div class="section-title"><strong>正确答案C:</strong></div> Aurora只读副本可实现产品目录的全球同步访问，各区域独立Aurora实例确保客户数据合规隔离，保持现有关系型数据库架构无需应用程序重构 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A-Redshift是数据仓库服务不适合OLTP场景，且需要重大应用程序架构变更 </div><div class="compact-content">• 选项B-从Aurora迁移到DynamoDB需要重写应用程序数据访问层，违反最少更改原则 </div><div class="compact-content">• 选项D-DynamoDB Global Tables会在所有区域复制客户数据，违反合规要求 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-Aurora只读副本提供低延迟的全球产品目录访问 </div><div class="compact-content">• 成本-利用现有Aurora架构避免数据迁移和应用重构成本 </div><div class="compact-content">• 可扩展性-Aurora支持自动扩展，只读副本可按需添加到新区域</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: C</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-50">
            <div class="question-header">
                <div class="question-title">Question #50 ✅ ⚪ <small style="float: right;">(50/353)</small></div>
            </div>
            <div class="question-content">A company is implementing a well-architected design for its globally accessible API stack. The design needs to ensure both high reliability and fast response times for users located in North America and Europe. The API stack contains the following three tiers: - <span class="key-service">Amazon API Gateway</span> - <span class="key-service">AWS Lambda</span> - <span class="key-service">Amazon DynamoDB</span> Which solution will meet the requirements? B (100%) Unlock free, top-quality video courses on ExamTopics with a simple registration. Elevate your learning journey with our expertly curated content. Register now to access a diverse range of educational resources designed for success!</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Configure <span class="key-service">Amazon Route 53</span> to point to API Gateway APIs in North America and Europe using health checks. Configure the APIs to forward requests to a Lambda function in that Region. Configure the Lambda functions to retrieve and update the data in a DynamoDB table in the same Region as the Lambda function.</div>                <div class="option correct-answer"><strong>B.</strong> Configure <span class="key-service">Amazon Route 53</span> to point to API Gateway APIs in North America and Europe using latency-based routing and health checks. Configure the APIs to forward requests to a Lambda function in that Region. Configure the Lambda functions to retrieve and update the data in a DynamoDB global table.</div>                <div class="option"><strong>C.</strong> Configure <span class="key-service">Amazon Route 53</span> to point to API Gateway in North America, create a disaster recovery API in Europe, and configure both APIs to forward requests to the Lambda functions in that Region. Retrieve the data from a DynamoDB global table. Deploy a Lambda function to check the North America API health every 5 minutes. In the event of a failure, update Route 53 to point to the disaster recovery API.</div>                <div class="option"><strong>D.</strong> Configure <span class="key-service">Amazon Route 53</span> to point to API Gateway API in North America using latency-based routing. Configure the API to forward requests to the Lambda function in the Region nearest to the user. Configure the Lambda function to retrieve and update the data in a DynamoDB table.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司正在为其全球可访问的API堆栈实施良好架构设计。该设计需要确保位于北美和欧洲的用户具有高可靠性和快速响应时间。API堆栈包含三层：<span class="key-service">Amazon API Gateway</span>、<span class="key-service">AWS Lambda</span>、<span class="key-service">Amazon DynamoDB</span>。 <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 配置Amazon Route 53使用健康检查指向北美和欧洲的API Gateway API，配置API将请求转发到该Region的Lambda函数，配置Lambda函数在与Lambda函数相同Region的DynamoDB表中检索和更新数据。</div> <div class="option-analysis"><strong>B.</strong> 配置Amazon Route 53使用基于延迟的路由和健康检查指向北美和欧洲的API Gateway API，配置API将请求转发到该Region的Lambda函数，配置Lambda函数从DynamoDB全球表中检索和更新数据。</div> <div class="option-analysis"><strong>C.</strong> 配置Amazon Route 53指向北美的API Gateway，在欧洲创建灾难恢复API，配置两个API将请求转发到该Region的Lambda函数，从DynamoDB全球表检索数据，部署Lambda函数每5分钟检查北美API健康状况，故障时更新Route 53指向灾难恢复API。</div> <div class="option-analysis"><strong>D.</strong> 配置Amazon Route 53使用基于延迟的路由指向北美的API Gateway API，配置API将请求转发到距离用户最近Region的Lambda函数，配置Lambda函数在DynamoDB表中检索和更新数据。<div class="section-title"><strong>核心要求:</strong></div> 为全球用户提供高可靠性和快速响应时间的API服务 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• Route 53-提供基于延迟的路由和健康检查 </div><div class="compact-content">• API Gateway-多区域部署提供就近访问 </div><div class="compact-content">• DynamoDB Global Tables-实现跨区域数据同步 <div class="section-title"><strong>正确答案B:</strong></div> 使用基于延迟的路由确保用户访问最近的API端点，结合健康检查保证高可用性，DynamoDB全球表实现跨区域数据一致性 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A-缺少基于延迟的路由，无法保证最优响应时间，且使用独立的区域DynamoDB表无法保证数据一致性 </div><div class="compact-content">• 选项C-采用主备模式而非主主模式，无法充分利用多区域优势，且自定义健康检查复杂度高 </div><div class="compact-content">• 选项D-仅在北美部署API Gateway，欧洲用户仍需跨区域访问，无法实现真正的就近服务 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-基于延迟路由+多区域部署确保最佳响应时间 </div><div class="compact-content">• 成本-避免复杂的自定义监控方案，使用托管服务 </div><div class="compact-content">• 可扩展性-全球表支持无限扩展和自动故障转移</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: B</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-51">
            <div class="question-header">
                <div class="question-title">Question #51 ✅ ⚪ <small style="float: right;">(51/353)</small></div>
            </div>
            <div class="question-content">A rapidly growing company wants to scale for developer demand for AWS development environments. Development environments are created manually in the AWS Management Console. The networking team uses <span class="key-service">AWS CloudFormation</span> to manage the networking infrastructure, exporting stack output values for the <span class="key-service">Amazon <span class="key-service">VPC</span></span> and all subnets. The development environments have common standards, such as Application Load Balancers, <span class="key-service">Amazon EC2</span> Auto Scaling groups, security groups, and <span class="key-service">Amazon DynamoDB</span> tables. To keep up with demand, the DevOps engineer wants to automate the creation of development environments. Because the infrastructure required to support the application is expected to grow, there must be a way to easily update the deployed infrastructure. CloudFormation will be used to create a template for the development environments. Which approach will meet these requirements and quickly provide consistent AWS environments for developers? C (77%) B (23%)</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Use Fn::ImportValue intrinsic functions in the Resources section of the template to retrieve Virtual Private Cloud (<span class="key-service">VPC</span>) and subnet values. Use CloudFormation StackSets for the development environments, using the Count input parameter to indicate the number of environments needed. Use the UpdateStackSet command to update existing development environments.</div>                <div class="option"><strong>B.</strong> Use nested stacks to define common infrastructure components. To access the exported values, use TemplateURL to reference the networking team's template. To retrieve Virtual Private Cloud (<span class="key-service">VPC</span>) and subnet values, use Fn::ImportValue intrinsic functions in the Parameters section of the root template. Use the CreateChangeSet and ExecuteChangeSet commands to update existing development environments.</div>                <div class="option correct-answer"><strong>C.</strong> Use nested stacks to define common infrastructure components. Use Fn::ImportValue intrinsic functions with the resources of the nested stack to retrieve Virtual Private Cloud (<span class="key-service">VPC</span>) and subnet values. Use the CreateChangeSet and ExecuteChangeSet commands to update existing development environments.</div>                <div class="option"><strong>D.</strong> Use Fn::ImportValue intrinsic functions in the Parameters section of the root template to retrieve Virtual Private Cloud (<span class="key-service">VPC</span>) and subnet values. Define the development resources in the order they need to be created in the CloudFormation nested stacks. Use the CreateChangeSet and ExecuteChangeSet commands to update existing development environments.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家快速增长的公司希望扩展以满足开发者对AWS开发环境的需求。开发环境目前在AWS Management Console中手动创建。网络团队使用AWS CloudFormation管理网络基础设施，导出VPC和所有子网的堆栈输出值。开发环境有通用标准，如Application Load Balancers、<span class="key-service">Amazon EC2</span> Auto Scaling组、安全组和Amazon DynamoDB表。为跟上需求，DevOps工程师希望自动化创建开发环境。由于支持应用程序所需的基础设施预计会增长，必须有一种方法来轻松更新已部署的基础设施。将使用CloudFormation为开发环境创建模板。哪种方法能满足这些要求并快速为开发者提供一致的AWS环境？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 在模板的Resources部分使用Fn::ImportValue内在函数检索VPC和子网值。对开发环境使用CloudFormation StackSets，使用Count输入参数指示所需环境数量。使用UpdateStackSet命令更新现有开发环境。</div> <div class="option-analysis"><strong>B.</strong> 使用嵌套堆栈定义通用基础设施组件。要访问导出值，使用TemplateURL引用网络团队的模板。要检索VPC和子网值，在根模板的Parameters部分使用Fn::ImportValue内在函数。使用CreateChangeSet和ExecuteChangeSet命令更新现有开发环境。</div> <div class="option-analysis"><strong>C.</strong> 使用嵌套堆栈定义通用基础设施组件。在嵌套堆栈的资源中使用Fn::ImportValue内在函数检索VPC和子网值。使用CreateChangeSet和ExecuteChangeSet命令更新现有开发环境。</div> <div class="option-analysis"><strong>D.</strong> 在根模板的Parameters部分使用Fn::ImportValue内在函数检索VPC和子网值。在CloudFormation嵌套堆栈中按创建顺序定义开发资源。使用CreateChangeSet和ExecuteChangeSet命令更新现有开发环境。<div class="section-title"><strong>核心要求:</strong></div> 自动化创建标准化开发环境并支持基础设施更新 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• CloudFormation嵌套堆栈-模块化管理通用基础设施组件 </div><div class="compact-content">• Fn::ImportValue-从其他堆栈导入导出值 </div><div class="compact-content">• ChangeSet-安全预览和执行堆栈更新 <div class="section-title"><strong>正确答案C:</strong></div> 使用嵌套堆栈实现组件复用，在嵌套堆栈资源中正确使用Fn::ImportValue导入网络值，通过ChangeSet安全更新 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A-StackSets用于跨账户/区域部署，不适合单账户多环境场景 </div><div class="compact-content">• 选项B-Fn::ImportValue不能在Parameters部分使用，且TemplateURL用法错误 </div><div class="compact-content">• 选项D-Fn::ImportValue在Parameters部分使用错误，应在Resources部分使用 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-嵌套堆栈提供模块化和复用性 </div><div class="compact-content">• 成本-避免重复定义通用组件降低维护成本 </div><div class="compact-content">• 可扩展性-ChangeSet支持安全的基础设施演进和更新</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: C</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-52">
            <div class="question-header">
                <div class="question-title">Question #52 ✅ ⚪ <small style="float: right;">(52/353)</small></div>
            </div>
            <div class="question-content">A company uses <span class="key-service">AWS Organizations</span> to manage multiple accounts. Information security policies require that all unencrypted Amazon EBS volumes be marked as non-compliant. A DevOps engineer needs to automatically deploy the solution and ensure that this compliance check is always present. Which solution will accomplish this? B (100%)</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Create an <span class="key-service">AWS CloudFormation</span> template that defines an AWS Inspector rule to check whether EBS encryption is enabled. Save the template to an <span class="key-service">Amazon S3</span> bucket that has been shared with all accounts within the company. Update the account creation script pointing to the CloudFormation template in <span class="key-service">Amazon S3</span>.</div>                <div class="option correct-answer"><strong>B.</strong> Create an <span class="key-service">AWS Config</span> organizational rule to check whether EBS encryption is enabled and deploy the rule using the AWS CLI. Create and apply an <span class="key-service">SCP</span> to prohibit stopping and deleting <span class="key-service">AWS Config</span> across the organization.</div>                <div class="option"><strong>C.</strong> Create an <span class="key-service">SCP</span> in Organizations. Set the policy to prevent the launch of <span class="key-service">Amazon EC2</span> instances without encryption on the EBS volumes using a conditional expression. Apply the <span class="key-service">SCP</span> to all AWS accounts. Use Amazon Athena to analyze the <span class="key-service">AWS CloudTrail</span> output, looking for events that deny an ec2:RunInstances action.</div>                <div class="option"><strong>D.</strong> Deploy an IAM role to all accounts from a single trusted account. Build a pipeline with <span class="key-service">AWS CodePipeline</span> with a stage in <span class="key-service">AWS Lambda</span> to assume the IAM role, and list all EBS volumes in the account. Publish a report to <span class="key-service">Amazon S3</span>.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司使用AWS Organizations管理多个账户。信息安全策略要求所有未加密的Amazon EBS卷都标记为不合规。DevOps工程师需要自动部署解决方案并确保此合规检查始终存在。哪个解决方案能实现这一目标？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 创建AWS CloudFormation模板定义AWS Inspector规则检查EBS加密是否启用，将模板保存到与公司所有账户共享的Amazon S3存储桶，更新账户创建脚本指向S3中的CloudFormation模板。</div> <div class="option-analysis"><strong>B.</strong> 创建AWS Config组织规则检查EBS加密是否启用并使用AWS CLI部署规则，创建并应用SCP禁止在整个组织中停止和删除AWS Config。</div> <div class="option-analysis"><strong>C.</strong> 在Organizations中创建SCP，设置策略使用条件表达式阻止启动EBS卷未加密的EC2实例，将SCP应用到所有AWS账户，使用Amazon Athena分析AWS CloudTrail输出查找拒绝ec2:RunInstances操作的事件。</div> <div class="option-analysis"><strong>D.</strong> 从单个受信任账户向所有账户部署IAM角色，使用AWS CodePipeline构建管道在AWS Lambda阶段承担IAM角色并列出账户中所有EBS卷，将报告发布到Amazon S3。<div class="section-title"><strong>核心要求:</strong></div> 在多账户环境中自动检测未加密EBS卷的合规性并确保检查机制持续存在 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• <span class="key-service">AWS Config</span> - 提供资源配置监控和合规性检查 </div><div class="compact-content">• <span class="key-service">AWS Organizations</span> - 管理多账户环境和组织级策略 </div><div class="compact-content">• <span class="key-service">SCP</span> - 服务控制策略，限制账户级别的操作权限 <div class="section-title"><strong>正确答案B:</strong></div> 使用AWS Config组织规则实现跨账户EBS加密合规检查，通过SCP保护Config服务不被删除确保持续监控 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A - AWS Inspector主要用于安全漏洞评估，不是配置合规检查的最佳工具 </div><div class="compact-content">• 选项C - SCP只能预防创建未加密卷，无法检测现有未加密卷的合规状态 </div><div class="compact-content">• 选项D - 需要手动构建复杂管道，缺乏自动化且无法确保持续运行 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能 - Config组织规则提供实时合规监控和自动化检测 </div><div class="compact-content">• 成本 - 使用托管服务避免自建解决方案的开发和维护成本 </div><div class="compact-content">• 可扩展性 - 组织级规则自动应用到所有账户，SCP确保服务持续可用</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: B</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-53">
            <div class="question-header">
                <div class="question-title">Question #53 ✅ 📝 <small style="float: right;">(53/353)</small></div>
            </div>
            <div class="question-content">A company is performing vulnerability scanning for all <span class="key-service">Amazon EC2</span> instances across many accounts. The accounts are in an organization in <span class="key-service">AWS Organizations</span>. Each account's VPCs are attached to a shared transit gateway. The VPCs send traffic to the internet through a central egress <span class="key-service">VPC</span>. The company has enabled Amazon Inspector in a delegated administrator account and has enabled scanning for all member accounts. A DevOps engineer discovers that some EC2 instances are listed in the "not scanning" tab in Amazon Inspector. Which combination of actions should the DevOps engineer take to resolve this issue? (Choose three.) ABE (100%)</div>
            <div class="options-container">                <div class="option correct-answer"><strong>A.</strong> Verify that <span class="key-service">AWS Systems Manager</span> Agent is installed and is running on the EC2 instances that Amazon Inspector is not scanning.</div>                <div class="option correct-answer"><strong>B.</strong> Associate the target EC2 instances with security groups that allow outbound communication on port 443 to the <span class="key-service">AWS Systems Manager</span> service endpoint.</div>                <div class="option correct-answer"><strong>C.</strong> Grant inspector:StartAssessmentRun permissions to the IAM role that the DevOps engineer is using.</div>                <div class="option"><strong>D.</strong> Configure EC2 Instance Connect for the EC2 instances that Amazon Inspector is not scanning.</div>                <div class="option"><strong>E.</strong> Associate the target EC2 instances with instance profiles that grant permissions to communicate with <span class="key-service">AWS Systems Manager</span>. F. Create a managed-instance activation. Use the Activation Code and the Activation ID to register the EC2 instances.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司正在对AWS Organizations组织中多个账户的所有Amazon EC2实例执行漏洞扫描。各账户的VPC连接到共享的transit gateway，VPC通过中央出口VPC向互联网发送流量。公司已在委托管理员账户中启用Amazon Inspector并为所有成员账户启用扫描。DevOps工程师发现某些EC2实例在Amazon Inspector的"not scanning"标签中列出。DevOps工程师应采取哪些操作组合来解决此问题？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 验证AWS Systems Manager Agent已安装并在Amazon Inspector未扫描的EC2实例上运行</div> <div class="option-analysis"><strong>B.</strong> 将目标EC2实例与允许通过端口443向AWS Systems Manager服务端点进行出站通信的安全组关联</div> <div class="option-analysis"><strong>C.</strong> 向DevOps工程师使用的IAM角色授予inspector:StartAssessmentRun权限</div> <div class="option-analysis"><strong>D.</strong> 为Amazon Inspector未扫描的EC2实例配置EC2 Instance Connect</div> <div class="option-analysis"><strong>E.</strong> 将目标EC2实例与授予与AWS Systems Manager通信权限的实例配置文件关联 F. 创建托管实例激活，使用激活代码和激活ID注册EC2实例<div class="section-title"><strong>核心要求:</strong></div> 解决Amazon Inspector无法扫描某些EC2实例的问题 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• Amazon Inspector - 自动化安全评估服务，需要Systems Manager Agent支持 </div><div class="compact-content">• <span class="key-service">AWS Systems Manager</span> - 提供实例管理和通信能力，Inspector扫描的基础依赖 <div class="section-title"><strong>正确答案ABC:</strong></div> Inspector扫描需要三个关键要素：A确保SSM Agent运行以建立通信通道，B确保网络连通性允许443端口访问Systems Manager端点，C确保IAM权限允许启动评估运行 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项D - EC2 Instance Connect用于SSH连接，与Inspector扫描功能无关 </div><div class="compact-content">• 选项E - 实例配置文件权限重要但不是直接解决扫描问题的关键因素 </div><div class="compact-content">• 选项F - 托管实例激活用于混合环境，EC2实例不需要此激活过程 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能 - SSM Agent和网络连通性确保扫描效率 </div><div class="compact-content">• 成本 - 利用现有Systems Manager基础设施，无额外成本 </div><div class="compact-content">• 可扩展性 - 统一的IAM权限和网络配置支持大规模扫描</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: ABC (A、B、C)</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-54">
            <div class="question-header">
                <div class="question-title">Question #54 ✅ ⚪ <small style="float: right;">(54/353)</small></div>
            </div>
            <div class="question-content">A development team uses <span class="key-service">AWS CodeCommit</span> for version control for applications. The development team uses <span class="key-service">AWS CodePipeline</span>, <span class="key-service">AWS CodeBuild</span>, and <span class="key-service">AWS CodeDeploy</span> for CI/CD infrastructure. In CodeCommit, the development team recently merged pull requests that did not pass long-running tests in the code base. The development team needed to perform rollbacks to branches in the codebase, resulting in lost time and wasted effort. A DevOps engineer must automate testing of pull requests in CodeCommit to ensure that reviewers more easily see the results of automated tests as part of the pull request review. What should the DevOps engineer do to meet this requirement? C (65%) B (20%) D (16%)</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Create an Amazon EventBridge rule that reacts to the pullRequestStatusChanged event. Create an <span class="key-service">AWS Lambda</span> function that invokes a CodePipeline pipeline with a CodeBuild action that runs the tests for the application. Program the Lambda function to post the CodeBuild badge as a comment on the pull request so that developers will see the badge in their code review.</div>                <div class="option"><strong>B.</strong> Create an Amazon EventBridge rule that reacts to the pullRequestCreated event. Create an <span class="key-service">AWS Lambda</span> function that invokes a CodePipeline pipeline with a CodeBuild action that runs the tests for the application. Program the Lambda function to post the CodeBuild test results as a comment on the pull request when the test results are complete.</div>                <div class="option"><strong>C.</strong> Create an Amazon EventBridge rule that reacts to pullRequestCreated and pullRequestSourceBranchUpdated events. Create an <span class="key-service">AWS Lambda</span> function that invokes a CodePipeline pipeline with a CodeBuild action that runs the tests for the application. Program the Lambda function to post the CodeBuild badge as a comment on the pull request so that developers will see the badge in their code review.</div>                <div class="option correct-answer"><strong>D.</strong> Create an Amazon EventBridge rule that reacts to the pullRequestStatusChanged event. Create an <span class="key-service">AWS Lambda</span> function that invokes a CodePipeline pipeline with a CodeBuild action that runs the tests for the application. Program the Lambda function to post the CodeBuild test results as a comment on the pull request when the test results are complete.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 开发团队使用AWS CodeCommit进行版本控制，使用AWS CodePipeline、AWS CodeBuild和AWS CodeDeploy构建CI/CD基础设施。在CodeCommit中，开发团队最近合并了未通过长时间运行测试的pull request，导致需要回滚分支，浪费时间和精力。DevOps工程师必须自动化CodeCommit中pull request的测试，确保审查者能够更容易地看到自动化测试结果作为pull request审查的一部分。 <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 创建Amazon EventBridge规则响应pullRequestStatusChanged事件，创建AWS Lambda函数调用带有CodeBuild操作的CodePipeline管道运行应用程序测试，编程Lambda函数将CodeBuild徽章作为评论发布到pull request中，以便开发者在代码审查中看到徽章。</div> <div class="option-analysis"><strong>B.</strong> 创建Amazon EventBridge规则响应pullRequestCreated事件，创建AWS Lambda函数调用带有CodeBuild操作的CodePipeline管道运行应用程序测试，编程Lambda函数在测试结果完成时将CodeBuild测试结果作为评论发布到pull request中。</div> <div class="option-analysis"><strong>C.</strong> 创建Amazon EventBridge规则响应pullRequestCreated和pullRequestSourceBranchUpdated事件，创建AWS Lambda函数调用带有CodeBuild操作的CodePipeline管道运行应用程序测试，编程Lambda函数将CodeBuild徽章作为评论发布到pull request中，以便开发者在代码审查中看到徽章。</div> <div class="option-analysis"><strong>D.</strong> 创建Amazon EventBridge规则响应pullRequestStatusChanged事件，创建AWS Lambda函数调用带有CodeBuild操作的CodePipeline管道运行应用程序测试，编程Lambda函数在测试结果完成时将CodeBuild测试结果作为评论发布到pull request中。<div class="section-title"><strong>核心要求:</strong></div> 自动化pull request测试并在审查过程中显示测试结果 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• Amazon EventBridge-监听CodeCommit事件触发自动化流程 </div><div class="compact-content">• <span class="key-service">AWS Lambda</span>-编排测试流程并发布结果到pull request </div><div class="compact-content">• <span class="key-service">AWS CodeBuild</span>-执行自动化测试 <div class="section-title"><strong>正确答案D:</strong></div> 使用pullRequestStatusChanged事件确保在pull request状态变化时触发测试，并发布详细的测试结果而非仅徽章，为审查者提供完整的测试信息 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A-仅发布徽章而非详细测试结果，审查者无法获得足够的测试信息 </div><div class="compact-content">• 选项B-仅在创建时触发，无法处理后续更新的代码变更 </div><div class="compact-content">• 选项C-监听过多事件且仅提供徽章，缺乏详细测试结果信息 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-pullRequestStatusChanged事件覆盖所有相关状态变化 </div><div class="compact-content">• 成本-精确的事件触发避免不必要的测试执行 </div><div class="compact-content">• 可扩展性-详细测试结果支持复杂的审查决策流程</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: D</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-55">
            <div class="question-header">
                <div class="question-title">Question #55 ✅ ⚪ <small style="float: right;">(55/353)</small></div>
            </div>
            <div class="question-content">A company has deployed an application in a production <span class="key-service">VPC</span> in a single AWS account. The application is popular and is experiencing heavy usage. The company's security team wants to add additional security, such as AWS WAF, to the application deployment. However, the application's product manager is concerned about cost and does not want to approve the change unless the security team can prove that additional security is necessary. The security team believes that some of the application's demand might come from users that have IP addresses that are on a deny list. The security team provides the deny list to a DevOps engineer. If any of the IP addresses on the deny list access the application, the security team wants to receive automated notification in near real time so that the security team can document that the application needs additional security. The DevOps engineer creates a <span class="key-service">VPC</span> flow log for the production <span class="key-service">VPC</span>. Which set of additional steps should the DevOps engineer take to meet these requirements MOST cost-effectively? A (100%)</div>
            <div class="options-container">                <div class="option correct-answer"><strong>A.</strong> Create a log group in <span class="key-service">Amazon CloudWatch</span> Logs. Configure the <span class="key-service">VPC</span> flow log to capture accepted traffic and to send the data to the log group. Create an <span class="key-service">Amazon CloudWatch</span> metric filter for IP addresses on the deny list. Create a CloudWatch alarm with the metric filter as input. Set the period to 5 minutes and the datapoints to alarm to 1. Use an Amazon Simple Notification Service (<span class="key-service">Amazon SNS</span>) topic to send alarm notices to the security team. Most Voted</div>                <div class="option"><strong>B.</strong> Create an <span class="key-service">Amazon S3</span> bucket for log files. Configure the <span class="key-service">VPC</span> flow log to capture all traffic and to send the data to the S3 bucket. Configure Amazon Athena to return all log files in the S3 bucket for IP addresses on the deny list. Configure Amazon QuickSight to accept data from Athena and to publish the data as a dashboard that the security team can access. Create a threshold alert of 1 for successful access. Configure the alert to automatically notify the security team as frequently as possible when the alert threshold is met.</div>                <div class="option"><strong>C.</strong> Create an <span class="key-service">Amazon S3</span> bucket for log files. Configure the <span class="key-service">VPC</span> flow log to capture accepted traffic and to send the data to the S3 bucket. Configure an Amazon OpenSearch Service cluster and domain for the log files. Create an <span class="key-service">AWS Lambda</span> function to retrieve the logs from the S3 bucket, format the logs, and load the logs into the OpenSearch Service cluster. Schedule the Lambda function to run every 5 minutes. Configure an alert and condition in OpenSearch Service to send alerts to the security team through an Amazon Simple Notification Service (<span class="key-service">Amazon SNS</span>) topic when access from the IP addresses on the deny list is detected.</div>                <div class="option"><strong>D.</strong> Create a log group in <span class="key-service">Amazon CloudWatch</span> Logs. Create an <span class="key-service">Amazon S3</span> bucket to hold query results. Configure the <span class="key-service">VPC</span> flow log to capture all traffic and to send the data to the log group. Deploy an Amazon Athena CloudWatch connector in <span class="key-service">AWS Lambda</span>. Connect the connector to the log group. Configure Athena to periodically query for all accepted traffic from the IP addresses on the deny list and to store the results in the S3 bucket. Configure an S3 event notification to automatically notify the security team through an Amazon Simple Notification Service (<span class="key-service">Amazon SNS</span>) topic when new objects are added to the S3 bucket.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司在单个AWS账户的生产VPC中部署了应用程序。应用程序很受欢迎，使用量很大。安全团队想要添加额外的安全措施如AWS WAF，但产品经理担心成本，除非安全团队能证明额外安全是必要的。安全团队认为部分应用需求可能来自拒绝列表中的IP地址。安全团队向DevOps工程师提供拒绝列表。如果拒绝列表中的任何IP地址访问应用程序，安全团队希望近实时收到自动通知，以便记录应用程序需要额外安全。DevOps工程师为生产VPC创建了VPC flow log。哪组额外步骤最具成本效益地满足这些要求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 在Amazon CloudWatch Logs中创建日志组。配置VPC flow log捕获已接受流量并发送数据到日志组。为拒绝列表中的IP地址创建Amazon CloudWatch指标过滤器。使用指标过滤器作为输入创建CloudWatch告警。设置周期为5分钟，告警数据点为1。使用Amazon SNS主题向安全团队发送告警通知。</div> <div class="option-analysis"><strong>B.</strong> 为日志文件创建Amazon S3存储桶。配置VPC flow log捕获所有流量并发送数据到S3存储桶。配置Amazon Athena返回S3存储桶中拒绝列表IP地址的所有日志文件。配置Amazon QuickSight接受Athena数据并发布为安全团队可访问的仪表板。创建成功访问阈值告警为1。配置告警在满足阈值时尽可能频繁地自动通知安全团队。</div> <div class="option-analysis"><strong>C.</strong> 为日志文件创建Amazon S3存储桶。配置VPC flow log捕获已接受流量并发送数据到S3存储桶。为日志文件配置Amazon OpenSearch Service集群和域。创建AWS Lambda函数从S3存储桶检索日志，格式化日志并加载到OpenSearch Service集群。安排Lambda函数每5分钟运行一次。在OpenSearch Service中配置告警和条件，当检测到拒绝列表IP地址访问时通过Amazon SNS主题向安全团队发送告警。</div> <div class="option-analysis"><strong>D.</strong> 在Amazon CloudWatch Logs中创建日志组。创建Amazon S3存储桶保存查询结果。配置VPC flow log捕获所有流量并发送数据到日志组。在AWS Lambda中部署Amazon Athena CloudWatch连接器。将连接器连接到日志组。配置Athena定期查询拒绝列表IP地址的所有已接受流量并将结果存储在S3存储桶中。配置S3事件通知在向S3存储桶添加新对象时通过Amazon SNS主题自动通知安全团队。<div class="section-title"><strong>核心要求:</strong></div> 近实时监控拒绝列表IP地址访问并自动通知安全团队，要求最具成本效益 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• <span class="key-service">VPC</span> Flow Logs-捕获网络流量数据 </div><div class="compact-content">• CloudWatch Logs-实时日志处理和监控 </div><div class="compact-content">• CloudWatch Metric Filter-从日志中提取特定模式 </div><div class="compact-content">• CloudWatch Alarm-基于指标触发告警 </div><div class="compact-content">• <span class="key-service">Amazon SNS</span>-发送通知消息 <div class="section-title"><strong>正确答案A:</strong></div> 使用CloudWatch Logs接收VPC flow logs，通过metric filter实时检测拒绝列表IP地址，CloudWatch alarm提供近实时告警，SNS发送通知，架构简单成本最低 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项B-使用Athena和QuickSight增加不必要的复杂性和成本，无法提供近实时告警 </div><div class="compact-content">• 选项C-使用OpenSearch Service和Lambda定期处理增加显著成本，5分钟调度延迟不是近实时 </div><div class="compact-content">• 选项D-使用Athena定期查询和额外S3存储增加复杂性和成本，无法实现近实时监控 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-CloudWatch提供近实时日志处理和告警能力 </div><div class="compact-content">• 成本-CloudWatch Logs和基本告警服务成本最低，避免额外分析服务 </div><div class="compact-content">• 可扩展性-CloudWatch原生支持大规模日志处理和告警</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: A</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-56">
            <div class="question-header">
                <div class="question-title">Question #56 ✅ 📝 <small style="float: right;">(56/353)</small></div>
            </div>
            <div class="question-content">A DevOps engineer has automated a web service deployment by using <span class="key-service">AWS CodePipeline</span> with the following steps: 1. An <span class="key-service">AWS CodeBuild</span> project compiles the deployment artifact and runs unit tests. 2. An <span class="key-service">AWS CodeDeploy</span> deployment group deploys the web service to <span class="key-service">Amazon EC2</span> instances in the staging environment. 3. A CodeDeploy deployment group deploys the web service to EC2 instances in the production environment. The quality assurance (QA) team requests permission to inspect the build artifact before the deployment to the production environment occurs. The QA team wants to run an internal penetration testing tool to conduct manual tests. The tool will be invoked by a REST API call. Which combination of actions should the DevOps engineer take to fulfill this request? (Choose two.) AE (77%) AD (23%)</div>
            <div class="options-container">                <div class="option correct-answer"><strong>A.</strong> Insert a manual approval action between the test actions and deployment actions of the pipeline.</div>                <div class="option"><strong>B.</strong> Modify the buildspec.yml file for the compilation stage to require manual approval before completion.</div>                <div class="option"><strong>C.</strong> Update the CodeDeploy deployment groups so that they require manual approval to proceed.</div>                <div class="option"><strong>D.</strong> Update the pipeline to directly call the REST API for the penetration testing tool.</div>                <div class="option correct-answer"><strong>E.</strong> Update the pipeline to invoke an <span class="key-service">AWS Lambda</span> function that calls the REST API for the penetration testing tool.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一名DevOps工程师使用AWS CodePipeline自动化了Web服务部署，包含以下步骤：1. AWS CodeBuild项目编译部署构件并运行单元测试；2. AWS CodeDeploy部署组将Web服务部署到暂存环境的EC2实例；3. CodeDeploy部署组将Web服务部署到生产环境的EC2实例。QA团队请求在生产环境部署前检查构建构件的权限，希望运行内部渗透测试工具进行手动测试，该工具通过REST API调用。DevOps工程师应采取哪些组合操作来满足此请求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 在管道的测试操作和部署操作之间插入手动批准操作</div> <div class="option-analysis"><strong>B.</strong> 修改编译阶段的buildspec.yml文件，要求在完成前进行手动批准</div> <div class="option-analysis"><strong>C.</strong> 更新CodeDeploy部署组，使其需要手动批准才能继续</div> <div class="option-analysis"><strong>D.</strong> 更新管道直接调用渗透测试工具的REST API</div> <div class="option-analysis"><strong>E.</strong> 更新管道调用AWS Lambda函数来调用渗透测试工具的REST API<div class="section-title"><strong>核心要求:</strong></div> 在生产部署前添加QA手动检查和渗透测试流程 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• <span class="key-service">AWS CodePipeline</span> - 提供手动批准操作和自动化编排 </div><div class="compact-content">• <span class="key-service">AWS Lambda</span> - 执行REST API调用集成外部工具 <div class="section-title"><strong>正确答案AE:</strong></div> 手动批准操作暂停管道执行让QA检查构件，Lambda函数提供REST API调用能力集成外部渗透测试工具 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项B - buildspec.yml控制构建过程而非管道流程控制 </div><div class="compact-content">• 选项C - CodeDeploy部署组不提供手动批准功能 </div><div class="compact-content">• 选项D - CodePipeline无法直接调用外部REST API <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能 - Lambda函数提供高效API调用能力 </div><div class="compact-content">• 成本 - 利用现有CodePipeline功能最小化额外成本 </div><div class="compact-content">• 可扩展性 - 手动批准和Lambda集成支持灵活的QA流程扩展</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: AE (A、E)</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-57">
            <div class="question-header">
                <div class="question-title">Question #57 ✅ ⚪ <small style="float: right;">(57/353)</small></div>
            </div>
            <div class="question-content">A company is hosting a web application in an AWS Region. For disaster recovery purposes, a second region is being used as a standby. Disaster recovery requirements state that session data must be replicated between regions in near-real time and 1% of requests should route to the secondary region to continuously verify system functionality. Additionally, if there is a disruption in service in the main region, traffic should be automatically routed to the secondary region, and the secondary region must be able to scale up to handle all traffic. How should a DevOps engineer meet these requirements? A (81%) D (19%)</div>
            <div class="options-container">                <div class="option correct-answer"><strong>A.</strong> In both regions, deploy the application on AWS Elastic Beanstalk and use <span class="key-service">Amazon DynamoDB</span> global tables for session data. Use an <span class="key-service">Amazon Route 53</span> weighted routing policy with health checks to distribute the traffic across the regions. Most Voted</div>                <div class="option"><strong>B.</strong> In both regions, launch the application in Auto Scaling groups and use DynamoDB for session data. Use a Route 53 failover routing policy with health checks to distribute the traffic across the regions.</div>                <div class="option"><strong>C.</strong> In both regions, deploy the application in <span class="key-service">AWS Lambda</span>, exposed by <span class="key-service">Amazon API Gateway</span>, and use <span class="key-service">Amazon RDS</span> for PostgreSQL with cross-region replication for session data. Deploy the web application with client-side logic to call the API Gateway directly.</div>                <div class="option"><strong>D.</strong> In both regions, launch the application in Auto Scaling groups and use DynamoDB global tables for session data. Enable an Amazon CloudFront weighted distribution across regions. Point the <span class="key-service">Amazon Route 53</span> DNS record at the CloudFront distribution.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司在AWS Region中托管Web应用程序。出于灾难恢复目的，第二个区域用作备用。灾难恢复要求会话数据必须在区域间近实时复制，1%的请求应路由到辅助区域以持续验证系统功能。此外，如果主区域服务中断，流量应自动路由到辅助区域，辅助区域必须能够扩展以处理所有流量。DevOps工程师应如何满足这些要求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 在两个区域中，在AWS Elastic Beanstalk上部署应用程序并使用Amazon DynamoDB global tables存储会话数据。使用Amazon Route 53加权路由策略配合健康检查在区域间分配流量。</div> <div class="option-analysis"><strong>B.</strong> 在两个区域中，在Auto Scaling groups中启动应用程序并使用DynamoDB存储会话数据。使用Route 53故障转移路由策略配合健康检查在区域间分配流量。</div> <div class="option-analysis"><strong>C.</strong> 在两个区域中，在AWS Lambda中部署应用程序，通过Amazon API Gateway暴露，并使用Amazon RDS for PostgreSQL跨区域复制存储会话数据。使用客户端逻辑直接调用API Gateway部署Web应用程序。</div> <div class="option-analysis"><strong>D.</strong> 在两个区域中，在Auto Scaling groups中启动应用程序并使用DynamoDB global tables存储会话数据。启用Amazon CloudFront跨区域加权分配。将Amazon Route 53 DNS记录指向CloudFront分配。<div class="section-title"><strong>核心要求:</strong></div> 实现跨区域灾难恢复，支持1%流量分配验证和自动故障转移 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• DynamoDB Global Tables-提供跨区域近实时会话数据复制 </div><div class="compact-content">• Route 53加权路由-支持1%流量分配和健康检查自动故障转移 <div class="section-title"><strong>正确答案A:</strong></div> Elastic Beanstalk提供自动扩展能力，DynamoDB Global Tables实现近实时跨区域复制，Route 53加权路由策略可精确控制1%流量分配并通过健康检查实现自动故障转移 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项B-故障转移路由策略无法实现1%流量持续分配验证，只能在故障时切换 </div><div class="compact-content">• 选项C-RDS跨区域复制延迟较高，无法满足近实时要求，且Lambda冷启动影响性能 </div><div class="compact-content">• 选项D-CloudFront无法提供精确的1%流量分配控制，且增加不必要的复杂性 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-DynamoDB Global Tables提供毫秒级跨区域复制延迟 </div><div class="compact-content">• 成本-Elastic Beanstalk按需扩展，避免Lambda冷启动和RDS跨区域复制成本 </div><div class="compact-content">• 可扩展性-Auto Scaling groups和Elastic Beanstalk都支持自动扩展应对流量激增</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: A</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-58">
            <div class="question-header">
                <div class="question-title">Question #58 ✅ 📝 <small style="float: right;">(58/353)</small></div>
            </div>
            <div class="question-content">A company runs an application on <span class="key-service">Amazon EC2</span> instances. The company uses a series of <span class="key-service">AWS CloudFormation</span> stacks to define the application resources. A developer performs updates by building and testing the application on a laptop and then uploading the build output and CloudFormation stack templates to <span class="key-service">Amazon S3</span>. The developer's peers review the changes before the developer performs the CloudFormation stack update and installs a new version of the application onto the EC2 instances. The deployment process is prone to errors and is time-consuming when the developer updates each EC2 instance with the new application. The company wants to automate as much of the application deployment process as possible while retaining a final manual approval step before the modification of the application or resources. The company already has moved the source code for the application and the CloudFormation templates to <span class="key-service">AWS CodeCommit</span>. The company also has created an <span class="key-service">AWS CodeBuild</span> project to build and test the application. Which combination of steps will meet the company's requirements? (Choose two.) AD (69%) BD (31%)</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Create an application group and a deployment group in <span class="key-service">AWS CodeDeploy</span>. Install the CodeDeploy agent on the EC2 instances.</div>                <div class="option correct-answer"><strong>B.</strong> Create an application revision and a deployment group in <span class="key-service">AWS CodeDeploy</span>. Create an environment in CodeDeploy. Register the EC2 instances to the CodeDeploy environment.</div>                <div class="option"><strong>C.</strong> Use <span class="key-service">AWS CodePipeline</span> to invoke the CodeBuild job, run the CloudFormation update, and pause for a manual approval step. After approval, start the <span class="key-service">AWS CodeDeploy</span> deployment.</div>                <div class="option correct-answer"><strong>D.</strong> Use <span class="key-service">AWS CodePipeline</span> to invoke the CodeBuild job, create CloudFormation change sets for each of the application stacks, and pause for a manual approval step. After approval, run the CloudFormation change sets and start the <span class="key-service">AWS CodeDeploy</span> deployment.</div>                <div class="option"><strong>E.</strong> Use <span class="key-service">AWS CodePipeline</span> to invoke the CodeBuild job, create CloudFormation change sets for each of the application stacks, and pause for a manual approval step. After approval, start the <span class="key-service">AWS CodeDeploy</span> deployment.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司在Amazon EC2实例上运行应用程序，使用一系列AWS CloudFormation堆栈定义应用程序资源。开发人员通过在笔记本电脑上构建和测试应用程序，然后将构建输出和CloudFormation堆栈模板上传到Amazon S3来执行更新。开发人员的同事在开发人员执行CloudFormation堆栈更新并在EC2实例上安装新版本应用程序之前审查更改。当开发人员更新每个EC2实例的新应用程序时，部署过程容易出错且耗时。公司希望尽可能自动化应用程序部署过程，同时在修改应用程序或资源之前保留最终的手动批准步骤。公司已经将应用程序源代码和CloudFormation模板移动到AWS CodeCommit，并创建了AWS CodeBuild项目来构建和测试应用程序。哪些步骤组合将满足公司的要求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 在AWS CodeDeploy中创建应用程序组和部署组，在EC2实例上安装CodeDeploy代理</div> <div class="option-analysis"><strong>B.</strong> 在AWS CodeDeploy中创建应用程序修订版和部署组，在CodeDeploy中创建环境，将EC2实例注册到CodeDeploy环境</div> <div class="option-analysis"><strong>C.</strong> 使用AWS CodePipeline调用CodeBuild作业，运行CloudFormation更新，并暂停进行手动批准步骤，批准后启动AWS CodeDeploy部署</div> <div class="option-analysis"><strong>D.</strong> 使用AWS CodePipeline调用CodeBuild作业，为每个应用程序堆栈创建CloudFormation变更集，并暂停进行手动批准步骤，批准后运行CloudFormation变更集并启动AWS CodeDeploy部署</div> <div class="option-analysis"><strong>E.</strong> 使用AWS CodePipeline调用CodeBuild作业，为每个应用程序堆栈创建CloudFormation变更集，并暂停进行手动批准步骤，批准后启动AWS CodeDeploy部署<div class="section-title"><strong>核心要求:</strong></div> 自动化应用程序部署流程，保留手动批准步骤，解决EC2实例更新的错误和耗时问题 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• <span class="key-service">AWS CodeDeploy</span>-自动化应用程序部署到EC2实例 </div><div class="compact-content">• <span class="key-service">AWS CodePipeline</span>-编排CI/CD流水线和手动批准流程 </div><div class="compact-content">• CloudFormation变更集-在执行前预览基础设施变更 <div class="section-title"><strong>正确答案BD:</strong></div> B选项正确配置了CodeDeploy的应用程序修订版、部署组和环境来管理EC2实例部署；D选项使用CodePipeline编排完整流程，通过变更集实现安全的CloudFormation更新和手动批准机制 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A-术语错误，CodeDeploy中应该是应用程序和部署组，不是应用程序组 </div><div class="compact-content">• 选项C-直接运行CloudFormation更新而不是先创建变更集进行审查，不够安全 </div><div class="compact-content">• 选项E-批准后没有执行CloudFormation变更集，只创建了变更集但未应用 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-CodeDeploy自动化部署消除手动更新EC2实例的耗时过程 </div><div class="compact-content">• 成本-利用现有CodeCommit和CodeBuild资源，通过自动化减少人工成本 </div><div class="compact-content">• 可扩展性-CodePipeline和CodeDeploy支持多实例并行部署和多环境扩展</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: BD (B、D)</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-59">
            <div class="question-header">
                <div class="question-title">Question #59 ✅ ⚪ <small style="float: right;">(59/353)</small></div>
            </div>
            <div class="question-content">A DevOps engineer manages a web application that runs on <span class="key-service">Amazon EC2</span> instances behind an Application Load Balancer (ALB). The instances run in an EC2 Auto Scaling group across multiple Availability Zones. The engineer needs to implement a deployment strategy that: Launches a second fleet of instances with the same capacity as the original fleet. Maintains the original fleet unchanged while the second fleet is launched. Transitions traffic to the second fleet when the second fleet is fully deployed. Terminates the original fleet automatically 1 hour after transition. Which solution will satisfy these requirements? C (92%) 8%</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Use an <span class="key-service">AWS CloudFormation</span> template with a retention policy for the ALB set to 1 hour. Update the <span class="key-service">Amazon Route 53</span> record to reflect the new ALB.</div>                <div class="option"><strong>B.</strong> Use two AWS Elastic Beanstalk environments to perform a blue/green deployment from the original environment to the new one. Create an application version lifecycle policy to terminate the original environment in 1 hour.</div>                <div class="option correct-answer"><strong>C.</strong> Use <span class="key-service">AWS CodeDeploy</span> with a deployment group configured with a blue/green deployment configuration. Select the option Terminate the original instances in the deployment group with a waiting period of 1 hour.</div>                <div class="option"><strong>D.</strong> Use AWS Elastic Beanstalk with the configuration set to Immutable. Create an .ebextension using the Resources key that sets the deletion policy of the ALB to 1 hour, and deploy the application.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一名DevOps工程师管理运行在Application Load Balancer (ALB)后面Amazon EC2实例上的Web应用程序。实例在跨多个Availability Zone的EC2 Auto Scaling组中运行。工程师需要实现一个部署策略：启动与原始fleet相同容量的第二个fleet，在启动第二个fleet时保持原始fleet不变，当第二个fleet完全部署后将流量转移到第二个fleet，在转移后1小时自动终止原始fleet。 <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 使用AWS CloudFormation模板，将ALB的保留策略设置为1小时，更新Amazon Route 53记录以反映新的ALB。</div> <div class="option-analysis"><strong>B.</strong> 使用两个AWS Elastic Beanstalk环境执行从原始环境到新环境的蓝/绿部署，创建应用程序版本生命周期策略在1小时后终止原始环境。</div> <div class="option-analysis"><strong>C.</strong> 使用AWS CodeDeploy配置蓝/绿部署配置的部署组，选择在部署组中终止原始实例并设置1小时等待期的选项。</div> <div class="option-analysis"><strong>D.</strong> 使用AWS Elastic Beanstalk并将配置设置为Immutable，创建使用Resources键的.ebextension将ALB的删除策略设置为1小时，然后部署应用程序。<div class="section-title"><strong>核心要求:</strong></div> 实现蓝/绿部署策略，确保零停机时间和自动化的fleet切换与清理 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• <span class="key-service">AWS CodeDeploy</span> - 提供原生蓝/绿部署功能，支持EC2/ALB架构 </div><div class="compact-content">• Application Load Balancer - 流量路由和健康检查支持 <div class="section-title"><strong>正确答案C:</strong></div> CodeDeploy蓝/绿部署配置完全匹配需求：创建相同容量的新fleet，保持原fleet不变，自动切换流量，支持配置1小时延迟终止原实例 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A - CloudFormation不提供蓝/绿部署逻辑，Route 53切换无法满足自动fleet管理需求 </div><div class="compact-content">• 选项B - Elastic Beanstalk环境切换复杂，无法精确控制现有EC2 Auto Scaling组的部署流程 </div><div class="compact-content">• 选项D - Immutable部署不是蓝/绿策略，.ebextension配置ALB删除策略不符合实际需求 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能 - CodeDeploy提供原生蓝/绿部署，确保零停机切换 </div><div class="compact-content">• 成本 - 自动化fleet管理避免手动操作成本，1小时延迟终止提供回滚窗口 </div><div class="compact-content">• 可扩展性 - 与现有EC2 Auto Scaling和ALB架构无缝集成</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: C</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-60">
            <div class="question-header">
                <div class="question-title">Question #60 ✅ ⚪ <small style="float: right;">(60/353)</small></div>
            </div>
            <div class="question-content">A video-sharing company stores its videos in <span class="key-service">Amazon S3</span>. The company has observed a sudden increase in video access requests, but the company does not know which videos are most popular. The company needs to identify the general access pattern for the video files. This pattern includes the number of users who access a certain file on a given day, as well as the number of pull requests for certain files. How can the company meet these requirements with the LEAST amount of effort? B (100%)</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Activate S3 server access logging. Import the access logs into an Amazon Aurora database. Use an Aurora SQL query to analyze the access patterns.</div>                <div class="option correct-answer"><strong>B.</strong> Activate S3 server access logging. Use Amazon Athena to create an external table with the log files. Use Athena to create a SQL query to analyze the access patterns.</div>                <div class="option"><strong>C.</strong> Invoke an <span class="key-service">AWS Lambda</span> function for every S3 object access event. Configure the Lambda function to write the file access information, such as user, S3 bucket, and file key, to an Amazon Aurora database. Use an Aurora SQL query to analyze the access patterns.</div>                <div class="option"><strong>D.</strong> Record an <span class="key-service">Amazon CloudWatch</span> Logs log message for every S3 object access event. Configure a CloudWatch Logs log stream to write the file access information, such as user, S3 bucket, and file key, to an Amazon Kinesis Data Analytics for SQL application. Perform a sliding window analysis.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家视频分享公司将视频存储在Amazon S3中。公司观察到视频访问请求突然增加，但不知道哪些视频最受欢迎。公司需要识别视频文件的一般访问模式，包括特定日期访问某个文件的用户数量以及某些文件的拉取请求数量。公司如何以最少的工作量满足这些要求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 激活S3服务器访问日志记录，将访问日志导入Amazon Aurora数据库，使用Aurora SQL查询分析访问模式</div> <div class="option-analysis"><strong>B.</strong> 激活S3服务器访问日志记录，使用Amazon Athena创建包含日志文件的外部表，使用Athena创建SQL查询分析访问模式</div> <div class="option-analysis"><strong>C.</strong> 为每个S3对象访问事件调用AWS Lambda函数，配置Lambda函数将文件访问信息写入Amazon Aurora数据库，使用Aurora SQL查询分析访问模式</div> <div class="option-analysis"><strong>D.</strong> 为每个S3对象访问事件记录Amazon CloudWatch Logs日志消息，配置CloudWatch Logs日志流将文件访问信息写入Amazon Kinesis Data Analytics for SQL应用程序，执行滑动窗口分析<div class="section-title"><strong>核心要求:</strong></div> 以最少工作量分析S3视频文件访问模式和用户访问统计 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• S3 Server Access Logging-记录S3存储桶的详细访问请求信息 </div><div class="compact-content">• Amazon Athena-无服务器交互式查询服务，直接查询S3中的数据 <div class="section-title"><strong>正确答案B:</strong></div> S3访问日志自动记录所有访问信息，Athena可直接查询S3中的日志文件无需数据迁移，实现serverless分析 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A-需要额外的Aurora数据库资源和数据导入过程，增加成本和复杂性 </div><div class="compact-content">• 选项C-需要为每次访问触发Lambda函数，成本高且架构复杂，存在性能瓶颈 </div><div class="compact-content">• 选项D-需要配置复杂的实时流处理架构，过度工程化且成本高昂 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-Athena直接查询S3日志，无需数据传输延迟 </div><div class="compact-content">• 成本-无服务器架构，按查询付费，无需维护数据库 </div><div class="compact-content">• 可扩展性-Athena自动扩展，S3日志原生支持大规模访问记录</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: B</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-61">
            <div class="question-header">
                <div class="question-title">Question #61 ✅ ⚪ <small style="float: right;">(61/353)</small></div>
            </div>
            <div class="question-content">A development team wants to use <span class="key-service">AWS CloudFormation</span> stacks to deploy an application. However, the developer IAM role does not have the required permissions to provision the resources that are specified in the <span class="key-service">AWS CloudFormation</span> template. A DevOps engineer needs to implement a solution that allows the developers to deploy the stacks. The solution must follow the principle of least privilege. Which solution will meet these requirements? D (82%) Other</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Create an IAM policy that allows the developers to provision the required resources. Attach the policy to the developer IAM role.</div>                <div class="option correct-answer"><strong>B.</strong> Create an IAM policy that allows full access to <span class="key-service">AWS CloudFormation</span>. Attach the policy to the developer IAM role.</div>                <div class="option"><strong>C.</strong> Create an <span class="key-service">AWS CloudFormation</span> service role that has the required permissions. Grant the developer IAM role a cloudformation:* action. Use the new service role during stack deployments.</div>                <div class="option"><strong>D.</strong> Create an <span class="key-service">AWS CloudFormation</span> service role that has the required permissions. Grant the developer IAM role the iam:PassRole permission. Use the new service role during stack deployments.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 开发团队想要使用AWS CloudFormation堆栈来部署应用程序。但是，开发者IAM角色没有所需权限来配置AWS CloudFormation模板中指定的资源。DevOps工程师需要实现一个解决方案，允许开发者部署堆栈。解决方案必须遵循最小权限原则。哪个解决方案满足这些要求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 创建一个IAM策略，允许开发者配置所需资源。将策略附加到开发者IAM角色。</div> <div class="option-analysis"><strong>B.</strong> 创建一个IAM策略，允许完全访问AWS CloudFormation。将策略附加到开发者IAM角色。</div> <div class="option-analysis"><strong>C.</strong> 创建一个具有所需权限的AWS CloudFormation服务角色。授予开发者IAM角色cloudformation:*操作。在堆栈部署期间使用新的服务角色。</div> <div class="option-analysis"><strong>D.</strong> 创建一个具有所需权限的AWS CloudFormation服务角色。授予开发者IAM角色iam:PassRole权限。在堆栈部署期间使用新的服务角色。<div class="section-title"><strong>核心要求:</strong></div> 在遵循最小权限原则的前提下，允许开发者通过CloudFormation部署应用程序堆栈 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• <span class="key-service">AWS CloudFormation</span> - 基础设施即代码服务，用于自动化资源配置 </div><div class="compact-content">• IAM服务角色 - 允许AWS服务代表用户执行操作的角色机制 <div class="section-title"><strong>正确答案D:</strong></div> 通过创建CloudFormation服务角色承担实际资源配置权限，开发者只需iam:PassRole权限即可传递角色给CloudFormation使用，实现权限分离和最小权限原则 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A - 直接给开发者资源配置权限违反最小权限原则，权限过大 </div><div class="compact-content">• 选项B - 给予CloudFormation完全访问权限严重违反最小权限原则，存在安全风险 </div><div class="compact-content">• 选项C - cloudformation:*权限过于宽泛，超出了部署堆栈的必要权限范围 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 安全性 - 通过服务角色实现权限分离，开发者无直接资源访问权限 </div><div class="compact-content">• 权限控制 - iam:PassRole是传递角色的最小必要权限 </div><div class="compact-content">• 可管理性 - 集中管理服务角色权限，便于维护和审计</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: B</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-62">
            <div class="question-header">
                <div class="question-title">Question #62 ✅ ⚪ <small style="float: right;">(62/353)</small></div>
            </div>
            <div class="question-content">A production account has a requirement that any <span class="key-service">Amazon EC2</span> instance that has been logged in to manually must be terminated within 24 hours. All applications in the production account are using Auto Scaling groups with the <span class="key-service">Amazon CloudWatch</span> Logs agent configured. How can this process be automated? D (100%)</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Create a CloudWatch Logs subscription to an <span class="key-service">AWS Step Functions</span> application. Configure an <span class="key-service">AWS Lambda</span> function to add a tag to the EC2 instance that produced the login event and mark the instance to be decommissioned. Create an Amazon EventBridge rule to invoke a second Lambda function once a day that will terminate all instances with this tag.</div>                <div class="option"><strong>B.</strong> Create an <span class="key-service">Amazon CloudWatch</span> alarm that will be invoked by the login event. Send the notification to an Amazon Simple Notification Service (<span class="key-service">Amazon SNS</span>) topic that the operations team is subscribed to, and have them terminate the EC2 instance within 24 hours.</div>                <div class="option"><strong>C.</strong> Create an <span class="key-service">Amazon CloudWatch</span> alarm that will be invoked by the login event. Configure the alarm to send to an Amazon Simple Queue Service (<span class="key-service">Amazon SQS</span>) queue. Use a group of worker instances to process messages from the queue, which then schedules an Amazon EventBridge rule to be invoked.</div>                <div class="option correct-answer"><strong>D.</strong> Create a CloudWatch Logs subscription to an <span class="key-service">AWS Lambda</span> function. Configure the function to add a tag to the EC2 instance that produced the login event and mark the instance to be decommissioned. Create an Amazon EventBridge rule to invoke a daily Lambda function that terminates all instances with this tag. Most Voted</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 生产账户要求任何手动登录的Amazon EC2实例必须在24小时内终止。生产账户中的所有应用程序都使用配置了Amazon CloudWatch Logs代理的Auto Scaling组。如何自动化此过程？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 创建CloudWatch Logs订阅到AWS Step Functions应用程序。配置AWS Lambda函数为产生登录事件的EC2实例添加标签并标记为待退役。创建Amazon EventBridge规则每天调用第二个Lambda函数终止所有带此标签的实例。</div> <div class="option-analysis"><strong>B.</strong> 创建由登录事件触发的Amazon CloudWatch告警。将通知发送到运维团队订阅的Amazon Simple Notification Service (<span class="key-service">Amazon SNS</span>)主题，让他们在24小时内终止EC2实例。</div> <div class="option-analysis"><strong>C.</strong> 创建由登录事件触发的Amazon CloudWatch告警。配置告警发送到Amazon Simple Queue Service (<span class="key-service">Amazon SQS</span>)队列。使用工作实例组处理队列消息，然后调度Amazon EventBridge规则被调用。</div> <div class="option-analysis"><strong>D.</strong> 创建CloudWatch Logs订阅到AWS Lambda函数。配置函数为产生登录事件的EC2实例添加标签并标记为待退役。创建Amazon EventBridge规则调用每日Lambda函数终止所有带此标签的实例。<div class="section-title"><strong>核心要求:</strong></div> 自动检测EC2实例手动登录事件并在24小时内自动终止 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• CloudWatch Logs - 捕获和分析登录日志事件 </div><div class="compact-content">• Lambda - 处理事件并执行自动化任务 </div><div class="compact-content">• EventBridge - 定时触发清理任务 <div class="section-title"><strong>正确答案D:</strong></div> 通过CloudWatch Logs订阅直接触发Lambda函数处理登录事件，添加标签标记实例，使用EventBridge定时规则每日清理带标签的实例，实现完全自动化 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A - 使用Step Functions增加不必要的复杂性和成本 </div><div class="compact-content">• 选项B - 依赖人工干预，无法实现完全自动化 </div><div class="compact-content">• 选项C - 架构过于复杂，使用工作实例组增加成本和管理开销 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能 - 直接事件驱动响应最快 </div><div class="compact-content">• 成本 - 无服务器架构最经济 </div><div class="compact-content">• 可扩展性 - Lambda和EventBridge自动扩展</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: D</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-63">
            <div class="question-header">
                <div class="question-title">Question #63 ✅ ⚪ <small style="float: right;">(63/353)</small></div>
            </div>
            <div class="question-content">A company has enabled all features for its organization in <span class="key-service">AWS Organizations</span>. The organization contains 10 AWS accounts. The company has turned on <span class="key-service">AWS CloudTrail</span> in all the accounts. The company expects the number of AWS accounts in the organization to increase to 500 during the next year. The company plans to use multiple OUs for these accounts. The company has enabled <span class="key-service">AWS Config</span> in each existing AWS account in the organization. A DevOps engineer must implement a solution that enables <span class="key-service">AWS Config</span> automatically for all future AWS accounts that are created in the organization. Which solution will meet this requirement? B (100%)</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> In the organization's management account, create an Amazon EventBridge rule that reacts to a CreateAccount API call. Configure the rule to invoke an <span class="key-service">AWS Lambda</span> function that enables trusted access to <span class="key-service">AWS Config</span> for the organization.</div>                <div class="option correct-answer"><strong>B.</strong> In the organization's management account, create an <span class="key-service">AWS CloudFormation</span> stack set to enable <span class="key-service">AWS Config</span>. Configure the stack set to deploy automatically when an account is created through Organizations. Most Voted</div>                <div class="option"><strong>C.</strong> In the organization's management account, create an <span class="key-service">SCP</span> that allows the appropriate <span class="key-service">AWS Config</span> API calls to enable <span class="key-service">AWS Config</span>. Apply the <span class="key-service">SCP</span> to the root-level OU.</div>                <div class="option"><strong>D.</strong> In the organization's management account, create an Amazon EventBridge rule that reacts to a CreateAccount API call. Configure the rule to invoke an <span class="key-service">AWS Systems Manager</span> Automation runbook to enable <span class="key-service">AWS Config</span> for the account.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司在AWS Organizations中启用了所有功能，组织包含10个AWS账户并在所有账户中开启了AWS CloudTrail。公司预计明年账户数量将增加到500个，计划使用多个OU管理这些账户。公司已在每个现有AWS账户中启用了AWS Config。DevOps工程师必须实现一个解决方案，为组织中创建的所有未来AWS账户自动启用AWS Config。 <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 在组织的管理账户中，创建一个Amazon EventBridge规则响应CreateAccount API调用，配置规则调用AWS Lambda函数为组织启用AWS Config的可信访问。</div> <div class="option-analysis"><strong>B.</strong> 在组织的管理账户中，创建AWS CloudFormation stack set来启用AWS Config，配置stack set在通过Organizations创建账户时自动部署。</div> <div class="option-analysis"><strong>C.</strong> 在组织的管理账户中，创建一个SCP允许适当的AWS Config API调用来启用AWS Config，将SCP应用到根级OU。</div> <div class="option-analysis"><strong>D.</strong> 在组织的管理账户中，创建一个Amazon EventBridge规则响应CreateAccount API调用，配置规则调用AWS Systems Manager Automation runbook为账户启用AWS Config。<div class="section-title"><strong>核心要求:</strong></div> 为AWS Organizations中未来创建的所有新账户自动启用AWS Config <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• <span class="key-service">AWS Organizations</span> - 集中管理多个AWS账户 </div><div class="compact-content">• <span class="key-service">AWS Config</span> - 监控和评估AWS资源配置 </div><div class="compact-content">• CloudFormation StackSets - 跨多个账户和区域自动部署资源 <div class="section-title"><strong>正确答案B:</strong></div> CloudFormation StackSets提供原生的自动部署功能，可配置为在Organizations创建新账户时自动部署AWS Config配置，无需额外的事件处理逻辑 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A - 仅启用可信访问不足以自动配置AWS Config，需要额外的配置步骤 </div><div class="compact-content">• 选项C - SCP只控制权限策略，不能主动启用或配置AWS Config服务 </div><div class="compact-content">• 选项D - 虽然技术可行但增加了复杂性，需要维护Automation runbook和事件处理逻辑 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能 - StackSets提供原生自动化，响应速度快 </div><div class="compact-content">• 成本 - 无需额外的Lambda或Systems Manager执行成本 </div><div class="compact-content">• 可扩展性 - 原生支持大规模账户管理，适合500账户的扩展需求</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: B</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-64">
            <div class="question-header">
                <div class="question-title">Question #64 ✅ ⚪ <small style="float: right;">(64/353)</small></div>
            </div>
            <div class="question-content">A company has many applications. Different teams in the company developed the applications by using multiple languages and frameworks. The applications run on premises and on different servers with different operating systems. Each team has its own release protocol and process. The company wants to reduce the complexity of the release and maintenance of these applications. The company is migrating its technology stacks, including these applications, to AWS. The company wants centralized control of source code, a consistent and automatic delivery pipeline, and as few maintenance tasks as possible on the underlying infrastructure. What should a DevOps engineer do to meet these requirements? D (93%) 7%</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Create one <span class="key-service">AWS CodeCommit</span> repository for all applications. Put each application's code in a different branch. Merge the branches, and use <span class="key-service">AWS CodeBuild</span> to build the applications. Use <span class="key-service">AWS CodeDeploy</span> to deploy the applications to one centralized application server.</div>                <div class="option"><strong>B.</strong> Create one <span class="key-service">AWS CodeCommit</span> repository for each of the applications. Use <span class="key-service">AWS CodeBuild</span> to build the applications one at a time. Use <span class="key-service">AWS CodeDeploy</span> to deploy the applications to one centralized application server.</div>                <div class="option"><strong>C.</strong> Create one <span class="key-service">AWS CodeCommit</span> repository for each of the applications. Use <span class="key-service">AWS CodeBuild</span> to build the applications one at a time and to create one AMI for each server. Use <span class="key-service">AWS CloudFormation</span> StackSets to automatically provision and decommission <span class="key-service">Amazon EC2</span> fleets by using these AMIs.</div>                <div class="option correct-answer"><strong>D.</strong> Create one <span class="key-service">AWS CodeCommit</span> repository for each of the applications. Use <span class="key-service">AWS CodeBuild</span> to build one Docker image for each application in Amazon Elastic Container Registry (<span class="key-service">Amazon ECR</span>). Use <span class="key-service">AWS CodeDeploy</span> to deploy the applications to Amazon Elastic Container Service (<span class="key-service">Amazon ECS</span>) on infrastructure that <span class="key-service">AWS Fargate</span> manages.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司有多个应用程序，不同团队使用多种语言和框架开发，运行在不同操作系统的本地服务器上，各团队有自己的发布协议和流程。公司希望降低应用程序发布和维护的复杂性，正在将技术栈迁移到AWS，需要源代码集中控制、一致的自动交付管道，以及尽可能少的底层基础设施维护任务。 <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 为所有应用程序创建一个AWS CodeCommit仓库，将每个应用程序代码放在不同分支中，合并分支后使用AWS CodeBuild构建应用程序，使用AWS CodeDeploy部署到一个集中的应用服务器。</div> <div class="option-analysis"><strong>B.</strong> 为每个应用程序创建一个AWS CodeCommit仓库，使用AWS CodeBuild逐个构建应用程序，使用AWS CodeDeploy部署到一个集中的应用服务器。</div> <div class="option-analysis"><strong>C.</strong> 为每个应用程序创建一个AWS CodeCommit仓库，使用AWS CodeBuild逐个构建应用程序并为每个服务器创建一个AMI，使用AWS CloudFormation StackSets自动配置和停用使用这些AMI的Amazon EC2集群。</div> <div class="option-analysis"><strong>D.</strong> 为每个应用程序创建一个AWS CodeCommit仓库，使用AWS CodeBuild为每个应用程序在Amazon ECR中构建一个Docker镜像，使用AWS CodeDeploy将应用程序部署到由AWS Fargate管理的Amazon ECS上。<div class="section-title"><strong>核心要求:</strong></div> 实现多语言应用程序的统一CI/CD管道，最小化基础设施维护工作 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• <span class="key-service">AWS CodeCommit</span>-集中式源代码管理 </div><div class="compact-content">• <span class="key-service">AWS CodeBuild</span>-自动化构建服务 </div><div class="compact-content">• <span class="key-service">Amazon ECS</span>+Fargate-无服务器容器运行平台 </div><div class="compact-content">• <span class="key-service">Amazon ECR</span>-容器镜像仓库 <div class="section-title"><strong>正确答案D:</strong></div> 使用容器化技术解决多语言框架兼容性问题，Fargate提供无服务器容器运行环境，完全消除基础设施维护需求，实现真正的自动化部署管道。 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A-单一仓库多分支架构不适合多团队独立开发，集中服务器存在单点故障风险 </div><div class="compact-content">• 选项B-集中应用服务器无法处理多语言环境兼容性问题，仍需手动维护服务器 </div><div class="compact-content">• 选项C-EC2+AMI方案需要管理虚拟机和操作系统，增加而非减少基础设施维护工作 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-容器化提供应用隔离和资源优化 </div><div class="compact-content">• 成本-Fargate按需付费，无需预置服务器资源 </div><div class="compact-content">• 可扩展性-ECS自动扩缩容，支持多应用程序独立部署</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: D</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-65">
            <div class="question-header">
                <div class="question-title">Question #65 ✅ 📝 <small style="float: right;">(65/353)</small></div>
            </div>
            <div class="question-content">A company's application is currently deployed to a single AWS Region. Recently, the company opened a new office on a different continent. The users in the new office are experiencing high latency. The company's application runs on <span class="key-service">Amazon EC2</span> instances behind an Application Load Balancer (ALB) and uses <span class="key-service">Amazon DynamoDB</span> as the database layer. The instances run in an EC2 Auto Scaling group across multiple Availability Zones. A DevOps engineer is tasked with minimizing application response times and improving availability for users in both Regions. Which combination of actions should be taken to address the latency issues? (Choose three.) CDF (100%)</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Create a new DynamoDB table in the new Region with cross-Region replication enabled.</div>                <div class="option"><strong>B.</strong> Create new ALB and Auto Scaling group global resources and configure the new ALB to direct traffic to the new Auto Scaling group.</div>                <div class="option correct-answer"><strong>C.</strong> Create new ALB and Auto Scaling group resources in the new Region and configure the new ALB to direct traffic to the new Auto Scaling group.</div>                <div class="option correct-answer"><strong>D.</strong> Create <span class="key-service">Amazon Route 53</span> records, health checks, and latency-based routing policies to route to the ALB.</div>                <div class="option"><strong>E.</strong> Create <span class="key-service">Amazon Route 53</span> aliases, health checks, and failover routing policies to route to the AL<div class="option-analysis"><strong>B.</strong> F. Convert the DynamoDB table to a global table. Most Voted</div></div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司的应用程序目前部署在单个AWS Region中。最近，该公司在不同大陆开设了新办公室。新办公室的用户遇到高延迟问题。公司应用程序运行在Application Load Balancer (ALB)后的Amazon EC2实例上，使用Amazon DynamoDB作为数据库层。实例在跨多个Availability Zone的EC2 Auto Scaling组中运行。DevOps工程师需要最小化应用程序响应时间并提高两个Region用户的可用性。应采取哪些操作组合来解决延迟问题？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 在新Region中创建启用跨Region复制的新DynamoDB表</div> <div class="option-analysis"><strong>B.</strong> 创建新的ALB和Auto Scaling组全局资源，并配置新ALB将流量导向新Auto Scaling组</div> <div class="option-analysis"><strong>C.</strong> 在新Region中创建新的ALB和Auto Scaling组资源，并配置新ALB将流量导向新Auto Scaling组</div> <div class="option-analysis"><strong>D.</strong> 创建Amazon Route 53记录、健康检查和基于延迟的路由策略来路由到ALB</div> <div class="option-analysis"><strong>E.</strong> 创建Amazon Route 53别名、健康检查和故障转移路由策略来路由到ALB F. 将DynamoDB表转换为全局表<div class="section-title"><strong>核心要求:</strong></div> 为不同大陆用户解决高延迟问题并提高可用性 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• Route 53-提供基于延迟的DNS路由 </div><div class="compact-content">• ALB+Auto Scaling-在新Region部署应用基础设施 </div><div class="compact-content">• DynamoDB Global Tables-实现跨Region数据同步 <strong>正确答案CDF:</strong> C在新Region部署完整应用架构，D通过Route 53基于延迟路由用户到最近Region，F使用Global Tables实现数据库跨Region同步 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A-手动跨Region复制比Global Tables复杂且功能有限 </div><div class="compact-content">• 选项B-"全局资源"概念错误，ALB和Auto Scaling组是Region级服务 </div><div class="compact-content">• 选项E-故障转移路由不如基于延迟路由适合解决延迟问题 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-基于延迟路由确保用户访问最近Region </div><div class="compact-content">• 成本-利用现有服务扩展而非重新架构 </div><div class="compact-content">• 可扩展性-Global Tables和多Region架构支持全球扩展</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: CD (C、D)</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-66">
            <div class="question-header">
                <div class="question-title">Question #66 ✅ ⚪ <small style="float: right;">(66/353)</small></div>
            </div>
            <div class="question-content">A DevOps engineer needs to apply a core set of security controls to an existing set of AWS accounts. The accounts are in an organization in <span class="key-service">AWS Organizations</span>. Individual teams will administer individual accounts by using the AdministratorAccess AWS managed policy. For all accounts, <span class="key-service">AWS CloudTrail</span> and <span class="key-service">AWS Config</span> must be turned on in all available AWS Regions. Individual account administrators must not be able to edit or delete any of the baseline resources. However, individual account administrators must be able to edit or delete their own CloudTrail trails and <span class="key-service">AWS Config</span> rules. Which solution will meet these requirements in the MOST operationally efficient way? C (54%) D (38%) 9%</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Create an <span class="key-service">AWS CloudFormation</span> template that defines the standard account resources. Deploy the template to all accounts from the organization's management account by using CloudFormation StackSets. Set the stack policy to deny Update:Delete actions.</div>                <div class="option"><strong>B.</strong> Enable AWS Control Tower. Enroll the existing accounts in AWS Control Tower. Grant the individual account administrators access to CloudTrail and <span class="key-service">AWS Config</span>.</div>                <div class="option correct-answer"><strong>C.</strong> Designate an <span class="key-service">AWS Config</span> management account. Create <span class="key-service">AWS Config</span> recorders in all accounts by using <span class="key-service">AWS CloudFormation</span> StackSets. Deploy <span class="key-service">AWS Config</span> rules to the organization by using the <span class="key-service">AWS Config</span> management account. Create a CloudTrail organization trail in the organization's management account. Deny modification or deletion of the <span class="key-service">AWS Config</span> recorders by using an <span class="key-service">SCP</span>. Most Voted</div>                <div class="option"><strong>D.</strong> Create an <span class="key-service">AWS CloudFormation</span> template that defines the standard account resources. Deploy the template to all accounts from the organization's management account by using CloudFormation StackSets. Create an <span class="key-service">SCP</span> that prevents updates or deletions to CloudTrail resources or <span class="key-service">AWS Config</span> resources unless the principal is an administrator of the organization's management account. Most Voted</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一名DevOps工程师需要对AWS Organizations中现有的一组AWS账户应用核心安全控制。各团队将使用AdministratorAccess AWS托管策略管理各自账户。所有账户必须在所有可用AWS区域启用AWS CloudTrail和AWS Config。各账户管理员不能编辑或删除基线资源，但可以编辑或删除自己的CloudTrail轨迹和AWS Config规则。哪种解决方案最具运营效率？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 创建定义标准账户资源的AWS CloudFormation模板，使用CloudFormation StackSets从组织管理账户部署到所有账户，设置堆栈策略拒绝Update:Delete操作</div> <div class="option-analysis"><strong>B.</strong> 启用AWS Control Tower，将现有账户注册到AWS Control Tower中，授予各账户管理员访问CloudTrail和AWS Config的权限</div> <div class="option-analysis"><strong>C.</strong> 指定AWS Config管理账户，使用AWS CloudFormation StackSets在所有账户中创建AWS Config记录器，通过AWS Config管理账户向组织部署AWS Config规则，在组织管理账户中创建CloudTrail组织轨迹，使用SCP拒绝修改或删除AWS Config记录器</div> <div class="option-analysis"><strong>D.</strong> 创建定义标准账户资源的AWS CloudFormation模板，使用CloudFormation StackSets从组织管理账户部署到所有账户，创建SCP阻止更新或删除CloudTrail资源或AWS Config资源，除非主体是组织管理账户的管理员<div class="section-title"><strong>核心要求:</strong></div> 在AWS Organizations中统一部署安全控制，保护基线资源但允许管理员管理自己的资源 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• AWS Config管理账户-集中管理配置合规性 </div><div class="compact-content">• CloudTrail组织轨迹-集中审计日志记录 </div><div class="compact-content">• <span class="key-service">SCP</span>-组织级权限控制 <div class="section-title"><strong>正确答案C:</strong></div> 使用AWS Config管理账户和CloudTrail组织轨迹实现集中管理，通过SCP精确控制基线资源权限，允许管理员创建自己的资源 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A-CloudFormation堆栈策略无法区分基线资源和用户创建的资源 </div><div class="compact-content">• 选项B-AWS Control Tower缺乏足够的权限粒度控制来满足特定需求 </div><div class="compact-content">• 选项D-SCP会阻止所有CloudTrail和Config操作，不允许管理员创建自己的资源 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-集中管理减少运营开销 </div><div class="compact-content">• 成本-利用组织级服务降低成本 </div><div class="compact-content">• 可扩展性-支持大规模账户管理和权限控制</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: C</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-67">
            <div class="question-header">
                <div class="question-title">Question #67 ✅ 📝 <small style="float: right;">(67/353)</small></div>
            </div>
            <div class="question-content">A company has its AWS accounts in an organization in <span class="key-service">AWS Organizations</span>. <span class="key-service">AWS Config</span> is manually configured in each AWS account. The company needs to implement a solution to centrally configure <span class="key-service">AWS Config</span> for all accounts in the organization. The solution also must record resource changes to a central account. Which combination of actions should a DevOps engineer perform to meet these requirements? (Choose two.) AE (84%) BD (16%)</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Configure a delegated administrator account for <span class="key-service">AWS Config</span>. Enable trusted access for <span class="key-service">AWS Config</span> in the organization.</div>                <div class="option correct-answer"><strong>B.</strong> Configure a delegated administrator account for <span class="key-service">AWS Config</span>. Create a service-linked role for <span class="key-service">AWS Config</span> in the organization's management account.</div>                <div class="option"><strong>C.</strong> Create an <span class="key-service">AWS CloudFormation</span> template to create an <span class="key-service">AWS Config</span> aggregator. Configure a CloudFormation stack set to deploy the template to all accounts in the organization.</div>                <div class="option correct-answer"><strong>D.</strong> Create an <span class="key-service">AWS Config</span> organization aggregator in the organization's management account. Configure data collection from all AWS accounts in the organization and from all AWS Regions.</div>                <div class="option"><strong>E.</strong> Create an <span class="key-service">AWS Config</span> organization aggregator in the delegated administrator account. Configure data collection from all AWS accounts in the organization and from all AWS Regions.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司在AWS Organizations中有多个AWS账户，每个账户都手动配置了AWS Config。公司需要实现一个解决方案来集中配置组织中所有账户的AWS Config，并将资源变更记录到中央账户。DevOps工程师应该执行哪些操作组合来满足这些要求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 为AWS Config配置委托管理员账户，在组织中为AWS Config启用可信访问</div> <div class="option-analysis"><strong>B.</strong> 为AWS Config配置委托管理员账户，在组织的管理账户中为AWS Config创建服务链接角色</div> <div class="option-analysis"><strong>C.</strong> 创建AWS CloudFormation模板来创建AWS Config聚合器，配置CloudFormation堆栈集将模板部署到组织中的所有账户</div> <div class="option-analysis"><strong>D.</strong> 在组织的管理账户中创建AWS Config组织聚合器，配置从组织中所有AWS账户和所有AWS区域收集数据</div> <div class="option-analysis"><strong>E.</strong> 在委托管理员账户中创建AWS Config组织聚合器，配置从组织中所有AWS账户和所有AWS区域收集数据<div class="section-title"><strong>核心要求:</strong></div> 集中配置组织内所有账户的AWS Config并将资源变更记录到中央账户 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• <span class="key-service">AWS Config</span> - 记录和评估AWS资源配置的服务 </div><div class="compact-content">• <span class="key-service">AWS Organizations</span> - 集中管理多个AWS账户的服务 <div class="section-title"><strong>正确答案BD:</strong></div> B选项配置委托管理员账户和服务链接角色实现集中管理，D选项在管理账户中创建组织聚合器收集所有账户的配置数据到中央位置 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A - 仅启用可信访问不足以实现完整的集中配置和数据收集 </div><div class="compact-content">• 选项C - 使用CloudFormation堆栈集部署聚合器过于复杂且不是最佳实践 </div><div class="compact-content">• 选项E - 组织聚合器应在管理账户而非委托管理员账户中创建 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能 - 组织聚合器提供统一的配置数据视图 </div><div class="compact-content">• 成本 - 避免在每个账户重复部署聚合器 </div><div class="compact-content">• 可扩展性 - 委托管理员模式支持大规模组织管理</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: BD (B、D)</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-68">
            <div class="question-header">
                <div class="question-title">Question #68 ✅ ⚪ <small style="float: right;">(68/353)</small></div>
            </div>
            <div class="question-content">A company wants to migrate its content sharing web application hosted on <span class="key-service">Amazon EC2</span> to a serverless architecture. The company currently deploys changes to its application by creating a new Auto Scaling group of EC2 instances and a new Elastic Load Balancer, and then shifting the traffic away using an <span class="key-service">Amazon Route 53</span> weighted routing policy. For its new serverless application, the company is planning to use <span class="key-service">Amazon API Gateway</span> and <span class="key-service">AWS Lambda</span>. The company will need to update its deployment processes to work with the new application. It will also need to retain the ability to test new features on a small number of users before rolling the features out to the entire user base. Which deployment strategy will meet these requirements? B (100%)</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Use AWS CDK to deploy API Gateway and Lambda functions. When code needs to be changed, update the <span class="key-service">AWS CloudFormation</span> stack and deploy the new version of the APIs and Lambda functions. Use a Route 53 failover routing policy for the canary release strategy.</div>                <div class="option correct-answer"><strong>B.</strong> Use <span class="key-service">AWS CloudFormation</span> to deploy API Gateway and Lambda functions using Lambda function versions. When code needs to be changed, update the CloudFormation stack with the new Lambda code and update the API versions using a canary release strategy. Promote the new version when testing is complete.</div>                <div class="option"><strong>C.</strong> Use AWS Elastic Beanstalk to deploy API Gateway and Lambda functions. When code needs to be changed, deploy a new version of the API and Lambda functions. Shift traffic gradually using an Elastic Beanstalk blue/green deployment.</div>                <div class="option"><strong>D.</strong> Use AWS OpsWorks to deploy API Gateway in the service layer and Lambda functions in a custom layer. When code needs to be changed, use OpsWorks to perform a blue/green deployment and shift traffic gradually.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司想要将托管在Amazon EC2上的内容共享web应用程序迁移到serverless架构。公司目前通过创建新的Auto Scaling组和新的Elastic Load Balancer来部署应用程序变更，然后使用Amazon Route 53加权路由策略转移流量。对于新的serverless应用程序，公司计划使用Amazon API Gateway和AWS Lambda。公司需要更新其部署流程以适应新应用程序，还需要保留在向整个用户群推出功能之前在少数用户上测试新功能的能力。哪种部署策略能满足这些要求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 使用AWS CDK部署API Gateway和Lambda函数。当需要更改代码时，更新AWS CloudFormation堆栈并部署新版本的API和Lambda函数。使用Route 53故障转移路由策略进行金丝雀发布策略。</div> <div class="option-analysis"><strong>B.</strong> 使用AWS CloudFormation部署API Gateway和Lambda函数，使用Lambda函数版本。当需要更改代码时，使用新的Lambda代码更新CloudFormation堆栈，并使用金丝雀发布策略更新API版本。测试完成后提升新版本。</div> <div class="option-analysis"><strong>C.</strong> 使用AWS Elastic Beanstalk部署API Gateway和Lambda函数。当需要更改代码时，部署新版本的API和Lambda函数。使用Elastic Beanstalk蓝绿部署逐步转移流量。</div> <div class="option-analysis"><strong>D.</strong> 使用AWS OpsWorks在服务层部署API Gateway，在自定义层部署Lambda函数。当需要更改代码时，使用OpsWorks执行蓝绿部署并逐步转移流量。<div class="section-title"><strong>核心要求:</strong></div> 实现serverless架构的金丝雀部署，支持小规模用户测试后全量发布 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• API Gateway-提供serverless API管理和流量控制 </div><div class="compact-content">• Lambda函数版本-支持多版本并存和流量分配 </div><div class="compact-content">• CloudFormation-基础设施即代码管理 <div class="section-title"><strong>正确答案B:</strong></div> 使用CloudFormation管理基础设施，Lambda函数版本实现版本控制，API Gateway的金丝雀发布功能实现流量逐步切换 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A-Route 53故障转移路由不适用于金丝雀发布，且CDK不是必需的 </div><div class="compact-content">• 选项C-Elastic Beanstalk不支持Lambda函数部署，主要用于传统应用 </div><div class="compact-content">• 选项D-OpsWorks不是serverless服务的最佳部署工具 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-Lambda版本和API Gateway金丝雀发布提供无缝切换 </div><div class="compact-content">• 成本-serverless架构按使用量计费，CloudFormation免费 </div><div class="compact-content">• 可扩展性-Lambda自动扩展，API Gateway支持高并发</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: B</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-69">
            <div class="question-header">
                <div class="question-title">Question #69 ✅ ⚪ <small style="float: right;">(69/353)</small></div>
            </div>
            <div class="question-content">A development team uses <span class="key-service">AWS CodeCommit</span>, <span class="key-service">AWS CodePipeline</span>, and <span class="key-service">AWS CodeBuild</span> to develop and deploy an application. Changes to the code are submitted by pull requests. The development team reviews and merges the pull requests, and then the pipeline builds and tests the application. Over time, the number of pull requests has increased. The pipeline is frequently blocked because of failing tests. To prevent this blockage, the development team wants to run the unit and integration tests on each pull request before it is merged. Which solution will meet these requirements? B (77%) D (15%) 4%</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Create a CodeBuild project to run the unit and integration tests. Create a CodeCommit approval rule template. Configure the template to require the successful invocation of the CodeBuild project. Attach the approval rule to the project's CodeCommit repository.</div>                <div class="option correct-answer"><strong>B.</strong> Create an Amazon EventBridge rule to match pullRequestCreated events from CodeCommit. Create a CodeBuild project to run the unit and integration tests. Configure the CodeBuild project as a target of the EventBridge rule that includes a custom event payload with the CodeCommit repository and branch information from the event. Most Voted</div>                <div class="option"><strong>C.</strong> Create an Amazon EventBridge rule to match pullRequestCreated events from CodeCommit. Modify the existing CodePipeline pipeline to not run the deploy steps if the build is started from a pull request. Configure the EventBridge rule to run the pipeline with a custom payload that contains the CodeCommit repository and branch information from the event.</div>                <div class="option"><strong>D.</strong> Create a CodeBuild project to run the unit and integration tests. Create a CodeCommit notification rule that matches when a pull request is created or updated. Configure the notification rule to invoke the CodeBuild project.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 开发团队使用AWS CodeCommit、AWS CodePipeline和AWS CodeBuild开发部署应用。代码变更通过pull request提交，团队审查合并后pipeline构建测试应用。随着pull request增加，pipeline因测试失败频繁阻塞。团队希望在每个pull request合并前运行单元和集成测试以防止阻塞。 <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 创建CodeBuild项目运行单元和集成测试，创建CodeCommit审批规则模板，配置模板要求成功调用CodeBuild项目，将审批规则附加到项目的CodeCommit仓库</div> <div class="option-analysis"><strong>B.</strong> 创建Amazon EventBridge规则匹配CodeCommit的pullRequestCreated事件，创建CodeBuild项目运行单元和集成测试，配置CodeBuild项目作为EventBridge规则目标，包含来自事件的CodeCommit仓库和分支信息的自定义事件负载</div> <div class="option-analysis"><strong>C.</strong> 创建Amazon EventBridge规则匹配CodeCommit的pullRequestCreated事件，修改现有CodePipeline pipeline在从pull request启动构建时不运行部署步骤，配置EventBridge规则使用包含事件中CodeCommit仓库和分支信息的自定义负载运行pipeline</div> <div class="option-analysis"><strong>D.</strong> 创建CodeBuild项目运行单元和集成测试，创建CodeCommit通知规则匹配pull request创建或更新时，配置通知规则调用CodeBuild项目<div class="section-title"><strong>核心要求:</strong></div> 在pull request合并前自动运行测试防止pipeline阻塞 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• EventBridge-事件驱动架构，监听CodeCommit事件 </div><div class="compact-content">• CodeBuild-独立运行测试任务 </div><div class="compact-content">• CodeCommit-Git仓库服务，支持pull request事件 <div class="section-title"><strong>正确答案B:</strong></div> EventBridge监听pullRequestCreated事件自动触发专用CodeBuild项目执行测试，通过自定义负载传递仓库和分支信息，实现pull request级别的独立测试 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A-审批规则模板无法自动触发CodeBuild项目执行 </div><div class="compact-content">• 选项C-重用现有pipeline复杂且可能影响正常部署流程 </div><div class="compact-content">• 选项D-CodeCommit通知规则主要用于SNS/SQS通知，不直接支持调用CodeBuild <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-事件驱动架构实现实时响应pull request </div><div class="compact-content">• 成本-独立CodeBuild项目避免影响主pipeline </div><div class="compact-content">• 可扩展性-EventBridge支持多种事件类型和目标服务</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: B</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-70">
            <div class="question-header">
                <div class="question-title">Question #70 ✅ ⚪ <small style="float: right;">(70/353)</small></div>
            </div>
            <div class="question-content">A company has an application that runs on a fleet of <span class="key-service">Amazon EC2</span> instances. The application requires frequent restarts. The application logs contain error messages when a restart is required. The application logs are published to a log group in <span class="key-service">Amazon CloudWatch</span> Logs. An <span class="key-service">Amazon CloudWatch</span> alarm notifies an application engineer through an Amazon Simple Notification Service (<span class="key-service">Amazon SNS</span>) topic when the logs contain a large number of restart-related error messages. The application engineer manually restarts the application on the instances after the application engineer receives a notification from the SNS topic. A DevOps engineer needs to implement a solution to automate the application restart on the instances without restarting the instances. Which solution will meet these requirements in the MOST operationally efficient manner? D (68%) C (17%) B (14%)</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Configure an <span class="key-service">AWS Systems Manager</span> Automation runbook that runs a script to restart the application on the instances. Configure the SNS topic to invoke the runbook.</div>                <div class="option correct-answer"><strong>B.</strong> Create an <span class="key-service">AWS Lambda</span> function that restarts the application on the instances. Configure the Lambda function as an event destination of the SNS topic.</div>                <div class="option"><strong>C.</strong> Configure an <span class="key-service">AWS Systems Manager</span> Automation runbook that runs a script to restart the application on the instances. Create an <span class="key-service">AWS Lambda</span> function to invoke the runbook. Configure the Lambda function as an event destination of the SNS topic.</div>                <div class="option"><strong>D.</strong> Configure an <span class="key-service">AWS Systems Manager</span> Automation runbook that runs a script to restart the application on the instances. Configure an Amazon EventBridge rule that reacts when the CloudWatch alarm enters ALARM state. Specify the runbook as a target of the rule.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司有一个运行在Amazon EC2实例集群上的应用程序。该应用程序需要频繁重启。当需要重启时，应用程序日志包含错误消息。应用程序日志发布到Amazon CloudWatch Logs中的日志组。当日志包含大量重启相关错误消息时，Amazon CloudWatch告警通过Amazon SNS主题通知应用程序工程师。应用程序工程师在收到SNS主题通知后手动重启实例上的应用程序。DevOps工程师需要实现一个解决方案来自动重启实例上的应用程序而不重启实例。哪个解决方案能以最具操作效率的方式满足这些要求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 配置AWS Systems Manager Automation运行手册，运行脚本在实例上重启应用程序。配置SNS主题调用该运行手册。</div> <div class="option-analysis"><strong>B.</strong> 创建AWS Lambda函数在实例上重启应用程序。将Lambda函数配置为SNS主题的事件目标。</div> <div class="option-analysis"><strong>C.</strong> 配置AWS Systems Manager Automation运行手册，运行脚本在实例上重启应用程序。创建AWS Lambda函数调用运行手册。将Lambda函数配置为SNS主题的事件目标。</div> <div class="option-analysis"><strong>D.</strong> 配置AWS Systems Manager Automation运行手册，运行脚本在实例上重启应用程序。配置Amazon EventBridge规则响应CloudWatch告警进入ALARM状态。指定运行手册作为规则的目标。<div class="section-title"><strong>核心要求:</strong></div> 自动化应用程序重启而不重启EC2实例，实现最高操作效率 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• SNS - 现有告警通知机制 </div><div class="compact-content">• Lambda - 轻量级自动化执行 </div><div class="compact-content">• Systems Manager - 实例管理和自动化 <div class="section-title"><strong>正确答案B:</strong></div> Lambda函数直接响应SNS通知并执行应用重启，架构简单直接，无需额外组件 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A - SNS无法直接调用Systems Manager Automation运行手册 </div><div class="compact-content">• 选项C - 增加不必要的Lambda到Systems Manager的中间层，降低操作效率 </div><div class="compact-content">• 选项D - 改变现有告警流程，需要重新配置EventBridge，增加复杂性 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能 - Lambda直接响应SNS，延迟最低 </div><div class="compact-content">• 成本 - 单一Lambda函数成本最优 </div><div class="compact-content">• 可扩展性 - 利用现有SNS架构，变更最小</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: B</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-71">
            <div class="question-header">
                <div class="question-title">Question #71 ✅ 📝 <small style="float: right;">(71/353)</small></div>
            </div>
            <div class="question-content">A DevOps engineer at a company is supporting an AWS environment in which all users use <span class="key-service">AWS IAM</span> Identity Center (AWS Single Sign-On). The company wants to immediately disable credentials of any new IAM user and wants the security team to receive a notification. Which combination of steps should the DevOps engineer take to meet these requirements? (Choose three.) ACE (100%)</div>
            <div class="options-container">                <div class="option correct-answer"><strong>A.</strong> Create an Amazon EventBridge rule that reacts to an IAM CreateUser API call in <span class="key-service">AWS CloudTrail</span>.</div>                <div class="option"><strong>B.</strong> Create an Amazon EventBridge rule that reacts to an IAM GetLoginProfile API call in <span class="key-service">AWS CloudTrail</span>.</div>                <div class="option correct-answer"><strong>C.</strong> Create an <span class="key-service">AWS Lambda</span> function that is a target of the EventBridge rule. Configure the Lambda function to disable any access keys and delete the login profiles that are associated with the IAM user.</div>                <div class="option"><strong>D.</strong> Create an <span class="key-service">AWS Lambda</span> function that is a target of the EventBridge rule. Configure the Lambda function to delete the login profiles that are associated with the IAM user.</div>                <div class="option correct-answer"><strong>E.</strong> Create an Amazon Simple Notification Service (<span class="key-service">Amazon SNS</span>) topic that is a target of the EventBridge rule. Subscribe the security team's group email address to the topic. F. Create an Amazon Simple Queue Service (<span class="key-service">Amazon SQS</span>) queue that is a target of the Lambda function. Subscribe the security team's group email address to the queue.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司的DevOps工程师正在支持一个所有用户都使用AWS IAM Identity Center (AWS Single Sign-On)的AWS环境。公司希望立即禁用任何新IAM用户的凭证，并希望安全团队收到通知。DevOps工程师应该采取哪些步骤组合来满足这些要求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 创建一个Amazon EventBridge规则，对AWS CloudTrail中的IAM CreateUser API调用做出反应</div> <div class="option-analysis"><strong>B.</strong> 创建一个Amazon EventBridge规则，对AWS CloudTrail中的IAM GetLoginProfile API调用做出反应</div> <div class="option-analysis"><strong>C.</strong> 创建一个AWS Lambda函数作为EventBridge规则的目标，配置Lambda函数禁用任何访问密钥并删除与IAM用户关联的登录配置文件</div> <div class="option-analysis"><strong>D.</strong> 创建一个AWS Lambda函数作为EventBridge规则的目标，配置Lambda函数删除与IAM用户关联的登录配置文件</div> <div class="option-analysis"><strong>E.</strong> 创建一个Amazon SNS主题作为EventBridge规则的目标，将安全团队的组邮箱地址订阅到该主题 F. 创建一个Amazon SQS队列作为Lambda函数的目标，将安全团队的组邮箱地址订阅到该队列<div class="section-title"><strong>核心要求:</strong></div> 检测新IAM用户创建并立即禁用其凭证，同时通知安全团队 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• EventBridge-监控CloudTrail中的API调用事件 </div><div class="compact-content">• Lambda-执行自动化禁用凭证操作 </div><div class="compact-content">• SNS-发送通知给安全团队 <div class="section-title"><strong>正确答案ACE:</strong></div> EventBridge监控CreateUser API调用触发Lambda函数禁用访问密钥和登录配置文件，同时通过SNS通知安全团队 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项B-GetLoginProfile是查询操作，不是创建用户的触发事件 </div><div class="compact-content">• 选项D-只删除登录配置文件，未禁用访问密钥，安全措施不完整 </div><div class="compact-content">• 选项F-SQS不能直接发送邮件通知，且架构设计不合理 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-EventBridge实时响应API调用，Lambda快速执行禁用操作 </div><div class="compact-content">• 成本-按使用量付费的无服务器架构，成本效益高 </div><div class="compact-content">• 可扩展性-事件驱动架构自动处理任意数量的用户创建事件</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: ACE (A、C、E)</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-72">
            <div class="question-header">
                <div class="question-title">Question #72 ✅ ⚪ <small style="float: right;">(72/353)</small></div>
            </div>
            <div class="question-content">A company wants to set up a continuous delivery pipeline. The company stores application code in a private GitHub repository. The company needs to deploy the application components to Amazon Elastic Container Service (<span class="key-service">Amazon ECS</span>), <span class="key-service">Amazon EC2</span>, and <span class="key-service">AWS Lambda</span>. The pipeline must support manual approval actions. Which solution will meet these requirements? B (92%) 4%</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Use <span class="key-service">AWS CodePipeline</span> with <span class="key-service">Amazon ECS</span>, <span class="key-service">Amazon EC2</span>, and Lambda as deploy providers.</div>                <div class="option correct-answer"><strong>B.</strong> Use <span class="key-service">AWS CodePipeline</span> with <span class="key-service">AWS CodeDeploy</span> as the deploy provider.</div>                <div class="option"><strong>C.</strong> Use <span class="key-service">AWS CodePipeline</span> with AWS Elastic Beanstalk as the deploy provider.</div>                <div class="option"><strong>D.</strong> Use <span class="key-service">AWS CodeDeploy</span> with GitHub integration to deploy the application.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司想要建立持续交付管道。公司将应用程序代码存储在私有GitHub仓库中。公司需要将应用程序组件部署到Amazon ECS、Amazon EC2和AWS Lambda。管道必须支持手动批准操作。 <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 使用AWS CodePipeline，以Amazon ECS、Amazon EC2和Lambda作为部署提供商。</div> <div class="option-analysis"><strong>B.</strong> 使用AWS CodePipeline，以AWS CodeDeploy作为部署提供商。</div> <div class="option-analysis"><strong>C.</strong> 使用AWS CodePipeline，以AWS Elastic Beanstalk作为部署提供商。</div> <div class="option-analysis"><strong>D.</strong> 使用AWS CodeDeploy与GitHub集成来部署应用程序。<div class="section-title"><strong>核心要求:</strong></div> 建立支持多目标部署和手动批准的持续交付管道 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• <span class="key-service">AWS CodePipeline</span>-提供持续交付管道和手动批准功能 </div><div class="compact-content">• <span class="key-service">AWS CodeDeploy</span>-支持向ECS、EC2、Lambda的统一部署 <div class="section-title"><strong>正确答案B:</strong></div> CodePipeline提供完整的CI/CD管道和手动批准功能，CodeDeploy作为部署提供商可以统一管理向ECS、EC2、Lambda的部署 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A-直接使用多个部署提供商会增加管道复杂性，不如统一使用CodeDeploy </div><div class="compact-content">• 选项C-Elastic Beanstalk不支持Lambda部署，无法满足多目标部署需求 </div><div class="compact-content">• 选项D-仅使用CodeDeploy缺少完整的管道功能和手动批准机制 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-统一部署提供商简化管道管理 </div><div class="compact-content">• 成本-CodePipeline+CodeDeploy组合成本效益最优 </div><div class="compact-content">• 可扩展性-支持未来添加更多部署目标和批准流程</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: B</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-73">
            <div class="question-header">
                <div class="question-title">Question #73 ✅ ⚪ <small style="float: right;">(73/353)</small></div>
            </div>
            <div class="question-content">A company has an application that runs on <span class="key-service">Amazon EC2</span> instances that are in an Auto Scaling group. When the application starts up, the application needs to process data from an <span class="key-service">Amazon S3</span> bucket before the application can start to serve requests. The size of the data that is stored in the S3 bucket is growing. When the Auto Scaling group adds new instances, the application now takes several minutes to download and process the data before the application can serve requests. The company must reduce the time that elapses before new EC2 instances are ready to serve requests. Which solution is the MOST cost-effective way to reduce the application startup time? A (86%) 14%</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Configure a warm pool for the Auto Scaling group with warmed EC2 instances in the Stopped state. Configure an autoscaling:EC2_INSTANCE_LAUNCHING lifecycle hook on the Auto Scaling group. Modify the application to complete the lifecycle hook when the application is ready to serve requests.</div>                <div class="option"><strong>B.</strong> Increase the maximum instance count of the Auto Scaling group. Configure an autoscaling:EC2_INSTANCE_LAUNCHING lifecycle hook on the Auto Scaling group. Modify the application to complete the lifecycle hook when the application is ready to serve requests.</div>                <div class="option correct-answer"><strong>C.</strong> Configure a warm pool for the Auto Scaling group with warmed EC2 instances in the Running state. Configure an autoscaling:EC2_INSTANCE_LAUNCHING lifecycle hook on the Auto Scaling group. Modify the application to complete the lifecycle hook when the application is ready to serve requests.</div>                <div class="option"><strong>D.</strong> Increase the maximum instance count of the Auto Scaling group. Configure an autoscaling:EC2_INSTANCE_LAUNCHING lifecycle hook on the Auto Scaling group. Modify the application to complete the lifecycle hook and to place the new instance in the Standby state when the application is ready to serve requests.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司的应用程序运行在Auto Scaling组中的Amazon EC2实例上。应用程序启动时需要先处理Amazon S3存储桶中的数据才能开始服务请求。S3存储桶中的数据量不断增长。当Auto Scaling组添加新实例时，应用程序现在需要几分钟下载和处理数据才能服务请求。公司必须减少新EC2实例准备好服务请求前的时间。哪种解决方案是减少应用程序启动时间最具成本效益的方式？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 为Auto Scaling组配置warm pool，其中预热的EC2实例处于Stopped状态。在Auto Scaling组上配置autoscaling:EC2_INSTANCE_LAUNCHING生命周期钩子。修改应用程序以在准备好服务请求时完成生命周期钩子。</div> <div class="option-analysis"><strong>B.</strong> 增加Auto Scaling组的最大实例数。在Auto Scaling组上配置autoscaling:EC2_INSTANCE_LAUNCHING生命周期钩子。修改应用程序以在准备好服务请求时完成生命周期钩子。</div> <div class="option-analysis"><strong>C.</strong> 为Auto Scaling组配置warm pool，其中预热的EC2实例处于Running状态。在Auto Scaling组上配置autoscaling:EC2_INSTANCE_LAUNCHING生命周期钩子。修改应用程序以在准备好服务请求时完成生命周期钩子。</div> <div class="option-analysis"><strong>D.</strong> 增加Auto Scaling组的最大实例数。在Auto Scaling组上配置autoscaling:EC2_INSTANCE_LAUNCHING生命周期钩子。修改应用程序以完成生命周期钩子并在准备好服务请求时将新实例置于Standby状态。<div class="section-title"><strong>核心要求:</strong></div> 减少新EC2实例启动时间，以最具成本效益的方式解决数据预处理延迟问题 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• Auto Scaling Warm Pool-预先创建和预热实例以减少启动时间 </div><div class="compact-content">• Lifecycle Hook-控制实例启动过程，确保应用程序完全就绪后才接收流量 <div class="section-title"><strong>正确答案C:</strong></div> 使用Running状态的warm pool实例已完成数据预处理，结合lifecycle hook确保应用程序完全准备就绪后才开始服务，实现最快启动时间 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A-Stopped状态的实例仍需启动时间和数据处理时间，无法充分减少延迟 </div><div class="compact-content">• 选项B-仅增加实例数量不解决启动时间问题，且增加不必要成本 </div><div class="compact-content">• 选项D-增加实例数量浪费资源，Standby状态配置不当且成本较高 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-Running状态warm pool提供最快的实例就绪时间 </div><div class="compact-content">• 成本-warm pool比持续运行额外实例更经济，避免资源浪费 </div><div class="compact-content">• 可扩展性-warm pool自动管理预热实例数量，适应扩展需求</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: C</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-74">
            <div class="question-header">
                <div class="question-title">Question #74 ✅ ⚪ <small style="float: right;">(74/353)</small></div>
            </div>
            <div class="question-content">A company is using an <span class="key-service">AWS CodeBuild</span> project to build and package an application. The packages are copied to a shared <span class="key-service">Amazon S3</span> bucket before being deployed across multiple AWS accounts. The buildspec.yml file contains the following: The DevOps engineer has noticed that anybody with an AWS account is able to download the artifacts. What steps should the DevOps engineer take to stop this? D (79%) A (21%)</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Modify the post_build command to use --acl public-read and configure a bucket policy that grants read access to the relevant AWS accounts only.</div>                <div class="option"><strong>B.</strong> Configure a default ACL for the S3 bucket that defines the set of authenticated users as the relevant AWS accounts only and grants read-only access.</div>                <div class="option"><strong>C.</strong> Create an S3 bucket policy that grants read access to the relevant AWS accounts and denies read access to the principal "*".</div>                <div class="option correct-answer"><strong>D.</strong> Modify the post_build command to remove --acl authenticated-read and configure a bucket policy that allows read access to the relevant AWS accounts only.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司使用AWS CodeBuild项目构建和打包应用程序。包被复制到共享的Amazon S3存储桶中，然后部署到多个AWS账户。buildspec.yml文件包含相关配置。DevOps工程师注意到任何拥有AWS账户的人都能下载这些构件。DevOps工程师应该采取什么步骤来阻止这种情况？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 修改post_build命令使用--acl public-read，并配置存储桶策略仅向相关AWS账户授予读取访问权限。</div> <div class="option-analysis"><strong>B.</strong> 为S3存储桶配置默认ACL，将经过身份验证的用户集定义为仅相关AWS账户并授予只读访问权限。</div> <div class="option-analysis"><strong>C.</strong> 创建S3存储桶策略，向相关AWS账户授予读取访问权限，并拒绝主体"*"的读取访问权限。</div> <div class="option-analysis"><strong>D.</strong> 修改post_build命令移除--acl authenticated-read，并配置存储桶策略仅允许相关AWS账户读取访问。<div class="section-title"><strong>核心要求:</strong></div> 限制S3存储桶中构建产物的访问权限，仅允许特定AWS账户访问 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• <span class="key-service">AWS CodeBuild</span> - 构建和打包应用程序的托管服务 </div><div class="compact-content">• <span class="key-service">Amazon S3</span> - 存储构建产物的对象存储服务，支持ACL和存储桶策略进行访问控制 <div class="section-title"><strong>正确答案D:</strong></div> 移除宽松的authenticated-read ACL（允许所有AWS用户访问），改用存储桶策略精确控制特定账户的访问权限，实现最小权限原则 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A - public-read ACL比authenticated-read更宽松，会使问题恶化，允许任何人访问 </div><div class="compact-content">• 选项B - 默认ACL无法精确指定特定AWS账户，且配置复杂度高 </div><div class="compact-content">• 选项C - 仅依赖存储桶策略但未移除ACL，ACL和策略冲突时可能导致意外访问 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 安全性 - 移除宽松ACL，使用存储桶策略实现精确访问控制 </div><div class="compact-content">• 管理性 - 存储桶策略比ACL更易于管理多账户访问权限 </div><div class="compact-content">• <span class="key-point">最佳实践</span> - 遵循最小权限原则，仅授予必要的访问权限</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: D</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-75">
            <div class="question-header">
                <div class="question-title">Question #75 ✅ ⚪ <small style="float: right;">(75/353)</small></div>
            </div>
            <div class="question-content">A company has developed a serverless web application that is hosted on AWS. The application consists of <span class="key-service">Amazon S3</span>, <span class="key-service">Amazon API Gateway</span>, several <span class="key-service">AWS Lambda</span> functions, and an <span class="key-service">Amazon RDS</span> for MySQL database. The company is using <span class="key-service">AWS CodeCommit</span> to store the source code. The source code is a combination of AWS Serverless Application Model (AWS SAM) templates and Python code. A security audit and penetration test reveal that user names and passwords for authentication to the database are hardcoded within CodeCommit repositories. A DevOps engineer must implement a solution to automatically detect and prevent hardcoded secrets. What is the MOST secure solution that meets these requirements? B (95%) 5%</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Enable Amazon CodeGuru Profiler. Decorate the handler function with @with_lambda_profiler(). Manually review the recommendation report. Write the secret to <span class="key-service">AWS Systems Manager</span> Parameter Store as a secure string. Update the SAM templates and the Python code to pull the secret from Parameter Store.</div>                <div class="option correct-answer"><strong>B.</strong> Associate the CodeCommit repository with Amazon CodeGuru Reviewer. Manually check the code review for any recommendations. Choose the option to protect the secret. Update the SAM templates and the Python code to pull the secret from AWS Secrets Manager.</div>                <div class="option"><strong>C.</strong> Enable Amazon CodeGuru Profiler. Decorate the handler function with @with_lambda_profiler(). Manually review the recommendation report. Choose the option to protect the secret. Update the SAM templates and the Python code to pull the secret from AWS Secrets Manager.</div>                <div class="option"><strong>D.</strong> Associate the CodeCommit repository with Amazon CodeGuru Reviewer. Manually check the code review for any recommendations. Write the secret to <span class="key-service">AWS Systems Manager</span> Parameter Store as a string. Update the SAM templates and the Python code to pull the secret from Parameter Store.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司开发了托管在AWS上的无服务器Web应用程序，由Amazon S3、<span class="key-service">Amazon API Gateway</span>、多个AWS Lambda函数和Amazon RDS for MySQL数据库组成。公司使用AWS CodeCommit存储源代码，源代码包含AWS SAM模板和Python代码。安全审计和渗透测试发现数据库认证的用户名和密码在CodeCommit仓库中硬编码。DevOps工程师必须实施解决方案来自动检测和防止硬编码密钥。什么是满足这些要求的最安全解决方案？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 启用Amazon CodeGuru Profiler，用@with_lambda_profiler()装饰处理函数，手动审查推荐报告，将密钥作为安全字符串写入AWS Systems Manager Parameter Store，更新SAM模板和Python代码从Parameter Store拉取密钥。</div> <div class="option-analysis"><strong>B.</strong> 将CodeCommit仓库与Amazon CodeGuru Reviewer关联，手动检查代码审查的任何建议，选择保护密钥选项，更新SAM模板和Python代码从AWS Secrets Manager拉取密钥。</div> <div class="option-analysis"><strong>C.</strong> 启用Amazon CodeGuru Profiler，用@with_lambda_profiler()装饰处理函数，手动审查推荐报告，选择保护密钥选项，更新SAM模板和Python代码从AWS Secrets Manager拉取密钥。</div> <div class="option-analysis"><strong>D.</strong> 将CodeCommit仓库与Amazon CodeGuru Reviewer关联，手动检查代码审查的任何建议，将密钥作为字符串写入AWS Systems Manager Parameter Store，更新SAM模板和Python代码从Parameter Store拉取密钥。<div class="section-title"><strong>核心要求:</strong></div> 自动检测和防止代码中的硬编码密钥，实现最安全的密钥管理方案 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• Amazon CodeGuru Reviewer-静态代码分析，检测安全问题包括硬编码密钥 </div><div class="compact-content">• AWS Secrets Manager-专门的密钥管理服务，支持自动轮换和加密 </div><div class="compact-content">• Amazon CodeGuru Profiler-运行时性能分析工具，不用于静态代码安全检查 <div class="section-title"><strong>正确答案B:</strong></div> 使用CodeGuru Reviewer进行静态代码分析检测硬编码密钥，结合Secrets Manager提供最高级别的密钥安全管理 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A-使用CodeGuru Profiler而非Reviewer，Profiler是性能分析工具不检测代码安全问题 </div><div class="compact-content">• 选项C-同样错误使用CodeGuru Profiler进行安全检测，工具选择错误 </div><div class="compact-content">• 选项D-虽然使用正确的CodeGuru Reviewer，但Parameter Store普通字符串存储不如Secrets Manager安全 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 安全性-Secrets Manager提供专业密钥管理和自动轮换，比Parameter Store更安全 </div><div class="compact-content">• 检测能力-CodeGuru Reviewer专门用于静态代码分析和安全检测 </div><div class="compact-content">• 自动化-CodeGuru Reviewer可自动检测硬编码密钥问题</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: B</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-76">
            <div class="question-header">
                <div class="question-title">Question #76 ✅ ⚪ <small style="float: right;">(76/353)</small></div>
            </div>
            <div class="question-content">A company is using <span class="key-service">Amazon S3</span> buckets to store important documents. The company discovers that some S3 buckets are not encrypted. Currently, the company's IAM users can create new S3 buckets without encryption. The company is implementing a new requirement that all S3 buckets must be encrypted. A DevOps engineer must implement a solution to ensure that server-side encryption is enabled on all existing S3 buckets and all new S3 buckets. The encryption must be enabled on new S3 buckets as soon as the S3 buckets are created. The default encryption type must be 256-bit Advanced Encryption Standard (AES-256). Which solution will meet these requirements? B (90%) 10%</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Create an <span class="key-service">AWS Lambda</span> function that is invoked periodically by an Amazon EventBridge scheduled rule. Program the Lambda function to scan all current S3 buckets for encryption status and to set AES-256 as the default encryption for any S3 bucket that does not have an encryption configuration.</div>                <div class="option"><strong>B.</strong> Set up and activate the s3-bucket-server-side-encryption-enabled <span class="key-service">AWS Config</span> managed rule. Configure the rule to use the AWS-EnableS3BucketEncryption <span class="key-service">AWS Systems Manager</span> Automation runbook as the remediation action. Manually run the re-evaluation process to ensure that existing S3 buckets are compliant.</div>                <div class="option"><strong>C.</strong> Create an <span class="key-service">AWS Lambda</span> function that is invoked by an Amazon EventBridge event rule. Define the rule with an event pattern that matches the creation of new S3 buckets. Program the Lambda function to parse the EventBridge event, check the configuration of the S3 buckets from the event, and set AES-256 as the default encryption.</div>                <div class="option correct-answer"><strong>D.</strong> Configure an IAM policy that denies the s3:CreateBucket action if the s3:x-amz-server-side-encryption condition key has a value that is not AES-256. Create an IAM group for all the company's IAM users. Associate the IAM policy with the IAM group.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司使用Amazon S3存储桶存储重要文档，发现部分S3存储桶未加密，当前IAM用户可以创建未加密的新S3存储桶。公司要求所有S3存储桶必须加密，DevOps工程师需要实现解决方案确保所有现有和新建S3存储桶都启用服务器端加密，新存储桶创建时立即启用加密，默认加密类型必须是256位AES-256。 <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 创建AWS Lambda函数，由Amazon EventBridge定时规则周期性调用，编程Lambda函数扫描所有当前S3存储桶的加密状态，为任何没有加密配置的S3存储桶设置AES-256作为默认加密。</div> <div class="option-analysis"><strong>B.</strong> 设置并激活s3-bucket-server-side-encryption-enabled AWS Config托管规则，配置规则使用AWS-EnableS3BucketEncryption <span class="key-service">AWS Systems Manager</span> Automation运行手册作为修复操作，手动运行重新评估过程确保现有S3存储桶合规。</div> <div class="option-analysis"><strong>C.</strong> 创建AWS Lambda函数，由Amazon EventBridge事件规则调用，定义规则使用匹配新S3存储桶创建的事件模式，编程Lambda函数解析EventBridge事件，检查事件中S3存储桶的配置并设置AES-256作为默认加密。</div> <div class="option-analysis"><strong>D.</strong> 配置IAM策略拒绝s3:CreateBucket操作，如果s3:x-amz-server-side-encryption条件键的值不是AES-256，为所有公司IAM用户创建IAM组并将IAM策略关联到IAM组。<div class="section-title"><strong>核心要求:</strong></div> 确保所有现有和新建S3存储桶强制启用AES-256加密 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• IAM Policy-通过条件键强制加密要求 </div><div class="compact-content">• S3 Bucket Encryption-服务器端加密配置 <div class="section-title"><strong>正确答案D:</strong></div> 使用IAM策略的条件键s3:x-amz-server-side-encryption在存储桶创建时强制要求AES-256加密，从源头预防创建未加密存储桶 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A-被动扫描方式存在时间窗口，无法在创建时立即强制加密 </div><div class="compact-content">• 选项B-Config规则是检测和修复机制，无法预防创建未加密存储桶 </div><div class="compact-content">• 选项C-事后检查和设置方式，存在短暂的未加密时间窗口 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-IAM策略在API调用时实时生效，无延迟 </div><div class="compact-content">• 成本-IAM策略无额外费用，Lambda和Config产生运行成本 </div><div class="compact-content">• 可扩展性-IAM策略自动应用于所有用户操作，无需额外配置</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: D</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-77">
            <div class="question-header">
                <div class="question-title">Question #77 ✅ ⚪ <small style="float: right;">(77/353)</small></div>
            </div>
            <div class="question-content">A DevOps engineer is architecting a continuous development strategy for a company's software as a service (SaaS) web application running on AWS. For application and security reasons, users subscribing to this application are distributed across multiple Application Load Balancers (ALBs), each of which has a dedicated Auto Scaling group and fleet of <span class="key-service">Amazon EC2</span> instances. The application does not require a build stage, and when it is committed to <span class="key-service">AWS CodeCommit</span>, the application must trigger a simultaneous deployment to all ALBs, Auto Scaling groups, and EC2 fleets. Which architecture will meet these requirements with the LEAST amount of configuration? C (73%) B (23%) 5%</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Create a single <span class="key-service">AWS CodePipeline</span> pipeline that deploys the application in parallel using unique <span class="key-service">AWS CodeDeploy</span> applications and deployment groups created for each ALB-Auto Scaling group pair.</div>                <div class="option"><strong>B.</strong> Create a single <span class="key-service">AWS CodePipeline</span> pipeline that deploys the application using a single <span class="key-service">AWS CodeDeploy</span> application and single deployment group.</div>                <div class="option correct-answer"><strong>C.</strong> Create a single <span class="key-service">AWS CodePipeline</span> pipeline that deploys the application in parallel using a single <span class="key-service">AWS CodeDeploy</span> application and unique deployment group for each ALB-Auto Scaling group pair.</div>                <div class="option"><strong>D.</strong> Create an <span class="key-service">AWS CodePipeline</span> pipeline for each ALB-Auto Scaling group pair that deploys the application using an <span class="key-service">AWS CodeDeploy</span> application and deployment group created for the same ALB-Auto Scaling group pair.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一名DevOps工程师正在为公司运行在AWS上的SaaS web应用程序设计持续开发策略。由于应用程序和安全原因，订阅此应用程序的用户分布在多个Application Load Balancer (ALB)上，每个ALB都有专用的Auto Scaling组和EC2实例集群。应用程序不需要构建阶段，当提交到AWS CodeCommit时，必须触发同时部署到所有ALB、Auto Scaling组和EC2集群。哪种架构能以最少的配置满足这些要求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 创建单个AWS CodePipeline流水线，使用为每个ALB-Auto Scaling组对创建的唯一AWS CodeDeploy应用程序和部署组并行部署应用程序。</div> <div class="option-analysis"><strong>B.</strong> 创建单个AWS CodePipeline流水线，使用单个AWS CodeDeploy应用程序和单个部署组部署应用程序。</div> <div class="option-analysis"><strong>C.</strong> 创建单个AWS CodePipeline流水线，使用单个AWS CodeDeploy应用程序和为每个ALB-Auto Scaling组对创建的唯一部署组并行部署应用程序。</div> <div class="option-analysis"><strong>D.</strong> 为每个ALB-Auto Scaling组对创建AWS CodePipeline流水线，使用为同一ALB-Auto Scaling组对创建的AWS CodeDeploy应用程序和部署组部署应用程序。<div class="section-title"><strong>核心要求:</strong></div> 实现同时部署到多个ALB-Auto Scaling组对的CI/CD架构，配置最少 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• <span class="key-service">AWS CodePipeline</span>-编排部署流程和并行执行 </div><div class="compact-content">• <span class="key-service">AWS CodeDeploy</span>-管理应用程序部署到EC2实例 </div><div class="compact-content">• <span class="key-service">AWS CodeCommit</span>-源代码仓库触发部署 <div class="section-title"><strong>正确答案C:</strong></div> 单个CodePipeline配合单个CodeDeploy应用程序和多个部署组，实现最优的资源复用和配置简化，每个部署组对应一个ALB-Auto Scaling组对，支持并行部署 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A-创建多个CodeDeploy应用程序增加不必要的配置复杂度 </div><div class="compact-content">• 选项B-单个部署组无法区分不同的ALB-Auto Scaling组对，无法满足分布式部署需求 </div><div class="compact-content">• 选项D-多个CodePipeline流水线大幅增加配置和维护成本 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-单个流水线并行部署确保同时触发所有目标 </div><div class="compact-content">• 成本-最少的CodePipeline和CodeDeploy应用程序数量降低运营成本 </div><div class="compact-content">• 可扩展性-部署组模式便于添加新的ALB-Auto Scaling组对</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: C</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-78">
            <div class="question-header">
                <div class="question-title">Question #78 ✅ ⚪ <small style="float: right;">(78/353)</small></div>
            </div>
            <div class="question-content">A company is hosting a static website from an <span class="key-service">Amazon S3</span> bucket. The website is available to customers at example.com. The company uses an <span class="key-service">Amazon Route 53</span> weighted routing policy with a TTL of 1 day. The company has decided to replace the existing static website with a dynamic web application. The dynamic web application uses an Application Load Balancer (ALB) in front of a fleet of <span class="key-service">Amazon EC2</span> instances. On the day of production launch to customers, the company creates an additional Route 53 weighted DNS record entry that points to the ALB with a weight of 255 and a TTL of 1 hour. Two days later, a DevOps engineer notices that the previous static website is displayed sometimes when customers navigate to example.com. How can the DevOps engineer ensure that the company serves only dynamic content for example.com? D (81%) B (19%)</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Delete all objects, including previous versions, from the S3 bucket that contains the static website content.</div>                <div class="option"><strong>B.</strong> Update the weighted DNS record entry that points to the S3 bucket. Apply a weight of 0. Specify the domain reset option to propagate changes immediately.</div>                <div class="option"><strong>C.</strong> Configure webpage redirect requests on the S3 bucket with a hostname that redirects to the ALB.</div>                <div class="option correct-answer"><strong>D.</strong> Remove the weighted DNS record entry that points to the S3 bucket from the example.com hosted zone. Wait for DNS propagation to become complete.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司从Amazon S3 bucket托管静态网站，客户通过example.com访问。公司使用Amazon Route 53加权路由策略，TTL为1天。公司决定用动态Web应用替换现有静态网站，动态应用使用Application Load Balancer (ALB)前置Amazon EC2实例集群。生产发布当天，公司创建了指向ALB的额外Route 53加权DNS记录，权重255，TTL为1小时。两天后，DevOps工程师发现客户访问example.com时有时仍显示旧的静态网站。工程师如何确保example.com只提供动态内容？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 删除包含静态网站内容的S3 bucket中的所有对象，包括以前的版本。</div> <div class="option-analysis"><strong>B.</strong> 更新指向S3 bucket的加权DNS记录条目，应用权重0，指定域重置选项以立即传播更改。</div> <div class="option-analysis"><strong>C.</strong> 在S3 bucket上配置网页重定向请求，使用重定向到ALB的主机名。</div> <div class="option-analysis"><strong>D.</strong> 从example.com托管区域中删除指向S3 bucket的加权DNS记录条目，等待DNS传播完成。<div class="section-title"><strong>核心要求:</strong></div> 确保域名只解析到新的动态应用而不再解析到旧的静态网站 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• Route 53 - DNS解析和加权路由策略管理 </div><div class="compact-content">• Application Load Balancer - 动态应用的负载均衡器 <div class="section-title"><strong>正确答案D:</strong></div> 直接删除指向S3的DNS记录是最彻底的解决方案，消除了DNS解析到旧网站的可能性，等待DNS传播后所有流量都将指向ALB <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A - 删除S3对象不能解决DNS仍然指向S3的根本问题 </div><div class="compact-content">• 选项B - Route 53没有"域重置选项"这个功能，且权重0仍保留记录 </div><div class="compact-content">• 选项C - 重定向方案增加复杂性且仍依赖DNS解析到S3 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能 - 直接DNS解析避免重定向延迟 </div><div class="compact-content">• 成本 - 删除不必要的DNS记录降低管理成本 </div><div class="compact-content">• 可扩展性 - 简化DNS配置便于后续维护</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: D</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-79">
            <div class="question-header">
                <div class="question-title">Question #79 ✅ ⚪ <small style="float: right;">(79/353)</small></div>
            </div>
            <div class="question-content">A company is implementing <span class="key-service">AWS CodePipeline</span> to automate its testing process. The company wants to be notified when the execution state fails and used the following custom event pattern in Amazon EventBridge: Which type of events will match this event pattern? B (100%)</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Failed deploy and build actions across all the pipelines</div>                <div class="option correct-answer"><strong>B.</strong> All rejected or failed approval actions across all the pipelines</div>                <div class="option"><strong>C.</strong> All the events across all pipelines</div>                <div class="option"><strong>D.</strong> Approval actions across all the pipelines</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司正在实施AWS CodePipeline来自动化其测试流程。该公司希望在执行状态失败时收到通知，并在Amazon EventBridge中使用了以下自定义事件模式：哪种类型的事件将匹配此事件模式？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 所有管道中失败的部署和构建操作</div> <div class="option-analysis"><strong>B.</strong> 所有管道中被拒绝或失败的审批操作</div> <div class="option-analysis"><strong>C.</strong> 所有管道中的所有事件</div> <div class="option-analysis"><strong>D.</strong> 所有管道中的审批操作<div class="section-title"><strong>核心要求:</strong></div> 理解EventBridge事件模式如何匹配CodePipeline中特定的审批操作状态 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• <span class="key-service">AWS CodePipeline</span> - 持续集成/持续部署服务，支持审批操作 </div><div class="compact-content">• Amazon EventBridge - 事件驱动架构服务，通过事件模式过滤特定事件 <div class="section-title"><strong>正确答案B:</strong></div> 事件模式专门配置为匹配CodePipeline中action-type为"Approval"且state为"FAILED"或"REJECTED"的事件，精确捕获审批操作的失败状态 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A - 事件模式限定了action-type为"Approval"，不包括deploy和build操作 </div><div class="compact-content">• 选项C - 事件模式有特定的state和action-type过滤条件，不会匹配所有事件 </div><div class="compact-content">• 选项D - 缺少state过滤条件，事件模式只匹配失败/拒绝状态的审批操作 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能 - EventBridge事件模式提供精确过滤，减少不必要的通知触发 </div><div class="compact-content">• 成本 - 精确的事件匹配降低下游处理成本和通知频率 </div><div class="compact-content">• 可扩展性 - 事件驱动架构支持多管道环境下的统一监控和通知机制</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: B</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-80">
            <div class="question-header">
                <div class="question-title">Question #80 ✅ ⚪ <small style="float: right;">(80/353)</small></div>
            </div>
            <div class="question-content">An application running on a set of <span class="key-service">Amazon EC2</span> instances in an Auto Scaling group requires a configuration file to operate. The instances are created and maintained with <span class="key-service">AWS CloudFormation</span>. A DevOps engineer wants the instances to have the latest configuration file when launched, and wants changes to the configuration file to be reflected on all the instances with a minimal delay when the CloudFormation template is updated. Company policy requires that application configuration files be maintained along with AWS infrastructure configuration files in source control. Which solution will accomplish this? D (77%) B (23%)</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> In the CloudFormation template, add an <span class="key-service">AWS Config</span> rule. Place the configuration file content in the rule's InputParameters property, and set the Scope property to the EC2 Auto Scaling group. Add an <span class="key-service">AWS Systems Manager</span> Resource Data Sync resource to the template to poll for updates to the configuration.</div>                <div class="option correct-answer"><strong>B.</strong> In the CloudFormation template, add an EC2 launch template resource. Place the configuration file content in the launch template. Configure the cfn-init script to run when the instance is launched, and configure the cfn-hup script to poll for updates to the configuration.</div>                <div class="option"><strong>C.</strong> In the CloudFormation template, add an EC2 launch template resource. Place the configuration file content in the launch template. Add an <span class="key-service">AWS Systems Manager</span> Resource Data Sync resource to the template to poll for updates to the configuration.</div>                <div class="option"><strong>D.</strong> In the CloudFormation template, add CloudFormation init metadata. Place the configuration file content in the metadata. Configure the cfn-init script to run when the instance is launched, and configure the cfn-hup script to poll for updates to the configuration.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 运行在Auto Scaling组中一组Amazon EC2实例上的应用程序需要配置文件才能运行。实例通过AWS CloudFormation创建和维护。DevOps工程师希望实例启动时拥有最新配置文件，并希望CloudFormation模板更新时配置文件变更能以最小延迟反映到所有实例上。公司政策要求应用程序配置文件与AWS基础设施配置文件一起在源代码控制中维护。 <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 在CloudFormation模板中添加AWS Config规则，将配置文件内容放在规则的InputParameters属性中，设置Scope属性为EC2 Auto Scaling组，添加AWS Systems Manager Resource Data Sync资源到模板中轮询配置更新。</div> <div class="option-analysis"><strong>B.</strong> 在CloudFormation模板中添加EC2启动模板资源，将配置文件内容放在启动模板中，配置cfn-init脚本在实例启动时运行，配置cfn-hup脚本轮询配置更新。</div> <div class="option-analysis"><strong>C.</strong> 在CloudFormation模板中添加EC2启动模板资源，将配置文件内容放在启动模板中，添加AWS Systems Manager Resource Data Sync资源到模板中轮询配置更新。</div> <div class="option-analysis"><strong>D.</strong> 在CloudFormation模板中添加CloudFormation init元数据，将配置文件内容放在元数据中，配置cfn-init脚本在实例启动时运行，配置cfn-hup脚本轮询配置更新。<div class="section-title"><strong>核心要求:</strong></div> 实现EC2实例配置文件的自动部署和实时更新机制 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• EC2 Launch Template-定义实例启动配置和用户数据 </div><div class="compact-content">• CloudFormation Helper Scripts-cfn-init初始化配置，cfn-hup监控更新 <div class="section-title"><strong>正确答案B:</strong></div> 使用EC2启动模板存储配置文件，通过cfn-init实现初始化部署，cfn-hup实现配置变更的实时监控和更新 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A-AWS Config用于合规性检查而非配置文件部署，Resource Data Sync用于数据同步而非配置更新 </div><div class="compact-content">• 选项C-缺少cfn-hup脚本无法实现配置变更的实时更新，Resource Data Sync不适用于此场景 </div><div class="compact-content">• 选项D-CloudFormation init元数据方式较老且不如启动模板灵活，但技术上可行 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-cfn-hup提供近实时的配置更新检测 </div><div class="compact-content">• 成本-使用原生CloudFormation功能无额外费用 </div><div class="compact-content">• 可扩展性-启动模板支持版本管理和Auto Scaling集成</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: B</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-81">
            <div class="question-header">
                <div class="question-title">Question #81 ✅ 📝 <small style="float: right;">(81/353)</small></div>
            </div>
            <div class="question-content">A company manages an application that stores logs in <span class="key-service">Amazon CloudWatch</span> Logs. The company wants to archive the logs to an <span class="key-service">Amazon S3</span> bucket. Logs are rarely accessed after 90 days and must be retained for 10 years. Which combination of steps should a DevOps engineer take to meet these requirements? (Choose two.) BD (83%) CD (17%)</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Configure a CloudWatch Logs subscription filter to use AWS Glue to transfer all logs to an S3 bucket.</div>                <div class="option correct-answer"><strong>B.</strong> Configure a CloudWatch Logs subscription filter to use Amazon Kinesis Data Firehose to stream all logs to an S3 bucket.</div>                <div class="option"><strong>C.</strong> Configure a CloudWatch Logs subscription filter to stream all logs to an S3 bucket.</div>                <div class="option correct-answer"><strong>D.</strong> Configure the S3 bucket lifecycle policy to transition logs to S3 Glacier after 90 days and to expire logs after 3,650 days.</div>                <div class="option"><strong>E.</strong> Configure the S3 bucket lifecycle policy to transition logs to Reduced Redundancy after 90 days and to expire logs after 3,650 days.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司管理一个将日志存储在Amazon CloudWatch Logs中的应用程序。公司希望将日志归档到Amazon S3存储桶。日志在90天后很少被访问，必须保留10年。DevOps工程师应采取哪些步骤组合来满足这些要求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 配置CloudWatch Logs订阅筛选器使用AWS Glue将所有日志传输到S3存储桶</div> <div class="option-analysis"><strong>B.</strong> 配置CloudWatch Logs订阅筛选器使用Amazon Kinesis Data Firehose将所有日志流式传输到S3存储桶</div> <div class="option-analysis"><strong>C.</strong> 配置CloudWatch Logs订阅筛选器将所有日志流式传输到S3存储桶</div> <div class="option-analysis"><strong>D.</strong> 配置S3存储桶生命周期策略在90天后将日志转换到S3 Glacier并在3650天后过期删除日志</div> <div class="option-analysis"><strong>E.</strong> 配置S3存储桶生命周期策略在90天后将日志转换到Reduced Redundancy并在3650天后过期删除日志<div class="section-title"><strong>核心要求:</strong></div> 将CloudWatch Logs归档到S3并实现长期低成本存储 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• CloudWatch Logs订阅筛选器-实现日志自动导出到其他AWS服务 </div><div class="compact-content">• Kinesis Data Firehose-提供可靠的流式数据传输到S3的托管服务 </div><div class="compact-content">• S3生命周期策略-自动管理对象存储类别转换和过期删除 <div class="section-title"><strong>正确答案BD:</strong></div> Kinesis Data Firehose提供可靠的流式传输机制将CloudWatch Logs持续导出到S3，生命周期策略将90天后的日志转换到Glacier实现低成本长期存储 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A-AWS Glue是ETL服务不是日志流式传输的最佳选择 </div><div class="compact-content">• 选项C-订阅筛选器无法直接流式传输到S3需要中间服务如Firehose </div><div class="compact-content">• 选项E-Reduced Redundancy存储类别成本高于Glacier且已被弃用 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-Firehose提供可靠的流式传输和自动重试机制 </div><div class="compact-content">• 成本-Glacier存储类别显著降低长期存储成本 </div><div class="compact-content">• 可扩展性-托管服务自动处理容量扩展和数据传输</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: BD (B、D)</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-82">
            <div class="question-header">
                <div class="question-title">Question #82 ✅ 📝 <small style="float: right;">(82/353)</small></div>
            </div>
            <div class="question-content">A company is developing a new application. The application uses <span class="key-service">AWS Lambda</span> functions for its compute tier. The company must use a canary deployment for any changes to the Lambda functions. Automated rollback must occur if any failures are reported. The company's DevOps team needs to create the infrastructure as code (IaC) and the CI/CD pipeline for this solution. Which combination of steps will meet these requirements? (Choose three.) BCF (89%) 11%</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Create an <span class="key-service">AWS CloudFormation</span> template for the application. Define each Lambda function in the template by using the AWS::Lambda::Function resource type. In the template, include a version for the Lambda function by using the AWS::Lambda::Version resource type. Declare the CodeSha256 property. Configure an AWS::Lambda::Alias resource that references the latest version of the Lambda function.</div>                <div class="option correct-answer"><strong>B.</strong> Create an AWS Serverless Application Model (AWS SAM) template for the application. Define each Lambda function in the template by using the AWS::Serverless::Function resource type. For each function, include configurations for the AutoPublishAlias property and the DeploymentPreference property. Configure the deployment configuration type to LambdaCanary10Percent10Minutes.</div>                <div class="option correct-answer"><strong>C.</strong> Create an <span class="key-service">AWS CodeCommit</span> repository. Create an <span class="key-service">AWS CodePipeline</span> pipeline. Use the CodeCommit repository in a new source stage that starts the pipeline. Create an <span class="key-service">AWS CodeBuild</span> project to deploy the AWS Serverless Application Model (AWS SAM) template. Upload the template and source code to the CodeCommit repository. In the CodeCommit repository, create a buildspec.yml file that includes the commands to build and deploy the SAM application. Most Voted</div>                <div class="option"><strong>D.</strong> Create an <span class="key-service">AWS CodeCommit</span> repository. Create an <span class="key-service">AWS CodePipeline</span> pipeline. Use the CodeCommit repository in a new source stage that starts the pipeline. Create an <span class="key-service">AWS CodeDeploy</span> deployment group that is configured for canary deployments with a DeploymentPreference type of Canary10Percent10Minutes. Upload the <span class="key-service">AWS CloudFormation</span> template and source code to the CodeCommit repository. In the CodeCommit repository, create an appspec.yml file that includes the commands to deploy the CloudFormation template.</div>                <div class="option"><strong>E.</strong> Create an <span class="key-service">Amazon CloudWatch</span> composite alarm for all the Lambda functions. Configure an evaluation period and dimensions for Lambda. Configure the alarm to enter the ALARM state if any errors are detected or if there is insufficient data. F. Create an <span class="key-service">Amazon CloudWatch</span> alarm for each Lambda function. Configure the alarms to enter the ALARM state if any errors are detected. Configure an evaluation period, dimensions for each Lambda function and version, and the namespace as AWS/Lambda on the Errors metric. Most Voted</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司正在开发新应用程序，使用AWS Lambda函数作为计算层。公司必须对Lambda函数的任何更改使用金丝雀部署，如果报告任何故障必须自动回滚。DevOps团队需要为此解决方案创建基础设施即代码(IaC)和CI/CD管道。哪些步骤组合将满足这些要求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 为应用程序创建AWS CloudFormation模板，使用AWS::Lambda::Function资源类型定义每个Lambda函数，在模板中使用AWS::Lambda::Version资源类型包含Lambda函数版本，声明CodeSha256属性，配置引用Lambda函数最新版本的AWS::Lambda::Alias资源</div> <div class="option-analysis"><strong>B.</strong> 为应用程序创建AWS SAM模板，使用AWS::Serverless::Function资源类型定义每个Lambda函数，为每个函数包含AutoPublishAlias属性和DeploymentPreference属性的配置，将部署配置类型配置为LambdaCanary10Percent10Minutes</div> <div class="option-analysis"><strong>C.</strong> 创建AWS CodeCommit存储库和AWS CodePipeline管道，在新的源阶段使用CodeCommit存储库启动管道，创建AWS CodeBuild项目部署AWS SAM模板，将模板和源代码上传到CodeCommit存储库，在存储库中创建包含构建和部署SAM应用程序命令的buildspec.yml文件</div> <div class="option-analysis"><strong>D.</strong> 创建AWS CodeCommit存储库和AWS CodePipeline管道，在新的源阶段使用CodeCommit存储库启动管道，创建配置为金丝雀部署的AWS CodeDeploy部署组，部署偏好类型为Canary10Percent10Minutes，将CloudFormation模板和源代码上传到CodeCommit存储库，创建包含部署CloudFormation模板命令的appspec.yml文件</div> <div class="option-analysis"><strong>E.</strong> 为所有Lambda函数创建Amazon CloudWatch复合告警，配置Lambda的评估周期和维度，配置告警在检测到任何错误或数据不足时进入ALARM状态 F. 为每个Lambda函数创建Amazon CloudWatch告警，配置告警在检测到任何错误时进入ALARM状态，为每个Lambda函数和版本配置评估周期、维度，在Errors指标上将命名空间设置为AWS/Lambda<div class="section-title"><strong>核心要求:</strong></div> 实现Lambda函数的金丝雀部署和自动回滚机制 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• AWS SAM-提供内置的金丝雀部署和自动回滚功能 </div><div class="compact-content">• <span class="key-service">AWS CodePipeline</span>/CodeBuild-构建完整的CI/CD管道 </div><div class="compact-content">• <span class="key-service">Amazon CloudWatch</span>-监控Lambda函数错误并触发自动回滚 <strong>正确答案BCF:</strong> AWS SAM模板通过DeploymentPreference属性原生支持金丝雀部署，CodePipeline+CodeBuild提供CI/CD管道，CloudWatch告警监控每个Lambda函数的错误指标并触发自动回滚 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A-原生CloudFormation不支持Lambda的金丝雀部署功能 </div><div class="compact-content">• 选项D-CodeDeploy不直接支持Lambda的金丝雀部署，需要通过SAM实现 </div><div class="compact-content">• 选项E-复合告警缺乏针对每个Lambda函数版本的精确监控 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-金丝雀部署最小化风险影响 </div><div class="compact-content">• 成本-使用托管服务降低运维成本 </div><div class="compact-content">• 可扩展性-SAM模板支持多Lambda函数统一管理</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: BC (B、C)</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-83">
            <div class="question-header">
                <div class="question-title">Question #83 ✅ 📝 <small style="float: right;">(83/353)</small></div>
            </div>
            <div class="question-content">A DevOps engineer is deploying a new version of a company's application in an <span class="key-service">AWS CodeDeploy</span> deployment group associated with its <span class="key-service">Amazon EC2</span> instances. After some time, the deployment fails. The engineer realizes that all the events associated with the specific deployment ID are in a Skipped status, and code was not deployed in the instances associated with the deployment group. What are valid reasons for this failure? (Choose two.) AD (91%) 9%</div>
            <div class="options-container">                <div class="option correct-answer"><strong>A.</strong> The networking configuration does not allow the EC2 instances to reach the internet via a NAT gateway or internet gateway, and the CodeDeploy endpoint cannot be reached.</div>                <div class="option"><strong>B.</strong> The IAM user who triggered the application deployment does not have permission to interact with the CodeDeploy endpoint.</div>                <div class="option"><strong>C.</strong> The target EC2 instances were not properly registered with the CodeDeploy endpoint.</div>                <div class="option correct-answer"><strong>D.</strong> An instance profile with proper permissions was not attached to the target EC2 instances.</div>                <div class="option"><strong>E.</strong> The appspec.yml file was not included in the application revision.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一名DevOps工程师正在使用AWS CodeDeploy部署组为公司应用程序部署新版本到Amazon EC2实例。一段时间后，部署失败。工程师发现与特定部署ID相关的所有事件都处于Skipped状态，代码未部署到部署组关联的实例上。导致此失败的有效原因是什么？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 网络配置不允许EC2实例通过NAT gateway或internet gateway访问互联网，无法到达CodeDeploy终端节点</div> <div class="option-analysis"><strong>B.</strong> 触发应用程序部署的IAM用户没有与CodeDeploy终端节点交互的权限</div> <div class="option-analysis"><strong>C.</strong> 目标EC2实例未正确注册到CodeDeploy终端节点</div> <div class="option-analysis"><strong>D.</strong> 目标EC2实例未附加具有适当权限的实例配置文件</div> <div class="option-analysis"><strong>E.</strong> 应用程序修订版本中未包含appspec.yml文件<div class="section-title"><strong>核心要求:</strong></div> 识别导致CodeDeploy部署事件显示Skipped状态的根本原因 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• <span class="key-service">AWS CodeDeploy</span> - 自动化应用程序部署服务，需要EC2实例具备网络连接和适当权限 </div><div class="compact-content">• <span class="key-service">Amazon EC2</span> - 计算实例，需要实例配置文件和网络连接来与CodeDeploy通信 <div class="section-title"><strong>正确答案AD:</strong></div> A选项：EC2实例无法访问CodeDeploy终端节点时，CodeDeploy agent无法与服务通信，导致部署事件被跳过；D选项：EC2实例缺少包含CodeDeploy权限的实例配置文件时，无法执行部署操作，所有事件显示Skipped状态 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项B - IAM用户权限问题会导致部署无法启动，而不是事件显示Skipped状态 </div><div class="compact-content">• 选项C - EC2实例通过CodeDeploy agent自动注册，不需要手动注册过程 </div><div class="compact-content">• 选项E - 缺少appspec.yml文件会导致部署失败错误，而不是Skipped状态 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能 - 确保网络连接和权限配置正确以避免部署延迟 </div><div class="compact-content">• 成本 - 正确配置避免重复部署尝试产生的额外费用 </div><div class="compact-content">• 可扩展性 - 标准化实例配置文件和网络设置支持大规模部署</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: AD (A、D)</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-84">
            <div class="question-header">
                <div class="question-title">Question #84 ✅ ⚪ <small style="float: right;">(84/353)</small></div>
            </div>
            <div class="question-content">A company has a guideline that every <span class="key-service">Amazon EC2</span> instance must be launched from an AMI that the company's security team produces. Every month, the security team sends an email message with the latest approved AMIs to all the development teams. The development teams use <span class="key-service">AWS CloudFormation</span> to deploy their applications. When developers launch a new service, they have to search their email for the latest AMIs that the security department sent. A DevOps engineer wants to automate the process that the security team uses to provide the AMI IDs to the development teams. What is the MOST scalable solution that meets these requirements? C (100%)</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Direct the security team to use CloudFormation to create new versions of the AMIs and to list the AMI ARNs in an encrypted <span class="key-service">Amazon S3</span> object as part of the stack's Outputs section. Instruct the developers to use a cross-stack reference to load the encrypted S3 object and obtain the most recent AMI ARNs.</div>                <div class="option"><strong>B.</strong> Direct the security team to use a CloudFormation stack to create an <span class="key-service">AWS CodePipeline</span> pipeline that builds new AMIs and places the latest AMI ARNs in an encrypted <span class="key-service">Amazon S3</span> object as part of the pipeline output. Instruct the developers to use a cross-stack reference within their own CloudFormation template to obtain the S3 object location and the most recent AMI ARNs.</div>                <div class="option correct-answer"><strong>C.</strong> Direct the security team to use <span class="key-service">Amazon EC2</span> Image Builder to create new AMIs and to place the AMI ARNs as parameters in <span class="key-service">AWS Systems Manager</span> Parameter Store. Instruct the developers to specify the parameter names in their CloudFormation template. Systems Manager Parameter Store. Instruct the developers to specify a parameter of type SSM in their CloudFormation stack to obtain the most recent AMI ARNs from Parameter Store. Most Voted</div>                <div class="option"><strong>D.</strong> Direct the security team to use <span class="key-service">Amazon EC2</span> Image Builder to create new AMIs and to create an Amazon Simple Notification Service (<span class="key-service">Amazon SNS</span>) topic so that every development team can receive notifications. When the development teams receive a notification, instruct them to write an <span class="key-service">AWS Lambda</span> function that will update their CloudFormation stack with the most recent AMI ARNs.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司有指导原则，每个Amazon EC2实例都必须从公司安全团队制作的AMI启动。每月安全团队向所有开发团队发送包含最新批准AMI的邮件。开发团队使用AWS CloudFormation部署应用程序。当开发人员启动新服务时，他们必须在邮件中搜索安全部门发送的最新AMI。DevOps工程师希望自动化安全团队向开发团队提供AMI ID的流程。什么是满足这些要求的最具可扩展性的解决方案？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 指导安全团队使用CloudFormation创建新版本的AMI，并将AMI ARN作为堆栈输出部分列在加密的Amazon S3对象中。指示开发人员使用跨堆栈引用加载加密的S3对象并获取最新的AMI ARN。</div> <div class="option-analysis"><strong>B.</strong> 指导安全团队使用CloudFormation堆栈创建AWS CodePipeline管道来构建新AMI，并将最新AMI ARN作为管道输出放在加密的Amazon S3对象中。指示开发人员在自己的CloudFormation模板中使用跨堆栈引用获取S3对象位置和最新AMI ARN。</div> <div class="option-analysis"><strong>C.</strong> 指导安全团队使用Amazon EC2 Image Builder创建新AMI，并将AMI ARN作为参数放在AWS Systems Manager Parameter Store中。指示开发人员在CloudFormation堆栈中指定SSM类型参数从Parameter Store获取最新AMI ARN。</div> <div class="option-analysis"><strong>D.</strong> 指导安全团队使用Amazon EC2 Image Builder创建新AMI，并创建Amazon Simple Notification Service (<span class="key-service">Amazon SNS</span>)主题让每个开发团队接收通知。当开发团队收到通知时，指示他们编写AWS Lambda函数来更新CloudFormation堆栈的最新AMI ARN。<div class="section-title"><strong>核心要求:</strong></div> 自动化AMI分发流程，实现安全团队到开发团队的AMI ID自动传递 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• EC2 Image Builder-专门用于自动化AMI构建和管理的服务 </div><div class="compact-content">• Systems Manager Parameter Store-集中存储配置参数，支持CloudFormation原生集成 <div class="section-title"><strong>正确答案C:</strong></div> 使用EC2 Image Builder自动构建AMI，通过Parameter Store存储AMI ARN，CloudFormation可直接引用SSM参数，实现完全自动化的端到端流程 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A-CloudFormation不是AMI构建工具，S3存储方式需要额外的访问逻辑 </div><div class="compact-content">• 选项B-CodePipeline增加了不必要的复杂性，S3方式不如Parameter Store集成度高 </div><div class="compact-content">• 选项D-SNS通知仍需人工干预，Lambda更新增加复杂性，未实现真正自动化 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-Parameter Store与CloudFormation原生集成，无需额外API调用 </div><div class="compact-content">• 成本-Image Builder和Parameter Store成本最优，无需额外Lambda或管道资源 </div><div class="compact-content">• 可扩展性-Parameter Store支持大规模参数管理，自动化程度最高</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: C</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-85">
            <div class="question-header">
                <div class="question-title">Question #85 ✅ ⚪ <small style="float: right;">(85/353)</small></div>
            </div>
            <div class="question-content">An application runs on <span class="key-service">Amazon EC2</span> instances behind an Application Load Balancer (ALB). A DevOps engineer is using <span class="key-service">AWS CodeDeploy</span> to release a new version. The deployment fails during the AllowTraffic lifecycle event, but a cause for the failure is not indicated in the deployment logs. What would cause this? C (100%)</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> The appspec.yml file contains an invalid script that runs in the AllowTraffic lifecycle hook.</div>                <div class="option"><strong>B.</strong> The user who initiated the deployment does not have the necessary permissions to interact with the ALB.</div>                <div class="option correct-answer"><strong>C.</strong> The health checks specified for the ALB target group are misconfigured.</div>                <div class="option"><strong>D.</strong> The CodeDeploy agent was not installed in the EC2 instances that are part of the ALB target group.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 应用程序运行在Application Load Balancer (ALB)后面的Amazon EC2实例上。DevOps工程师使用AWS CodeDeploy发布新版本。部署在AllowTraffic生命周期事件期间失败，但部署日志中没有显示失败原因。什么会导致这种情况？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> appspec.yml文件包含在AllowTraffic生命周期钩子中运行的无效脚本</div> <div class="option-analysis"><strong>B.</strong> 发起部署的用户没有与ALB交互的必要权限</div> <div class="option-analysis"><strong>C.</strong> 为ALB目标组指定的健康检查配置错误</div> <div class="option-analysis"><strong>D.</strong> CodeDeploy代理未安装在作为ALB目标组一部分的EC2实例中<div class="section-title"><strong>核心要求:</strong></div> 识别CodeDeploy在ALB环境中AllowTraffic阶段失败且日志无明确错误信息的根本原因 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• <span class="key-service">AWS CodeDeploy</span>-自动化应用部署服务，管理蓝绿部署生命周期 </div><div class="compact-content">• Application Load Balancer-七层负载均衡器，通过健康检查管理流量分发 <div class="section-title"><strong>正确答案C:</strong></div> ALB健康检查配置错误会导致新部署的实例无法通过健康检查，CodeDeploy在AllowTraffic阶段等待实例变为健康状态时超时失败，且ALB层面的健康检查问题不会在CodeDeploy部署日志中显示详细错误信息 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A-appspec.yml脚本错误会在CodeDeploy日志中明确显示脚本执行失败信息 </div><div class="compact-content">• 选项B-权限问题会在部署开始阶段就失败并在日志中显示权限拒绝错误 </div><div class="compact-content">• 选项D-CodeDeploy代理未安装会在部署初期就失败并在日志中显示代理连接错误 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-健康检查超时设置影响流量切换速度和部署成功率 </div><div class="compact-content">• 成本-错误的健康检查配置导致部署失败增加运维成本和回滚开销 </div><div class="compact-content">• 可扩展性-正确的健康检查配置确保自动扩展时新实例能正常接收流量</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: C</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-86">
            <div class="question-header">
                <div class="question-title">Question #86 ✅ ⚪ <small style="float: right;">(86/353)</small></div>
            </div>
            <div class="question-content">A company has 20 service teams. Each service team is responsible for its own microservice. Each service team uses a separate AWS account for its microservice and a <span class="key-service">VPC</span> with the 192.168.0.0/22 CIDR block. The company manages the AWS accounts with <span class="key-service">AWS Organizations</span>. Each service team hosts its microservice on multiple <span class="key-service">Amazon EC2</span> instances behind an Application Load Balancer. The microservices communicate with each other across the public internet. The company's security team has issued a new guideline that all communication between microservices must use HTTPS over private network connections and cannot traverse the public internet. A DevOps engineer must implement a solution that fulfills these obligations and minimizes the number of changes for each service team. Which solution will meet these requirements? B (77%) D (23%)</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Create a new AWS account in <span class="key-service">AWS Organizations</span>. Create a <span class="key-service">VPC</span> in this account, and use AWS Resource Access Manager to share the private subnets of this <span class="key-service">VPC</span> with the organization. Instruct the service teams to launch a new Network Load Balancer (NLB) and EC2 instances that use the shared private subnets. Use the NLB DNS names for communication between microservices.</div>                <div class="option correct-answer"><strong>B.</strong> Create a Network Load Balancer (NLB) in each of the microservice VPCs. Use AWS PrivateLink to create <span class="key-service">VPC</span> endpoints in each AWS account for the NLBs. Create subscriptions to each <span class="key-service">VPC</span> endpoint in each of the other AWS accounts. Use the <span class="key-service">VPC</span> endpoint DNS names for communication between microservices. for communication between microservices. Most Voted</div>                <div class="option"><strong>C.</strong> Create a Network Load Balancer (NLB) in each of the microservice VPCs. Create <span class="key-service"><span class="key-service">VPC</span> peering</span> connections between each of the microservice VPCs. Update the route tables for each <span class="key-service">VPC</span> to use the peering links. Use the NLB DNS names for communication between microservices.</div>                <div class="option"><strong>D.</strong> Create a new AWS account in <span class="key-service">AWS Organizations</span>. Create a transit gateway in this account, and use AWS Resource Access Manager to share the transit gateway with the organization. In each of the microservice VPCs, create a transit gateway attachment to the shared transit gateway. Update the route tables of each <span class="key-service">VPC</span> to use the transit gateway. Create a Network Load Balancer (NLB) in each of the microservice VPCs. Use the NLB DNS names for communication between microservices.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司有20个服务团队，每个团队负责自己的微服务，使用独立的AWS账户和192.168.0.0/22 CIDR的VPC。通过AWS Organizations管理账户，每个微服务运行在Application Load Balancer后的多个EC2实例上。当前微服务通过公网通信，安全团队要求所有微服务间通信必须使用HTTPS通过私有网络连接且不能经过公网。DevOps工程师需要实现满足要求且最小化各服务团队变更的解决方案。 <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 在AWS Organizations中创建新AWS账户，在此账户中创建VPC，使用AWS Resource Access Manager与组织共享此VPC的私有子网，指导服务团队启动新的Network Load Balancer和EC2实例使用共享私有子网，使用NLB DNS名称进行微服务间通信。</div> <div class="option-analysis"><strong>B.</strong> 在每个微服务VPC中创建Network Load Balancer，使用AWS PrivateLink为每个NLB在每个AWS账户中创建VPC endpoints，在每个其他AWS账户中创建每个VPC endpoint的订阅，使用VPC endpoint DNS名称进行微服务间通信。</div> <div class="option-analysis"><strong>C.</strong> 在每个微服务VPC中创建Network Load Balancer，在每个微服务VPC之间创建VPC peering连接，更新每个VPC的路由表使用peering链接，使用NLB DNS名称进行微服务间通信。</div> <div class="option-analysis"><strong>D.</strong> 在AWS Organizations中创建新AWS账户，在此账户中创建transit gateway，使用AWS Resource Access Manager与组织共享transit gateway，在每个微服务VPC中创建到共享transit gateway的attachment，更新每个VPC路由表使用transit gateway，在每个微服务VPC中创建Network Load Balancer，使用NLB DNS名称进行微服务间通信。<div class="section-title"><strong>核心要求:</strong></div> 实现跨账户微服务私有网络HTTPS通信且最小化服务团队变更 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• AWS PrivateLink-提供跨账户私有连接，无需修改现有VPC配置 </div><div class="compact-content">• <span class="key-service">VPC</span> Endpoints-允许私有访问其他账户的NLB服务 <div class="section-title"><strong>正确答案B:</strong></div> 使用AWS PrivateLink创建VPC endpoints实现跨账户私有通信，服务团队只需部署NLB并订阅其他服务的endpoints，无需修改现有VPC架构 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A-需要重新部署所有服务到共享VPC，变更量巨大且破坏现有架构 </div><div class="compact-content">• 选项C-20个VPC需要创建190个peering连接，管理复杂且扩展性差 </div><div class="compact-content">• 选项D-需要修改所有VPC路由表并管理transit gateway attachments，变更量大 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-PrivateLink提供高性能私有连接，避免公网延迟 </div><div class="compact-content">• 成本-按使用量付费，无需额外基础设施投资 </div><div class="compact-content">• 可扩展性-新服务只需创建endpoint订阅，线性扩展无复杂度增长</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: B</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-87">
            <div class="question-header">
                <div class="question-title">Question #87 ✅ 📝 <small style="float: right;">(87/353)</small></div>
            </div>
            <div class="question-content">An <span class="key-service">Amazon EC2</span> instance is running in a <span class="key-service">VPC</span> and needs to download an object from a restricted <span class="key-service">Amazon S3</span> bucket. When the DevOps engineer tries to download the object, an AccessDenied error is received. What are the possible causes for this error? (Choose two.) BD (100%)</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> The S3 bucket default encryption is enabled.</div>                <div class="option correct-answer"><strong>B.</strong> There is an error in the S3 bucket policy.</div>                <div class="option"><strong>C.</strong> The object has been moved to S3 Glacier.</div>                <div class="option correct-answer"><strong>D.</strong> There is an error in the IAM role configuration.</div>                <div class="option"><strong>E.</strong> S3 Versioning is enabled.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一个Amazon EC2实例运行在VPC中，需要从受限的Amazon S3存储桶下载对象。当DevOps工程师尝试下载对象时，收到AccessDenied错误。此错误的可能原因是什么？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> S3存储桶默认加密已启用</div> <div class="option-analysis"><strong>B.</strong> S3存储桶策略存在错误</div> <div class="option-analysis"><strong>C.</strong> 对象已移动到S3 Glacier</div> <div class="option-analysis"><strong>D.</strong> IAM角色配置存在错误</div> <div class="option-analysis"><strong>E.</strong> S3版本控制已启用<div class="section-title"><strong>核心要求:</strong></div> 识别导致S3 AccessDenied错误的权限相关原因 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• S3 Bucket Policy - 控制对S3资源的访问权限 </div><div class="compact-content">• IAM Role - 为EC2实例提供访问AWS服务的权限 <div class="section-title"><strong>正确答案BD:</strong></div> AccessDenied错误主要由权限配置问题引起：B选项中S3存储桶策略可能拒绝访问或配置错误；D选项中IAM角色可能缺少必要的S3访问权限或信任关系配置错误 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A - 默认加密不会导致AccessDenied错误，只是数据存储时加密 </div><div class="compact-content">• 选项C - 对象在Glacier中仍可访问，不会产生AccessDenied错误 </div><div class="compact-content">• 选项E - 版本控制功能不影响对象访问权限 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能 - 权限验证发生在访问层面，不影响数据传输性能 </div><div class="compact-content">• 成本 - 正确的权限配置避免不必要的访问尝试和错误处理开销 </div><div class="compact-content">• 可扩展性 - 合理的IAM和S3策略设计支持多实例和多用户场景</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: BD (B、D)</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-88">
            <div class="question-header">
                <div class="question-title">Question #88 ✅ ⚪ <small style="float: right;">(88/353)</small></div>
            </div>
            <div class="question-content">A company wants to use a grid system for a proprietary enterprise in-memory data store on top of AWS. This system can run in multiple server nodes in any Linux-based distribution. The system must be able to reconfigure the entire cluster every time a node is added or removed. When adding or removing nodes, an /etc/cluster/nodes.config file must be updated, listing the IP addresses of the current node members of that cluster. The company wants to automate the task of adding new nodes to a cluster. What can a DevOps engineer do to meet these requirements? A (100%)</div>
            <div class="options-container">                <div class="option correct-answer"><strong>A.</strong> Use AWS OpsWorks Stacks to layer the server nodes of that cluster. Create a Chef recipe that populates the content of the /etc/cluster/nodes.config file and restarts the service by using the current members of the layer. Assign that recipe to the Configure lifecycle event.</div>                <div class="option"><strong>B.</strong> Put the nodes.config file in version control. Create an <span class="key-service">AWS CodeDeploy</span> deployment configuration and deployment group based on an <span class="key-service">Amazon EC2</span> tag value for the cluster nodes. When adding a new node to the cluster, update the file with all tagged instances, and make a commit in version control. Deploy the new file and restart the services.</div>                <div class="option"><strong>C.</strong> Create an <span class="key-service">Amazon S3</span> bucket and upload a version of the /etc/cluster/nodes.config file. Create a crontab script that will poll for that S3 file and download it frequently. Use a process manager, such as Monit or systemd, to restart the cluster services when it detects that the new file was modified. When adding a node to the cluster, edit the file's most recent members. Upload the new file to the S3 bucket.</div>                <div class="option"><strong>D.</strong> Create a user data script that lists all members of the current security group of the cluster and automatically updates the /etc/cluster/nodes.config file whenever a new instance is added to the cluster.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司希望在AWS上为专有企业内存数据存储使用网格系统。该系统可在任何基于Linux发行版的多个服务器节点上运行。系统必须能够在每次添加或删除节点时重新配置整个集群。添加或删除节点时，必须更新/etc/cluster/nodes.config文件，列出该集群当前节点成员的IP地址。公司希望自动化向集群添加新节点的任务。DevOps工程师可以做什么来满足这些要求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 使用AWS OpsWorks Stacks对该集群的服务器节点进行分层。创建Chef配方来填充/etc/cluster/nodes.config文件内容，并使用层的当前成员重启服务。将该配方分配给Configure生命周期事件。</div> <div class="option-analysis"><strong>B.</strong> 将nodes.config文件放入版本控制。基于集群节点的EC2标签值创建AWS CodeDeploy部署配置和部署组。向集群添加新节点时，用所有标记实例更新文件，并在版本控制中提交。部署新文件并重启服务。</div> <div class="option-analysis"><strong>C.</strong> 创建S3存储桶并上传/etc/cluster/nodes.config文件版本。创建crontab脚本定期轮询和下载该S3文件。使用Monit或systemd等进程管理器在检测到新文件被修改时重启集群服务。向集群添加节点时，编辑文件的最新成员并上传新文件到S3存储桶。</div> <div class="option-analysis"><strong>D.</strong> 创建用户数据脚本，列出集群当前安全组的所有成员，并在新实例添加到集群时自动更新/etc/cluster/nodes.config文件。<div class="section-title"><strong>核心要求:</strong></div> 自动化集群节点管理，实现节点增减时配置文件的自动更新和服务重启 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• AWS OpsWorks Stacks-提供应用程序和服务器管理的托管服务 </div><div class="compact-content">• Chef-配置管理工具，用于自动化基础设施配置 <div class="section-title"><strong>正确答案A:</strong></div> OpsWorks Stacks的Configure生命周期事件在节点变化时自动触发，Chef配方可动态获取当前层成员并更新配置文件，实现完全自动化 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项B-需要手动更新版本控制文件并提交，无法实现完全自动化 </div><div class="compact-content">• 选项C-依赖定时轮询机制，存在延迟且需要手动编辑和上传文件 </div><div class="compact-content">• 选项D-用户数据脚本仅在实例启动时执行一次，无法处理后续节点变化 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-实时响应节点变化，无延迟配置更新 </div><div class="compact-content">• 成本-利用托管服务减少运维开销 </div><div class="compact-content">• 可扩展性-自动处理任意数量节点的增减操作</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: A</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-89">
            <div class="question-header">
                <div class="question-title">Question #89 ✅ 📝 <small style="float: right;">(89/353)</small></div>
            </div>
            <div class="question-content">A DevOps engineer is working on a data archival project that requires the migration of on-premises data to an <span class="key-service">Amazon S3</span> bucket. The DevOps engineer develops a script that incrementally archives on-premises data that is older than 1 month to <span class="key-service">Amazon S3</span>. Data that is transferred to <span class="key-service">Amazon S3</span> is deleted from the on-premises location. The script uses the S3 PutObject operation. During a code review, the DevOps engineer notices that the script does not verify whether the data was successfully copied to <span class="key-service">Amazon S3</span>. The DevOps engineer must update the script to ensure that data is not corrupted during transmission. The script must use MD5 checksums to verify data integrity before the on-premises data is deleted. Which solutions for the script will meet these requirements? (Choose two.) BD (100%)</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Check the returned response for the VersionId. Compare the returned VersionId against the MD5 checksum.</div>                <div class="option correct-answer"><strong>B.</strong> Include the MD5 checksum within the Content-MD5 parameter. Check the operation call's return status to find out if an error was returned.</div>                <div class="option"><strong>C.</strong> Include the checksum digest within the tagging parameter as a URL query parameter.</div>                <div class="option correct-answer"><strong>D.</strong> Check the returned response for the ETag. Compare the returned ETag against the MD5 checksum.</div>                <div class="option"><strong>E.</strong> Include the checksum digest within the Metadata parameter as a name-value pair. After upload, use the S3 HeadObject operation to retrieve metadata from the object.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一名DevOps工程师正在进行数据归档项目，需要将本地数据迁移到Amazon S3存储桶。工程师开发了一个脚本，将超过1个月的本地数据增量归档到Amazon S3。传输到Amazon S3的数据会从本地位置删除。脚本使用S3 PutObject操作。在代码审查中，工程师注意到脚本没有验证数据是否成功复制到Amazon S3。工程师必须更新脚本以确保数据在传输过程中不被损坏。脚本必须使用MD5校验和在删除本地数据之前验证数据完整性。哪些脚本解决方案能满足这些要求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 检查返回响应中的VersionId，将返回的VersionId与MD5校验和进行比较</div> <div class="option-analysis"><strong>B.</strong> 在Content-MD5参数中包含MD5校验和，检查操作调用的返回状态以确定是否返回错误</div> <div class="option-analysis"><strong>C.</strong> 将校验和摘要作为URL查询参数包含在tagging参数中</div> <div class="option-analysis"><strong>D.</strong> 检查返回响应中的ETag，将返回的ETag与MD5校验和进行比较</div> <div class="option-analysis"><strong>E.</strong> 将校验和摘要作为名称-值对包含在Metadata参数中，上传后使用S3 HeadObject操作从对象中检索元数据<div class="section-title"><strong>核心要求:</strong></div> 使用MD5校验和验证S3数据传输完整性，确保数据未损坏后再删除本地数据 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• <span class="key-service">Amazon S3</span> - 提供PutObject操作的Content-MD5参数和ETag响应进行数据完整性验证 </div><div class="compact-content">• MD5校验和机制 - 通过Content-MD5参数和ETag比较实现传输完整性检查 <div class="section-title"><strong>正确答案BD:</strong></div> B选项通过Content-MD5参数让S3自动验证上传数据完整性，D选项通过比较返回的ETag与MD5校验和验证数据完整性，两者都能有效检测传输错误 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A - VersionId用于版本控制，与MD5校验和无关，无法验证数据完整性 </div><div class="compact-content">• 选项C - tagging参数用于对象标记，不是数据完整性验证机制 </div><div class="compact-content">• 选项E - Metadata方法过于复杂且需要额外API调用，不如直接使用S3内置完整性检查 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能 - 使用S3内置Content-MD5和ETag机制，无需额外API调用 </div><div class="compact-content">• 成本 - 避免额外的HeadObject操作调用成本 </div><div class="compact-content">• 可扩展性 - 利用S3原生完整性检查功能，支持大规模数据迁移</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: BD (B、D)</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-90">
            <div class="question-header">
                <div class="question-title">Question #90 ✅ ⚪ <small style="float: right;">(90/353)</small></div>
            </div>
            <div class="question-content">A company deploys updates to its <span class="key-service">Amazon API Gateway</span> API several times a week by using an <span class="key-service">AWS CodePipeline</span> pipeline. As part of the update process, the company exports the JavaScript SDK for the API from the API Gateway console and uploads the SDK to an <span class="key-service">Amazon S3</span> bucket. The company has configured an Amazon CloudFront distribution that uses the S3 bucket as an origin. Web clients then download the SDK by using the CloudFront distribution's endpoint. A DevOps engineer needs to implement a solution to make the new SDK available automatically during new API deployments. Which solution will meet these requirements? A (100%)</div>
            <div class="options-container">                <div class="option correct-answer"><strong>A.</strong> Create a CodePipeline action immediately after the deployment stage of the API. Configure the action to invoke an <span class="key-service">AWS Lambda</span> function. Configure the Lambda function to download the SDK from API Gateway, upload the SDK to the S3 bucket, and create a CloudFront invalidation for the SDK path.</div>                <div class="option"><strong>B.</strong> Create a CodePipeline action immediately after the deployment stage of the API. Configure the action to use the CodePipeline integration with API Gateway to export the SDK to <span class="key-service">Amazon S3</span>. Create another action that uses the CodePipeline integration with <span class="key-service">Amazon S3</span> to invalidate the cache for the SDK path.</div>                <div class="option"><strong>C.</strong> Create an Amazon EventBridge rule that reacts to UpdateStage events from aws.apigateway. Configure the rule to invoke an <span class="key-service">AWS Lambda</span> function to download the SDK from API Gateway, upload the SDK to the S3 bucket, and call the CloudFront API to create an invalidation for the SDK path.</div>                <div class="option"><strong>D.</strong> Create an Amazon EventBridge rule that reacts to CreateDeployment events from aws.apigateway. Configure the rule to invoke an <span class="key-service">AWS Lambda</span> function to download the SDK from API Gateway, upload the SDK to the S3 bucket, and call the S3 API to invalidate the cache for the SDK path.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司每周多次使用AWS CodePipeline管道部署Amazon API Gateway API更新。作为更新过程的一部分，公司从API Gateway控制台导出JavaScript SDK并上传到Amazon S3存储桶。公司配置了使用S3存储桶作为源的Amazon CloudFront分发。Web客户端通过CloudFront分发端点下载SDK。DevOps工程师需要实现一个解决方案，在新API部署期间自动提供新SDK。 <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 在API部署阶段后立即创建CodePipeline操作，配置该操作调用AWS Lambda函数，配置Lambda函数从API Gateway下载SDK、上传SDK到S3存储桶并为SDK路径创建CloudFront失效。</div> <div class="option-analysis"><strong>B.</strong> 在API部署阶段后立即创建CodePipeline操作，配置该操作使用CodePipeline与API Gateway的集成将SDK导出到Amazon S3，创建另一个使用CodePipeline与Amazon S3集成的操作来使SDK路径的缓存失效。</div> <div class="option-analysis"><strong>C.</strong> 创建Amazon EventBridge规则响应来自aws.apigateway的UpdateStage事件，配置规则调用AWS Lambda函数从API Gateway下载SDK、上传SDK到S3存储桶并调用CloudFront API为SDK路径创建失效。</div> <div class="option-analysis"><strong>D.</strong> 创建Amazon EventBridge规则响应来自aws.apigateway的CreateDeployment事件，配置规则调用AWS Lambda函数从API Gateway下载SDK、上传SDK到S3存储桶并调用S3 API使缓存失效。<div class="section-title"><strong>核心要求:</strong></div> 在API部署过程中自动化SDK更新和分发流程 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• CodePipeline-管道编排和部署自动化 </div><div class="compact-content">• API Gateway-API管理和SDK生成 </div><div class="compact-content">• Lambda-执行SDK下载上传逻辑 </div><div class="compact-content">• CloudFront-内容分发和缓存失效 <div class="section-title"><strong>正确答案A:</strong></div> 直接在CodePipeline部署阶段后添加Lambda操作，确保SDK更新与API部署同步执行，并正确调用CloudFront失效API清除缓存 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项B-CodePipeline没有直接的API Gateway SDK导出集成功能，且S3无法直接执行CloudFront缓存失效 </div><div class="compact-content">• 选项C-UpdateStage事件触发时机不准确，无法保证与部署流程的同步性 </div><div class="compact-content">• 选项D-S3 API无法执行CloudFront缓存失效操作，需要使用CloudFront API <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-Pipeline内集成确保部署和SDK更新的原子性操作 </div><div class="compact-content">• 成本-Lambda按需执行，避免持续监听事件的资源消耗 </div><div class="compact-content">• 可扩展性-Pipeline操作易于扩展和维护，支持多环境部署</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: A</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-91">
            <div class="question-header">
                <div class="question-title">Question #91 ✅ ⚪ <small style="float: right;">(91/353)</small></div>
            </div>
            <div class="question-content">A company has developed an <span class="key-service">AWS Lambda</span> function that handles orders received through an API. The company is using <span class="key-service">AWS CodeDeploy</span> to deploy the Lambda function as the final stage of a CI/CD pipeline. A DevOps engineer has noticed there are intermittent failures of the ordering API for a few seconds after deployment. After some investigation, the DevOps engineer believes the failures are due to database changes not having fully propagated before the Lambda function is invoked. How should the DevOps engineer overcome this? A (100%)</div>
            <div class="options-container">                <div class="option correct-answer"><strong>A.</strong> Add a BeforeAllowTraffic hook to the AppSpec file that tests and waits for any necessary database changes before traffic can flow to the new version of the Lambda function. Most Voted</div>                <div class="option"><strong>B.</strong> Add an AfterAllowTraffic hook to the AppSpec file that forces traffic to wait for any pending database changes before allowing the new version of the Lambda function to respond.</div>                <div class="option"><strong>C.</strong> Add a BeforeInstall hook to the AppSpec file that tests and waits for any necessary database changes before deploying the new version of the Lambda function.</div>                <div class="option"><strong>D.</strong> Add a ValidateService hook to the AppSpec file that inspects incoming traffic and rejects the payload if dependent services, such as the database, are not yet ready.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司开发了一个AWS Lambda函数来处理通过API接收的订单。公司使用AWS CodeDeploy在CI/CD管道的最终阶段部署Lambda函数。DevOps工程师注意到在部署后的几秒钟内订单API会出现间歇性故障。经过调查，DevOps工程师认为故障是由于数据库更改在Lambda函数被调用之前尚未完全传播导致的。DevOps工程师应该如何解决这个问题？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 在AppSpec文件中添加BeforeAllowTraffic钩子，在流量流向Lambda函数新版本之前测试并等待任何必要的数据库更改。</div> <div class="option-analysis"><strong>B.</strong> 在AppSpec文件中添加AfterAllowTraffic钩子，强制流量等待任何待处理的数据库更改，然后允许Lambda函数新版本响应。</div> <div class="option-analysis"><strong>C.</strong> 在AppSpec文件中添加BeforeInstall钩子，在部署Lambda函数新版本之前测试并等待任何必要的数据库更改。</div> <div class="option-analysis"><strong>D.</strong> 在AppSpec文件中添加ValidateService钩子，检查传入流量并在依赖服务（如数据库）尚未准备就绪时拒绝负载。<div class="section-title"><strong>核心要求:</strong></div> 确保数据库更改完全传播后再允许流量访问新部署的Lambda函数 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• <span class="key-service">AWS CodeDeploy</span>-管理Lambda函数的蓝绿部署和流量切换 </div><div class="compact-content">• <span class="key-service">AWS Lambda</span>-处理订单API请求的无服务器函数 <div class="section-title"><strong>正确答案A:</strong></div> BeforeAllowTraffic钩子在流量切换到新版本之前执行，可以测试数据库状态并等待更改传播完成，确保新版本接收流量时数据库已准备就绪 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项B-AfterAllowTraffic钩子在流量已经开始流向新版本后执行，无法防止初始故障 </div><div class="compact-content">• 选项C-BeforeInstall钩子在函数部署前执行，此时数据库更改可能尚未开始，时机过早 </div><div class="compact-content">• 选项D-ValidateService钩子用于验证部署后的服务状态，不是用于等待依赖服务准备就绪 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-在正确时机检查依赖服务状态，避免API调用失败 </div><div class="compact-content">• 成本-使用内置钩子机制，无需额外基础设施成本 </div><div class="compact-content">• 可扩展性-钩子机制可适用于各种依赖服务的准备状态检查</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: A</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-92">
            <div class="question-header">
                <div class="question-title">Question #92 ✅ ⚪ <small style="float: right;">(92/353)</small></div>
            </div>
            <div class="question-content">A company uses a single AWS account to test applications on <span class="key-service">Amazon EC2</span> instances. The company has turned on <span class="key-service">AWS Config</span> in the AWS account and has activated the restricted-ssh <span class="key-service">AWS Config</span> managed rule. The company needs an automated monitoring solution that will provide a customized notification in real time if any security group in the account is not compliant with the restricted-ssh rule. The customized notification must contain the name and ID of the noncompliant security group. A DevOps engineer creates an Amazon Simple Notification Service (<span class="key-service">Amazon SNS</span>) topic in the account and subscribes the appropriate personnel to the topic. What should the DevOps engineer do next to meet these requirements? A (100%)</div>
            <div class="options-container">                <div class="option correct-answer"><strong>A.</strong> Create an Amazon EventBridge rule that matches an <span class="key-service">AWS Config</span> evaluation result of NON_COMPLIANT for the restricted-ssh rule. Configure an input transformer for the EventBridge rule. Configure the EventBridge rule to publish a notification to the SNS topic.</div>                <div class="option"><strong>B.</strong> Configure <span class="key-service">AWS Config</span> to send all evaluation results for the restricted-ssh rule to the SNS topic. Configure a filter policy on the SNS topic to send only notifications that contain the text of NON_COMPLIANT in the notification to subscribers.</div>                <div class="option"><strong>C.</strong> Create an Amazon EventBridge rule that matches an <span class="key-service">AWS Config</span> evaluation result of NON_COMPLIANT for the restricted-ssh rule. Configure the EventBridge rule to invoke <span class="key-service">AWS Systems Manager</span> Run Command on the SNS topic to customize a notification and to publish the notification to the SNS topic.</div>                <div class="option"><strong>D.</strong> Create an Amazon EventBridge rule that matches all <span class="key-service">AWS Config</span> evaluation results of NON_COMPLIANT. Configure an input transformer for the restricted-ssh rule. Configure the EventBridge rule to publish a notification to the SNS topic.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司使用单个AWS账户在Amazon EC2实例上测试应用程序。公司已在AWS账户中开启AWS Config并激活了restricted-ssh AWS Config托管规则。公司需要一个自动化监控解决方案，当账户中任何安全组不符合restricted-ssh规则时提供实时定制通知。定制通知必须包含不合规安全组的名称和ID。DevOps工程师在账户中创建了Amazon Simple Notification Service (<span class="key-service">Amazon SNS</span>)主题并为相关人员订阅了该主题。DevOps工程师接下来应该做什么来满足这些要求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 创建Amazon EventBridge规则匹配restricted-ssh规则的AWS Config评估结果NON_COMPLIANT，为EventBridge规则配置输入转换器，配置EventBridge规则向SNS主题发布通知</div> <div class="option-analysis"><strong>B.</strong> 配置AWS Config将restricted-ssh规则的所有评估结果发送到SNS主题，在SNS主题上配置过滤策略仅向订阅者发送包含NON_COMPLIANT文本的通知</div> <div class="option-analysis"><strong>C.</strong> 创建Amazon EventBridge规则匹配restricted-ssh规则的AWS Config评估结果NON_COMPLIANT，配置EventBridge规则调用AWS Systems Manager Run Command在SNS主题上定制通知并发布通知到SNS主题</div> <div class="option-analysis"><strong>D.</strong> 创建Amazon EventBridge规则匹配所有AWS Config评估结果NON_COMPLIANT，为restricted-ssh规则配置输入转换器，配置EventBridge规则向SNS主题发布通知<div class="section-title"><strong>核心要求:</strong></div> 实现AWS Config规则违规的实时定制通知，包含安全组名称和ID <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• <span class="key-service">AWS Config</span> - 监控资源合规性并生成评估事件 </div><div class="compact-content">• Amazon EventBridge - 捕获Config事件并触发通知 </div><div class="compact-content">• <span class="key-service">Amazon SNS</span> - 发送定制通知给订阅者 <div class="section-title"><strong>正确答案A:</strong></div> 使用EventBridge规则精确匹配特定规则的NON_COMPLIANT事件，通过输入转换器提取安全组详细信息并格式化为定制通知 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项B - AWS Config无法直接发送到SNS，且SNS过滤策略无法提供所需的定制化 </div><div class="compact-content">• 选项C - Systems Manager Run Command用途错误，不适用于SNS通知定制 </div><div class="compact-content">• 选项D - 匹配所有NON_COMPLIANT事件范围过广，输入转换器配置逻辑错误 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能 - EventBridge提供实时事件处理和精确规则匹配 </div><div class="compact-content">• 成本 - 仅处理特定规则事件，避免不必要的处理开销 </div><div class="compact-content">• 可扩展性 - 输入转换器支持灵活的通知内容定制和格式化</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: A</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-93">
            <div class="question-header">
                <div class="question-title">Question #93 ✅ 📝 <small style="float: right;">(93/353)</small></div>
            </div>
            <div class="question-content">A company requires an RPO of 2 hours and an RTO of 10 minutes for its data and application at all times. An application uses a MySQL database and <span class="key-service">Amazon EC2</span> web servers. The development team needs a strategy for failover and disaster recovery. Which combination of deployment strategies will meet these requirements? (Choose two.) BD (100%)</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Create an Amazon Aurora cluster in one Availability Zone across multiple Regions as the data store. Use Aurora's automatic recovery capabilities in the event of a disaster.</div>                <div class="option correct-answer"><strong>B.</strong> Create an Amazon Aurora global database in two Regions as the data store. In the event of a failure, promote the secondary Region as the primary for the application.</div>                <div class="option"><strong>C.</strong> Create an Amazon Aurora multi-master cluster across multiple Regions as the data store. Use a Network Load Balancer to balance the database traffic in different Regions.</div>                <div class="option correct-answer"><strong>D.</strong> Set up the application in two Regions and use <span class="key-service">Amazon Route 53</span> failover-based routing that points to the Application Load Balancers in both Regions. Use health checks to determine the availability in a given Region. Use Auto Scaling groups in each Region to adjust capacity based on demand.</div>                <div class="option"><strong>E.</strong> Set up the application in two Regions and use a multi-Region Auto Scaling group behind Application Load Balancers to manage the capacity based on demand. In the event of a disaster, adjust the Auto Scaling group's desired instance count to increase baseline capacity in the failover Region.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司要求其数据和应用程序始终保持RPO为2小时、RTO为10分钟。应用程序使用MySQL数据库和Amazon EC2 Web服务器。开发团队需要故障转移和灾难恢复策略。哪种部署策略组合能满足这些要求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 在一个Availability Zone中跨多个Region创建Amazon Aurora集群作为数据存储，在灾难事件中使用Aurora的自动恢复功能</div> <div class="option-analysis"><strong>B.</strong> 在两个Region中创建Amazon Aurora global database作为数据存储，在故障时将辅助Region提升为应用程序的主Region</div> <div class="option-analysis"><strong>C.</strong> 跨多个Region创建Amazon Aurora multi-master集群作为数据存储，使用Network Load Balancer在不同Region之间平衡数据库流量</div> <div class="option-analysis"><strong>D.</strong> 在两个Region中设置应用程序并使用Amazon Route 53基于故障转移的路由指向两个Region的Application Load Balancer，使用健康检查确定给定Region的可用性，在每个Region使用Auto Scaling groups根据需求调整容量</div> <div class="option-analysis"><strong>E.</strong> 在两个Region中设置应用程序并在Application Load Balancer后使用multi-Region Auto Scaling group根据需求管理容量，在灾难时调整Auto Scaling group的期望实例数量以增加故障转移Region的基线容量<div class="section-title"><strong>核心要求:</strong></div> 满足RPO 2小时和RTO 10分钟的严格灾难恢复要求 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• Amazon Aurora Global Database-提供跨Region数据复制和快速故障转移 </div><div class="compact-content">• Route 53故障转移路由-实现应用层的自动故障转移和健康检查 <div class="section-title"><strong>正确答案BD:</strong></div> Aurora Global Database提供秒级跨Region复制满足RPO要求，Route 53故障转移路由配合多Region部署实现分钟级RTO <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A-单AZ部署无法提供跨Region灾难恢复能力 </div><div class="compact-content">• 选项C-Multi-master复杂性高且不是专为灾难恢复设计 </div><div class="compact-content">• 选项E-Multi-Region Auto Scaling group不存在，且手动调整容量无法满足RTO要求 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-Aurora Global Database提供亚秒级跨Region复制延迟 </div><div class="compact-content">• 成本-Global Database和Route 53提供成本效益的灾难恢复方案 </div><div class="compact-content">• 可扩展性-Auto Scaling groups确保各Region容量自动调整</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: BD (B、D)</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-94">
            <div class="question-header">
                <div class="question-title">Question #94 ✅ ⚪ <small style="float: right;">(94/353)</small></div>
            </div>
            <div class="question-content">A business has an application that consists of five independent <span class="key-service">AWS Lambda</span> functions. The DevOps engineer has built a CI/CD pipeline using <span class="key-service">AWS CodePipeline</span> and <span class="key-service">AWS CodeBuild</span> that builds, tests, packages, and deploys each Lambda function in sequence. The pipeline uses an Amazon EventBridge rule to ensure the pipeline starts as quickly as possible after a change is made to the application source code. After working with the pipeline for a few months, the DevOps engineer has noticed the pipeline takes too long to complete. What should the DevOps engineer implement to BEST improve the speed of the pipeline? C (100%)</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Modify the CodeBuild projects within the pipeline to use a compute type with more available network throughput.</div>                <div class="option"><strong>B.</strong> Create a custom CodeBuild execution environment that includes a symmetric multiprocessing configuration to run the builds in parallel.</div>                <div class="option correct-answer"><strong>C.</strong> Modify the CodePipeline configuration to run actions for each Lambda function in parallel by specifying the same runOrder.</div>                <div class="option"><strong>D.</strong> Modify each CodeBuild project to run within a <span class="key-service">VPC</span> and use dedicated instances to increase throughput.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家企业有一个由五个独立AWS Lambda函数组成的应用程序。DevOps工程师使用AWS CodePipeline和AWS CodeBuild构建了CI/CD管道，按顺序构建、测试、打包和部署每个Lambda函数。管道使用Amazon EventBridge规则确保在应用程序源代码更改后尽快启动管道。使用管道几个月后，DevOps工程师注意到管道完成时间过长。DevOps工程师应该实施什么来最好地提高管道速度？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 修改管道中的CodeBuild项目以使用具有更多可用网络吞吐量的计算类型。</div> <div class="option-analysis"><strong>B.</strong> 创建自定义CodeBuild执行环境，包含对称多处理配置以并行运行构建。</div> <div class="option-analysis"><strong>C.</strong> 修改CodePipeline配置，通过指定相同的runOrder使每个Lambda函数的操作并行运行。</div> <div class="option-analysis"><strong>D.</strong> 修改每个CodeBuild项目在VPC内运行并使用专用实例来增加吞吐量。<div class="section-title"><strong>核心要求:</strong></div> 优化CI/CD管道性能，减少五个独立Lambda函数的串行部署时间 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• <span class="key-service">AWS CodePipeline</span>-管理CI/CD工作流程和阶段编排 </div><div class="compact-content">• <span class="key-service">AWS CodeBuild</span>-执行构建、测试和打包任务 </div><div class="compact-content">• Amazon EventBridge-触发管道自动启动 <div class="section-title"><strong>正确答案C:</strong></div> 通过设置相同的runOrder值，CodePipeline可以并行执行多个独立Lambda函数的构建和部署操作，将串行执行改为并行执行，显著减少总体管道执行时间 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A-网络吞吐量不是瓶颈，Lambda函数构建主要受CPU和构建逻辑限制 </div><div class="compact-content">• 选项B-单个CodeBuild项目内的并行处理无法解决多个独立函数间的串行问题 </div><div class="compact-content">• 选项D-VPC配置和专用实例会增加复杂性和成本，但不解决根本的串行执行问题 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-并行执行比优化单个构建环境更有效 </div><div class="compact-content">• 成本-使用现有资源并行化比升级硬件更经济 </div><div class="compact-content">• 可扩展性-runOrder配置易于管理和扩展到更多函数</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: C</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-95">
            <div class="question-header">
                <div class="question-title">Question #95 ✅ ⚪ <small style="float: right;">(95/353)</small></div>
            </div>
            <div class="question-content">A company uses <span class="key-service">AWS CloudFormation</span> stacks to deploy updates to its application. The stacks consist of different resources. The resources include AWS Auto Scaling groups, <span class="key-service">Amazon EC2</span> instances, Application Load Balancers (ALBs), and other resources that are necessary to launch and maintain independent stacks. Changes to application resources outside of CloudFormation stack updates are not allowed. The company recently attempted to update the application stack by using the AWS CLI. The stack failed to update and produced the following error message: "ERROR: both the deployment and the CloudFormation stack rollback failed. The deployment failed because the following resource(s) failed to update: [AutoScalingGroup]." The stack remains in a status of UPDATE_ROLLBACK_FAILE<div class="option-analysis"><strong>D.</strong> Which solution will resolve this issue? B (100%)</div></div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Update the subnet mappings that are configured for the ALBs. Run the <span class="key-service">aws cloudformation</span> update-stack-set AWS CLI command.</div>                <div class="option correct-answer"><strong>B.</strong> Update the IAM role by providing the necessary permissions to update the stack. Run the <span class="key-service">aws cloudformation</span> continue-update-rollback AWS CLI command.</div>                <div class="option"><strong>C.</strong> Submit a request for a quota increase for the number of EC2 instances for the account. Run the <span class="key-service">aws cloudformation</span> cancel-update-stack AWS CLI command.</div>                <div class="option"><strong>D.</strong> Delete the Auto Scaling group resource. Run the <span class="key-service">aws cloudformation</span> rollback-stack AWS CLI command.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司使用AWS CloudFormation堆栈部署应用程序更新。堆栈包含不同资源：AWS Auto Scaling组、Amazon EC2实例、Application Load Balancers (ALBs)等维护独立堆栈所需资源。不允许在CloudFormation堆栈更新之外更改应用程序资源。公司最近尝试使用AWS CLI更新应用程序堆栈，堆栈更新失败并产生错误消息："ERROR: both the deployment and the CloudFormation stack rollback failed. The deployment failed because the following resource(s) failed to update: [AutoScalingGroup]."堆栈状态为UPDATE_ROLLBACK_FAILED。哪个解决方案能解决此问题？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 更新为ALBs配置的子网映射。运行aws cloudformation update-stack-set AWS CLI命令。</div> <div class="option-analysis"><strong>B.</strong> 通过提供更新堆栈的必要权限来更新IAM角色。运行aws cloudformation continue-update-rollback AWS CLI命令。</div> <div class="option-analysis"><strong>C.</strong> 提交增加账户EC2实例数量配额的请求。运行aws cloudformation cancel-update-stack AWS CLI命令。</div> <div class="option-analysis"><strong>D.</strong> 删除Auto Scaling组资源。运行aws cloudformation rollback-stack AWS CLI命令。<div class="section-title"><strong>核心要求:</strong></div> 解决CloudFormation堆栈处于UPDATE_ROLLBACK_FAILED状态的问题 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• CloudFormation-管理基础设施即代码的堆栈更新和回滚 </div><div class="compact-content">• Auto Scaling Groups-自动扩展EC2实例的服务 </div><div class="compact-content">• IAM-提供权限管理和访问控制 <div class="section-title"><strong>正确答案B:</strong></div> UPDATE_ROLLBACK_FAILED状态通常由权限不足导致，需要更新IAM权限并使用continue-update-rollback命令从失败状态恢复 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A-子网映射问题与Auto Scaling组更新失败无关，且update-stack-set用于StackSets而非单个堆栈 </div><div class="compact-content">• 选项C-配额限制不是导致回滚失败的主要原因，cancel-update-stack无法解决UPDATE_ROLLBACK_FAILED状态 </div><div class="compact-content">• 选项D-手动删除资源违反了CloudFormation管理原则，rollback-stack命令不存在 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-continue-update-rollback能快速从失败状态恢复而无需重建整个堆栈 </div><div class="compact-content">• 成本-避免删除和重建资源，节省重新部署成本 </div><div class="compact-content">• 可扩展性-保持CloudFormation统一管理，确保基础设施即代码的一致性</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: B</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-96">
            <div class="question-header">
                <div class="question-title">Question #96 ✅ ⚪ <small style="float: right;">(96/353)</small></div>
            </div>
            <div class="question-content">A company is deploying a new application that uses <span class="key-service">Amazon EC2</span> instances. The company needs a solution to query application logs and AWS account API activity. Which solution will meet these requirements? B (100%)</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Use the <span class="key-service">Amazon CloudWatch</span> agent to send logs from the EC2 instances to <span class="key-service">Amazon CloudWatch</span> Logs. Configure <span class="key-service">AWS CloudTrail</span> to deliver the API logs to <span class="key-service">Amazon S3</span>. Use CloudWatch to query both sets of logs.</div>                <div class="option correct-answer"><strong>B.</strong> Use the <span class="key-service">Amazon CloudWatch</span> agent to send logs from the EC2 instances to <span class="key-service">Amazon CloudWatch</span> Logs. Configure <span class="key-service">AWS CloudTrail</span> to deliver the API logs to CloudWatch Logs. Use CloudWatch Logs Insights to query both sets of logs.</div>                <div class="option"><strong>C.</strong> Use the <span class="key-service">Amazon CloudWatch</span> agent to send logs from the EC2 instances to Amazon Kinesis. Configure <span class="key-service">AWS CloudTrail</span> to deliver the API logs to Kinesis. Use Kinesis to load the data into Amazon Redshift. Use Amazon Redshift to query both sets of logs.</div>                <div class="option"><strong>D.</strong> Use the <span class="key-service">Amazon CloudWatch</span> agent to send logs from the EC2 instances to <span class="key-service">Amazon S3</span>. Use <span class="key-service">AWS CloudTrail</span> to deliver the API logs to <span class="key-service">Amazon S3</span>. Use Amazon Athena to query both sets of logs in <span class="key-service">Amazon S3</span>.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司正在部署使用Amazon EC2实例的新应用程序。公司需要一个解决方案来查询应用程序日志和AWS账户API活动。哪个解决方案能满足这些要求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 使用Amazon CloudWatch代理将EC2实例的日志发送到Amazon CloudWatch Logs。配置AWS CloudTrail将API日志传送到Amazon S3。使用CloudWatch查询两组日志。</div> <div class="option-analysis"><strong>B.</strong> 使用Amazon CloudWatch代理将EC2实例的日志发送到Amazon CloudWatch Logs。配置AWS CloudTrail将API日志传送到CloudWatch Logs。使用CloudWatch Logs Insights查询两组日志。</div> <div class="option-analysis"><strong>C.</strong> 使用Amazon CloudWatch代理将EC2实例的日志发送到Amazon Kinesis。配置AWS CloudTrail将API日志传送到Kinesis。使用Kinesis将数据加载到Amazon Redshift。使用Amazon Redshift查询两组日志。</div> <div class="option-analysis"><strong>D.</strong> 使用Amazon CloudWatch代理将EC2实例的日志发送到Amazon S3。使用AWS CloudTrail将API日志传送到Amazon S3。使用Amazon Athena查询S3中的两组日志。<div class="section-title"><strong>核心要求:</strong></div> 需要统一查询应用程序日志和AWS API活动日志的解决方案 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• CloudWatch Logs - 集中存储和管理日志数据 </div><div class="compact-content">• CloudTrail - 记录AWS账户API调用活动 </div><div class="compact-content">• CloudWatch Logs Insights - 提供强大的日志查询和分析功能 <div class="section-title"><strong>正确答案B:</strong></div> 将应用日志和API日志都存储在CloudWatch Logs中，使用CloudWatch Logs Insights统一查询分析，提供最佳的集成性和查询体验 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A - CloudWatch无法直接查询存储在S3中的CloudTrail日志，缺乏统一查询能力 </div><div class="compact-content">• 选项C - 架构过于复杂，Kinesis和Redshift增加不必要的成本和复杂性 </div><div class="compact-content">• 选项D - CloudWatch代理不能直接发送日志到S3，需要额外配置步骤 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能 - CloudWatch Logs Insights提供实时查询和快速响应 </div><div class="compact-content">• 成本 - 避免使用Redshift等昂贵服务，选择成本效益最优方案 </div><div class="compact-content">• 可扩展性 - CloudWatch Logs原生支持大规模日志处理和存储</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: B</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-97">
            <div class="question-header">
                <div class="question-title">Question #97 ✅ ⚪ <small style="float: right;">(97/353)</small></div>
            </div>
            <div class="question-content">A company wants to ensure that their EC2 instances are secure. They want to be notified if any new vulnerabilities are discovered on their instances, and they also want an audit trail of all login activities on the instances. Which solution will meet these requirements? D (100%)</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Use <span class="key-service">AWS Systems Manager</span> to detect vulnerabilities on the EC2 instances. Install the Amazon Kinesis Agent to capture system logs and deliver them to <span class="key-service">Amazon S3</span>.</div>                <div class="option"><strong>B.</strong> Use <span class="key-service">AWS Systems Manager</span> to detect vulnerabilities on the EC2 instances. Install the Systems Manager Agent to capture system logs and view login activity in the CloudTrail console.</div>                <div class="option"><strong>C.</strong> Configure <span class="key-service">Amazon CloudWatch</span> to detect vulnerabilities on the EC2 instances. Install the <span class="key-service">AWS Config</span> daemon to capture system logs and view them in the <span class="key-service">AWS Config</span> console.</div>                <div class="option correct-answer"><strong>D.</strong> Configure Amazon Inspector to detect vulnerabilities on the EC2 instances. Install the <span class="key-service">Amazon CloudWatch</span> Agent to capture system logs and record them via <span class="key-service">Amazon CloudWatch</span> Logs.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司希望确保其EC2实例的安全性。他们希望在实例上发现任何新漏洞时收到通知，并且还希望获得实例上所有登录活动的审计跟踪。哪种解决方案能满足这些要求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 使用AWS Systems Manager检测EC2实例上的漏洞。安装Amazon Kinesis Agent捕获系统日志并将其传送到Amazon S3。</div> <div class="option-analysis"><strong>B.</strong> 使用AWS Systems Manager检测EC2实例上的漏洞。安装Systems Manager Agent捕获系统日志并在CloudTrail控制台中查看登录活动。</div> <div class="option-analysis"><strong>C.</strong> 配置Amazon CloudWatch检测EC2实例上的漏洞。安装AWS Config守护进程捕获系统日志并在AWS Config控制台中查看。</div> <div class="option-analysis"><strong>D.</strong> 配置Amazon Inspector检测EC2实例上的漏洞。安装Amazon CloudWatch Agent捕获系统日志并通过Amazon CloudWatch Logs记录。<div class="section-title"><strong>核心要求:</strong></div> 需要漏洞检测和登录活动审计跟踪的完整安全监控解决方案 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• Amazon Inspector-专门用于EC2实例漏洞评估和安全检测 </div><div class="compact-content">• CloudWatch Agent-收集系统日志和应用程序日志到CloudWatch Logs <div class="section-title"><strong>正确答案D:</strong></div> Inspector是AWS专用的漏洞评估服务，能自动检测EC2实例安全漏洞并发送通知；CloudWatch Agent可收集系统登录日志并存储到CloudWatch Logs进行审计 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A-Systems Manager主要用于补丁管理而非漏洞检测，Kinesis Agent主要用于流数据处理 </div><div class="compact-content">• 选项B-Systems Manager不是专门的漏洞检测服务，CloudTrail记录API调用而非实例内登录活动 </div><div class="compact-content">• 选项C-CloudWatch是监控服务不具备漏洞检测功能，Config用于配置合规性检查 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-Inspector提供自动化漏洞扫描，CloudWatch Agent高效日志收集 </div><div class="compact-content">• 成本-使用专门服务避免过度配置，按需付费模式 </div><div class="compact-content">• 可扩展性-两个服务都支持大规模EC2实例部署和集中管理</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: D</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-98">
            <div class="question-header">
                <div class="question-title">Question #98 ✅ ⚪ <small style="float: right;">(98/353)</small></div>
            </div>
            <div class="question-content">A company is running an application on <span class="key-service">Amazon EC2</span> instances in an Auto Scaling group. Recently, an issue occurred that prevented EC2 instances from launching successfully, and it took several hours for the support team to discover the issue. The support team wants to be notified by email whenever an EC2 instance does not start successfully. Which action will accomplish this? B (100%)</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Add a health check to the Auto Scaling group to invoke an <span class="key-service">AWS Lambda</span> function whenever an instance status is impaired.</div>                <div class="option correct-answer"><strong>B.</strong> Configure the Auto Scaling group to send a notification to an <span class="key-service">Amazon SNS</span> topic whenever a failed instance launch occurs.</div>                <div class="option"><strong>C.</strong> Create an <span class="key-service">Amazon CloudWatch</span> alarm that invokes an <span class="key-service">AWS Lambda</span> function when a failed AttachInstances Auto Scaling API call is made.</div>                <div class="option"><strong>D.</strong> Create a status check alarm on <span class="key-service">Amazon EC2</span> to send a notification to an <span class="key-service">Amazon SNS</span> topic whenever a status check fail occurs.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司在Auto Scaling组中的Amazon EC2实例上运行应用程序。最近发生了一个问题，阻止EC2实例成功启动，支持团队花了几个小时才发现问题。支持团队希望在EC2实例启动失败时通过邮件收到通知。哪个操作能实现这个目标？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 向Auto Scaling组添加健康检查，当实例状态受损时调用AWS Lambda函数</div> <div class="option-analysis"><strong>B.</strong> 配置Auto Scaling组在实例启动失败时向Amazon SNS主题发送通知</div> <div class="option-analysis"><strong>C.</strong> 创建Amazon CloudWatch告警，当AttachInstances Auto Scaling API调用失败时调用AWS Lambda函数</div> <div class="option-analysis"><strong>D.</strong> 在Amazon EC2上创建状态检查告警，当状态检查失败时向Amazon SNS主题发送通知<div class="section-title"><strong>核心要求:</strong></div> 在EC2实例启动失败时立即通过邮件通知支持团队 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• Auto Scaling Group-提供实例启动失败的原生通知机制 </div><div class="compact-content">• <span class="key-service">Amazon SNS</span>-提供邮件通知服务 <div class="section-title"><strong>正确答案B:</strong></div> Auto Scaling组原生支持在实例启动失败时向SNS主题发送通知，SNS可配置邮件订阅实现即时通知 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A-健康检查是针对运行中实例的状态监控，不能检测启动失败 </div><div class="compact-content">• 选项C-AttachInstances API与实例启动失败场景不匹配，且过于复杂 </div><div class="compact-content">• 选项D-EC2状态检查仅适用于已启动的实例，无法检测启动失败 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-Auto Scaling组原生通知机制响应最快 </div><div class="compact-content">• 成本-使用原生功能无需额外Lambda函数费用 </div><div class="compact-content">• 可扩展性-SNS支持多种通知方式和多个订阅者</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: B</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-99">
            <div class="question-header">
                <div class="question-title">Question #99 ✅ ⚪ <small style="float: right;">(99/353)</small></div>
            </div>
            <div class="question-content">A company is using <span class="key-service">AWS Organizations</span> to centrally manage its AWS accounts. The company has turned on <span class="key-service">AWS Config</span> in each member account by using <span class="key-service">AWS CloudFormation</span> StackSets. The company has configured trusted access in Organizations for <span class="key-service">AWS Config</span> and has configured a member account as a delegated administrator account for <span class="key-service">AWS Config</span>. A DevOps engineer needs to implement a new security policy. The policy must require all current and future AWS member accounts to use a common baseline of <span class="key-service">AWS Config</span> rules that contain remediation actions that are managed from a central account. Non-administrator users who can access member accounts must not be able to modify this common baseline of <span class="key-service">AWS Config</span> rules that are deployed into each member account. Which solution will meet these requirements? D (89%) 11%</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Create a CloudFormation template that contains the <span class="key-service">AWS Config</span> rules and remediation actions. Deploy the template from the Organizations management account by using CloudFormation StackSets.</div>                <div class="option"><strong>B.</strong> Create an <span class="key-service">AWS Config</span> conformance pack that contains the <span class="key-service">AWS Config</span> rules and remediation actions. Deploy the pack from the Organizations management account by using CloudFormation StackSets.</div>                <div class="option"><strong>C.</strong> Create a CloudFormation template that contains the <span class="key-service">AWS Config</span> rules and remediation actions. Deploy the template from the delegated administrator account by using <span class="key-service">AWS Config</span>.</div>                <div class="option correct-answer"><strong>D.</strong> Create an <span class="key-service">AWS Config</span> conformance pack that contains the <span class="key-service">AWS Config</span> rules and remediation actions. Deploy the pack from the delegated administrator account by using <span class="key-service">AWS Config</span>. Most Voted</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司使用AWS Organizations集中管理其AWS账户。公司通过AWS CloudFormation StackSets在每个成员账户中启用了AWS Config。公司已为AWS Config配置了Organizations中的可信访问，并将一个成员账户配置为AWS Config的委托管理员账户。DevOps工程师需要实施新的安全策略。该策略必须要求所有当前和未来的AWS成员账户使用包含修复操作的AWS Config规则通用基线，并从中央账户进行管理。能够访问成员账户的非管理员用户不得修改部署到每个成员账户的AWS Config规则通用基线。 <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 创建包含AWS Config规则和修复操作的CloudFormation模板，从Organizations管理账户使用CloudFormation StackSets部署模板</div> <div class="option-analysis"><strong>B.</strong> 创建包含AWS Config规则和修复操作的AWS Config conformance pack，从Organizations管理账户使用CloudFormation StackSets部署包</div> <div class="option-analysis"><strong>C.</strong> 创建包含AWS Config规则和修复操作的CloudFormation模板，从委托管理员账户使用AWS Config部署模板</div> <div class="option-analysis"><strong>D.</strong> 创建包含AWS Config规则和修复操作的AWS Config conformance pack，从委托管理员账户使用AWS Config部署包<div class="section-title"><strong>核心要求:</strong></div> 在多账户环境中集中管理AWS Config规则基线，防止非管理员用户修改 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• <span class="key-service">AWS Config</span> conformance pack-标准化配置规则和修复操作的打包部署方式 </div><div class="compact-content">• AWS Organizations委托管理员-允许成员账户代表管理账户执行特定服务管理任务 <div class="section-title"><strong>正确答案D:</strong></div> 使用AWS Config conformance pack提供标准化的规则打包，通过委托管理员账户部署确保集中控制和权限隔离 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A-使用CloudFormation模板而非conformance pack，缺乏AWS Config原生的标准化管理能力 </div><div class="compact-content">• 选项B-从管理账户部署而非委托管理员账户，不符合已配置的委托管理架构 </div><div class="compact-content">• 选项C-使用CloudFormation模板而非conformance pack，无法提供AWS Config原生的集中管理功能 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-conformance pack提供原生AWS Config集中管理能力 </div><div class="compact-content">• 成本-利用现有委托管理员配置，无需额外架构变更 </div><div class="compact-content">• 可扩展性-conformance pack自动适用于当前和未来所有成员账户</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: D</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-100">
            <div class="question-header">
                <div class="question-title">Question #100 ✅ ⚪ <small style="float: right;">(100/353)</small></div>
            </div>
            <div class="question-content">A DevOps engineer manages a large commercial website that runs on <span class="key-service">Amazon EC2</span>. The website uses Amazon Kinesis Data Streams to collect and process web logs. The DevOps engineer manages the Kinesis consumer application, which also runs on <span class="key-service">Amazon EC2</span>. Sudden increases of data cause the Kinesis consumer application to fall behind, and the Kinesis data streams drop records before the records can be processed. The DevOps engineer must implement a solution to improve stream handling. Which solution meets these requirements with the MOST operational efficiency? B (70%) C (28%)</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Modify the Kinesis consumer application to store the logs durably in <span class="key-service">Amazon S3</span>. Use Amazon EMR to process the data directly on <span class="key-service">Amazon S3</span> to derive customer insights. Store the results in <span class="key-service">Amazon S3</span>.</div>                <div class="option correct-answer"><strong>B.</strong> Horizontally scale the Kinesis consumer application by adding more EC2 instances based on the <span class="key-service">Amazon CloudWatch</span> GetRecords.IteratorAgeMilliseconds metric. Increase the retention period of the Kinesis data streams. Most Voted</div>                <div class="option"><strong>C.</strong> Convert the Kinesis consumer application to run as an <span class="key-service">AWS Lambda</span> function. Configure the Kinesis data streams as the event source for the Lambda function to process the data streams. Most Voted</div>                <div class="option"><strong>D.</strong> Increase the number of shards in the Kinesis data streams to increase the overall throughput so that the consumer application processes the data faster.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一名DevOps工程师管理运行在Amazon EC2上的大型商业网站。网站使用Amazon Kinesis Data Streams收集和处理web日志。DevOps工程师管理同样运行在Amazon EC2上的Kinesis消费者应用程序。数据突然增加导致Kinesis消费者应用程序滞后，Kinesis数据流在记录被处理前就丢弃了记录。DevOps工程师必须实施解决方案来改善流处理。哪个解决方案以最高运营效率满足这些要求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 修改Kinesis消费者应用程序将日志持久存储在Amazon S3中。使用Amazon EMR直接在Amazon S3上处理数据以获得客户洞察。将结果存储在Amazon S3中。</div> <div class="option-analysis"><strong>B.</strong> 基于Amazon CloudWatch GetRecords.IteratorAgeMilliseconds指标通过添加更多EC2实例水平扩展Kinesis消费者应用程序。增加Kinesis数据流的保留期。</div> <div class="option-analysis"><strong>C.</strong> 将Kinesis消费者应用程序转换为AWS Lambda函数运行。配置Kinesis数据流作为Lambda函数的事件源来处理数据流。</div> <div class="option-analysis"><strong>D.</strong> 增加Kinesis数据流中的分片数量以提高整体吞吐量，使消费者应用程序更快地处理数据。<div class="section-title"><strong>核心要求:</strong></div> 解决Kinesis消费者应用程序处理滞后和数据丢失问题，提高流处理能力 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• Amazon Kinesis Data Streams-实时数据流处理服务 </div><div class="compact-content">• <span class="key-service">Amazon CloudWatch</span>-监控服务，提供GetRecords.IteratorAgeMilliseconds指标 </div><div class="compact-content">• <span class="key-service">Amazon EC2</span>-弹性计算云服务 <div class="section-title"><strong>正确答案B:</strong></div> 通过CloudWatch指标监控消费滞后情况，自动水平扩展EC2实例增加处理能力，同时延长数据保留期防止数据丢失，是最直接有效的解决方案 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A-改变架构为批处理模式，无法解决实时流处理需求，运营复杂度高 </div><div class="compact-content">• 选项C-Lambda有15分钟执行时间限制和并发限制，可能无法处理大量持续数据流 </div><div class="compact-content">• 选项D-仅增加分片不能解决消费者处理能力不足的根本问题 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-水平扩展直接提升处理能力，延长保留期防止数据丢失 </div><div class="compact-content">• 成本-基于指标的自动扩展避免资源浪费，成本可控 </div><div class="compact-content">• 可扩展性-EC2水平扩展灵活性高，可根据负载动态调整</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: B</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-101">
            <div class="question-header">
                <div class="question-title">Question #101 ✅ 📝 <small style="float: right;">(101/353)</small></div>
            </div>
            <div class="question-content">A company recently created a new AWS Control Tower landing zone in a new organization in <span class="key-service">AWS Organizations</span>. The landing zone must be able to demonstrate compliance with the Center for Internet Security (CIS) Benchmarks for AWS Foundations. The company's security team wants to use AWS Security Hub to view compliance across all accounts. Only the security team can be allowed to view aggregated Security Hub findings. In addition, specific users must be able to view findings from their own accounts within the organization. All accounts must be enrolled in Security Hub after the accounts are created. Which combination of steps will meet these requirements in the MOST automated way? (Choose three.) ACE (76%) ADE (19%) 5%</div>
            <div class="options-container">                <div class="option correct-answer"><strong>A.</strong> Turn on trusted access for Security Hub in the organization's management account. Create a new security account by using AWS Control Tower. Configure the new security account as the delegated administrator account for Security Hub. In the new security account, provide Security Hub with the CIS Benchmarks for AWS Foundations standards.</div>                <div class="option"><strong>B.</strong> Turn on trusted access for Security Hub in the organization's management account. From the management account, provide Security Hub with the CIS Benchmarks for AWS Foundations standards.</div>                <div class="option correct-answer"><strong>C.</strong> Create an <span class="key-service">AWS IAM</span> Identity Center (AWS Single Sign-On) permission set that includes the required permissions. Use the CreateAccountAssignment API operation to associate the security team users with the permission set and with the delegated security account.</div>                <div class="option"><strong>D.</strong> Create an <span class="key-service">SCP</span> that explicitly denies any user who is not on the security team from accessing Security Hub.</div>                <div class="option correct-answer"><strong>E.</strong> In Security Hub, turn on automatic enablement. F. In the organization's management account, create an Amazon EventBridge rule that reacts to the CreateManagedAccount event. Create an <span class="key-service">AWS Lambda</span> function that uses the Security Hub CreateMembers API operation to add new accounts to Security Hub. Configure the EventBridge rule to invoke the Lambda function.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司最近在AWS Organizations的新组织中创建了新的AWS Control Tower landing zone。该landing zone必须能够证明符合AWS基础设施的互联网安全中心(CIS)基准。公司安全团队希望使用AWS Security Hub查看所有账户的合规性。只有安全团队可以查看聚合的Security Hub发现。此外，特定用户必须能够查看组织内自己账户的发现。所有账户在创建后必须自动注册到Security Hub。哪些步骤组合能以最自动化的方式满足这些要求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 在组织管理账户中为Security Hub开启可信访问。使用AWS Control Tower创建新的安全账户。将新安全账户配置为Security Hub的委托管理员账户。在新安全账户中，为Security Hub提供AWS基础设施CIS基准标准。</div> <div class="option-analysis"><strong>B.</strong> 在组织管理账户中为Security Hub开启可信访问。从管理账户为Security Hub提供AWS基础设施CIS基准标准。</div> <div class="option-analysis"><strong>C.</strong> 创建包含所需权限的AWS IAM Identity Center权限集。使用CreateAccountAssignment API操作将安全团队用户与权限集和委托安全账户关联。</div> <div class="option-analysis"><strong>D.</strong> 创建SCP明确拒绝非安全团队用户访问Security Hub。</div> <div class="option-analysis"><strong>E.</strong> 在Security Hub中开启自动启用功能。 F. 在组织管理账户中创建Amazon EventBridge规则响应CreateManagedAccount事件。创建AWS Lambda函数使用Security Hub CreateMembers API操作将新账户添加到Security Hub。配置EventBridge规则调用Lambda函数。<div class="section-title"><strong>核心要求:</strong></div> 建立跨组织账户的Security Hub合规监控，实现权限分离和自动化账户注册 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• AWS Security Hub-提供集中化安全合规监控和CIS基准检查 </div><div class="compact-content">• AWS Control Tower-管理多账户环境和自动化治理 </div><div class="compact-content">• <span class="key-service">AWS IAM</span> Identity Center-提供集中身份管理和权限控制 <div class="section-title"><strong>正确答案ACE:</strong></div> A建立委托管理架构实现权限分离，C通过IAM Identity Center实现细粒度权限控制，E通过自动启用功能实现新账户的自动Security Hub注册 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项B-从管理账户配置违反了安全最佳实践，应使用委托管理员账户 </div><div class="compact-content">• 选项D-SCP过于粗暴，无法实现用户查看自己账户发现的细粒度权限要求 </div><div class="compact-content">• 选项F-手动EventBridge+Lambda方案复杂度高，Security Hub自动启用功能更简单有效 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 安全性-委托管理员模式和IAM Identity Center提供最佳权限分离 </div><div class="compact-content">• 自动化-Security Hub自动启用比自定义Lambda方案更简单可靠 </div><div class="compact-content">• 可扩展性-委托管理架构支持大规模多账户环境的集中管理</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: ACE (A、C、E)</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-102">
            <div class="question-header">
                <div class="question-title">Question #102 ✅ ⚪ <small style="float: right;">(102/353)</small></div>
            </div>
            <div class="question-content">A company runs applications in AWS accounts that are in an organization in <span class="key-service">AWS Organizations</span>. The applications use <span class="key-service">Amazon EC2</span> instances and <span class="key-service">Amazon S3</span>. The company wants to detect potentially compromised EC2 instances, suspicious network activity, and unusual API activity in its existing AWS accounts and in any AWS accounts that the company creates in the future. When the company detects one of these events, the company wants to use an existing Amazon Simple Notification Service (<span class="key-service">Amazon SNS</span>) topic to send a notification to its operational support team for investigation and remediation. Which solution will meet these requirements in accordance with AWS best practices? A (88%) 13%</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> In the organization's management account, configure an AWS account as the <span class="key-service">Amazon GuardDuty</span> administrator account. In the GuardDuty administrator account, add the company's existing AWS accounts to GuardDuty as members. In the GuardDuty administrator account, create an Amazon EventBridge rule with an event pattern to match GuardDuty events and to forward matching events to the SNS topic. Most Voted</div>                <div class="option correct-answer"><strong>B.</strong> In the organization's management account, configure <span class="key-service">Amazon GuardDuty</span> to add newly created AWS accounts by invitation and to send invitations to the existing AWS accounts. Create an <span class="key-service">AWS CloudFormation</span> stack set that accepts the GuardDuty invitation and creates an Amazon EventBridge rule. Configure the rule with an event pattern to match GuardDuty events and to forward matching events to the SNS topic. Configure the CloudFormation stack set to deploy into all AWS accounts in the organization.</div>                <div class="option"><strong>C.</strong> In the organization's management account, create an <span class="key-service">AWS CloudTrail</span> organization trail. Activate the organization trail in all AWS accounts in the organization. Create an <span class="key-service">SCP</span> that enables <span class="key-service">VPC</span> Flow Logs in each account in the organization. Configure AWS Security Hub for the organization. Create an Amazon EventBridge rule with an event pattern to match Security Hub events and to forward matching events to the SNS topic.</div>                <div class="option"><strong>D.</strong> In the organization's management account, configure an AWS account as the <span class="key-service">AWS CloudTrail</span> administrator account. In the CloudTrail administrator account, create a CloudTrail organization trail. Add the company's existing AWS accounts to the organization trail. Create an <span class="key-service">SCP</span> that enables <span class="key-service">VPC</span> Flow Logs in each account in the organization. Configure AWS Security Hub for the organization. Create an Amazon EventBridge rule with an event pattern to match Security Hub events and to forward matching events to the SNS topic.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司在AWS Organizations组织中的AWS账户中运行应用程序。应用程序使用Amazon EC2实例和Amazon S3。公司希望在现有AWS账户和未来创建的任何AWS账户中检测潜在受损的EC2实例、可疑网络活动和异常API活动。当公司检测到这些事件之一时，希望使用现有的Amazon Simple Notification Service (<span class="key-service">Amazon SNS</span>)主题向运营支持团队发送通知以进行调查和修复。哪个解决方案符合AWS最佳实践来满足这些要求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 在组织的管理账户中，配置一个AWS账户作为Amazon GuardDuty管理员账户。在GuardDuty管理员账户中，将公司现有的AWS账户作为成员添加到GuardDuty。在GuardDuty管理员账户中，创建一个Amazon EventBridge规则，使用事件模式匹配GuardDuty事件并将匹配事件转发到SNS主题。</div> <div class="option-analysis"><strong>B.</strong> 在组织的管理账户中，配置Amazon GuardDuty通过邀请添加新创建的AWS账户并向现有AWS账户发送邀请。创建一个AWS CloudFormation堆栈集，接受GuardDuty邀请并创建Amazon EventBridge规则。配置规则使用事件模式匹配GuardDuty事件并将匹配事件转发到SNS主题。配置CloudFormation堆栈集部署到组织中的所有AWS账户。</div> <div class="option-analysis"><strong>C.</strong> 在组织的管理账户中，创建一个AWS CloudTrail组织跟踪。在组织中的所有AWS账户中激活组织跟踪。创建一个SCP在组织中的每个账户中启用VPC Flow Logs。为组织配置AWS Security Hub。创建一个Amazon EventBridge规则，使用事件模式匹配Security Hub事件并将匹配事件转发到SNS主题。</div> <div class="option-analysis"><strong>D.</strong> 在组织的管理账户中，配置一个AWS账户作为AWS CloudTrail管理员账户。在CloudTrail管理员账户中，创建一个CloudTrail组织跟踪。将公司现有的AWS账户添加到组织跟踪。创建一个SCP在组织中的每个账户中启用VPC Flow Logs。为组织配置AWS Security Hub。创建一个Amazon EventBridge规则，使用事件模式匹配Security Hub事件并将匹配事件转发到SNS主题。<div class="section-title"><strong>核心要求:</strong></div> 在AWS Organizations中检测安全威胁并自动通知运营团队 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• <span class="key-service">Amazon GuardDuty</span>-专门检测EC2实例威胁、可疑网络活动和异常API活动的托管威胁检测服务 </div><div class="compact-content">• <span class="key-service">AWS CloudFormation</span> StackSets-在多个账户和区域中自动部署和管理资源的服务 </div><div class="compact-content">• Amazon EventBridge-事件驱动架构服务，用于路由GuardDuty事件到SNS <div class="section-title"><strong>正确答案B:</strong></div> 使用GuardDuty组织级配置通过邀请机制管理成员账户，结合CloudFormation StackSets自动化部署EventBridge规则到所有账户，实现统一威胁检测和通知 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A-需要手动管理GuardDuty管理员账户，不符合AWS Organizations最佳实践，且无法自动处理未来新账户 </div><div class="compact-content">• 选项C-CloudTrail和Security Hub不是专门的威胁检测服务，无法有效检测题目要求的特定威胁类型 </div><div class="compact-content">• 选项D-同选项C，使用错误的服务组合，CloudTrail主要用于审计而非实时威胁检测 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-GuardDuty提供实时威胁检测和机器学习分析 </div><div class="compact-content">• 成本-避免重复配置和手动管理，使用托管服务降低运营成本 </div><div class="compact-content">• 可扩展性-CloudFormation StackSets自动处理新账户，支持组织级扩展</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: B</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-103">
            <div class="question-header">
                <div class="question-title">Question #103 ✅ ⚪ <small style="float: right;">(103/353)</small></div>
            </div>
            <div class="question-content">A company's DevOps engineer is working in a multi-account environment. The company uses AWS Transit Gateway to route all outbound traffic through a network operations account. In the network operations account, all account traffic passes through a firewall appliance for inspection before the traffic goes to an internet gateway. The firewall appliance sends logs to <span class="key-service">Amazon CloudWatch</span> Logs and includes event severities of CRITICAL, HIGH, MEDIUM, LOW, and INFO. The security team wants to receive an alert if any CRITICAL events occur. What should the DevOps engineer do to meet these requirements? B (100%)</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Create an <span class="key-service">Amazon CloudWatch</span> Synthetics canary to monitor the firewall state. If the firewall reaches a CRITICAL state or logs a CRITICAL event, use a CloudWatch alarm to publish a notification to an Amazon Simple Notification Service (<span class="key-service">Amazon SNS</span>) topic. Subscribe the security team's email address to the topic.</div>                <div class="option correct-answer"><strong>B.</strong> Create an <span class="key-service">Amazon CloudWatch</span> metric filter by using a search for CRITICAL events. Publish a custom metric for the finding. Use a CloudWatch alarm based on the custom metric to publish a notification to an Amazon Simple Notification Service (<span class="key-service">Amazon SNS</span>) topic. Subscribe the security team's email address to the topic. Most Voted</div>                <div class="option"><strong>C.</strong> Enable <span class="key-service">Amazon GuardDuty</span> in the network operations account. Configure GuardDuty to monitor flow logs. Create an Amazon EventBridge event rule that is invoked by GuardDuty events that are CRITICAL. Define an Amazon Simple Notification Service (<span class="key-service">Amazon SNS</span>) topic as a target. Subscribe the security team's email address to the topic.</div>                <div class="option"><strong>D.</strong> Use AWS Firewall Manager to apply consistent policies across all accounts. Create an Amazon EventBridge event rule that is invoked by Firewall Manager events that are CRITICAL. Define an Amazon Simple Notification Service (<span class="key-service">Amazon SNS</span>) topic as a target. Subscribe the security team's email address to the topic.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司的DevOps工程师在多账户环境中工作。公司使用AWS Transit Gateway将所有出站流量路由到网络运营账户。在网络运营账户中，所有账户流量在到达internet gateway之前都要通过防火墙设备进行检查。防火墙设备将日志发送到Amazon CloudWatch Logs，包含CRITICAL、HIGH、MEDIUM、LOW和INFO等事件严重级别。安全团队希望在发生任何CRITICAL事件时收到警报。DevOps工程师应该如何满足这些要求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 创建Amazon CloudWatch Synthetics canary来监控防火墙状态。如果防火墙达到CRITICAL状态或记录CRITICAL事件，使用CloudWatch alarm向Amazon Simple Notification Service (<span class="key-service">Amazon SNS</span>) topic发布通知。将安全团队的邮箱地址订阅到该topic。</div> <div class="option-analysis"><strong>B.</strong> 通过搜索CRITICAL事件创建Amazon CloudWatch metric filter。为发现结果发布自定义指标。基于自定义指标使用CloudWatch alarm向Amazon Simple Notification Service (<span class="key-service">Amazon SNS</span>) topic发布通知。将安全团队的邮箱地址订阅到该topic。</div> <div class="option-analysis"><strong>C.</strong> 在网络运营账户中启用Amazon GuardDuty。配置GuardDuty监控flow logs。创建由CRITICAL级别GuardDuty事件触发的Amazon EventBridge event rule。定义Amazon Simple Notification Service (<span class="key-service">Amazon SNS</span>) topic作为目标。将安全团队的邮箱地址订阅到该topic。</div> <div class="option-analysis"><strong>D.</strong> 使用AWS Firewall Manager在所有账户中应用一致的策略。创建由CRITICAL级别Firewall Manager事件触发的Amazon EventBridge event rule。定义Amazon Simple Notification Service (<span class="key-service">Amazon SNS</span>) topic作为目标。将安全团队的邮箱地址订阅到该topic。<div class="section-title"><strong>核心要求:</strong></div> 监控防火墙设备发送到CloudWatch Logs的CRITICAL事件并发送警报通知 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• CloudWatch Logs-存储防火墙日志 </div><div class="compact-content">• CloudWatch Metric Filter-从日志中提取特定模式创建指标 </div><div class="compact-content">• CloudWatch Alarm-基于指标阈值触发通知 </div><div class="compact-content">• SNS-发送通知给订阅者 <div class="section-title"><strong>正确答案B:</strong></div> 使用CloudWatch metric filter搜索日志中的CRITICAL关键词，创建自定义指标，然后基于该指标设置CloudWatch alarm触发SNS通知，这是处理日志监控和警报的标准方案 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A-CloudWatch Synthetics用于监控应用程序端点可用性，不适用于日志内容分析 </div><div class="compact-content">• 选项C-GuardDuty用于威胁检测，不是用来解析防火墙应用程序的自定义日志格式 </div><div class="compact-content">• 选项D-Firewall Manager用于管理防火墙策略，不处理日志监控和事件检测 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-直接从现有日志源创建监控，响应迅速 </div><div class="compact-content">• 成本-利用现有CloudWatch服务，无需额外安全服务 </div><div class="compact-content">• 可扩展性-metric filter可处理大量日志数据并支持复杂搜索模式</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: B</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-104">
            <div class="question-header">
                <div class="question-title">Question #104 ✅ ⚪ <small style="float: right;">(104/353)</small></div>
            </div>
            <div class="question-content">A company is divided into teams. Each team has an AWS account, and all the accounts are in an organization in <span class="key-service">AWS Organizations</span>. Each team must retain full administrative rights to its AWS account. Each team also must be allowed to access only AWS services that the company approves for use. AWS services must gain approval through a request and approval process. How should a DevOps engineer configure the accounts to meet these requirements? D (50%) C (47%)</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Use <span class="key-service">AWS CloudFormation</span> StackSets to provision IAM policies in each account to deny access to restricted AWS services. In each account, configure <span class="key-service">AWS Config</span> rules that ensure that the policies are attached to IAM principals in the account.</div>                <div class="option"><strong>B.</strong> Use AWS Control Tower to provision the accounts into OUs within the organization. Configure AWS Control Tower to enable <span class="key-service">AWS IAM</span> Identity Center (AWS Single Sign-On). Configure IAM Identity Center to provide administrative access. Include deny policies on user roles for restricted AWS services.</div>                <div class="option correct-answer"><strong>C.</strong> Place all the accounts under a new top-level OU within the organization. Create an <span class="key-service">SCP</span> that denies access to restricted AWS services. Attach the <span class="key-service">SCP</span> to the OU.</div>                <div class="option"><strong>D.</strong> Create an <span class="key-service">SCP</span> that allows access to only approved AWS services. Attach the <span class="key-service">SCP</span> to the root OU of the organization. Remove the FullAWSAccess <span class="key-service">SCP</span> from the root OU of the organization.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司分为多个团队，每个团队有一个AWS账户，所有账户都在AWS Organizations的组织中。每个团队必须保留对其AWS账户的完全管理权限，同时只能访问公司批准使用的AWS服务。AWS服务必须通过请求和批准流程获得批准。DevOps工程师应如何配置账户以满足这些要求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 使用AWS CloudFormation StackSets在每个账户中配置IAM策略以拒绝访问受限的AWS服务，在每个账户中配置AWS Config规则确保策略附加到账户中的IAM主体。</div> <div class="option-analysis"><strong>B.</strong> 使用AWS Control Tower将账户配置到组织内的OU中，配置AWS Control Tower启用AWS IAM Identity Center，配置IAM Identity Center提供管理访问权限，在用户角色上包含受限AWS服务的拒绝策略。</div> <div class="option-analysis"><strong>C.</strong> 将所有账户放在组织内新的顶级OU下，创建拒绝访问受限AWS服务的SCP，将SCP附加到该OU。</div> <div class="option-analysis"><strong>D.</strong> 创建仅允许访问已批准AWS服务的SCP，将SCP附加到组织的根OU，从组织根OU中移除FullAWSAccess <span class="key-service">SCP</span>。<div class="section-title"><strong>核心要求:</strong></div> 在保持团队完全管理权限的同时限制对未批准AWS服务的访问 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• <span class="key-service">AWS Organizations</span> <span class="key-service">SCP</span>-提供组织级别的服务访问控制 </div><div class="compact-content">• OU(Organizational Unit)-组织单元用于分组管理账户 <div class="section-title"><strong>正确答案C:</strong></div> 通过在专门OU上附加拒绝策略的SCP，既保持了账户内的完全管理权限，又有效限制了对受限服务的访问 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A-使用IAM策略和Config规则过于复杂，且无法防止管理员修改这些限制 </div><div class="compact-content">• 选项B-Control Tower和IAM Identity Center改变了现有的管理模式，不符合保持完全管理权限的要求 </div><div class="compact-content">• 选项D-在根OU级别应用限制会影响所有账户，且移除FullAWSAccess可能过于严格 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-SCP在组织级别提供即时的服务访问控制 </div><div class="compact-content">• 成本-利用现有Organizations功能，无需额外服务成本 </div><div class="compact-content">• 可扩展性-OU结构便于管理多团队账户和灵活调整服务权限</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: C</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-105">
            <div class="question-header">
                <div class="question-title">Question #105 ✅ ⚪ <small style="float: right;">(105/353)</small></div>
            </div>
            <div class="question-content">A DevOps engineer used an <span class="key-service">AWS CloudFormation</span> custom resource to set up AD Connector. The <span class="key-service">AWS Lambda</span> function ran and created AD Connector, but CloudFormation is not transitioning from CREATE_IN_PROGRESS to CREATE_COMPLET<div class="option-analysis"><strong>E.</strong> Which action should the engineer take to resolve this issue? B (100%)</div></div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Ensure the Lambda function code has exited successfully.</div>                <div class="option correct-answer"><strong>B.</strong> Ensure the Lambda function code returns a response to the pre-signed URL.</div>                <div class="option"><strong>C.</strong> Ensure the Lambda function IAM role has cloudformation:UpdateStack permissions for the stack ARN.</div>                <div class="option"><strong>D.</strong> Ensure the Lambda function IAM role has ds:ConnectDirectory permissions for the AWS account.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一位DevOps工程师使用AWS CloudFormation自定义资源来设置AD Connector。AWS Lambda函数运行并创建了AD Connector，但CloudFormation没有从CREATE_IN_PROGRESS转换到CREATE_COMPLETE状态。工程师应该采取什么行动来解决这个问题？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 确保Lambda函数代码已成功退出</div> <div class="option-analysis"><strong>B.</strong> 确保Lambda函数代码向预签名URL返回响应</div> <div class="option-analysis"><strong>C.</strong> 确保Lambda函数IAM角色对堆栈ARN具有cloudformation:UpdateStack权限</div> <div class="option-analysis"><strong>D.</strong> 确保Lambda函数IAM角色对AWS账户具有ds:ConnectDirectory权限<div class="section-title"><strong>核心要求:</strong></div> CloudFormation自定义资源需要Lambda函数正确响应来完成状态转换 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• CloudFormation - 基础设施即代码服务，需要自定义资源响应来更新堆栈状态 </div><div class="compact-content">• Lambda - 执行自定义资源逻辑，必须向CloudFormation发送响应信号 <div class="section-title"><strong>正确答案B:</strong></div> CloudFormation自定义资源要求Lambda函数向预签名URL发送响应（SUCCESS/FAILED），否则堆栈会一直处于IN_PROGRESS状态直到超时 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A - 函数成功退出不等于向CloudFormation发送了状态响应 </div><div class="compact-content">• 选项C - UpdateStack权限与自定义资源响应机制无关 </div><div class="compact-content">• 选项D - ds:ConnectDirectory权限用于创建AD Connector，不影响CloudFormation状态转换 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能 - 正确响应机制确保堆栈状态及时更新 </div><div class="compact-content">• 成本 - 避免因超时导致的资源浪费和重复部署 </div><div class="compact-content">• 可扩展性 - 标准响应模式适用于所有CloudFormation自定义资源场景</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: B</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-106">
            <div class="question-header">
                <div class="question-title">Question #106 ✅ ⚪ <small style="float: right;">(106/353)</small></div>
            </div>
            <div class="question-content">A company uses <span class="key-service">AWS CodeCommit</span> for source code control. Developers apply their changes to various feature branches and create pull requests to move those changes to the main branch when the changes are ready for production. The developers should not be able to push changes directly to the main branch. The company applied the AWSCodeCommitPowerUser managed policy to the developers' IAM role, and now these developers can push changes to the main branch directly on every repository in the AWS account. What should the company do to restrict the developers' ability to push changes to the main branch directly? A (93%) 7%</div>
            <div class="options-container">                <div class="option correct-answer"><strong>A.</strong> Create an additional policy to include a Deny rule for the GitPush and PutFile actions. Include a restriction for the specific repositories in the policy statement with a condition that references the main branch.</div>                <div class="option"><strong>B.</strong> Remove the IAM policy, and add an AWSCodeCommitReadOnly managed policy. Add an Allow rule for the GitPush and PutFile actions for the specific repositories in the policy statement with a condition that references the main branch.</div>                <div class="option"><strong>C.</strong> Modify the IAM policy. Include a Deny rule for the GitPush and PutFile actions for the specific repositories in the policy statement with a condition that references the main branch.</div>                <div class="option"><strong>D.</strong> Create an additional policy to include an Allow rule for the GitPush and PutFile actions. Include a restriction for the specific repositories in the policy statement with a condition that references the feature branches.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司使用AWS CodeCommit进行源代码控制。开发人员将更改应用到各种功能分支，并在更改准备投产时创建拉取请求将这些更改移动到主分支。开发人员不应能够直接向主分支推送更改。公司为开发人员的IAM角色应用了AWSCodeCommitPowerUser托管策略，现在这些开发人员可以直接向AWS账户中每个存储库的主分支推送更改。公司应该如何限制开发人员直接向主分支推送更改的能力？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 创建一个额外的策略，包含对GitPush和PutFile操作的拒绝规则。在策略声明中包含对特定存储库的限制，并添加引用主分支的条件。</div> <div class="option-analysis"><strong>B.</strong> 删除IAM策略，添加AWSCodeCommitReadOnly托管策略。为策略声明中的特定存储库添加GitPush和PutFile操作的允许规则，并添加引用主分支的条件。</div> <div class="option-analysis"><strong>C.</strong> 修改IAM策略。在策略声明中为特定存储库包含GitPush和PutFile操作的拒绝规则，并添加引用主分支的条件。</div> <div class="option-analysis"><strong>D.</strong> 创建一个额外的策略，包含对GitPush和PutFile操作的允许规则。在策略声明中包含对特定存储库的限制，并添加引用功能分支的条件。<div class="section-title"><strong>核心要求:</strong></div> 限制开发人员直接向CodeCommit主分支推送代码的权限 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• <span class="key-service">AWS CodeCommit</span>-Git代码存储库服务 </div><div class="compact-content">• IAM策略-权限控制和访问管理 <div class="section-title"><strong>正确答案A:</strong></div> 创建额外的拒绝策略是最佳实践，因为拒绝规则优先级高于允许规则，可以在保持现有权限的基础上精确限制主分支的推送操作 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项B-删除现有策略会移除开发人员的必要权限，且ReadOnly策略无法提供推送功能分支的权限 </div><div class="compact-content">• 选项C-直接修改托管策略不可行，托管策略由AWS维护无法修改 </div><div class="compact-content">• 选项D-仅允许功能分支推送无法阻止主分支推送，因为原有PowerUser权限仍然生效 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 安全性-使用拒绝规则确保主分支保护不被绕过 </div><div class="compact-content">• 可维护性-保持现有权限结构，仅添加必要限制 </div><div class="compact-content">• 精确控制-通过条件语句精确定位主分支和特定存储库</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: A</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-107">
            <div class="question-header">
                <div class="question-title">Question #107 ✅ ⚪ <small style="float: right;">(107/353)</small></div>
            </div>
            <div class="question-content">A company manages a web application that runs on <span class="key-service">Amazon EC2</span> instances behind an Application Load Balancer (ALB). The EC2 instances run in an Auto Scaling group across multiple Availability Zones. The application uses an <span class="key-service">Amazon RDS</span> for MySQL DB instance to store the data. The company has configured <span class="key-service">Amazon Route 53</span> with an alias record that points to the AL<div class="option-analysis"><strong>B.</strong> A new company guideline requires a geographically isolated disaster recovery (DR) site with an RTO of 4 hours and an RPO of 15 minutes. Which DR strategy will meet these requirements with the LEAST change to the application stack? D (89%) 11%</div></div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Launch a replica environment of everything except <span class="key-service">Amazon RDS</span> in a different Availability Zone. Create an RDS read replica in the new Availability Zone, and configure the new stack to point to the local RDS DB instance. Add the new stack to the Route 53 record set by using a health check to configure a failover routing policy.</div>                <div class="option"><strong>B.</strong> Launch a replica environment of everything except <span class="key-service">Amazon RDS</span> in a different AWS Region. Create an RDS read replica in the new Region, and configure the new stack to point to the local RDS DB instance. Add the new stack to the Route 53 record set by using a health check to configure a latency routing policy.</div>                <div class="option"><strong>C.</strong> Launch a replica environment of everything except <span class="key-service">Amazon RDS</span> in a different AWS Region. In the event of an outage, copy and restore the latest RDS snapshot from the primary Region to the DR Region. Adjust the Route 53 record set to point to the ALB in the DR Region.</div>                <div class="option correct-answer"><strong>D.</strong> Launch a replica environment of everything except <span class="key-service">Amazon RDS</span> in a different AWS Region. Create an RDS read replica in the new Region, and configure the new environment to point to the local RDS DB instance. Add the new stack to the Route 53 record set by using a health check to configure a failover routing policy. In the event of an outage, promote the read replica to primary.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司管理运行在Application Load Balancer (ALB)后面Amazon EC2实例上的Web应用程序。EC2实例在跨多个Availability Zone的Auto Scaling组中运行。应用程序使用Amazon RDS for MySQL数据库实例存储数据。公司已配置Amazon Route 53别名记录指向ALB。新的公司指导方针要求地理隔离的灾难恢复(DR)站点，RTO为4小时，RPO为15分钟。哪种DR策略能以最少的应用程序堆栈更改满足这些要求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 在不同Availability Zone中启动除Amazon RDS外所有组件的副本环境，在新AZ中创建RDS只读副本，配置新堆栈指向本地RDS数据库实例，使用健康检查将新堆栈添加到Route 53记录集以配置故障转移路由策略</div> <div class="option-analysis"><strong>B.</strong> 在不同AWS Region中启动除Amazon RDS外所有组件的副本环境，在新Region中创建RDS只读副本，配置新堆栈指向本地RDS数据库实例，使用健康检查将新堆栈添加到Route 53记录集以配置延迟路由策略</div> <div class="option-analysis"><strong>C.</strong> 在不同AWS Region中启动除Amazon RDS外所有组件的副本环境，在发生故障时从主Region复制并恢复最新RDS快照到DR Region，调整Route 53记录集指向DR Region中的ALB</div> <div class="option-analysis"><strong>D.</strong> 在不同AWS Region中启动除Amazon RDS外所有组件的副本环境，在新Region中创建RDS只读副本，配置新环境指向本地数据库实例，使用健康检查将新堆栈添加到Route 53记录集以配置故障转移路由策略，在发生故障时将只读副本提升为主库<div class="section-title"><strong>核心要求:</strong></div> 建立地理隔离的DR站点，满足RTO 4小时和RPO 15分钟要求 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• RDS Read Replica-提供跨Region数据复制和快速故障转移能力 </div><div class="compact-content">• Route 53 Failover Routing-实现自动DNS故障转移 </div><div class="compact-content">• Cross-Region部署-确保地理隔离 <div class="section-title"><strong>正确答案D:</strong></div> 跨Region部署+RDS只读副本+故障转移路由策略，只读副本可满足15分钟RPO，提升操作可在4小时RTO内完成，应用程序代码无需修改 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A-使用不同AZ而非Region，不满足地理隔离要求 </div><div class="compact-content">• 选项B-使用延迟路由策略而非故障转移策略，不适合DR场景 </div><div class="compact-content">• 选项C-依赖快照恢复无法满足15分钟RPO要求，恢复时间过长 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-RDS只读副本提供近实时数据同步满足RPO要求 </div><div class="compact-content">• 成本-预置DR环境成本较高但满足RTO要求 </div><div class="compact-content">• 可扩展性-跨Region架构提供最佳的地理隔离和扩展能力</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: D</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-108">
            <div class="question-header">
                <div class="question-title">Question #108 ✅ ⚪ <small style="float: right;">(108/353)</small></div>
            </div>
            <div class="question-content">A large enterprise is deploying a web application on AWS. The application runs on <span class="key-service">Amazon EC2</span> instances behind an Application Load Balancer. The instances run in an Auto Scaling group across multiple Availability Zones. The application stores data in an <span class="key-service">Amazon RDS</span> for Oracle DB instance and <span class="key-service">Amazon DynamoDB</span>. There are separate environments for development, testing, and production. What is the MOST secure and flexible way to obtain password credentials during deployment? B (100%)</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Retrieve an access key from an <span class="key-service">AWS Systems Manager</span> SecureString parameter to access AWS services. Retrieve the database credentials from a Systems Manager SecureString parameter.</div>                <div class="option correct-answer"><strong>B.</strong> Launch the EC2 instances with an EC2 IAM role to access AWS services. Retrieve the database credentials from AWS Secrets Manager.</div>                <div class="option"><strong>C.</strong> Retrieve an access key from an <span class="key-service">AWS Systems Manager</span> plaintext parameter to access AWS services. Retrieve the database credentials from a Systems Manager SecureString parameter.</div>                <div class="option"><strong>D.</strong> Launch the EC2 instances with an EC2 IAM role to access AWS services. Store the database passwords in an encrypted config file with the application artifacts.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家大型企业在AWS上部署Web应用程序。应用程序运行在Application Load Balancer后的Amazon EC2实例上。实例在Auto Scaling组中跨多个Availability Zone运行。应用程序将数据存储在Amazon RDS for Oracle数据库实例和Amazon DynamoDB中。有开发、测试和生产的独立环境。在部署期间获取密码凭证的最安全和最灵活的方式是什么？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 从AWS Systems Manager SecureString参数检索访问密钥来访问AWS服务，从Systems Manager SecureString参数检索数据库凭证</div> <div class="option-analysis"><strong>B.</strong> 使用EC2 IAM角色启动EC2实例来访问AWS服务，从AWS Secrets Manager检索数据库凭证</div> <div class="option-analysis"><strong>C.</strong> 从AWS Systems Manager明文参数检索访问密钥来访问AWS服务，从Systems Manager SecureString参数检索数据库凭证</div> <div class="option-analysis"><strong>D.</strong> 使用EC2 IAM角色启动EC2实例来访问AWS服务，将数据库密码存储在与应用程序工件一起的加密配置文件中<div class="section-title"><strong>核心要求:</strong></div> 为多环境Web应用程序部署提供最安全和最灵活的密码凭证获取方式 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• IAM Role-为EC2实例提供临时凭证，无需硬编码访问密钥 </div><div class="compact-content">• AWS Secrets Manager-专门管理数据库凭证，支持自动轮换和细粒度访问控制 <div class="section-title"><strong>正确答案B:</strong></div> 使用IAM Role避免访问密钥泄露风险，Secrets Manager提供数据库凭证的集中管理、自动轮换和跨环境灵活配置 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A-使用访问密钥存在泄露风险，不如IAM Role安全 </div><div class="compact-content">• 选项C-明文参数存储访问密钥极不安全，存在严重泄露风险 </div><div class="compact-content">• 选项D-加密配置文件缺乏自动轮换功能，管理复杂度高 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 安全性-IAM Role临时凭证优于静态访问密钥，Secrets Manager提供加密和访问控制 </div><div class="compact-content">• 灵活性-Secrets Manager支持跨环境配置和自动轮换，适应多环境需求 </div><div class="compact-content">• 可管理性-集中化凭证管理，避免硬编码和手动更新密码</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: B</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-109">
            <div class="question-header">
                <div class="question-title">Question #109 ✅ ⚪ <small style="float: right;">(109/353)</small></div>
            </div>
            <div class="question-content">The security team depends on <span class="key-service">AWS CloudTrail</span> to detect sensitive security issues in the company's AWS account. The DevOps engineer needs a solution to auto-remediate CloudTrail being turned off in an AWS account. What solution ensures the LEAST amount of downtime for the CloudTrail log deliveries? A (92%) 8%</div>
            <div class="options-container">                <div class="option correct-answer"><strong>A.</strong> Create an Amazon EventBridge rule for the CloudTrail StopLogging event. Create an <span class="key-service">AWS Lambda</span> function that uses the AWS SDK to call StartLogging on the ARN of the resource in which StopLogging was called. Add the Lambda function ARN as a target to the EventBridge rule.</div>                <div class="option"><strong>B.</strong> Deploy the AWS-managed CloudTrail-enabled <span class="key-service">AWS Config</span> rule, set with a periodic interval of 1 hour. Create an Amazon EventBridge rule for <span class="key-service">AWS Config</span> rules compliance change. Create an <span class="key-service">AWS Lambda</span> function that uses the AWS SDK to call StartLogging on the ARN of the resource in which StopLogging was called. Add the Lambda function ARN as a target to the EventBridge rule.</div>                <div class="option"><strong>C.</strong> Create an Amazon EventBridge rule for a scheduled event every 5 minutes. Create an <span class="key-service">AWS Lambda</span> function that uses the AWS SDK to call StartLogging on a CloudTrail trail in the AWS account. Add the Lambda function ARN as a target to the EventBridge rule.</div>                <div class="option"><strong>D.</strong> Launch a t2.nano instance with a script running every 5 minutes that uses the AWS SDK to query CloudTrail in the current account. If the CloudTrail trail is disabled, have the script re-enable the trail.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 安全团队依赖AWS CloudTrail来检测公司AWS账户中的敏感安全问题。DevOps工程师需要一个解决方案来自动修复AWS账户中CloudTrail被关闭的情况。什么解决方案能确保CloudTrail日志传输的停机时间最少？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 为CloudTrail StopLogging事件创建Amazon EventBridge规则。创建AWS Lambda函数，使用AWS SDK在调用StopLogging的资源ARN上调用StartLogging。将Lambda函数ARN作为目标添加到EventBridge规则中。</div> <div class="option-analysis"><strong>B.</strong> 部署AWS托管的CloudTrail-enabled AWS Config规则，设置1小时的周期间隔。为AWS Config规则合规性变更创建Amazon EventBridge规则。创建AWS Lambda函数，使用AWS SDK在调用StopLogging的资源ARN上调用StartLogging。将Lambda函数ARN作为目标添加到EventBridge规则中。</div> <div class="option-analysis"><strong>C.</strong> 创建每5分钟触发的Amazon EventBridge计划事件规则。创建AWS Lambda函数，使用AWS SDK在AWS账户中的CloudTrail trail上调用StartLogging。将Lambda函数ARN作为目标添加到EventBridge规则中。</div> <div class="option-analysis"><strong>D.</strong> 启动t2.nano实例，运行每5分钟执行的脚本，使用AWS SDK查询当前账户中的CloudTrail。如果CloudTrail trail被禁用，脚本重新启用trail。<div class="section-title"><strong>核心要求:</strong></div> 实现CloudTrail被关闭时的自动修复，确保最少停机时间 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• Amazon EventBridge-事件驱动的无服务器服务，用于应用程序集成 </div><div class="compact-content">• <span class="key-service">AWS Lambda</span>-无服务器计算服务，执行自动修复逻辑 </div><div class="compact-content">• <span class="key-service">AWS CloudTrail</span>-记录AWS API调用的审计服务 <div class="section-title"><strong>正确答案A:</strong></div> 使用EventBridge监听CloudTrail StopLogging事件，实时触发Lambda函数立即重新启用CloudTrail，实现零延迟的自动修复 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项B-依赖AWS Config周期性检查(1小时间隔)，检测延迟过长，无法满足最少停机时间要求 </div><div class="compact-content">• 选项C-使用定时触发(5分钟间隔)而非事件驱动，存在最多5分钟的检测延迟 </div><div class="compact-content">• 选项D-基于EC2实例的轮询方案，存在单点故障风险且有5分钟检测延迟，成本和可靠性都不佳 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-事件驱动架构提供实时响应，无检测延迟 </div><div class="compact-content">• 成本-无服务器架构按需付费，避免持续运行EC2实例成本 </div><div class="compact-content">• 可扩展性-EventBridge和Lambda自动扩展，无需管理基础设施</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: A</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-110">
            <div class="question-header">
                <div class="question-title">Question #110 ✅ 📝 <small style="float: right;">(110/353)</small></div>
            </div>
            <div class="question-content">A company uses AWS CodeArtifact to centrally store Python packages. The CodeArtifact repository is configured with the following repository policy: A development team is building a new project in an account that is in an organization in <span class="key-service">AWS Organizations</span>. The development team wants to use a Python library that has already been stored in the CodeArtifact repository in the organization. The development team uses <span class="key-service">AWS CodePipeline</span> and <span class="key-service">AWS CodeBuild</span> to build the new application. The CodeBuild job that the development team uses to build the application is configured to run in a <span class="key-service">VPC</span>. Because of compliance requirements, the <span class="key-service">VPC</span> has no internet connectivity. The development team creates the <span class="key-service">VPC</span> endpoints for CodeArtifact and updates the CodeBuild buildspec.yaml file. However, the development team cannot download the Python library from the repository. Which combination of steps should a DevOps engineer take so that the development team can use CodeArtifact? (Choose two.) BD (47%) AD (47%) 6%</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Create an <span class="key-service">Amazon S3</span> gateway endpoint. Update the route tables for the subnets that are running the CodeBuild job.</div>                <div class="option correct-answer"><strong>B.</strong> Update the repository policy's Principal statement to include the ARN of the role that the CodeBuild project uses.</div>                <div class="option"><strong>C.</strong> Share the CodeArtifact repository with the organization by using AWS Resource Access Manager (AWS RAM).</div>                <div class="option correct-answer"><strong>D.</strong> Update the role that the CodeBuild project uses so that the role has sufficient permissions to use the CodeArtifact repository.</div>                <div class="option"><strong>E.</strong> Specify the account that hosts the repository as the delegated administrator for CodeArtifact in the organization.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司使用AWS CodeArtifact集中存储Python包。CodeArtifact仓库配置了仓库策略。开发团队在AWS Organizations组织中的账户构建新项目，想要使用已存储在组织CodeArtifact仓库中的Python库。团队使用AWS CodePipeline和AWS CodeBuild构建应用程序。CodeBuild作业配置在VPC中运行。由于合规要求，VPC无互联网连接。开发团队创建了CodeArtifact的VPC端点并更新了CodeBuild buildspec.yaml文件，但无法从仓库下载Python库。DevOps工程师应采取哪些步骤组合使开发团队能够使用CodeArtifact？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 创建Amazon S3网关端点，更新运行CodeBuild作业的子网的路由表</div> <div class="option-analysis"><strong>B.</strong> 更新仓库策略的Principal语句以包含CodeBuild项目使用的角色ARN</div> <div class="option-analysis"><strong>C.</strong> 使用AWS Resource Access Manager (AWS RAM)与组织共享CodeArtifact仓库</div> <div class="option-analysis"><strong>D.</strong> 更新CodeBuild项目使用的角色，使该角色具有使用CodeArtifact仓库的足够权限</div> <div class="option-analysis"><strong>E.</strong> 指定托管仓库的账户作为组织中CodeArtifact的委托管理员<div class="section-title"><strong>核心要求:</strong></div> 解决跨账户CodeArtifact访问权限问题，使CodeBuild能在无互联网VPC中下载Python包 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• AWS CodeArtifact-集中式包管理服务，需要适当的仓库策略和IAM权限 </div><div class="compact-content">• <span class="key-service">AWS CodeBuild</span>-构建服务，需要IAM角色权限访问CodeArtifact </div><div class="compact-content">• VPC端点-在无互联网VPC中访问AWS服务的网络连接 <div class="section-title"><strong>正确答案BD:</strong></div> CodeArtifact跨账户访问需要双重权限配置：仓库策略必须允许特定Principal访问(B)，同时CodeBuild的IAM角色必须具有CodeArtifact操作权限(D) <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A-CodeArtifact通过接口端点访问，不需要S3网关端点 </div><div class="compact-content">• 选项C-组织内账户可直接配置仓库策略，无需RAM共享 </div><div class="compact-content">• 选项E-委托管理员用于组织级管理，不解决权限访问问题 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-VPC端点提供高性能私有连接 </div><div class="compact-content">• 成本-利用现有IAM和仓库策略，无额外服务成本 </div><div class="compact-content">• 可扩展性-权限配置支持组织内多账户访问模式</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: BD (B、D)</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-111">
            <div class="question-header">
                <div class="question-title">Question #111 ✅ ⚪ <small style="float: right;">(111/353)</small></div>
            </div>
            <div class="question-content">A company uses a series of individual Amazon CloudFormation templates to deploy its multi-Region applications. These templates must be deployed in a specific order. The company is making more changes to the templates than previously expected and wants to deploy new templates more efficiently. Additionally, the data engineering team must be notified of all changes to the templates. What should the company do to accomplish these goals? D (93%) 7%</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Create an <span class="key-service">AWS Lambda</span> function to deploy the CloudFormation templates in the required order. Use stack policies to alert the data engineering team.</div>                <div class="option correct-answer"><strong>B.</strong> Host the CloudFormation templates in <span class="key-service">Amazon S3</span>. Use <span class="key-service">Amazon S3</span> events to directly trigger CloudFormation updates and <span class="key-service">Amazon SNS</span> notifications.</div>                <div class="option"><strong>C.</strong> Implement CloudFormation StackSets and use drift detection to trigger update alerts to the data engineering team.</div>                <div class="option"><strong>D.</strong> Leverage CloudFormation nested stacks and stack sets for deployments. Use <span class="key-service">Amazon SNS</span> to notify the data engineering team.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司使用一系列独立的Amazon CloudFormation模板来部署其多区域应用程序。这些模板必须按特定顺序部署。公司对模板的更改比预期更频繁，希望更高效地部署新模板。此外，数据工程团队必须收到所有模板更改的通知。 <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 创建AWS Lambda函数按所需顺序部署CloudFormation模板。使用堆栈策略向数据工程团队发送警报。</div> <div class="option-analysis"><strong>B.</strong> 将CloudFormation模板托管在Amazon S3中。使用Amazon S3事件直接触发CloudFormation更新和Amazon SNS通知。</div> <div class="option-analysis"><strong>C.</strong> 实施CloudFormation StackSets并使用漂移检测触发向数据工程团队的更新警报。</div> <div class="option-analysis"><strong>D.</strong> 利用CloudFormation嵌套堆栈和堆栈集进行部署。使用Amazon SNS通知数据工程团队。<div class="section-title"><strong>核心要求:</strong></div> 实现多区域CloudFormation模板的有序高效部署和变更通知 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• <span class="key-service">Amazon S3</span>-提供模板存储和事件触发机制 </div><div class="compact-content">• <span class="key-service">Amazon SNS</span>-实现自动化通知功能 </div><div class="compact-content">• CloudFormation-基础设施即代码部署服务 <div class="section-title"><strong>正确答案B:</strong></div> S3事件驱动机制可自动触发模板更新和SNS通知，实现高效部署和实时通知 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A-Lambda函数增加复杂性，堆栈策略不是通知机制 </div><div class="compact-content">• 选项C-漂移检测用于配置偏移而非变更通知，StackSets不解决部署效率问题 </div><div class="compact-content">• 选项D-嵌套堆栈和堆栈集组合复杂，未解决自动化触发需求 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-S3事件触发提供实时响应和自动化部署 </div><div class="compact-content">• 成本-利用托管服务减少运维开销和自定义代码维护 </div><div class="compact-content">• 可扩展性-S3和SNS原生支持多区域和大规模部署场景</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: B</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-112">
            <div class="question-header">
                <div class="question-title">Question #112 ✅ ⚪ <small style="float: right;">(112/353)</small></div>
            </div>
            <div class="question-content">A DevOps engineer has implemented a CI/CD pipeline to deploy an <span class="key-service">AWS CloudFormation</span> template that provisions a web application. The web application consists of an Application Load Balancer (ALB), a target group, a launch template that uses an Amazon Linux 2 AMI, an Auto Scaling group of <span class="key-service">Amazon EC2</span> instances, a security group, and an <span class="key-service">Amazon RDS</span> for MySQL database. The launch template includes user data that specifies a script to install and start the application. The initial deployment of the application was successful. The DevOps engineer made changes to update the version of the application with the user data. The CI/CD pipeline has deployed a new version of the template. However, the health checks on the ALB are now failing. The health checks have marked all targets as unhealthy. During investigation, the DevOps engineer notices that the CloudFormation stack has a status of UPDATE_COMPLET<div class="option-analysis"><strong>E.</strong> However, when the DevOps engineer connects to one of the EC2 instances and checks /var/log/messages, the DevOps engineer notices that the Apache web server failed to start successfully because of a configuration error. How can the DevOps engineer ensure that the CloudFormation deployment will fail if the user data fails to successfully finish running? A (100%)</div></div>
            <div class="options-container">                <div class="option correct-answer"><strong>A.</strong> Use the cfn-signal helper script to signal success or failure to CloudFormation. Use the WaitOnResourceSignals update policy within the CloudFormation template. Set an appropriate timeout for the update policy. Most Voted</div>                <div class="option"><strong>B.</strong> Create an <span class="key-service">Amazon CloudWatch</span> alarm for the UnhealthyHostCount metric. Include an appropriate alarm threshold for the target group. Create an Amazon Simple Notification Service (<span class="key-service">Amazon SNS</span>) topic as the target to signal success or failure to CloudFormation.</div>                <div class="option"><strong>C.</strong> Create a lifecycle hook on the Auto Scaling group by using the AWS::AutoScaling::LifecycleHook resource. Create an Amazon Simple Notification Service (<span class="key-service">Amazon SNS</span>) topic as the target to signal success or failure to CloudFormation. Set an appropriate timeout on the lifecycle hook.</div>                <div class="option"><strong>D.</strong> Use the <span class="key-service">Amazon CloudWatch</span> agent to stream the cloud-init logs. Create a subscription filter that includes an <span class="key-service">AWS Lambda</span> function with an appropriate invocation timeout. Configure the Lambda function to use the SignalResource API operation to signal success or failure to CloudFormation.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一个DevOps工程师实施了CI/CD管道来部署AWS CloudFormation模板，该模板配置了一个Web应用程序。Web应用程序包含Application Load Balancer (ALB)、目标组、使用Amazon Linux 2 AMI的启动模板、EC2实例的Auto Scaling组、安全组和Amazon RDS for MySQL数据库。启动模板包含用户数据，指定安装和启动应用程序的脚本。应用程序的初始部署成功。DevOps工程师修改了用户数据以更新应用程序版本。CI/CD管道已部署新版本模板。但是，ALB上的健康检查现在失败，所有目标都被标记为不健康。调查期间，DevOps工程师注意到CloudFormation堆栈状态为UPDATE_COMPLETE。但是，当DevOps工程师连接到其中一个EC2实例并检查/var/log/messages时，发现Apache Web服务器由于配置错误未能成功启动。DevOps工程师如何确保在用户数据未能成功完成运行时CloudFormation部署会失败？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 使用cfn-signal辅助脚本向CloudFormation发送成功或失败信号。在CloudFormation模板中使用WaitOnResourceSignals更新策略。为更新策略设置适当的超时时间。</div> <div class="option-analysis"><strong>B.</strong> 为UnhealthyHostCount指标创建Amazon CloudWatch告警。为目标组包含适当的告警阈值。创建Amazon Simple Notification Service (<span class="key-service">Amazon SNS</span>)主题作为目标向CloudFormation发送成功或失败信号。</div> <div class="option-analysis"><strong>C.</strong> 通过使用AWS::AutoScaling::LifecycleHook资源在Auto Scaling组上创建生命周期钩子。创建Amazon Simple Notification Service (<span class="key-service">Amazon SNS</span>)主题作为目标向CloudFormation发送成功或失败信号。在生命周期钩子上设置适当的超时时间。</div> <div class="option-analysis"><strong>D.</strong> 使用Amazon CloudWatch代理流式传输cloud-init日志。创建包含具有适当调用超时的AWS Lambda函数的订阅过滤器。配置Lambda函数使用SignalResource API操作向CloudFormation发送成功或失败信号。<div class="section-title"><strong>核心要求:</strong></div> 确保CloudFormation在用户数据脚本执行失败时部署失败 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• CloudFormation - 基础设施即代码服务，需要接收用户数据执行状态信号 </div><div class="compact-content">• cfn-signal - CloudFormation辅助脚本，用于向CloudFormation发送资源创建成功或失败信号 </div><div class="compact-content">• WaitOnResourceSignals - CloudFormation更新策略，等待资源信号确认 <div class="section-title"><strong>正确答案A:</strong></div> 使用cfn-signal在用户数据脚本中发送执行状态信号，配合WaitOnResourceSignals策略让CloudFormation等待信号确认，脚本失败时CloudFormation部署也会失败 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项B - CloudWatch告警只能监控指标但无法直接影响CloudFormation部署状态 </div><div class="compact-content">• 选项C - 生命周期钩子用于Auto Scaling事件处理，无法检测用户数据脚本执行状态 </div><div class="compact-content">• 选项D - 过于复杂，通过日志分析间接检测不如直接信号机制可靠 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能 - cfn-signal提供实时直接的状态反馈机制 </div><div class="compact-content">• 成本 - 使用内置CloudFormation功能，无需额外服务成本 </div><div class="compact-content">• 可扩展性 - 标准CloudFormation模式，易于维护和扩展</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: A</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-113">
            <div class="question-header">
                <div class="question-title">Question #113 ✅ ⚪ <small style="float: right;">(113/353)</small></div>
            </div>
            <div class="question-content">A company has a data ingestion application that runs across multiple AWS accounts. The accounts are in an organization in <span class="key-service">AWS Organizations</span>. The company needs to monitor the application and consolidate access to the application. Currently, the company is running the application on <span class="key-service">Amazon EC2</span> instances from several Auto Scaling groups. The EC2 instances have no access to the internet because the data is sensitive. Engineers have deployed the necessary <span class="key-service">VPC</span> endpoints. The EC2 instances run a custom AMI that is built specifically for the application. To maintain and troubleshoot the application, system administrators need the ability to log in to the EC2 instances. This access must be automated and controlled centrally. The company's security team must receive a notification whenever the instances are accessed. Which solution will meet these requirements? C (100%)</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Create an Amazon EventBridge rule to send notifications to the security team whenever a user logs in to an EC2 instance. Use EC2 Instance Connect to log in to the instances. Deploy Auto Scaling groups by using <span class="key-service">AWS CloudFormation</span>. Use the cfn-init helper script to deploy appropriate <span class="key-service">VPC</span> routes for external access. Rebuild the custom AMI so that the custom AMI includes <span class="key-service">AWS Systems Manager</span> Agent.</div>                <div class="option"><strong>B.</strong> Deploy a NAT gateway and a bastion host that has internet access. Create a security group that allows incoming traffic on all the EC2 instances from the bastion host. Install <span class="key-service">AWS Systems Manager</span> Agent on all the EC2 instances. Use Auto Scaling group lifecycle hooks for monitoring and auditing access. Use Systems Manager Session Manager to log in to the instances. Send logs to a log group in <span class="key-service">Amazon CloudWatch</span> Logs. Export data to <span class="key-service">Amazon S3</span> for auditing. Send notifications to the security team by using S3 event notifications.</div>                <div class="option correct-answer"><strong>C.</strong> Use EC2 Image Builder to rebuild the custom AMI. Include the most recent version of <span class="key-service">AWS Systems Manager</span> Agent in the image. Configure the Auto Scaling group to attach the AmazonSSMManagedInstanceCore role to all the EC2 instances. Use Systems Manager Session Manager to log in to the instances. Enable logging of session details to <span class="key-service">Amazon S3</span>. Create an S3 event notification for new file uploads to send a message to the security team through an Amazon Simple Notification Service (<span class="key-service">Amazon SNS</span>) topic.</div>                <div class="option"><strong>D.</strong> Use <span class="key-service">AWS Systems Manager</span> Automation to build Systems Manager Agent into the custom AMI. Configure <span class="key-service">AWS Config</span> to attach an <span class="key-service">SCP</span> to the root organization account to allow the EC2 instances to connect to Systems Manager. Use Systems Manager Session Manager to log in to the instances. Enable logging of session details to <span class="key-service">Amazon S3</span>. Create an S3 event notification for new file uploads to send a message to the security team through an Amazon Simple Notification Service (<span class="key-service">Amazon SNS</span>) topic.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司有一个跨多个AWS账户运行的数据摄取应用程序，这些账户在AWS Organizations中。公司需要监控应用程序并整合对应用程序的访问。目前应用程序运行在多个Auto Scaling组的EC2实例上，由于数据敏感，EC2实例无法访问互联网，工程师已部署必要的VPC端点。EC2实例运行专门为应用程序构建的自定义AMI。为了维护和故障排除，系统管理员需要能够登录到EC2实例，此访问必须自动化并集中控制。公司安全团队必须在实例被访问时收到通知。 <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 创建Amazon EventBridge规则在用户登录EC2实例时向安全团队发送通知，使用EC2 Instance Connect登录实例，通过AWS CloudFormation部署Auto Scaling组，使用cfn-init辅助脚本部署适当的VPC路由以进行外部访问，重建自定义AMI以包含AWS Systems Manager Agent。</div> <div class="option-analysis"><strong>B.</strong> 部署NAT网关和具有互联网访问权限的堡垒主机，创建允许堡垒主机访问所有EC2实例的安全组，在所有EC2实例上安装AWS Systems Manager Agent，使用Auto Scaling组生命周期钩子进行监控和审计访问，使用Systems Manager Session Manager登录实例，将日志发送到CloudWatch Logs日志组，导出数据到S3进行审计，通过S3事件通知向安全团队发送通知。</div> <div class="option-analysis"><strong>C.</strong> 使用EC2 Image Builder重建自定义AMI并包含最新版本的AWS Systems Manager Agent，配置Auto Scaling组为所有EC2实例附加AmazonSSMManagedInstanceCore角色，使用Systems Manager Session Manager登录实例，启用会话详细信息记录到S3，创建S3事件通知通过Amazon SNS主题向安全团队发送新文件上传消息。</div> <div class="option-analysis"><strong>D.</strong> 使用AWS Systems Manager Automation将Systems Manager Agent构建到自定义AMI中，配置AWS Config将SCP附加到根组织账户以允许EC2实例连接到Systems Manager，使用Systems Manager Session Manager登录实例，启用会话详细信息记录到S3，创建S3事件通知通过Amazon SNS主题向安全团队发送新文件上传消息。<div class="section-title"><strong>核心要求:</strong></div> 为无互联网访问的EC2实例提供集中化、自动化的安全访问和监控解决方案 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• Systems Manager Session Manager-提供无需SSH密钥的安全实例访问 </div><div class="compact-content">• EC2 Image Builder-自动化AMI构建和更新流程 </div><div class="compact-content">• S3事件通知+SNS-实现访问审计和安全团队通知 <div class="section-title"><strong>正确答案C:</strong></div> 使用EC2 Image Builder确保AMI包含最新SSM Agent，通过IAM角色授权，Session Manager提供安全访问，S3记录会话日志，SNS实现通知机制，完全满足无互联网环境下的集中化访问控制要求 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A-EC2 Instance Connect需要互联网访问，与题目要求矛盾，且EventBridge规则配置复杂 </div><div class="compact-content">• 选项B-引入NAT网关和堡垒主机增加复杂性和成本，违背了无互联网访问的安全要求 </div><div class="compact-content">• 选项D-AWS Config和SCP配置错误，Config不用于附加SCP，且SCP不是实例连接SSM的正确方式 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-Session Manager提供低延迟的直接访问，无需额外网络跳转 </div><div class="compact-content">• 成本-避免NAT网关和堡垒主机的额外费用，使用托管服务降低运维成本 </div><div class="compact-content">• 可扩展性-EC2 Image Builder和Systems Manager可跨多账户自动化管理和扩展</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: C</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-114">
            <div class="question-header">
                <div class="question-title">Question #114 ✅ ⚪ <small style="float: right;">(114/353)</small></div>
            </div>
            <div class="question-content">A company uses <span class="key-service">Amazon S3</span> to store proprietary information. The development team creates buckets for new projects on a daily basis. The security team wants to ensure that all existing and future buckets have encryption, logging, and versioning enabled. Additionally, no buckets should ever be publicly read or write accessible. What should a DevOps engineer do to meet these requirements? B (100%)</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Enable <span class="key-service">AWS CloudTrail</span> and configure automatic remediation using <span class="key-service">AWS Lambda</span>.</div>                <div class="option correct-answer"><strong>B.</strong> Enable <span class="key-service">AWS Config</span> rules and configure automatic remediation using <span class="key-service">AWS Systems Manager</span> documents.</div>                <div class="option"><strong>C.</strong> Enable AWS Trusted Advisor and configure automatic remediation using Amazon EventBridge.</div>                <div class="option"><strong>D.</strong> Enable <span class="key-service">AWS Systems Manager</span> and configure automatic remediation using Systems Manager documents.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司使用Amazon S3存储专有信息。开发团队每天为新项目创建存储桶。安全团队希望确保所有现有和未来的存储桶都启用加密、日志记录和版本控制。此外，任何存储桶都不应具有公共读或写访问权限。DevOps工程师应该如何满足这些要求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 启用AWS CloudTrail并使用AWS Lambda配置自动修复</div> <div class="option-analysis"><strong>B.</strong> 启用AWS Config规则并使用AWS Systems Manager文档配置自动修复</div> <div class="option-analysis"><strong>C.</strong> 启用AWS Trusted Advisor并使用Amazon EventBridge配置自动修复</div> <div class="option-analysis"><strong>D.</strong> 启用AWS Systems Manager并使用Systems Manager文档配置自动修复<div class="section-title"><strong>核心要求:</strong></div> 确保所有S3存储桶的合规性配置并实现自动修复 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• <span class="key-service">AWS Config</span> - 监控资源配置合规性并触发修复操作 </div><div class="compact-content">• Systems Manager - 提供自动化文档执行配置修复 <div class="section-title"><strong>正确答案B:</strong></div> AWS Config规则可持续监控S3存储桶的加密、版本控制、日志记录和公共访问配置，当检测到不合规时自动触发Systems Manager文档执行修复操作 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A - CloudTrail主要用于API调用审计，不具备配置合规性监控和自动修复能力 </div><div class="compact-content">• 选项C - Trusted Advisor提供最佳实践建议但不支持自动修复功能 </div><div class="compact-content">• 选项D - 缺少Config规则来检测配置违规，无法触发自动修复流程 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能 - Config规则实时监控配置变更，及时发现违规 </div><div class="compact-content">• 成本 - 自动化修复减少人工干预成本和安全风险 </div><div class="compact-content">• 可扩展性 - 自动应用于所有现有和新创建的S3存储桶</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: B</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-115">
            <div class="question-header">
                <div class="question-title">Question #115 ✅ ⚪ <small style="float: right;">(115/353)</small></div>
            </div>
            <div class="question-content">A DevOps engineer is researching the least expensive way to implement an image batch processing cluster on AWS. The application cannot run in Docker containers and must run on <span class="key-service">Amazon EC2</span>. The batch job stores checkpoint data on an NFS volume and can tolerate interruptions. Configuring the cluster software from a generic EC2 Linux image takes 30 minutes. What is the MOST cost-effective solution? D (87%) C (9%)</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Use <span class="key-service">Amazon <span class="key-service">EFS</span></span> for checkpoint data. To complete the job, use an EC2 Auto Scaling group and an On-Demand pricing model to provision EC2 instances temporarily.</div>                <div class="option"><strong>B.</strong> Use GlusterFS on EC2 instances for checkpoint data. To run the batch job, configure EC2 instances manually. When the job completes, shut down the instances manually.</div>                <div class="option correct-answer"><strong>C.</strong> Use <span class="key-service">Amazon <span class="key-service">EFS</span></span> for checkpoint data. Use EC2 Fleet to launch EC2 Spot Instances, and utilize user data to configure the EC2 Linux instance on startup.</div>                <div class="option"><strong>D.</strong> Use <span class="key-service">Amazon <span class="key-service">EFS</span></span> for checkpoint data. Use EC2 Fleet to launch EC2 Spot Instances. Create a custom AMI for the cluster and use the latest AMI when creating instances.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一名DevOps工程师正在研究在AWS上实现图像批处理集群的最经济方式。应用程序无法在Docker容器中运行，必须在Amazon EC2上运行。批处理作业将检查点数据存储在NFS卷上，可以容忍中断。从通用EC2 Linux镜像配置集群软件需要30分钟。最具成本效益的解决方案是什么？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 使用Amazon EFS存储检查点数据。为完成作业，使用EC2 Auto Scaling组和On-Demand定价模式临时配置EC2实例。</div> <div class="option-analysis"><strong>B.</strong> 在EC2实例上使用GlusterFS存储检查点数据。运行批处理作业时手动配置EC2实例，作业完成后手动关闭实例。</div> <div class="option-analysis"><strong>C.</strong> 使用Amazon EFS存储检查点数据。使用EC2 Fleet启动EC2 Spot实例，并利用用户数据在启动时配置EC2 Linux实例。</div> <div class="option-analysis"><strong>D.</strong> 使用Amazon EFS存储检查点数据。使用EC2 Fleet启动EC2 Spot实例。为集群创建自定义AMI，在创建实例时使用最新AMI。<div class="section-title"><strong>核心要求:</strong></div> 实现最经济的图像批处理集群，支持中断容忍和NFS存储 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• <span class="key-service">Amazon <span class="key-service">EFS</span></span>-提供托管NFS文件系统，支持多实例并发访问 </div><div class="compact-content">• EC2 Spot实例-提供最高90%折扣的可中断计算资源 </div><div class="compact-content">• EC2 Fleet-自动化管理多个Spot实例的启动和配置 <div class="section-title"><strong>正确答案C:</strong></div> 使用EFS提供NFS存储，EC2 Fleet管理Spot实例降低成本，用户数据脚本自动配置避免额外AMI维护成本 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A-使用On-Demand实例成本比Spot实例高很多，不符合最经济要求 </div><div class="compact-content">• 选项B-手动管理实例缺乏自动化，GlusterFS需要额外配置和维护成本 </div><div class="compact-content">• 选项D-创建和维护自定义AMI增加存储成本，且需要定期更新维护 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-EFS提供高可用NFS存储，EC2 Fleet确保实例可用性 </div><div class="compact-content">• 成本-Spot实例最大化成本节约，用户数据避免AMI存储费用 </div><div class="compact-content">• 可扩展性-EC2 Fleet自动管理实例生命周期，支持动态扩缩容</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: C</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-116">
            <div class="question-header">
                <div class="question-title">Question #116 ✅ ⚪ <small style="float: right;">(116/353)</small></div>
            </div>
            <div class="question-content">A company recently migrated its legacy application from on-premises to AWS. The application is hosted on <span class="key-service">Amazon EC2</span> instances behind an Application Load Balancer, which is behind <span class="key-service">Amazon API Gateway</span>. The company wants to ensure users experience minimal disruptions during any deployment of a new version of the application. The company also wants to ensure it can quickly roll back updates if there is an issue. Which solution will meet these requirements with MINIMAL changes to the application? A (83%) Other</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Introduce changes as a separate environment parallel to the existing one. Configure API Gateway to use a canary release deployment to send a small subset of user traffic to the new environment.</div>                <div class="option"><strong>B.</strong> Introduce changes as a separate environment parallel to the existing one. Update the application's DNS alias records to point to the new environment.</div>                <div class="option correct-answer"><strong>C.</strong> Introduce changes as a separate target group behind the existing Application Load Balancer. Configure API Gateway to route user traffic to the new target group in steps.</div>                <div class="option"><strong>D.</strong> Introduce changes as a separate target group behind the existing Application Load Balancer. Configure API Gateway to route all traffic to the Application Load Balancer, which then sends the traffic to the new target group.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司最近将其遗留应用从本地迁移到AWS。应用托管在Application Load Balancer后的Amazon EC2实例上，Application Load Balancer位于Amazon API Gateway后面。公司希望确保用户在部署新版本应用时体验到最小的中断。公司还希望确保在出现问题时能够快速回滚更新。哪种解决方案能以最小的应用更改满足这些要求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 将更改作为与现有环境并行的独立环境引入。配置API Gateway使用金丝雀发布部署将一小部分用户流量发送到新环境。</div> <div class="option-analysis"><strong>B.</strong> 将更改作为与现有环境并行的独立环境引入。更新应用的DNS别名记录以指向新环境。</div> <div class="option-analysis"><strong>C.</strong> 将更改作为现有Application Load Balancer后的独立目标组引入。配置API Gateway分步将用户流量路由到新目标组。</div> <div class="option-analysis"><strong>D.</strong> 将更改作为现有Application Load Balancer后的独立目标组引入。配置API Gateway将所有流量路由到Application Load Balancer，然后将流量发送到新目标组。<div class="section-title"><strong>核心要求:</strong></div> 实现零停机部署和快速回滚能力，同时最小化应用更改 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• API Gateway-提供流量路由和部署控制能力 </div><div class="compact-content">• Application Load Balancer-支持多目标组的流量分发 </div><div class="compact-content">• Target Group-实现应用版本隔离和渐进式部署 <div class="section-title"><strong>正确答案C:</strong></div> 利用现有ALB基础设施创建新目标组，通过API Gateway实现渐进式流量切换，既保持架构简单又支持快速回滚 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A-创建完全独立环境增加复杂性和成本，不符合最小更改要求 </div><div class="compact-content">• 选项B-DNS更改传播时间长，无法实现快速回滚 </div><div class="compact-content">• 选项D-描述了正常的负载均衡行为，未提供渐进式部署机制 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-利用现有ALB避免额外网络跳转 </div><div class="compact-content">• 成本-复用现有基础设施，无需重复环境 </div><div class="compact-content">• 可扩展性-目标组方式支持灵活的流量分配策略</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: C</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-117">
            <div class="question-header">
                <div class="question-title">Question #117 ✅ 📝 <small style="float: right;">(117/353)</small></div>
            </div>
            <div class="question-content">A company is storing 100 GB of log data in .csv format in an <span class="key-service">Amazon S3</span> bucket. SQL developers want to query this data and generate graphs to visualize it. The SQL developers also need an efficient, automated way to store metadata from the .csv file. Which combination of steps will meet these requirements with the LEAST amount of effort? (Choose three.) BCE (100%)</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Filter the data through AWS X-Ray to visualize the data.</div>                <div class="option correct-answer"><strong>B.</strong> Filter the data through Amazon QuickSight to visualize the data.</div>                <div class="option correct-answer"><strong>C.</strong> Query the data with Amazon Athena.</div>                <div class="option"><strong>D.</strong> Query the data with Amazon Redshift.</div>                <div class="option correct-answer"><strong>E.</strong> Use the AWS Glue Data Catalog as the persistent metadata store. F. Use <span class="key-service">Amazon DynamoDB</span> as the persistent metadata store.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司在Amazon S3存储桶中以.csv格式存储了100GB的日志数据。SQL开发人员希望查询这些数据并生成图表进行可视化。SQL开发人员还需要一种高效的自动化方式来存储.csv文件的元数据。哪种步骤组合能以最少的工作量满足这些要求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 通过AWS X-Ray过滤数据以可视化数据</div> <div class="option-analysis"><strong>B.</strong> 通过Amazon QuickSight过滤数据以可视化数据</div> <div class="option-analysis"><strong>C.</strong> 使用Amazon Athena查询数据</div> <div class="option-analysis"><strong>D.</strong> 使用Amazon Redshift查询数据</div> <div class="option-analysis"><strong>E.</strong> 使用AWS Glue Data Catalog作为持久化元数据存储 F. 使用Amazon DynamoDB作为持久化元数据存储<div class="section-title"><strong>核心要求:</strong></div> 对S3中CSV数据进行SQL查询、可视化和自动化元数据管理 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• Amazon Athena-无服务器SQL查询引擎，直接查询S3数据 </div><div class="compact-content">• Amazon QuickSight-商业智能服务，生成图表和可视化 </div><div class="compact-content">• AWS Glue Data Catalog-自动发现和存储数据元数据 <div class="section-title"><strong>正确答案BCE:</strong></div> Athena提供无服务器SQL查询能力直接访问S3数据，QuickSight提供强大的数据可视化和图表生成功能，Glue Data Catalog自动爬取和管理CSV文件元数据，三者集成度高且无需额外基础设施 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A-X-Ray是应用程序性能监控服务，不提供数据可视化功能 </div><div class="compact-content">• 选项D-Redshift需要数据加载和集群管理，增加复杂性和成本 </div><div class="compact-content">• 选项F-DynamoDB需要手动管理元数据，缺乏自动化能力 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-Athena无服务器架构提供按需查询能力 </div><div class="compact-content">• 成本-按查询付费模式，无需预置资源 </div><div class="compact-content">• 可扩展性-服务完全托管，自动处理扩展需求</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: BCE (B、C、E)</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-118">
            <div class="question-header">
                <div class="question-title">Question #118 ✅ 📝 <small style="float: right;">(118/353)</small></div>
            </div>
            <div class="question-content">A company deploys its corporate infrastructure on AWS across multiple AWS Regions and Availability Zones. The infrastructure is deployed on <span class="key-service">Amazon EC2</span> instances and connects with AWS IoT Greengrass devices. The company deploys additional resources on on-premises servers that are located in the corporate headquarters. The company wants to reduce the overhead involved in maintaining and updating its resources. The company's DevOps team plans to use <span class="key-service">AWS Systems Manager</span> to implement automated management and application of patches. The DevOps team confirms that Systems Manager is available in the Regions that the resources are deployed in. Systems Manager also is available in a Region near the corporate headquarters. Which combination of steps must the DevOps team take to implement automated patch and configuration management across the company's EC2 instances, IoT devices, and on-premises infrastructure? (Choose three.) CEF (100%)</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Apply tags to all the EC2 instances, AWS IoT Greengrass devices, and on-premises servers. Use Systems Manager Session Manager to push patches to all the tagged devices.</div>                <div class="option correct-answer"><strong>B.</strong> Use Systems Manager Run Command to schedule patching for the EC2 instances, AWS IoT Greengrass devices, and on-premises servers.</div>                <div class="option correct-answer"><strong>C.</strong> Use Systems Manager Patch Manager to schedule patching for the EC2 instances, AWS IoT Greengrass devices, and on-premises servers as a Systems Manager maintenance window task.</div>                <div class="option"><strong>D.</strong> Configure Amazon EventBridge to monitor Systems Manager Patch Manager for updates to patch baselines. Associate Systems Manager Run Command with the event to initiate a patch action for all EC2 instances, AWS IoT Greengrass devices, and on-premises servers.</div>                <div class="option"><strong>E.</strong> Create an IAM instance profile for Systems Manager. Attach the instance profile to all the EC2 instances in the AWS account. For the AWS IoT Greengrass devices and on-premises servers, create an IAM service role for Systems Manager. F. Generate a managed-instance activation. Use the Activation Code and Activation ID to install Systems Manager Agent (SSM Agent) on each server in the on-premises environment. Update the AWS IoT Greengrass IAM token exchange role. Use the role to deploy SSM Agent on all the IoT devices. Most Voted</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司在多个AWS区域和可用区部署企业基础设施，包括EC2实例和AWS IoT Greengrass设备，还有本地服务器。公司希望减少维护和更新资源的开销，DevOps团队计划使用AWS Systems Manager实现自动化补丁管理。需要选择三个步骤来实现跨EC2实例、IoT设备和本地基础设施的自动化补丁和配置管理。 <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 对所有EC2实例、AWS IoT Greengrass设备和本地服务器应用标签，使用Systems Manager Session Manager向所有标记的设备推送补丁</div> <div class="option-analysis"><strong>B.</strong> 使用Systems Manager Run Command为EC2实例、AWS IoT Greengrass设备和本地服务器安排补丁计划</div> <div class="option-analysis"><strong>C.</strong> 使用Systems Manager Patch Manager作为Systems Manager维护窗口任务，为EC2实例、AWS IoT Greengrass设备和本地服务器安排补丁计划</div> <div class="option-analysis"><strong>D.</strong> 配置Amazon EventBridge监控Systems Manager Patch Manager的补丁基线更新，将Systems Manager Run Command与事件关联以启动所有设备的补丁操作</div> <div class="option-analysis"><strong>E.</strong> 为Systems Manager创建IAM实例配置文件并附加到所有EC2实例，为AWS IoT Greengrass设备和本地服务器创建IAM服务角色 F. 生成托管实例激活，使用激活代码和ID在本地环境安装SSM Agent，更新AWS IoT Greengrass IAM令牌交换角色以在IoT设备上部署SSM Agent<div class="section-title"><strong>核心要求:</strong></div> 实现跨混合环境的自动化补丁和配置管理 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• Systems Manager Patch Manager-提供自动化补丁管理和维护窗口功能 </div><div class="compact-content">• Systems Manager Run Command-执行远程命令和补丁部署操作 <div class="section-title"><strong>正确答案BC:</strong></div> Run Command提供补丁执行能力，Patch Manager提供补丁调度和维护窗口管理，两者结合实现完整的自动化补丁管理流程 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A-Session Manager用于交互式会话而非自动化补丁推送 </div><div class="compact-content">• 选项D-EventBridge监控补丁基线更新过于复杂且非标准做法 </div><div class="compact-content">• 选项E-仅涉及权限配置，缺少实际补丁管理功能 </div><div class="compact-content">• 选项F-仅涉及Agent安装，未包含补丁管理实现 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-Run Command和Patch Manager提供高效的批量补丁管理 </div><div class="compact-content">• 成本-使用原生Systems Manager服务避免额外组件成本 </div><div class="compact-content">• 可扩展性-支持跨区域和混合环境的统一补丁管理</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: BC (B、C)</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-119">
            <div class="question-header">
                <div class="question-title">Question #119 ✅ ⚪ <small style="float: right;">(119/353)</small></div>
            </div>
            <div class="question-content">A company is testing a web application that runs on <span class="key-service">Amazon EC2</span> instances behind an Application Load Balancer. The instances run in an Auto Scaling group across multiple Availability Zones. The company uses a blue/green deployment process with immutable instances when deploying new software. During testing, users are being automatically logged out of the application at random times. Testers also report that, when a new version of the application is deployed, all users are logged out. The development team needs a solution to ensure users remain logged in across scaling events and application deployments. What is the MOST operationally efficient way to ensure users remain logged in? D (100%)</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Enable smart sessions on the load balancer and modify the application to check for an existing session.</div>                <div class="option"><strong>B.</strong> Enable session sharing on the load balancer and modify the application to read from the session store.</div>                <div class="option"><strong>C.</strong> Store user session information in an <span class="key-service">Amazon S3</span> bucket and modify the application to read session information from the bucket.</div>                <div class="option correct-answer"><strong>D.</strong> Modify the application to store user session information in an Amazon ElastiCache cluster.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司正在测试运行在Application Load Balancer后面Amazon EC2实例上的Web应用程序。实例在跨多个Availability Zone的Auto Scaling组中运行。公司在部署新软件时使用蓝/绿部署流程和不可变实例。测试期间，用户随机被自动登出应用程序。测试人员还报告，当部署新版本应用程序时，所有用户都被登出。开发团队需要一个解决方案来确保用户在扩展事件和应用程序部署期间保持登录状态。确保用户保持登录的最具运营效率的方法是什么？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 在负载均衡器上启用智能会话并修改应用程序以检查现有会话</div> <div class="option-analysis"><strong>B.</strong> 在负载均衡器上启用会话共享并修改应用程序从会话存储中读取</div> <div class="option-analysis"><strong>C.</strong> 将用户会话信息存储在Amazon S3存储桶中并修改应用程序从存储桶读取会话信息</div> <div class="option-analysis"><strong>D.</strong> 修改应用程序将用户会话信息存储在Amazon ElastiCache集群中<div class="section-title"><strong>核心要求:</strong></div> 解决蓝/绿部署和Auto Scaling导致的用户会话丢失问题 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• ElastiCache-提供高性能内存缓存用于会话存储 </div><div class="compact-content">• Application Load Balancer-支持粘性会话但不适用于不可变实例部署 <div class="section-title"><strong>正确答案D:</strong></div> 使用ElastiCache作为外部会话存储，实现会话数据与EC2实例解耦，支持高并发访问和亚毫秒级延迟 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A-Application Load Balancer没有"智能会话"功能 </div><div class="compact-content">• 选项B-Application Load Balancer没有内置"会话共享"功能 </div><div class="compact-content">• 选项C-S3不适合频繁的会话读写操作，延迟高且成本不优 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-ElastiCache提供亚毫秒级访问延迟，最适合会话存储 </div><div class="compact-content">• 成本-ElastiCache按使用量计费，比S3频繁访问更经济 </div><div class="compact-content">• 可扩展性-ElastiCache支持集群模式，可随应用负载自动扩展</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: D</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-120">
            <div class="question-header">
                <div class="question-title">Question #120 ✅ ⚪ <small style="float: right;">(120/353)</small></div>
            </div>
            <div class="question-content">A DevOps engineer needs to configure a blue/green deployment for an existing three-tier application. The application runs on <span class="key-service">Amazon EC2</span> instances and uses an <span class="key-service">Amazon RDS</span> database. The EC2 instances run behind an Application Load Balancer (ALB) and are in an Auto Scaling group. The DevOps engineer has created a launch template and an Auto Scaling group for the blue environment. The DevOps engineer also has created a launch template and an Auto Scaling group for the green environment. Each Auto Scaling group deploys to a matching blue or green target group. The target group also specifies which software, blue or green, gets loaded on the EC2 instances. The ALB can be configured to send traffic to the blue environment's target group or the green environment's target group. An <span class="key-service">Amazon Route 53</span> record for www.example.com points to the AL<div class="option-analysis"><strong>B.</strong> The deployment must move traffic all at once between the software on the blue environment's EC2 instances to the newly deployed software on the green environment's EC2 instances. What should the DevOps engineer do to meet these requirements? A (100%)</div></div>
            <div class="options-container">                <div class="option correct-answer"><strong>A.</strong> Start a rolling restart of the Auto Scaling group for the green environment to deploy the new software on the green environment's EC2 instances. When the rolling restart is complete, use an AWS CLI command to update the ALB to send traffic to the green environment's target group.</div>                <div class="option"><strong>B.</strong> Use an AWS CLI command to update the ALB to send traffic to the green environment's target group. Then start a rolling restart of the Auto Scaling group for the green environment to deploy the new software on the green environment's EC2 instances.</div>                <div class="option"><strong>C.</strong> Update the launch template to deploy the green environment's software on the blue environment's EC2 instances. Keep the target groups and Auto Scaling groups unchanged in both environments. Perform a rolling restart of the blue environment's EC2 instances.</div>                <div class="option"><strong>D.</strong> Start a rolling restart of the Auto Scaling group for the green environment to deploy the new software on the green environment's EC2 instances. When the rolling restart is complete, update the Route 53 DNS to point to the green environment's endpoint on the ALB.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一名DevOps工程师需要为现有的三层应用程序配置蓝/绿部署。应用程序运行在Amazon EC2实例上并使用Amazon RDS数据库。EC2实例运行在Application Load Balancer (ALB)后面并位于Auto Scaling组中。DevOps工程师已为蓝环境创建了启动模板和Auto Scaling组，也为绿环境创建了启动模板和Auto Scaling组。每个Auto Scaling组部署到匹配的蓝色或绿色目标组。目标组还指定在EC2实例上加载哪个软件（蓝色或绿色）。ALB可以配置为将流量发送到蓝环境或绿环境的目标组。Amazon Route 53记录www.example.com指向ALB。部署必须一次性将流量从蓝环境EC2实例上的软件切换到绿环境EC2实例上新部署的软件。 <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 启动绿环境Auto Scaling组的滚动重启以在绿环境的EC2实例上部署新软件。当滚动重启完成后，使用AWS CLI命令更新ALB将流量发送到绿环境的目标组。</div> <div class="option-analysis"><strong>B.</strong> 使用AWS CLI命令更新ALB将流量发送到绿环境的目标组。然后启动绿环境Auto Scaling组的滚动重启以在绿环境的EC2实例上部署新软件。</div> <div class="option-analysis"><strong>C.</strong> 更新启动模板以在蓝环境的EC2实例上部署绿环境的软件。保持两个环境中的目标组和Auto Scaling组不变。对蓝环境的EC2实例执行滚动重启。</div> <div class="option-analysis"><strong>D.</strong> 启动绿环境Auto Scaling组的滚动重启以在绿环境的EC2实例上部署新软件。当滚动重启完成后，更新Route 53 DNS指向ALB上的绿环境端点。<div class="section-title"><strong>核心要求:</strong></div> 实现蓝/绿部署的一次性流量切换，确保新软件部署完成后再进行流量切换 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• Auto Scaling Group-管理EC2实例的自动扩缩和滚动更新 </div><div class="compact-content">• Application Load Balancer-在蓝绿环境间进行流量路由切换 </div><div class="compact-content">• Target Group-定义不同环境的实例组和软件版本 <div class="section-title"><strong>正确答案A:</strong></div> 先完成绿环境的软件部署和实例准备，确保新版本完全就绪后再通过ALB进行瞬时流量切换，符合蓝/绿部署的零停机要求 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项B-先切换流量再部署软件会导致用户访问到未准备好的实例，造成服务中断 </div><div class="compact-content">• 选项C-在蓝环境中滚动更新违背了蓝/绿部署的原理，无法实现一次性切换 </div><div class="compact-content">• 选项D-Route 53 DNS更新有传播延迟，无法实现题目要求的"一次性"流量切换 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-确保新环境完全就绪后再切换，避免服务中断 </div><div class="compact-content">• 成本-利用现有ALB进行瞬时切换，无需额外DNS传播时间 </div><div class="compact-content">• 可扩展性-保持蓝绿环境独立，支持快速回滚和未来部署</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: A</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-121">
            <div class="question-header">
                <div class="question-title">Question #121 ✅ 📝 <small style="float: right;">(121/353)</small></div>
            </div>
            <div class="question-content">A company is building a new pipeline by using <span class="key-service">AWS CodePipeline</span> and <span class="key-service">AWS CodeBuild</span> in a build account. The pipeline consists of two stages. The first stage is a CodeBuild job to build and package an <span class="key-service">AWS Lambda</span> function. The second stage consists of deployment actions that operate on two different AWS accounts: a development environment account and a production environment account. The deployment stages use the <span class="key-service">AWS CloudFormation</span> action that CodePipeline invokes to deploy the infrastructure that the Lambda function requires. A DevOps engineer creates the CodePipeline pipeline and configures the pipeline to encrypt build artifacts by using the AWS Key Management Service (AWS KMS) AWS managed key for <span class="key-service">Amazon S3</span> (the aws/s3 key). The artifacts are stored in an S3 bucket. When the pipeline runs, the CloudFormation actions fail with an access denied error. Which combination of actions must the DevOps engineer perform to resolve this error? (Choose two.) BE (83%) Other</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Create an S3 bucket in each AWS account for the artifacts. Allow the pipeline to write to the S3 buckets. Create a CodePipeline S3 action to copy the artifacts to the S3 bucket in each AWS account. Update the CloudFormation actions to reference the artifacts S3 bucket in the production account.</div>                <div class="option correct-answer"><strong>B.</strong> Create a customer managed KMS key. Configure the KMS key policy to allow the IAM roles used by the CloudFormation action to perform decrypt operations. Modify the pipeline to use the customer managed KMS key to encrypt artifacts. Most Voted</div>                <div class="option"><strong>C.</strong> Create an AWS managed KMS key. Configure the KMS key policy to allow the development account and the production account to perform decrypt operations. Modify the pipeline to use the KMS key to encrypt artifacts.</div>                <div class="option correct-answer"><strong>D.</strong> In the development account and in the production account, create an IAM role for CodePipeline. Configure the roles with permissions to perform CloudFormation operations and with permissions to retrieve and decrypt objects from the artifacts S3 bucket. In the CodePipeline account, configure the CodePipeline CloudFormation action to use the roles.</div>                <div class="option"><strong>E.</strong> In the development account and in the production account, create an IAM role for CodePipeline. Configure the roles with permissions to perform CloudFormation operations and with permissions to retrieve and decrypt objects from the artifacts S3 bucket. In the CodePipeline account, modify the artifacts S3 bucket policy to allow the roles access. Configure the CodePipeline CloudFormation action to use the roles.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司正在使用AWS CodePipeline和AWS CodeBuild在构建账户中建立新的管道。管道包含两个阶段：第一阶段是CodeBuild作业来构建和打包AWS Lambda函数；第二阶段包含在两个不同AWS账户（开发环境账户和生产环境账户）上操作的部署操作。部署阶段使用CodePipeline调用的AWS CloudFormation操作来部署Lambda函数所需的基础设施。DevOps工程师创建了CodePipeline管道并配置管道使用AWS Key Management Service (AWS KMS) AWS托管密钥for <span class="key-service">Amazon S3</span> (aws/s3密钥)来加密构建工件。工件存储在S3存储桶中。当管道运行时，CloudFormation操作失败并出现访问拒绝错误。DevOps工程师必须执行哪些操作组合来解决此错误？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 在每个AWS账户中为工件创建S3存储桶，允许管道写入S3存储桶，创建CodePipeline S3操作将工件复制到每个AWS账户的S3存储桶，更新CloudFormation操作以引用生产账户中的工件S3存储桶。</div> <div class="option-analysis"><strong>B.</strong> 创建客户托管的KMS密钥，配置KMS密钥策略以允许CloudFormation操作使用的IAM角色执行解密操作，修改管道以使用客户托管的KMS密钥来加密工件。</div> <div class="option-analysis"><strong>C.</strong> 创建AWS托管的KMS密钥，配置KMS密钥策略以允许开发账户和生产账户执行解密操作，修改管道以使用KMS密钥来加密工件。</div> <div class="option-analysis"><strong>D.</strong> 在开发账户和生产账户中为CodePipeline创建IAM角色，配置角色具有执行CloudFormation操作的权限以及从工件S3存储桶检索和解密对象的权限，在CodePipeline账户中配置CodePipeline CloudFormation操作以使用这些角色。<div class="section-title"><strong>核心要求:</strong></div> 解决跨账户CodePipeline部署中的KMS加密工件访问权限问题 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• AWS KMS - 管理加密密钥和跨账户访问权限 </div><div class="compact-content">• CodePipeline - 跨账户部署需要适当的IAM角色配置 </div><div class="compact-content">• CloudFormation - 需要解密工件的权限来执行部署 <div class="section-title"><strong>正确答案BD:</strong></div> B选项创建客户托管KMS密钥并配置策略允许跨账户解密访问，D选项在目标账户创建具有适当权限的IAM角色供CodePipeline使用，两者结合解决了跨账户KMS访问和IAM权限问题 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A - 不必要地复制工件到多个存储桶，未解决根本的KMS权限问题 </div><div class="compact-content">• 选项C - AWS托管密钥策略无法修改，不能配置跨账户访问权限 </div><div class="compact-content">• 选项E - 缺少CodePipeline账户的配置步骤，仅修改S3存储桶策略不足以解决KMS权限问题 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能 - 使用客户托管KMS密钥提供更好的跨账户访问控制 </div><div class="compact-content">• 成本 - 客户托管密钥成本略高但提供必要的灵活性 </div><div class="compact-content">• 可扩展性 - 跨账户IAM角色配置支持多环境部署扩展</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: BD (B、D)</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-122">
            <div class="question-header">
                <div class="question-title">Question #122 ✅ 📝 <small style="float: right;">(122/353)</small></div>
            </div>
            <div class="question-content">A company is using an organization in <span class="key-service">AWS Organizations</span> to manage multiple AWS accounts. The company's development team wants to use <span class="key-service">AWS Lambda</span> functions to meet resiliency requirements and is rewriting all applications to work with Lambda functions that are deployed in a <span class="key-service">VPC</span>. The development team is using Amazon Elastic File System (<span class="key-service">Amazon <span class="key-service">EFS</span></span>) as shared storage in Account A in the organization. The company wants to continue to use <span class="key-service">Amazon <span class="key-service">EFS</span></span> with Lambda. Company policy requires all serverless projects to be deployed in Account <div class="option-analysis"><strong>B.</strong> A DevOps engineer needs to reconfigure an existing <span class="key-service">EFS</span> file system to allow Lambda functions to access the data through an existing <span class="key-service">EFS</span> access point. Which combination of steps should the DevOps engineer take to meet these requirements? (Choose three.) ADE (71%) AEF (21%) 8%</div></div>
            <div class="options-container">                <div class="option correct-answer"><strong>A.</strong> Update the <span class="key-service">EFS</span> file system policy to provide Account B with access to mount and write to the <span class="key-service">EFS</span> file system in Account A.</div>                <div class="option"><strong>B.</strong> Create SCPs to set permission guardrails with fine-grained control for <span class="key-service">Amazon <span class="key-service">EFS</span></span>.</div>                <div class="option correct-answer"><strong>C.</strong> Create a new <span class="key-service">EFS</span> file system in Account <div class="option-analysis"><strong>B.</strong> Use AWS Database Migration Service (<span class="key-service">AWS <span class="key-service">DMS</span></span>) to keep data from Account A and Account B synchronized.</div></div>                <div class="option"><strong>D.</strong> Update the Lambda execution roles with permission to access the <span class="key-service">VPC</span> and the <span class="key-service">EFS</span> file system.</div>                <div class="option correct-answer"><strong>E.</strong> Create a <span class="key-service"><span class="key-service">VPC</span> peering</span> connection to connect Account A to Account <div class="option-analysis"><strong>B.</strong> F. Configure the Lambda functions in Account B to assume an existing IAM role in Account A.</div></div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司使用AWS Organizations管理多个AWS账户。开发团队想使用Lambda函数满足弹性要求，正在重写所有应用以使用部署在VPC中的Lambda函数。开发团队在组织的账户A中使用Amazon EFS作为共享存储。公司希望继续在Lambda中使用Amazon <span class="key-service">EFS</span>。公司政策要求所有无服务器项目部署在账户B中。DevOps工程师需要重新配置现有EFS文件系统，允许Lambda函数通过现有EFS访问点访问数据。 <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 更新EFS文件系统策略，为账户B提供挂载和写入账户A中EFS文件系统的访问权限</div> <div class="option-analysis"><strong>B.</strong> 创建SCP来设置权限护栏，对Amazon EFS进行细粒度控制</div> <div class="option-analysis"><strong>C.</strong> 在账户B中创建新的EFS文件系统，使用AWS DMS保持账户A和账户B的数据同步</div> <div class="option-analysis"><strong>D.</strong> 更新Lambda执行角色，添加访问VPC和EFS文件系统的权限</div> <div class="option-analysis"><strong>E.</strong> 创建VPC对等连接，连接账户A到账户B F. 配置账户B中的Lambda函数承担账户A中的现有IAM角色<div class="section-title"><strong>核心要求:</strong></div> 实现跨账户Lambda函数访问EFS文件系统的配置 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• <span class="key-service">Amazon <span class="key-service">EFS</span></span> - 提供跨账户共享文件存储 </div><div class="compact-content">• <span class="key-service">AWS Lambda</span> - 在VPC中运行的无服务器计算 </div><div class="compact-content">• <span class="key-service"><span class="key-service">VPC</span> Peering</span> - 实现跨账户网络连接 <div class="section-title"><strong>正确答案ACE:</strong></div> 通过EFS文件系统策略授权跨账户访问，在目标账户创建新EFS并使用DMS同步数据，建立VPC对等连接实现网络互通 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项B - SCP用于组织级权限控制，不解决跨账户EFS访问问题 </div><div class="compact-content">• 选项D - Lambda执行角色权限配置不足以解决跨账户访问和网络连接问题 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能 - VPC对等连接提供低延迟跨账户网络访问 </div><div class="compact-content">• 成本 - 利用现有EFS资源，避免重复存储成本 </div><div class="compact-content">• 可扩展性 - 跨账户架构支持组织级资源管理和扩展</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: ACE (A、C、E)</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-123">
            <div class="question-header">
                <div class="question-title">Question #123 ✅ ⚪ <small style="float: right;">(123/353)</small></div>
            </div>
            <div class="question-content">A media company has several thousand <span class="key-service">Amazon EC2</span> instances in an AWS account. The company is using Slack and a shared email inbox for team communications and important updates. A DevOps engineer needs to send all AWS-scheduled EC2 maintenance notifications to the Slack channel and the shared inbox. The solution must include the instances' Name and Owner tags. Which solution will meet these requirements? B (100%)</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Integrate AWS Trusted Advisor with <span class="key-service">AWS Config</span>. Configure a custom <span class="key-service">AWS Config</span> rule to invoke an <span class="key-service">AWS Lambda</span> function to publish notifications to an Amazon Simple Notification Service (<span class="key-service">Amazon SNS</span>) topic. Subscribe a Slack channel endpoint and the shared inbox to the topic.</div>                <div class="option correct-answer"><strong>B.</strong> Use Amazon EventBridge to monitor for AWS Health events. Configure the maintenance events to target an Amazon Simple Notification Service (<span class="key-service">Amazon SNS</span>) topic. Subscribe an <span class="key-service">AWS Lambda</span> function to the SNS topic to send notifications to the Slack channel and the shared inbox.</div>                <div class="option"><strong>C.</strong> Create an <span class="key-service">AWS Lambda</span> function that sends EC2 maintenance notifications to the Slack channel and the shared inbox. Monitor EC2 health events by using <span class="key-service">Amazon CloudWatch</span> metrics. Configure a CloudWatch alarm that invokes the Lambda function when a maintenance notification is received.</div>                <div class="option"><strong>D.</strong> Configure AWS Support integration with <span class="key-service">AWS CloudTrail</span>. Create a CloudTrail lookup event to invoke an <span class="key-service">AWS Lambda</span> function to pass EC2 maintenance notifications to Amazon Simple Notification Service (<span class="key-service">Amazon SNS</span>). Configure <span class="key-service">Amazon SNS</span> to target the Slack channel and the shared inbox.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家媒体公司在AWS账户中有数千个Amazon EC2实例。公司使用Slack和共享邮箱进行团队沟通和重要更新。DevOps工程师需要将所有AWS计划的EC2维护通知发送到Slack频道和共享邮箱。解决方案必须包含实例的Name和Owner标签。 <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 将AWS Trusted Advisor与AWS Config集成。配置自定义AWS Config规则调用AWS Lambda函数将通知发布到Amazon SNS主题。将Slack频道端点和共享邮箱订阅该主题。</div> <div class="option-analysis"><strong>B.</strong> 使用Amazon EventBridge监控AWS Health事件。配置维护事件目标为Amazon SNS主题。订阅AWS Lambda函数到SNS主题以发送通知到Slack频道和共享邮箱。</div> <div class="option-analysis"><strong>C.</strong> 创建AWS Lambda函数发送EC2维护通知到Slack频道和共享邮箱。使用Amazon CloudWatch指标监控EC2健康事件。配置CloudWatch告警在收到维护通知时调用Lambda函数。</div> <div class="option-analysis"><strong>D.</strong> 配置AWS Support与AWS CloudTrail集成。创建CloudTrail查找事件调用AWS Lambda函数将EC2维护通知传递给Amazon SNS。配置Amazon SNS目标为Slack频道和共享邮箱。<div class="section-title"><strong>核心要求:</strong></div> 自动捕获AWS计划的EC2维护通知并发送到多个通信渠道 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• AWS Health - 提供AWS服务健康状态和计划维护事件信息 </div><div class="compact-content">• Amazon EventBridge - 事件驱动架构服务，可监控和路由AWS Health事件 </div><div class="compact-content">• <span class="key-service">Amazon SNS</span> - 消息通知服务，支持多种订阅端点 <div class="section-title"><strong>正确答案B:</strong></div> EventBridge原生支持AWS Health事件监控，可直接捕获EC2维护通知并通过SNS分发到多个目标，Lambda函数可获取实例标签信息并格式化通知内容 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A - Trusted Advisor和Config主要用于合规性检查，不是维护通知的正确事件源 </div><div class="compact-content">• 选项C - CloudWatch指标无法直接监控AWS计划维护事件，缺乏事件驱动机制 </div><div class="compact-content">• 选项D - CloudTrail记录API调用日志，不是AWS Health维护事件的合适监控方式 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能 - EventBridge提供实时事件处理和自动路由 </div><div class="compact-content">• 成本 - 事件驱动架构避免持续轮询，降低运营成本 </div><div class="compact-content">• 可扩展性 - SNS支持多种订阅类型，易于扩展到更多通知渠道</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: B</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-124">
            <div class="question-header">
                <div class="question-title">Question #124 ✅ ⚪ <small style="float: right;">(124/353)</small></div>
            </div>
            <div class="question-content">An <span class="key-service">AWS CodePipeline</span> pipeline has implemented a code release process. The pipeline is integrated with <span class="key-service">AWS CodeDeploy</span> to deploy versions of an application to multiple <span class="key-service">Amazon EC2</span> instances for each CodePipeline stage. During a recent deployment, the pipeline failed due to a CodeDeploy issue. The DevOps team wants to improve monitoring and notifications during deployment to decrease resolution times. What should the DevOps engineer do to create notifications when issues are discovered? B (100%)</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Implement <span class="key-service">Amazon CloudWatch</span> Logs for CodePipeline and CodeDeploy, create an <span class="key-service">AWS Config</span> rule to evaluate code deployment issues, and create an Amazon Simple Notification Service (<span class="key-service">Amazon SNS</span>) topic to notify stakeholders of deployment issues.</div>                <div class="option correct-answer"><strong>B.</strong> Implement Amazon EventBridge for CodePipeline and CodeDeploy, create an <span class="key-service">AWS Lambda</span> function to evaluate code deployment issues, and create an Amazon Simple Notification Service (<span class="key-service">Amazon SNS</span>) topic to notify stakeholders of deployment issues.</div>                <div class="option"><strong>C.</strong> Implement <span class="key-service">AWS CloudTrail</span> to record CodePipeline and CodeDeploy API call information, create an <span class="key-service">AWS Lambda</span> function to evaluate code deployment issues, and create an Amazon Simple Notification Service (<span class="key-service">Amazon SNS</span>) topic to notify stakeholders of deployment issues.</div>                <div class="option"><strong>D.</strong> Implement Amazon EventBridge for CodePipeline and CodeDeploy, create an Amazon Inspector assessment target to evaluate code deployment issues, and create an Amazon Simple Notification Service (<span class="key-service">Amazon SNS</span>) topic to notify stakeholders of deployment issues.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一个AWS CodePipeline流水线实现了代码发布流程。该流水线与AWS CodeDeploy集成，为每个CodePipeline阶段将应用程序版本部署到多个Amazon EC2实例。在最近的部署中，流水线因CodeDeploy问题而失败。DevOps团队希望改进部署期间的监控和通知以缩短解决时间。DevOps工程师应该如何创建发现问题时的通知？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 为CodePipeline和CodeDeploy实施Amazon CloudWatch Logs，创建AWS Config规则来评估代码部署问题，并创建Amazon Simple Notification Service (<span class="key-service">Amazon SNS</span>)主题来通知利益相关者部署问题。</div> <div class="option-analysis"><strong>B.</strong> 为CodePipeline和CodeDeploy实施Amazon EventBridge，创建AWS Lambda函数来评估代码部署问题，并创建Amazon Simple Notification Service (<span class="key-service">Amazon SNS</span>)主题来通知利益相关者部署问题。</div> <div class="option-analysis"><strong>C.</strong> 实施AWS CloudTrail记录CodePipeline和CodeDeploy API调用信息，创建AWS Lambda函数来评估代码部署问题，并创建Amazon Simple Notification Service (<span class="key-service">Amazon SNS</span>)主题来通知利益相关者部署问题。</div> <div class="option-analysis"><strong>D.</strong> 为CodePipeline和CodeDeploy实施Amazon EventBridge，创建Amazon Inspector评估目标来评估代码部署问题，并创建Amazon Simple Notification Service (<span class="key-service">Amazon SNS</span>)主题来通知利益相关者部署问题。<div class="section-title"><strong>核心要求:</strong></div> 为CodePipeline和CodeDeploy部署失败创建实时监控和通知机制 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• Amazon EventBridge-捕获CodePipeline和CodeDeploy状态变化事件 </div><div class="compact-content">• <span class="key-service">AWS Lambda</span>-处理事件并执行自定义逻辑评估部署问题 </div><div class="compact-content">• <span class="key-service">Amazon SNS</span>-发送通知给利益相关者 <div class="section-title"><strong>正确答案B:</strong></div> EventBridge原生集成CodePipeline/CodeDeploy事件，Lambda提供灵活的问题评估逻辑，SNS实现多渠道通知，形成完整的事件驱动监控方案 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A-CloudWatch Logs主要用于日志存储，AWS Config用于资源配置合规性检查，不适合实时部署事件监控 </div><div class="compact-content">• 选项C-CloudTrail记录API调用审计信息，不是实时事件监控的最佳选择，延迟较高 </div><div class="compact-content">• 选项D-Amazon Inspector用于安全漏洞评估，不是用于部署问题评估的正确服务 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-EventBridge提供实时事件处理，响应速度快 </div><div class="compact-content">• 成本-事件驱动架构按需付费，成本效益高 </div><div class="compact-content">• 可扩展性-EventBridge和Lambda自动扩展，支持大规模部署监控</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: B</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-125">
            <div class="question-header">
                <div class="question-title">Question #125 ✅ ⚪ <small style="float: right;">(125/353)</small></div>
            </div>
            <div class="question-content">A global company manages multiple AWS accounts by using AWS Control Tower. The company hosts internal applications and public applications. Each application team in the company has its own AWS account for application hosting. The accounts are consolidated in an organization in <span class="key-service">AWS Organizations</span>. One of the AWS Control Tower member accounts serves as a centralized DevOps account with CI/CD pipelines that application teams use to deploy applications to their respective target AWS accounts. An IAM role for deployment exists in the centralized DevOps account. An application team is attempting to deploy its application to an Amazon Elastic Kubernetes Service (<span class="key-service">Amazon EKS</span>) cluster in an application AWS account. An IAM role for deployment exists in the application AWS account. The deployment is through an <span class="key-service">AWS CodeBuild</span> project that is set up in the centralized DevOps account. The CodeBuild project uses an IAM service role for CodeBuild. The deployment is failing with an Unauthorized error during attempts to connect to the cross-account EKS cluster from CodeBuild. Which solution will resolve this error? A (100%)</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Configure the application account's deployment IAM role to have a trust relationship with the centralized DevOps account. Configure the trust relationship to allow the sts:AssumeRole action. Configure the application account's deployment IAM role to have the required access to the EKS cluster. Configure the EKS cluster aws-auth ConfigMap to map the role to the appropriate system permissions.</div>                <div class="option correct-answer"><strong>B.</strong> Configure the centralized DevOps account's deployment IAM role to have a trust relationship with the application account. Configure the trust relationship to allow the sts:AssumeRole action. Configure the centralized DevOps account's deployment IAM role to allow the required access to CodeBuild.</div>                <div class="option"><strong>C.</strong> Configure the centralized DevOps account's deployment IAM role to have a trust relationship with the application account. Configure the trust relationship to allow the sts:AssumeRoleWithSAML action. Configure the centralized DevOps account's deployment IAM role to allow the required access to CodeBuild.</div>                <div class="option"><strong>D.</strong> Configure the application account's deployment IAM role to have a trust relationship with the AWS Control Tower management account. Configure the trust relationship to allow the sts:AssumeRole action. Configure the application account's deployment IAM role to have the required access to the EKS cluster. Configure the EKS cluster aws-auth ConfigMap to map the role to the appropriate system permissions.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家全球公司使用AWS Control Tower管理多个AWS账户。公司托管内部应用和公共应用。每个应用团队都有自己的AWS账户用于应用托管。账户在AWS Organizations中的组织里合并。其中一个AWS Control Tower成员账户作为集中式DevOps账户，包含CI/CD管道供应用团队部署应用到各自的目标AWS账户。集中式DevOps账户中存在用于部署的IAM角色。应用团队尝试将应用部署到应用AWS账户中的Amazon EKS集群。应用AWS账户中存在用于部署的IAM角色。部署通过在集中式DevOps账户中设置的AWS CodeBuild项目进行。CodeBuild项目使用CodeBuild的IAM服务角色。从CodeBuild尝试连接到跨账户EKS集群时，部署失败并出现未授权错误。 <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 配置应用账户的部署IAM角色与集中式DevOps账户建立信任关系，配置信任关系允许sts:AssumeRole操作，配置应用账户的部署IAM角色具有EKS集群所需访问权限，配置EKS集群aws-auth ConfigMap将角色映射到适当的系统权限。</div> <div class="option-analysis"><strong>B.</strong> 配置集中式DevOps账户的部署IAM角色与应用账户建立信任关系，配置信任关系允许sts:AssumeRole操作，配置集中式DevOps账户的部署IAM角色允许CodeBuild所需访问权限。</div> <div class="option-analysis"><strong>C.</strong> 配置集中式DevOps账户的部署IAM角色与应用账户建立信任关系，配置信任关系允许sts:AssumeRoleWithSAML操作，配置集中式DevOps账户的部署IAM角色允许CodeBuild所需访问权限。</div> <div class="option-analysis"><strong>D.</strong> 配置应用账户的部署IAM角色与AWS Control Tower管理账户建立信任关系，配置信任关系允许sts:AssumeRole操作，配置应用账户的部署IAM角色具有EKS集群所需访问权限，配置EKS集群aws-auth ConfigMap将角色映射到适当的系统权限。<div class="section-title"><strong>核心要求:</strong></div> 解决CodeBuild跨账户访问EKS集群的未授权错误 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• <span class="key-service">AWS CodeBuild</span>-执行部署任务的CI/CD服务 </div><div class="compact-content">• <span class="key-service">Amazon EKS</span>-目标Kubernetes集群服务 </div><div class="compact-content">• IAM-跨账户角色权限管理 <div class="section-title"><strong>正确答案B:</strong></div> 建立从DevOps账户到应用账户的信任关系，允许CodeBuild服务角色assume应用账户的部署角色来访问EKS集群 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A-信任关系方向错误，应用账户角色无法被DevOps账户的CodeBuild直接使用 </div><div class="compact-content">• 选项C-使用错误的SAML assume操作，应使用标准的AssumeRole </div><div class="compact-content">• 选项D-涉及不必要的Control Tower管理账户，增加复杂性且不符合最小权限原则 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-直接的跨账户角色切换，减少中间环节 </div><div class="compact-content">• 成本-使用现有IAM功能，无额外服务费用 </div><div class="compact-content">• 可扩展性-标准的跨账户访问模式，易于复制到其他应用团队</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: B</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-126">
            <div class="question-header">
                <div class="question-title">Question #126 ✅ ⚪ <small style="float: right;">(126/353)</small></div>
            </div>
            <div class="question-content">A highly regulated company has a policy that DevOps engineers should not log in to their <span class="key-service">Amazon EC2</span> instances except in emergencies. If a DevOps engineer does log in, the security team must be notified within 15 minutes of the occurrence. Which solution will meet these requirements? B (94%) 6%</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Install the Amazon Inspector agent on each EC2 instance. Subscribe to Amazon EventBridge notifications. Invoke an <span class="key-service">AWS Lambda</span> function to check if a message is about user logins. If it is, send a notification to the security team using <span class="key-service">Amazon SNS</span>.</div>                <div class="option correct-answer"><strong>B.</strong> Install the <span class="key-service">Amazon CloudWatch</span> agent on each EC2 instance. Configure the agent to push all logs to <span class="key-service">Amazon CloudWatch</span> Logs and set up a CloudWatch metric filter that searches for user logins. If a login is found, send a notification to the security team using <span class="key-service">Amazon SNS</span>.</div>                <div class="option"><strong>C.</strong> Set up <span class="key-service">AWS CloudTrail</span> with <span class="key-service">Amazon CloudWatch</span> Logs. Subscribe CloudWatch Logs to Amazon Kinesis. Attach <span class="key-service">AWS Lambda</span> to Kinesis to parse and determine if a log contains a user login. If it does, send a notification to the security team using <span class="key-service">Amazon SNS</span>.</div>                <div class="option"><strong>D.</strong> Set up a script on each <span class="key-service">Amazon EC2</span> instance to push all logs to <span class="key-service">Amazon S3</span>. Set up an S3 event to invoke an <span class="key-service">AWS Lambda</span> function, which invokes an Amazon Athena query to run. The Athena query checks for logins and sends the output to the security team using <span class="key-service">Amazon SNS</span>.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家高度监管的公司有政策规定DevOps工程师除紧急情况外不应登录其Amazon EC2实例。如果DevOps工程师确实登录了，安全团队必须在事件发生后15分钟内收到通知。哪个解决方案能满足这些要求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 在每个EC2实例上安装Amazon Inspector代理，订阅Amazon EventBridge通知，调用AWS Lambda函数检查消息是否关于用户登录，如果是则使用Amazon SNS向安全团队发送通知。</div> <div class="option-analysis"><strong>B.</strong> 在每个EC2实例上安装Amazon CloudWatch代理，配置代理将所有日志推送到Amazon CloudWatch Logs并设置CloudWatch指标过滤器搜索用户登录，如果发现登录则使用Amazon SNS向安全团队发送通知。</div> <div class="option-analysis"><strong>C.</strong> 设置AWS CloudTrail与Amazon CloudWatch Logs，将CloudWatch Logs订阅到Amazon Kinesis，将AWS Lambda附加到Kinesis来解析并确定日志是否包含用户登录，如果包含则使用Amazon SNS向安全团队发送通知。</div> <div class="option-analysis"><strong>D.</strong> 在每个Amazon EC2实例上设置脚本将所有日志推送到Amazon S3，设置S3事件调用AWS Lambda函数来调用Amazon Athena查询，Athena查询检查登录并使用Amazon SNS将输出发送给安全团队。<div class="section-title"><strong>核心要求:</strong></div> 监控EC2实例用户登录并在15分钟内实时通知安全团队 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• CloudWatch Agent-收集实例系统日志并推送到CloudWatch Logs </div><div class="compact-content">• CloudWatch Logs-集中存储和实时监控日志数据 </div><div class="compact-content">• CloudWatch Metric Filter-实时搜索日志中的特定模式并触发告警 <div class="section-title"><strong>正确答案B:</strong></div> CloudWatch Agent收集系统登录日志推送到CloudWatch Logs，Metric Filter实时检测登录事件并通过SNS立即通知，满足15分钟内通知要求 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A-Inspector主要用于安全漏洞评估，不监控用户登录活动，且EventBridge不直接处理登录日志 </div><div class="compact-content">• 选项C-CloudTrail记录API调用而非实例内用户登录，且通过Kinesis增加了不必要的复杂性和延迟 </div><div class="compact-content">• 选项D-基于S3的批处理方式无法满足15分钟实时通知要求，Athena查询存在明显延迟 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-CloudWatch实时日志处理和Metric Filter即时触发确保快速响应 </div><div class="compact-content">• 成本-直接的CloudWatch监控方案避免了额外的数据流转和处理成本 </div><div class="compact-content">• 可扩展性-CloudWatch原生支持大规模EC2实例监控且配置简单统一</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: B</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-127">
            <div class="question-header">
                <div class="question-title">Question #127 ✅ 📝 <small style="float: right;">(127/353)</small></div>
            </div>
            <div class="question-content">A company updated the <span class="key-service">AWS CloudFormation</span> template for a critical business application. The stack update process failed due to an error in the updated template, and <span class="key-service">AWS CloudFormation</span> automatically began the stack rollback process. Later, a DevOps engineer discovered that the application was still unavailable and that the stack was in the UPDATE_ROLLBACK_FAILED state. Which combination of actions should the DevOps engineer perform so that the stack rollback can complete successfully? (Choose two.) CD (100%)</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Attach the AWSCloudFormationFullAccess IAM policy to the <span class="key-service">AWS CloudFormation</span> role.</div>                <div class="option"><strong>B.</strong> Automatically recover the stack resources by using <span class="key-service">AWS CloudFormation</span> drift detection.</div>                <div class="option correct-answer"><strong>C.</strong> Issue a ContinueUpdateRollback command from the <span class="key-service">AWS CloudFormation</span> console or the AWS CLI.</div>                <div class="option correct-answer"><strong>D.</strong> Manually adjust the resources to match the expectations of the stack.</div>                <div class="option"><strong>E.</strong> Update the existing <span class="key-service">AWS CloudFormation</span> stack by using the original template.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司更新了关键业务应用的AWS CloudFormation模板。由于更新模板中的错误，堆栈更新过程失败，AWS CloudFormation自动开始堆栈回滚过程。后来，DevOps工程师发现应用程序仍然不可用，堆栈处于UPDATE_ROLLBACK_FAILED状态。DevOps工程师应该执行哪些操作组合，以便堆栈回滚能够成功完成？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 将AWSCloudFormationFullAccess IAM策略附加到AWS CloudFormation角色</div> <div class="option-analysis"><strong>B.</strong> 使用AWS CloudFormation漂移检测自动恢复堆栈资源</div> <div class="option-analysis"><strong>C.</strong> 从AWS CloudFormation控制台或AWS CLI发出ContinueUpdateRollback命令</div> <div class="option-analysis"><strong>D.</strong> 手动调整资源以匹配堆栈的期望状态</div> <div class="option-analysis"><strong>E.</strong> 使用原始模板更新现有的AWS CloudFormation堆栈<div class="section-title"><strong>核心要求:</strong></div> 解决CloudFormation堆栈处于UPDATE_ROLLBACK_FAILED状态的问题 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• <span class="key-service">AWS CloudFormation</span> - 基础设施即代码服务，管理AWS资源的生命周期 </div><div class="compact-content">• ContinueUpdateRollback - CloudFormation命令，用于继续失败的回滚操作 <div class="section-title"><strong>正确答案CD:</strong></div> 当堆栈回滚失败时，需要先手动修复导致回滚失败的资源状态问题(D)，然后使用ContinueUpdateRollback命令继续完成回滚过程(C) <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A - 权限问题通常不是回滚失败的根本原因，且过度授权存在安全风险 </div><div class="compact-content">• 选项B - 漂移检测只能发现配置差异，无法自动修复回滚失败状态 </div><div class="compact-content">• 选项E - 在回滚失败状态下无法直接进行堆栈更新操作 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能 - 快速恢复应用程序可用性，避免长时间服务中断 </div><div class="compact-content">• 成本 - 避免资源长期处于不一致状态导致的额外费用 </div><div class="compact-content">• 可扩展性 - 建立标准的回滚失败处理流程，适用于未来类似问题</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: CD (C、D)</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-128">
            <div class="question-header">
                <div class="question-title">Question #128 ✅ 📝 <small style="float: right;">(128/353)</small></div>
            </div>
            <div class="question-content">A development team manually builds an artifact locally and then places it in an <span class="key-service">Amazon S3</span> bucket. The application has a local cache that must be cleared when a deployment occurs. The team runs a command to do this, downloads the artifact from <span class="key-service">Amazon S3</span>, and unzips the artifact to complete the deployment. A DevOps team wants to migrate to a CI/CD process and build in checks to stop and roll back the deployment when a failure occurs. This requires the team to track the progression of the deployment. Which combination of actions will accomplish this? (Choose three.) BDE (100%)</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Allow developers to check the code into a code repository. Using Amazon EventBridge, on every pull into the main branch, invoke an <span class="key-service">AWS Lambda</span> function to build the artifact and store it in <span class="key-service">Amazon S3</span>.</div>                <div class="option correct-answer"><strong>B.</strong> Create a custom script to clear the cache. Specify the script in the BeforeInstall lifecycle hook in the AppSpec file.</div>                <div class="option"><strong>C.</strong> Create user data for each <span class="key-service">Amazon EC2</span> instance that contains the clear cache script. Once deployed, test the application. If it is not successful, deploy it again.</div>                <div class="option correct-answer"><strong>D.</strong> Set up <span class="key-service">AWS CodePipeline</span> to deploy the application. Allow developers to check the code into a code repository as a source for the pipeline.</div>                <div class="option correct-answer"><strong>E.</strong> Use <span class="key-service">AWS CodeBuild</span> to build the artifact and place it in <span class="key-service">Amazon S3</span>. Use <span class="key-service">AWS CodeDeploy</span> to deploy the artifact to <span class="key-service">Amazon EC2</span> instances. F. Use <span class="key-service">AWS Systems Manager</span> to fetch the artifact from <span class="key-service">Amazon S3</span> and deploy it to all the instances.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 开发团队手动在本地构建制品并放入Amazon S3存储桶。应用程序有本地缓存，部署时必须清除。团队运行命令清除缓存，从Amazon S3下载制品并解压完成部署。DevOps团队希望迁移到CI/CD流程，并在失败时构建检查以停止和回滚部署。这需要团队跟踪部署进度。哪些操作组合能实现此目标？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 允许开发人员将代码检入代码仓库。使用Amazon EventBridge，在每次拉取到主分支时，调用AWS Lambda函数构建制品并存储到Amazon S3。</div> <div class="option-analysis"><strong>B.</strong> 创建自定义脚本清除缓存。在AppSpec文件的BeforeInstall生命周期钩子中指定该脚本。</div> <div class="option-analysis"><strong>C.</strong> 为每个Amazon EC2实例创建包含清除缓存脚本的用户数据。部署后测试应用程序。如果不成功，重新部署。</div> <div class="option-analysis"><strong>D.</strong> 设置AWS CodePipeline部署应用程序。允许开发人员将代码检入代码仓库作为管道源。</div> <div class="option-analysis"><strong>E.</strong> 使用AWS CodeBuild构建制品并放入Amazon S3。使用AWS CodeDeploy将制品部署到Amazon EC2实例。 F. 使用AWS Systems Manager从Amazon S3获取制品并部署到所有实例。<div class="section-title"><strong>核心要求:</strong></div> 建立完整的CI/CD流程，支持部署跟踪、失败检查和回滚机制 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• <span class="key-service">AWS CodePipeline</span>-提供端到端CI/CD编排和部署进度跟踪 </div><div class="compact-content">• <span class="key-service">AWS CodeBuild</span>-自动化构建制品替代手动构建 </div><div class="compact-content">• <span class="key-service">AWS CodeDeploy</span>-提供部署生命周期管理、失败检查和自动回滚 <div class="section-title"><strong>正确答案BDE:</strong></div> CodePipeline提供CI/CD编排和跟踪，CodeBuild自动化构建，CodeDeploy管理部署生命周期，BeforeInstall钩子确保缓存清除时机正确 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A-EventBridge+Lambda方案缺乏完整的CI/CD编排和部署跟踪能力 </div><div class="compact-content">• 选项C-用户数据方案无法提供失败检查和自动回滚机制 </div><div class="compact-content">• 选项F-Systems Manager缺乏CodeDeploy的生命周期管理和回滚功能 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-自动化构建部署流程，消除手动操作延迟 </div><div class="compact-content">• 成本-使用托管服务减少运维开销，按需付费模式 </div><div class="compact-content">• 可扩展性-CodePipeline支持多环境部署和复杂工作流编排</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: BDE (B、D、E)</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-129">
            <div class="question-header">
                <div class="question-title">Question #129 ✅ 📝 <small style="float: right;">(129/353)</small></div>
            </div>
            <div class="question-content">A DevOps engineer is working on a project that is hosted on Amazon Linux and has failed a security review. The DevOps manager has been asked to review the company buildspec.yaml file for an <span class="key-service">AWS CodeBuild</span> project and provide recommendations. The buildspec.yaml file is configured as follows: What changes should be recommended to comply with AWS security best practices? (Choose three.) BCE (76%) ABC (24%)</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Add a post-build command to remove the temporary files from the container before termination to ensure they cannot be seen by other CodeBuild users.</div>                <div class="option correct-answer"><strong>B.</strong> Update the CodeBuild project role with the necessary permissions and then remove the AWS credentials from the environment variable.</div>                <div class="option correct-answer"><strong>C.</strong> Store the DB_PASSWORD as a SecureString value in <span class="key-service">AWS Systems Manager</span> Parameter Store and then remove the DB_PASSWORD from the environment variables.</div>                <div class="option"><strong>D.</strong> Move the environment variables to the 'db-deploy-bucket' <span class="key-service">Amazon S3</span> bucket, add a prebuild stage to download, then export the variables.</div>                <div class="option correct-answer"><strong>E.</strong> Use <span class="key-service">AWS Systems Manager</span> run command versus <span class="key-service">scp</span> and ssh commands directly to the instance. F. Scramble the environment variables using XOR followed by Base64, add a section to install, and then run XOR and Base64 to the build phase.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一名DevOps工程师正在处理一个托管在Amazon Linux上的项目，该项目未通过安全审查。DevOps经理被要求审查公司的buildspec.yaml文件（用于AWS CodeBuild项目）并提供建议。应该推荐哪些更改来符合AWS安全最佳实践？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 添加构建后命令，在容器终止前删除临时文件，确保其他CodeBuild用户无法看到这些文件</div> <div class="option-analysis"><strong>B.</strong> 更新CodeBuild项目角色的必要权限，然后从环境变量中删除AWS凭证</div> <div class="option-analysis"><strong>C.</strong> 将DB_PASSWORD作为SecureString值存储在AWS Systems Manager Parameter Store中，然后从环境变量中删除DB_PASSWORD</div> <div class="option-analysis"><strong>D.</strong> 将环境变量移动到'db-deploy-bucket' Amazon S3存储桶，添加预构建阶段下载然后导出变量</div> <div class="option-analysis"><strong>E.</strong> 使用AWS Systems Manager run command而不是直接使用scp和ssh命令连接实例 F. 使用XOR加Base64对环境变量进行加扰，添加安装部分，然后在构建阶段运行XOR和Base64<div class="section-title"><strong>核心要求:</strong></div> 改进CodeBuild项目的安全配置以符合AWS安全最佳实践 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• <span class="key-service">AWS CodeBuild</span> - 托管构建服务，需要安全的凭证管理 </div><div class="compact-content">• <span class="key-service">AWS Systems Manager</span> Parameter Store - 安全存储敏感配置参数 </div><div class="compact-content">• <span class="key-service">AWS Systems Manager</span> Run Command - 安全的远程命令执行 <div class="section-title"><strong>正确答案BCE:</strong></div> B选项使用IAM角色而非硬编码凭证，C选项将敏感数据存储在Parameter Store中加密保护，E选项使用AWS托管服务替代不安全的SSH连接 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A - 临时文件清理不是主要安全问题，CodeBuild容器本身是隔离的 </div><div class="compact-content">• 选项D - 将凭证存储在S3中仍然不安全，且增加了复杂性 </div><div class="compact-content">• 选项F - 自定义加密方案不如AWS托管的安全服务可靠 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 安全性 - 使用IAM角色、Parameter Store加密存储、AWS托管服务 </div><div class="compact-content">• 可维护性 - 避免硬编码凭证和自定义加密方案 </div><div class="compact-content">• <span class="key-point">合规性</span> - 遵循AWS安全最佳实践和行业标准</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: BCE (B、C、E)</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-130">
            <div class="question-header">
                <div class="question-title">Question #130 ✅ ⚪ <small style="float: right;">(130/353)</small></div>
            </div>
            <div class="question-content">A company has a legacy application. A DevOps engineer needs to automate the process of building the deployable artifact for the legacy application. The solution must store the deployable artifact in an existing <span class="key-service">Amazon S3</span> bucket for future deployments to reference. Which solution will meet these requirements in the MOST operationally efficient way? A (100%)</div>
            <div class="options-container">                <div class="option correct-answer"><strong>A.</strong> Create a custom Docker image that contains all the dependencies for the legacy application. Store the custom Docker image in a new Amazon Elastic Container Registry (<span class="key-service">Amazon ECR</span>) repository. Configure a new <span class="key-service">AWS CodeBuild</span> project to use the custom Docker image to build the deployable artifact and to save the artifact to the S3 bucket.</div>                <div class="option"><strong>B.</strong> Launch a new <span class="key-service">Amazon EC2</span> instance. Install all the dependencies for the legacy application on the EC2 instance. Use the EC2 instance to build the deployable artifact and to save the artifact to the S3 bucket.</div>                <div class="option"><strong>C.</strong> Create a custom EC2 Image Builder image. Install all the dependencies for the legacy application on the image. Launch a new <span class="key-service">Amazon EC2</span> instance from the image. Use the new EC2 instance to build the deployable artifact and to save the artifact to the S3 bucket.</div>                <div class="option"><strong>D.</strong> Create an Amazon Elastic Kubernetes Service (<span class="key-service">Amazon EKS</span>) cluster with an <span class="key-service">AWS Fargate</span> profile that runs in multiple Availability Zones. Create a custom Docker image that contains all the dependencies for the legacy application. Store the custom Docker image in a new Amazon Elastic Container Registry (<span class="key-service">Amazon ECR</span>) repository. Use the custom Docker image inside the EKS cluster to build the deployable artifact and to save the artifact to the S3 bucket.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司有一个遗留应用程序。DevOps工程师需要自动化构建该遗留应用程序可部署工件的过程。解决方案必须将可部署工件存储在现有的Amazon S3存储桶中，以供未来部署参考。哪种解决方案能以最具运营效率的方式满足这些要求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 创建包含遗留应用程序所有依赖项的自定义Docker镜像，将自定义Docker镜像存储在新的Amazon Elastic Container Registry (<span class="key-service">Amazon ECR</span>)存储库中，配置新的AWS CodeBuild项目使用自定义Docker镜像构建可部署工件并将工件保存到S3存储桶。</div> <div class="option-analysis"><strong>B.</strong> 启动新的Amazon EC2实例，在EC2实例上安装遗留应用程序的所有依赖项，使用EC2实例构建可部署工件并将工件保存到S3存储桶。</div> <div class="option-analysis"><strong>C.</strong> 创建自定义EC2 Image Builder镜像，在镜像上安装遗留应用程序的所有依赖项，从镜像启动新的Amazon EC2实例，使用新EC2实例构建可部署工件并将工件保存到S3存储桶。</div> <div class="option-analysis"><strong>D.</strong> 创建在多个可用区运行的带有AWS Fargate配置文件的Amazon Elastic Kubernetes Service (<span class="key-service">Amazon EKS</span>)集群，创建包含遗留应用程序所有依赖项的自定义Docker镜像，将自定义Docker镜像存储在新的Amazon Elastic Container Registry (<span class="key-service">Amazon ECR</span>)存储库中，在EKS集群内使用自定义Docker镜像构建可部署工件并将工件保存到S3存储桶。<div class="section-title"><strong>核心要求:</strong></div> 自动化构建遗留应用程序的可部署工件并存储到S3存储桶 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• <span class="key-service">AWS CodeBuild</span>-托管构建服务，支持自动化CI/CD流程 </div><div class="compact-content">• <span class="key-service">Amazon ECR</span>-Docker容器镜像注册表服务 </div><div class="compact-content">• <span class="key-service">Amazon S3</span>-对象存储服务，用于存储构建工件 <div class="section-title"><strong>正确答案A:</strong></div> 使用CodeBuild托管构建服务配合ECR存储的自定义Docker镜像，实现完全托管的自动化构建流程，无需管理基础设施 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项B-需要手动管理EC2实例，运营开销大，缺乏自动化 </div><div class="compact-content">• 选项C-虽然使用Image Builder但仍需管理EC2实例，运营效率不如托管服务 </div><div class="compact-content">• 选项D-EKS集群过于复杂，对于简单构建任务存在过度工程化问题 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-CodeBuild提供按需构建能力，无需预置资源 </div><div class="compact-content">• 成本-按使用量付费，避免持续运行EC2实例的成本 </div><div class="compact-content">• 可扩展性-托管服务自动扩展，无需管理基础设施</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: A</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-131">
            <div class="question-header">
                <div class="question-title">Question #131 ✅ ⚪ <small style="float: right;">(131/353)</small></div>
            </div>
            <div class="question-content">A company builds a container image in an <span class="key-service">AWS CodeBuild</span> project by running Docker commands. After the container image is built, the CodeBuild project uploads the container image to an <span class="key-service">Amazon S3</span> bucket. The CodeBuild project has an IAM service role that has permissions to access the S3 bucket. A DevOps engineer needs to replace the S3 bucket with an Amazon Elastic Container Registry (<span class="key-service">Amazon ECR</span>) repository to store the container images. The DevOps engineer creates an ECR private image repository in the same AWS Region of the CodeBuild project. The DevOps engineer adjusts the IAM service role with the permissions that are necessary to work with the new ECR repository. The DevOps engineer also places new repository information into the docker build command and the docker push command that are used in the buildspec.yml file. When the CodeBuild project runs a build job, the job fails when the job tries to access the ECR repository. Which solution will resolve the issue of failed access to the ECR repository? A (100%)</div>
            <div class="options-container">                <div class="option correct-answer"><strong>A.</strong> Update the buildspec.yml file to log in to the ECR repository by using the aws ecr get-login-password AWS CLI command to obtain an authentication token. Update the docker login command to use the authentication token to access the ECR repository. Most Voted</div>                <div class="option"><strong>B.</strong> Add an environment variable of type SECRETS_MANAGER to the CodeBuild project. In the environment variable, include the ARN of the CodeBuild project's IAM service role. Update the buildspec.yml file to use the new environment variable to log in with the docker login command to access the ECR repository.</div>                <div class="option"><strong>C.</strong> Update the ECR repository to be a public image repository. Add an ECR repository policy that allows the IAM service role to have access.</div>                <div class="option"><strong>D.</strong> Update the buildspec.yml file to use the AWS CLI to assume the IAM service role for ECR operations. Add an ECR repository policy that allows the IAM service role to have access.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司在AWS CodeBuild项目中通过运行Docker命令构建容器镜像。构建完成后，CodeBuild项目将容器镜像上传到Amazon S3存储桶。CodeBuild项目有一个IAM服务角色，具有访问S3存储桶的权限。DevOps工程师需要用Amazon Elastic Container Registry (<span class="key-service">Amazon ECR</span>)存储库替换S3存储桶来存储容器镜像。DevOps工程师在CodeBuild项目相同的AWS区域创建了ECR私有镜像存储库。DevOps工程师调整了IAM服务角色，添加了使用新ECR存储库所需的权限。DevOps工程师还在buildspec.yml文件中的docker build命令和docker push命令中放置了新的存储库信息。当CodeBuild项目运行构建作业时，作业在尝试访问ECR存储库时失败。哪个解决方案能解决ECR存储库访问失败的问题？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 更新buildspec.yml文件，使用aws ecr get-login-password AWS CLI命令获取认证令牌来登录ECR存储库。更新docker login命令使用认证令牌访问ECR存储库。</div> <div class="option-analysis"><strong>B.</strong> 向CodeBuild项目添加SECRETS_MANAGER类型的环境变量。在环境变量中包含CodeBuild项目IAM服务角色的ARN。更新buildspec.yml文件使用新环境变量通过docker login命令登录访问ECR存储库。</div> <div class="option-analysis"><strong>C.</strong> 将ECR存储库更新为公共镜像存储库。添加ECR存储库策略，允许IAM服务角色访问。</div> <div class="option-analysis"><strong>D.</strong> 更新buildspec.yml文件使用AWS CLI为ECR操作承担IAM服务角色。添加ECR存储库策略，允许IAM服务角色访问。<div class="section-title"><strong>核心要求:</strong></div> CodeBuild需要正确认证才能访问ECR私有存储库 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• CodeBuild-容器构建服务，需要ECR认证 </div><div class="compact-content">• ECR-私有容器镜像存储库，需要认证令牌访问 <div class="section-title"><strong>正确答案A:</strong></div> 使用aws ecr get-login-password获取认证令牌，然后通过docker login进行ECR认证，这是访问ECR私有存储库的标准方法 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项B-SECRETS_MANAGER环境变量不是ECR认证的正确方式，IAM角色ARN不能直接用于docker login </div><div class="compact-content">• 选项C-改为公共存储库不符合安全最佳实践，且不是解决认证问题的正确方法 </div><div class="compact-content">• 选项D-CodeBuild已经在IAM服务角色下运行，不需要再次承担角色，且缺少具体的认证步骤 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-标准ECR认证流程，无额外开销 </div><div class="compact-content">• 成本-使用现有IAM权限，无额外成本 </div><div class="compact-content">• 可扩展性-标准认证方法，适用于所有ECR操作</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: A</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-132">
            <div class="question-header">
                <div class="question-title">Question #132 ✅ ⚪ <small style="float: right;">(132/353)</small></div>
            </div>
            <div class="question-content">A company manually provisions IAM access for its employees. The company wants to replace the manual process with an automated process. The company has an existing Active Directory system configured with an external SAML 2.0 identity provider (IdP). The company wants employees to use their existing corporate credentials to access AWS. The groups from the existing Active Directory system must be available for permission management in AWS Identity and Access Management (IAM). A DevOps engineer has completed the initial configuration of <span class="key-service">AWS IAM</span> Identity Center (AWS Single Sign-On) in the company's AWS account. What should the DevOps engineer do next to meet the requirements? A (90%) 10%</div>
            <div class="options-container">                <div class="option correct-answer"><strong>A.</strong> Configure an external IdP as an identity source. Configure automatic provisioning of users and groups by using the SCIM protocol.</div>                <div class="option"><strong>B.</strong> Configure AWS Directory Service as an identity source. Configure automatic provisioning of users and groups by using the SAML protocol.</div>                <div class="option"><strong>C.</strong> Configure an AD Connector as an identity source. Configure automatic provisioning of users and groups by using the SCIM protocol.</div>                <div class="option"><strong>D.</strong> Configure an external IdP as an identity source. Configure automatic provisioning of users and groups by using the SAML protocol.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司手动为员工配置IAM访问权限，希望用自动化流程替代手动流程。公司有配置了外部SAML 2.0 identity provider (IdP)的现有Active Directory系统，希望员工使用现有企业凭证访问AWS。现有Active Directory系统的组必须在AWS Identity and Access Management (IAM)中可用于权限管理。DevOps工程师已完成AWS IAM Identity Center (AWS Single Sign-On)的初始配置。工程师接下来应该做什么来满足要求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 配置外部IdP作为身份源，使用SCIM协议配置用户和组的自动配置</div> <div class="option-analysis"><strong>B.</strong> 配置AWS Directory Service作为身份源，使用SAML协议配置用户和组的自动配置</div> <div class="option-analysis"><strong>C.</strong> 配置AD Connector作为身份源，使用SCIM协议配置用户和组的自动配置</div> <div class="option-analysis"><strong>D.</strong> 配置外部IdP作为身份源，使用SAML协议配置用户和组的自动配置<div class="section-title"><strong>核心要求:</strong></div> 实现从外部SAML 2.0 IdP到AWS IAM Identity Center的自动化用户和组同步 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• <span class="key-service">AWS IAM</span> Identity Center-统一身份管理和单点登录服务 </div><div class="compact-content">• SCIM协议-用于身份信息自动同步的标准协议 </div><div class="compact-content">• SAML 2.0 IdP-外部身份提供商用于身份验证 <div class="section-title"><strong>正确答案A:</strong></div> 外部IdP提供身份验证，SCIM协议专门用于用户和组的自动配置同步，满足自动化和组管理需求 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项B-AWS Directory Service不是外部IdP的正确配置方式，且SAML用于认证而非用户配置 </div><div class="compact-content">• 选项C-AD Connector用于连接本地AD，但题目已有外部SAML 2.0 IdP配置 </div><div class="compact-content">• 选项D-SAML协议用于身份验证而非用户和组的自动配置，应使用SCIM <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-SCIM协议提供高效的用户组同步机制 </div><div class="compact-content">• 成本-利用现有外部IdP基础设施，无需额外Directory Service </div><div class="compact-content">• 可扩展性-外部IdP配置支持企业级用户管理和扩展</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: A</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-133">
            <div class="question-header">
                <div class="question-title">Question #133 ✅ ⚪ <small style="float: right;">(133/353)</small></div>
            </div>
            <div class="question-content">A company is using AWS to run digital workloads. Each application team in the company has its own AWS account for application hosting. The accounts are consolidated in an organization in <span class="key-service">AWS Organizations</span>. The company wants to enforce security standards across the entire organization. To avoid noncompliance because of security misconfiguration, the company has enforced the use of <span class="key-service">AWS CloudFormation</span>. A production support team can modify resources in the production environment by using the AWS Management Console to troubleshoot and resolve application-related issues. A DevOps engineer must implement a solution to identify in near real time any AWS service misconfiguration that results in noncompliance. The solution must automatically remediate the issue within 15 minutes of identification. The solution also must track noncompliant resources and events in a centralized dashboard with accurate timestamps. Which solution will meet these requirements with the LEAST development overhead? C (85%) A (15%)</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Use CloudFormation drift detection to identify noncompliant resources. Use drift detection events from CloudFormation to invoke an <span class="key-service">AWS Lambda</span> function for remediation. Configure the Lambda function to publish logs to an <span class="key-service">Amazon CloudWatch</span> Logs log group. Configure an <span class="key-service">Amazon CloudWatch</span> dashboard to use the log group for tracking.</div>                <div class="option"><strong>B.</strong> Turn on <span class="key-service">AWS CloudTrail</span> in the AWS accounts. Analyze CloudTrail logs by using Amazon Athena to identify noncompliant resources. Use <span class="key-service">AWS Step Functions</span> to track query results on Athena for drift detection and to invoke an <span class="key-service">AWS Lambda</span> function for remediation. For tracking, set up an Amazon QuickSight dashboard that uses Athena as the data source.</div>                <div class="option correct-answer"><strong>C.</strong> Turn on the configuration recorder in <span class="key-service">AWS Config</span> in all the AWS accounts to identify noncompliant resources. Enable AWS Security Hub with the --no-enable-default-standards option in all the AWS accounts. Set up <span class="key-service">AWS Config</span> managed rules and custom rules. Set up automatic remediation by using <span class="key-service">AWS Config</span> conformance packs. For tracking, set up a dashboard on Security Hub in a designated Security Hub administrator account.</div>                <div class="option"><strong>D.</strong> Turn on <span class="key-service">AWS CloudTrail</span> in the AWS accounts. Analyze CloudTrail logs by using <span class="key-service">Amazon CloudWatch</span> Logs to identify noncompliant resources. Use CloudWatch Logs filters for drift detection. Use Amazon EventBridge to invoke the Lambda function for remediation. Stream filtered CloudWatch logs to Amazon OpenSearch Service. Set up a dashboard on OpenSearch Service for tracking.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司使用AWS运行数字化工作负载，每个应用团队都有自己的AWS账户，账户通过AWS Organizations整合。公司希望在整个组织中强制执行安全标准，为避免安全配置错误导致的不合规，公司强制使用AWS CloudFormation。生产支持团队可以通过AWS Management Console修改生产环境资源来排查和解决应用相关问题。DevOps工程师必须实施一个解决方案，近实时识别导致不合规的AWS服务配置错误，在识别后15分钟内自动修复问题，并在集中式仪表板中跟踪不合规资源和事件，显示准确的时间戳。 <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 使用CloudFormation漂移检测识别不合规资源，使用CloudFormation的漂移检测事件调用AWS Lambda函数进行修复，配置Lambda函数将日志发布到Amazon CloudWatch Logs日志组，配置Amazon CloudWatch仪表板使用日志组进行跟踪。</div> <div class="option-analysis"><strong>B.</strong> 在AWS账户中开启AWS CloudTrail，使用Amazon Athena分析CloudTrail日志识别不合规资源，使用AWS Step Functions跟踪Athena查询结果进行漂移检测并调用AWS Lambda函数修复，设置使用Athena作为数据源的Amazon QuickSight仪表板进行跟踪。</div> <div class="option-analysis"><strong>C.</strong> 在所有AWS账户中开启AWS Config的配置记录器识别不合规资源，在所有AWS账户中使用--no-enable-default-standards选项启用AWS Security Hub，设置AWS Config托管规则和自定义规则，使用AWS Config conformance packs设置自动修复，在指定的Security Hub管理员账户中设置Security Hub仪表板进行跟踪。</div> <div class="option-analysis"><strong>D.</strong> 在AWS账户中开启AWS CloudTrail，使用Amazon CloudWatch Logs分析CloudTrail日志识别不合规资源，使用CloudWatch Logs过滤器进行漂移检测，使用Amazon EventBridge调用Lambda函数修复，将过滤的CloudWatch日志流式传输到Amazon OpenSearch Service，在OpenSearch Service上设置仪表板进行跟踪。<div class="section-title"><strong>核心要求:</strong></div> 近实时识别AWS服务配置错误并在15分钟内自动修复，同时提供集中式跟踪仪表板 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• <span class="key-service">AWS Config</span>-持续监控和评估AWS资源配置合规性 </div><div class="compact-content">• AWS Security Hub-提供集中式安全态势管理和合规性跟踪 </div><div class="compact-content">• <span class="key-service">AWS Config</span> conformance packs-自动化合规性修复 <div class="section-title"><strong>正确答案C:</strong></div> AWS Config提供持续配置监控和近实时合规性检测，conformance packs支持自动修复，Security Hub提供跨账户集中式仪表板和准确时间戳跟踪，完全满足所有要求且开发开销最小 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A-CloudFormation漂移检测无法提供近实时监控，且CloudWatch仪表板功能有限 </div><div class="compact-content">• 选项B-基于CloudTrail和Athena的方案复杂度高，无法满足近实时要求，开发开销大 </div><div class="compact-content">• 选项D-CloudTrail日志分析方案架构复杂，开发开销大，且无法有效实现近实时监控 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-AWS Config提供近实时配置监控，满足15分钟修复要求 </div><div class="compact-content">• 成本-使用托管服务减少开发和运维成本 </div><div class="compact-content">• 可扩展性-Security Hub支持跨多账户集中管理和监控</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: C</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-134">
            <div class="question-header">
                <div class="question-title">Question #134 ✅ ⚪ <small style="float: right;">(134/353)</small></div>
            </div>
            <div class="question-content">A company uses <span class="key-service">AWS Organizations</span> to manage its AWS accounts. The organization root has an OU that is named Environments. The Environments OU has two child OUs that are named Development and Production, respectively. The Environments OU and the child OUs have the default FullAWSAccess policy in place. A DevOps engineer plans to remove the FullAWSAccess policy from the Development OU and replace the policy with a policy that allows all actions on <span class="key-service">Amazon EC2</span> resources. What will be the outcome of this policy replacement? B (77%) A (23%)</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> All users in the Development OU will be allowed all API actions on all resources.</div>                <div class="option correct-answer"><strong>B.</strong> All users in the Development OU will be allowed all API actions on EC2 resources. All other API actions will be denied.</div>                <div class="option"><strong>C.</strong> All users in the Development OU will be denied all API actions on all resources.</div>                <div class="option"><strong>D.</strong> All users in the Development OU will be denied all API actions on EC2 resources. All other API actions will be allowed.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司使用AWS Organizations管理其AWS账户。组织根有一个名为Environments的OU。Environments OU有两个子OU，分别名为Development和Production。Environments OU和子OU都有默认的FullAWSAccess策略。DevOps工程师计划从Development OU中移除FullAWSAccess策略，并用允许对Amazon EC2资源执行所有操作的策略替换。这种策略替换的结果是什么？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> Development OU中的所有用户将被允许对所有资源执行所有API操作。</div> <div class="option-analysis"><strong>B.</strong> Development OU中的所有用户将被允许对EC2资源执行所有API操作。所有其他API操作将被拒绝。</div> <div class="option-analysis"><strong>C.</strong> Development OU中的所有用户将被拒绝对所有资源执行所有API操作。</div> <div class="option-analysis"><strong>D.</strong> Development OU中的所有用户将被拒绝对EC2资源执行所有API操作。所有其他API操作将被允许。<div class="section-title"><strong>核心要求:</strong></div> 理解AWS Organizations中SCP策略替换对权限的影响 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• <span class="key-service">AWS Organizations</span> - 提供集中式账户管理和策略控制 </div><div class="compact-content">• <span class="key-service">SCP</span> (Service Control Policy) - 定义OU和账户的最大权限边界 <div class="section-title"><strong>正确答案B:</strong></div> SCP作为权限边界，当FullAWSAccess被替换为仅允许EC2操作的策略时，Development OU中的用户只能执行EC2相关操作，其他服务操作被拒绝 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A - 忽略了策略替换的限制效果，新策略只允许EC2操作而非所有操作 </div><div class="compact-content">• 选项C - 误解了策略内容，新策略允许EC2操作而非拒绝所有操作 </div><div class="compact-content">• 选项D - 完全颠倒了策略效果，新策略是允许EC2操作而拒绝其他操作 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 权限控制 - SCP定义最大权限边界，限制可执行的操作范围 </div><div class="compact-content">• 策略继承 - 子OU继承父级策略限制，策略替换直接影响权限 </div><div class="compact-content">• 安全原则 - 明确的权限边界确保最小权限原则的实施</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: B</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-135">
            <div class="question-header">
                <div class="question-title">Question #135 ✅ ⚪ <small style="float: right;">(135/353)</small></div>
            </div>
            <div class="question-content">A company is examining its disaster recovery capability and wants the ability to switch over its daily operations to a secondary AWS Region. The company uses <span class="key-service">AWS CodeCommit</span> as a source control tool in the primary Region. A DevOps engineer must provide the capability for the company to develop code in the secondary Region. If the company needs to use the secondary Region, developers can add an additional remote URL to their local Git configuration. Which solution will meet these requirements? A (86%) 14%</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Create a CodeCommit repository in the secondary Region. Create an <span class="key-service">AWS CodeBuild</span> project to perform a Git mirror operation of the primary Region's CodeCommit repository to the secondary Region's CodeCommit repository. Create an <span class="key-service">AWS Lambda</span> function that invokes the CodeBuild project. Create an Amazon EventBridge rule that reacts to merge events in the primary Region's CodeCommit repository. Configure the EventBridge rule to invoke the Lambda function. Most Voted</div>                <div class="option correct-answer"><strong>B.</strong> Create an <span class="key-service">Amazon S3</span> bucket in the secondary Region. Create an <span class="key-service">AWS Fargate</span> task to perform a Git mirror operation of the primary Region's CodeCommit repository and copy the result to the S3 bucket. Create an <span class="key-service">AWS Lambda</span> function that initiates the Fargate task. Create an Amazon EventBridge rule that reacts to merge events in the CodeCommit repository. Configure the EventBridge rule to invoke the Lambda function.</div>                <div class="option"><strong>C.</strong> Create an AWS CodeArtifact repository in the secondary Region. Create an <span class="key-service">AWS CodePipeline</span> pipeline that uses the primary Region's CodeCommit repository for the source action. Create a cross-Region stage in the pipeline that packages the CodeCommit repository contents and stores the contents in the CodeArtifact repository when a pull request is merged into the CodeCommit repository.</div>                <div class="option"><strong>D.</strong> Create an AWS Cloud9 environment and a CodeCommit repository in the secondary Region. Configure the primary Region's CodeCommit repository as a remote repository in the AWS Cloud9 environment. Connect the secondary Region's CodeCommit repository to the AWS Cloud9 environment.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司正在检查其灾难恢复能力，希望能够将日常运营切换到辅助AWS区域。该公司在主区域使用AWS CodeCommit作为源代码控制工具。DevOps工程师必须为公司提供在辅助区域开发代码的能力。如果公司需要使用辅助区域，开发人员可以在本地Git配置中添加额外的远程URL。 <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 在辅助区域创建CodeCommit存储库，创建AWS CodeBuild项目执行主区域CodeCommit存储库到辅助区域CodeCommit存储库的Git镜像操作，创建Lambda函数调用CodeBuild项目，创建Amazon EventBridge规则响应主区域CodeCommit存储库的合并事件并配置规则调用Lambda函数</div> <div class="option-analysis"><strong>B.</strong> 在辅助区域创建Amazon S3存储桶，创建AWS Fargate任务执行主区域CodeCommit存储库的Git镜像操作并将结果复制到S3存储桶，创建Lambda函数启动Fargate任务，创建Amazon EventBridge规则响应CodeCommit存储库的合并事件并配置规则调用Lambda函数</div> <div class="option-analysis"><strong>C.</strong> 在辅助区域创建AWS CodeArtifact存储库，创建AWS CodePipeline管道使用主区域的CodeCommit存储库作为源操作，在管道中创建跨区域阶段当拉取请求合并到CodeCommit存储库时打包CodeCommit存储库内容并存储到CodeArtifact存储库</div> <div class="option-analysis"><strong>D.</strong> 在辅助区域创建AWS Cloud9环境和CodeCommit存储库，将主区域的CodeCommit存储库配置为AWS Cloud9环境中的远程存储库，将辅助区域的CodeCommit存储库连接到AWS Cloud9环境<div class="section-title"><strong>核心要求:</strong></div> 在辅助区域建立Git存储库镜像以支持灾难恢复时的代码开发 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• CodeCommit-Git源代码控制服务 </div><div class="compact-content">• EventBridge-事件驱动的自动化触发 </div><div class="compact-content">• Fargate-无服务器容器运行平台 <div class="section-title"><strong>正确答案B:</strong></div> 使用Fargate执行Git镜像操作到S3存储桶，通过EventBridge自动触发同步，满足开发人员添加远程URL的Git工作流需求 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A-CodeCommit到CodeCommit的镜像不支持标准Git远程URL添加方式 </div><div class="compact-content">• 选项C-CodeArtifact是包管理服务，不是Git存储库，无法作为Git远程 </div><div class="compact-content">• 选项D-手动配置方案，缺乏自动同步机制，不满足灾难恢复要求 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-EventBridge实时触发确保数据同步及时性 </div><div class="compact-content">• 成本-Fargate按需计费，S3存储成本低于CodeCommit </div><div class="compact-content">• 可扩展性-S3支持Git标准协议，兼容现有开发工作流</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: B</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-136">
            <div class="question-header">
                <div class="question-title">Question #136 ✅ ⚪ <small style="float: right;">(136/353)</small></div>
            </div>
            <div class="question-content">A DevOps team is merging code revisions for an application that uses an <span class="key-service">Amazon RDS</span> Multi-AZ DB cluster for its production database. The DevOps team uses continuous integration to periodically verify that the application works. The DevOps team needs to test the changes before the changes are deployed to the production database. Which solution will meet these requirements? A (100%)</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Use a buildspec file in <span class="key-service">AWS CodeBuild</span> to restore the DB cluster from a snapshot of the production database, run integration tests, and drop the restored database after verification.</div>                <div class="option"><strong>B.</strong> Deploy the application to production. Configure an audit log of data control language (DCL) operations to capture database activities to perform if verification fails.</div>                <div class="option"><strong>C.</strong> Create a snapshot of the DB cluster before deploying the application. Use the Update requires: Replacement property on the DB instance in <span class="key-service">AWS CloudFormation</span> to deploy the application and apply the changes.</div>                <div class="option correct-answer"><strong>D.</strong> Ensure that the DB cluster is a Multi-AZ deployment. Deploy the application with the updates. Fail over to the standby instance if verification fails.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一个DevOps团队正在为使用Amazon RDS Multi-AZ DB集群作为生产数据库的应用程序合并代码修订。DevOps团队使用持续集成定期验证应用程序是否正常工作。DevOps团队需要在将更改部署到生产数据库之前测试更改。哪种解决方案将满足这些要求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 在AWS CodeBuild中使用buildspec文件从生产数据库快照恢复DB集群，运行集成测试，并在验证后删除恢复的数据库。</div> <div class="option-analysis"><strong>B.</strong> 将应用程序部署到生产环境。配置数据控制语言(DCL)操作的审计日志来捕获数据库活动，以便在验证失败时执行。</div> <div class="option-analysis"><strong>C.</strong> 在部署应用程序之前创建DB集群快照。在AWS CloudFormation中使用DB实例上的Update requires: Replacement属性来部署应用程序并应用更改。</div> <div class="option-analysis"><strong>D.</strong> 确保DB集群是Multi-AZ部署。使用更新部署应用程序。如果验证失败则故障转移到备用实例。<div class="section-title"><strong>核心要求:</strong></div> 在生产环境中安全测试数据库更改并提供回滚机制 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• <span class="key-service">Amazon RDS</span> Multi-AZ-提供自动故障转移和高可用性 </div><div class="compact-content">• <span class="key-service">AWS CodeBuild</span>-持续集成构建服务 <div class="section-title"><strong>正确答案D:</strong></div> 利用Multi-AZ的内置故障转移机制，在主实例上测试更改，失败时可立即切换到未受影响的备用实例 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A-创建临时数据库进行测试，但无法完全模拟生产环境的真实条件 </div><div class="compact-content">• 选项B-直接在生产环境部署存在风险，审计日志无法提供有效的回滚机制 </div><div class="compact-content">• 选项C-CloudFormation的Replacement属性会重建整个实例，过程复杂且耗时 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-Multi-AZ故障转移速度快，最小化停机时间 </div><div class="compact-content">• 成本-利用现有Multi-AZ架构，无需额外资源 </div><div class="compact-content">• 可扩展性-原生AWS服务集成，易于自动化管理</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: D</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-137">
            <div class="question-header">
                <div class="question-title">Question #137 ✅ ⚪ <small style="float: right;">(137/353)</small></div>
            </div>
            <div class="question-content">A company manages a multi-tenant environment in its <span class="key-service">VPC</span> and has configured <span class="key-service">Amazon GuardDuty</span> for the corresponding AWS account. The company sends all GuardDuty findings to AWS Security Hub. Traffic from suspicious sources is generating a large number of findings. A DevOps engineer needs to implement a solution to automatically deny traffic across the entire <span class="key-service">VPC</span> when GuardDuty discovers a new suspicious source. Which solution will meet these requirements? C (91%) 5%</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Create a GuardDuty threat list. Configure GuardDuty to reference the list. Create an <span class="key-service">AWS Lambda</span> function that will update the threat list. Configure the Lambda function to run in response to new Security Hub findings that come from GuardDuty.</div>                <div class="option correct-answer"><strong>B.</strong> Configure an AWS WAF web ACL that includes a custom rule group. Create an <span class="key-service">AWS Lambda</span> function that will create a block rule in the custom rule group. Configure the Lambda function to run in response to new Security Hub findings that come from GuardDuty.</div>                <div class="option"><strong>C.</strong> Configure a firewall in AWS Network Firewall. Create an <span class="key-service">AWS Lambda</span> function that will create a Drop action rule in the firewall policy. Configure the Lambda function to run in response to new Security Hub findings that come from GuardDuty.</div>                <div class="option"><strong>D.</strong> Create an <span class="key-service">AWS Lambda</span> function that will create a GuardDuty suppression rule. Configure the Lambda function to run in response to new Security Hub findings that come from GuardDuty.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司在其VPC中管理多租户环境，并为相应的AWS账户配置了Amazon GuardDuty。公司将所有GuardDuty发现发送到AWS Security Hub。来自可疑源的流量产生大量发现。DevOps工程师需要实施解决方案，当GuardDuty发现新的可疑源时自动拒绝整个VPC的流量。 <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 创建GuardDuty威胁列表，配置GuardDuty引用该列表，创建AWS Lambda函数更新威胁列表，配置Lambda函数响应来自GuardDuty的新Security Hub发现。</div> <div class="option-analysis"><strong>B.</strong> 配置包含自定义规则组的AWS WAF web ACL，创建AWS Lambda函数在自定义规则组中创建阻止规则，配置Lambda函数响应来自GuardDuty的新Security Hub发现。</div> <div class="option-analysis"><strong>C.</strong> 在AWS Network Firewall中配置防火墙，创建AWS Lambda函数在防火墙策略中创建Drop动作规则，配置Lambda函数响应来自GuardDuty的新Security Hub发现。</div> <div class="option-analysis"><strong>D.</strong> 创建AWS Lambda函数创建GuardDuty抑制规则，配置Lambda函数响应来自GuardDuty的新Security Hub发现。<div class="section-title"><strong>核心要求:</strong></div> 自动阻止整个VPC中来自可疑源的流量 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• AWS WAF - 应用层防火墙，可阻止恶意IP地址的HTTP/HTTPS流量 </div><div class="compact-content">• AWS Network Firewall - 网络层防火墙，提供VPC级别的流量过滤和保护 <div class="section-title"><strong>正确答案B:</strong></div> AWS WAF通过自定义规则组可以有效阻止来自可疑IP的web流量，Lambda函数可以动态更新阻止规则实现自动化响应 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A - GuardDuty威胁列表仅用于检测，不能直接阻止流量 </div><div class="compact-content">• 选项C - Network Firewall适用但成本较高，对于web流量WAF更合适 </div><div class="compact-content">• 选项D - 抑制规则只是隐藏发现，不会阻止实际的恶意流量 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能 - WAF专门优化web流量过滤，响应速度快 </div><div class="compact-content">• 成本 - WAF比Network Firewall成本更低，适合web应用保护 </div><div class="compact-content">• 可扩展性 - 自定义规则组支持动态更新，易于自动化管理</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: B</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-138">
            <div class="question-header">
                <div class="question-title">Question #138 ✅ 📝 <small style="float: right;">(138/353)</small></div>
            </div>
            <div class="question-content">A company uses AWS Secrets Manager to store a set of sensitive API keys that an <span class="key-service">AWS Lambda</span> function uses. When the Lambda function is invoked, the Lambda function retrieves the API keys and makes an API call to an external service. The Secrets Manager secret is encrypted with the default AWS Key Management Service (AWS KMS) key. A DevOps engineer needs to update the infrastructure to ensure that only the Lambda function's execution role can access the values in Secrets Manager. The solution must apply the principle of least privilege. Which combination of steps will meet these requirements? (Choose two.) BD (94%) 6%</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Update the default KMS key for Secrets Manager to allow only the Lambda function's execution role to decrypt.</div>                <div class="option"><strong>B.</strong> Create a KMS customer managed key that trusts Secrets Manager and allows the Lambda function's execution role to decrypt. Update Secrets Manager to use the new customer managed key.</div>                <div class="option correct-answer"><strong>C.</strong> Create a KMS customer managed key that trusts Secrets Manager and allows the account's root principal to decrypt. Update Secrets Manager to use the new customer managed key</div>                <div class="option"><strong>D.</strong> Ensure that the Lambda function's execution role has the KMS permissions scoped on the resource level. Configure the permissions so that the KMS key can encrypt the Secrets Manager secret</div>                <div class="option correct-answer"><strong>E.</strong> Remove all KMS permissions from the Lambda function's execution role</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司使用AWS Secrets Manager存储一组敏感的API密钥供AWS Lambda函数使用。当Lambda函数被调用时，它检索API密钥并调用外部服务的API。Secrets Manager密钥使用默认的AWS KMS密钥加密。DevOps工程师需要更新基础设施以确保只有Lambda函数的执行角色可以访问Secrets Manager中的值。解决方案必须应用最小权限原则。哪些步骤组合将满足这些要求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 更新Secrets Manager的默认KMS密钥，仅允许Lambda函数的执行角色进行解密</div> <div class="option-analysis"><strong>B.</strong> 创建一个信任Secrets Manager并允许Lambda函数执行角色解密的KMS客户托管密钥，更新Secrets Manager使用新的客户托管密钥</div> <div class="option-analysis"><strong>C.</strong> 创建一个信任Secrets Manager并允许账户根主体解密的KMS客户托管密钥，更新Secrets Manager使用新的客户托管密钥</div> <div class="option-analysis"><strong>D.</strong> 确保Lambda函数的执行角色具有资源级别范围的KMS权限，配置权限使KMS密钥可以加密Secrets Manager密钥</div> <div class="option-analysis"><strong>E.</strong> 从Lambda函数的执行角色中移除所有KMS权限<div class="section-title"><strong>核心要求:</strong></div> 确保只有Lambda函数执行角色能访问Secrets Manager中的敏感API密钥，遵循最小权限原则 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• AWS Secrets Manager-存储和管理敏感API密钥 </div><div class="compact-content">• AWS KMS-提供加密密钥管理和访问控制 </div><div class="compact-content">• Lambda执行角色-控制函数的权限范围 <div class="section-title"><strong>正确答案CE:</strong></div> 通过创建客户托管KMS密钥并移除Lambda角色的KMS权限，依靠Secrets Manager的资源策略和KMS密钥策略实现精确访问控制 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A-无法修改AWS托管的默认KMS密钥策略 </div><div class="compact-content">• 选项B-在Lambda角色上直接授予KMS权限违反了最小权限原则 </div><div class="compact-content">• 选项D-描述了加密权限而非解密权限，且权限配置过于宽泛 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 安全性-使用客户托管密钥提供更精细的访问控制 </div><div class="compact-content">• <span class="key-point">权限管理</span>-通过资源策略而非角色权限实现访问控制 </div><div class="compact-content">• <span class="key-point">合规性</span>-严格遵循最小权限原则，仅授予必要的访问权限</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: CE (C、E)</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-139">
            <div class="question-header">
                <div class="question-title">Question #139 ✅ 📝 <small style="float: right;">(139/353)</small></div>
            </div>
            <div class="question-content">A company's DevOps engineer is creating an <span class="key-service">AWS Lambda</span> function to process notifications from an Amazon Simple Notification Service (<span class="key-service">Amazon SNS</span>) topic. The Lambda function will process the notification messages and will write the contents of the notification messages to an <span class="key-service">Amazon RDS</span> Multi-AZ DB instance. During testing, a database administrator accidentally shut down the DB instance. While the database was down the company lost several of the SNS notification messages that were delivered during that time. The DevOps engineer needs to prevent the loss of notification messages in the future. Which solutions will meet this requirement? (Choose two.) CD (95%) 5%</div>
            <div class="options-container">                <div class="option correct-answer"><strong>A.</strong> Replace the RDS Multi-AZ DB instance with an <span class="key-service">Amazon DynamoDB</span> table.</div>                <div class="option"><strong>B.</strong> Configure an Amazon Simple Queue Service (<span class="key-service">Amazon SQS</span>) queue as a destination of the Lambda function.</div>                <div class="option"><strong>C.</strong> Configure an Amazon Simple Queue Service (<span class="key-service">Amazon SQS</span>) dead-letter queue for the SNS topic.</div>                <div class="option correct-answer"><strong>D.</strong> Subscribe an Amazon Simple Queue Service (<span class="key-service">Amazon SQS</span>) queue to the SNS topic. Configure the Lambda function to process messages from the SQS queue.</div>                <div class="option"><strong>E.</strong> Replace the SNS topic with an Amazon EventBridge event bus. Configure an EventBridge rule on the new event bus to invoke the Lambda function for each event.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 公司的DevOps工程师正在创建AWS Lambda函数来处理Amazon SNS主题的通知。Lambda函数将处理通知消息并将内容写入Amazon RDS Multi-AZ数据库实例。测试期间，数据库管理员意外关闭了数据库实例。数据库停机期间，公司丢失了几条SNS通知消息。DevOps工程师需要防止未来通知消息丢失。 <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 用Amazon DynamoDB表替换RDS Multi-AZ数据库实例。</div> <div class="option-analysis"><strong>B.</strong> 配置Amazon SQS队列作为Lambda函数的目标。</div> <div class="option-analysis"><strong>C.</strong> 为SNS主题配置Amazon SQS死信队列。</div> <div class="option-analysis"><strong>D.</strong> 将Amazon SQS队列订阅到SNS主题。配置Lambda函数从SQS队列处理消息。</div> <div class="option-analysis"><strong>E.</strong> 用Amazon EventBridge事件总线替换SNS主题。在新事件总线上配置EventBridge规则为每个事件调用Lambda函数。<div class="section-title"><strong>核心要求:</strong></div> 防止数据库停机时SNS通知消息丢失 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• <span class="key-service">Amazon SNS</span> - 消息发布服务，同步推送消息 </div><div class="compact-content">• <span class="key-service">Amazon SQS</span> - 消息队列服务，提供消息持久化和重试机制 </div><div class="compact-content">• <span class="key-service">Amazon DynamoDB</span> - 高可用NoSQL数据库服务 <div class="section-title"><strong>正确答案AD:</strong></div> A选项用DynamoDB替换RDS提供更高可用性和自动故障转移；D选项通过SQS队列解耦SNS和Lambda，提供消息持久化、重试机制和错误处理能力 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项B - SQS不能作为Lambda函数的目标，应该是Lambda从SQS拉取消息 </div><div class="compact-content">• 选项C - 死信队列用于处理失败消息，不能解决数据库停机导致的消息丢失问题 </div><div class="compact-content">• 选项E - EventBridge仍然是推送模式，无法解决数据库停机时的消息丢失问题 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能 - DynamoDB提供毫秒级延迟和自动扩展 </div><div class="compact-content">• 成本 - SQS按使用量付费，DynamoDB按需计费模式成本效益高 </div><div class="compact-content">• 可扩展性 - DynamoDB和SQS都支持自动扩展，无需手动管理容量</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: AD (A、D)</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-140">
            <div class="question-header">
                <div class="question-title">Question #140 ✅ ⚪ <small style="float: right;">(140/353)</small></div>
            </div>
            <div class="question-content">A company has an application that runs on <span class="key-service">Amazon EC2</span> instances. The company uses an <span class="key-service">AWS CodePipeline</span> pipeline to deploy the application into multiple AWS Regions. The pipeline is configured with a stage for each Region. Each stage contains an <span class="key-service">AWS CloudFormation</span> action for each Region. When the pipeline deploys the application to a Region, the company wants to confirm that the application is in a healthy state before the pipeline moves on to the next Region. <span class="key-service">Amazon Route 53</span> record sets are configured for the application in each Region. A DevOps engineer creates a Route 53 health check that is based on an <span class="key-service">Amazon CloudWatch</span> alarm for each Region where the application is deployed. What should the DevOps engineer do next to meet the requirements? A (93%) 7%</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Create an <span class="key-service">AWS Step Functions</span> workflow to check the state of the CloudWatch alarm. Configure the Step Functions workflow to exit with an error if the alarm is in the ALARM state. Create a new stage in the pipeline between each Region deployment stage. In each new stage, include an action to invoke the Step Functions workflow.</div>                <div class="option"><strong>B.</strong> Configure an <span class="key-service">AWS CodeDeploy</span> application to deploy a CloudFormation template with automatic rollback. Configure the CloudWatch alarm as the instance health check for the CodeDeploy application. Remove the CloudFormation actions from the pipeline. Create a CodeDeploy action in the pipeline stage for each Region.</div>                <div class="option"><strong>C.</strong> Create a new pipeline stage for each Region where the application is deployed. Configure a CloudWatch alarm action for the new stage to check the state of the CloudWatch alarm and to exit with an error if the alarm is in the ALARM state.</div>                <div class="option correct-answer"><strong>D.</strong> Configure the CloudWatch agent on the EC2 instances to report the application status to the Route 53 health check. Create a new pipeline stage for each Region where the application is deployed. Configure a CloudWatch alarm action to exit with an error if the CloudWatch alarm is in the ALARM state.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司有运行在Amazon EC2实例上的应用程序。公司使用AWS CodePipeline管道将应用程序部署到多个AWS区域。管道为每个区域配置了一个阶段，每个阶段包含该区域的AWS CloudFormation操作。当管道将应用程序部署到一个区域时，公司希望在管道继续到下一个区域之前确认应用程序处于健康状态。每个区域都为应用程序配置了Amazon Route 53记录集。DevOps工程师为部署应用程序的每个区域创建了基于Amazon CloudWatch告警的Route 53健康检查。DevOps工程师接下来应该做什么来满足要求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 创建AWS Step Functions工作流来检查CloudWatch告警状态。配置Step Functions工作流在告警处于ALARM状态时退出并报错。在每个区域部署阶段之间创建新的管道阶段，在每个新阶段中包含调用Step Functions工作流的操作。</div> <div class="option-analysis"><strong>B.</strong> 配置AWS CodeDeploy应用程序来部署具有自动回滚功能的CloudFormation模板。将CloudWatch告警配置为CodeDeploy应用程序的实例健康检查。从管道中移除CloudFormation操作，为每个区域的管道阶段创建CodeDeploy操作。</div> <div class="option-analysis"><strong>C.</strong> 为部署应用程序的每个区域创建新的管道阶段。为新阶段配置CloudWatch告警操作来检查CloudWatch告警状态，如果告警处于ALARM状态则退出并报错。</div> <div class="option-analysis"><strong>D.</strong> 在EC2实例上配置CloudWatch代理向Route 53健康检查报告应用程序状态。为部署应用程序的每个区域创建新的管道阶段。配置CloudWatch告警操作在CloudWatch告警处于ALARM状态时退出并报错。<div class="section-title"><strong>核心要求:</strong></div> 在CodePipeline多区域部署中实现健康检查验证机制 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• CodePipeline-多区域部署编排 </div><div class="compact-content">• CloudWatch-应用程序监控和告警 </div><div class="compact-content">• Route 53-健康检查和DNS管理 <div class="section-title"><strong>正确答案D:</strong></div> 通过CloudWatch代理收集应用程序状态数据并与Route 53健康检查集成，在管道中添加验证阶段检查告警状态 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A-Step Functions增加了不必要的复杂性，直接使用CloudWatch告警更简单有效 </div><div class="compact-content">• 选项B-完全改变部署架构使用CodeDeploy，不符合现有CloudFormation部署模式 </div><div class="compact-content">• 选项C-缺少CloudWatch代理配置，无法确保应用程序状态正确报告给健康检查 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-CloudWatch代理提供实时应用程序状态监控 </div><div class="compact-content">• 成本-利用现有CloudWatch和Route 53服务，无需额外复杂组件 </div><div class="compact-content">• 可扩展性-标准化的健康检查机制可复用于所有区域部署</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: D</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-141">
            <div class="question-header">
                <div class="question-title">Question #141 ✅ ⚪ <small style="float: right;">(141/353)</small></div>
            </div>
            <div class="question-content">A company plans to use <span class="key-service">Amazon CloudWatch</span> to monitor its <span class="key-service">Amazon EC2</span> instances. The company needs to stop EC2 instances when the average of the NetworkPacketsIn metric is less than 5 for at least 3 hours in a 12-hour time window. The company must evaluate the metric every hour. The EC2 instances must continue to run if there is missing data for the NetworkPacketsIn metric during the evaluation period. A DevOps engineer creates a CloudWatch alarm for the NetworkPacketsIn metric. The DevOps engineer configures a threshold value of 5 and an evaluation period of 1 hour. Which set of additional actions should the DevOps engineer take to meet these requirements? B (100%)</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Configure the Datapoints to Alarm value to be 3 out of 12. Configure the alarm to treat missing data as breaching the threshold. Add an <span class="key-service">AWS Systems Manager</span> action to stop the instance when the alarm enters the ALARM state.</div>                <div class="option"><strong>B.</strong> Configure the Datapoints to Alarm value to be 3 out of 12. Configure the alarm to treat missing data as not breaching the threshold. Add an EC2 action to stop the instance when the alarm enters the ALARM state.</div>                <div class="option correct-answer"><strong>C.</strong> Configure the Datapoints to Alarm value to be 9 out of 12. Configure the alarm to treat missing data as breaching the threshold. Add an EC2 action to stop the instance when the alarm enters the ALARM state.</div>                <div class="option"><strong>D.</strong> Configure the Datapoints to Alarm value to be 9 out of 12. Configure the alarm to treat missing data as not breaching the threshold. Add an <span class="key-service">AWS Systems Manager</span> action to stop the instance when the alarm enters the ALARM state.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司计划使用Amazon CloudWatch监控其Amazon EC2实例。公司需要在12小时时间窗口内，当NetworkPacketsIn指标的平均值连续至少3小时小于5时停止EC2实例。公司必须每小时评估一次指标。如果在评估期间NetworkPacketsIn指标数据缺失，EC2实例必须继续运行。DevOps工程师为NetworkPacketsIn指标创建了CloudWatch告警，配置阈值为5，评估周期为1小时。 <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 配置Datapoints to Alarm值为3 out of 12，配置告警将缺失数据视为违反阈值，添加AWS Systems Manager操作在告警进入ALARM状态时停止实例</div> <div class="option-analysis"><strong>B.</strong> 配置Datapoints to Alarm值为3 out of 12，配置告警将缺失数据视为不违反阈值，添加EC2操作在告警进入ALARM状态时停止实例</div> <div class="option-analysis"><strong>C.</strong> 配置Datapoints to Alarm值为9 out of 12，配置告警将缺失数据视为违反阈值，添加EC2操作在告警进入ALARM状态时停止实例</div> <div class="option-analysis"><strong>D.</strong> 配置Datapoints to Alarm值为9 out of 12，配置告警将缺失数据视为不违反阈值，添加AWS Systems Manager操作在告警进入ALARM状态时停止实例<div class="section-title"><strong>核心要求:</strong></div> 配置CloudWatch告警在12小时窗口内连续3小时低于阈值时停止EC2实例，缺失数据时保持运行 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• CloudWatch - 监控EC2实例NetworkPacketsIn指标并触发告警 </div><div class="compact-content">• EC2 - 提供实例停止操作和指标数据源 <div class="section-title"><strong>正确答案C:</strong></div> 使用9 out of 12配置表示12个数据点中需要9个正常数据点才不触发告警，即允许3个数据点违反阈值；将缺失数据视为违反阈值确保数据缺失时不会错误停止实例；EC2操作直接停止实例最高效 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A - 使用Systems Manager操作复杂且非必需，EC2直接操作更简单 </div><div class="compact-content">• 选项B - 3 out of 12配置错误，应该是9 out of 12来满足连续3小时要求 </div><div class="compact-content">• 选项D - 3 out of 12配置错误，且使用Systems Manager操作不必要 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能 - 每小时评估确保及时响应，EC2直接操作响应最快 </div><div class="compact-content">• 成本 - 避免不必要的Systems Manager操作降低成本 </div><div class="compact-content">• 可扩展性 - CloudWatch告警配置简单易于大规模部署管理</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: C</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-142">
            <div class="question-header">
                <div class="question-title">Question #142 ✅ ⚪ <small style="float: right;">(142/353)</small></div>
            </div>
            <div class="question-content">A company manages 500 AWS accounts that are in an organization in <span class="key-service">AWS Organizations</span>. The company discovers many unattached Amazon Elastic Block Store (Amazon EBS) volumes in all the accounts. The company wants to automatically tag the unattached EBS volumes for investigation. A DevOps engineer needs to deploy an <span class="key-service">AWS Lambda</span> function to all the AWS accounts. The Lambda function must run every 30 minutes to tag all the EBS volumes that have been unattached for a period of 7 days or more. Which solution will meet these requirements in the MOST operationally efficient manner? C (100%)</div>
            <div class="options-container">                <div class="option correct-answer"><strong>A.</strong> Configure a delegated administrator account for the organization. Create an <span class="key-service">AWS CloudFormation</span> template that contains the Lambda function. Use CloudFormation StackSets to deploy the CloudFormation template from the delegated administrator account to all the member accounts in the organization. Create an Amazon EventBridge event bus in the delegated administrator account to invoke the Lambda function in each member account every 30 minutes.</div>                <div class="option"><strong>B.</strong> Create a cross-account IAM role in the organization's member accounts. Attach the AWSLambda_FullAccess policy and the AWSCloudFormationFullAccess policy to the role. Create an <span class="key-service">AWS CloudFormation</span> template that contains the Lambda function and an Amazon EventBridge scheduled rule to invoke the Lambda function every 30 minutes. Create a custom script in the organization's management account that assumes the role and deploys the CloudFormation template to the member accounts.</div>                <div class="option"><strong>C.</strong> Configure a delegated administrator account for the organization. Create an <span class="key-service">AWS CloudFormation</span> template that contains the Lambda function and an Amazon EventBridge scheduled rule to invoke the Lambda function every 30 minutes. Use CloudFormation StackSets to deploy the CloudFormation template from the delegated administrator account to all the member accounts in the organization</div>                <div class="option"><strong>D.</strong> Create a cross-account IAM role in the organization's member accounts. Attach the AmazonS3FullAccess policy and the AWSCodeDeployDeployerAccess policy to the role. Use <span class="key-service">AWS CodeDeploy</span> to assume the role to deploy the Lambda function from the organization's management account. Configure an Amazon EventBridge scheduled rule in the member accounts to invoke the Lambda function every 30 minutes.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司管理着AWS Organizations中500个AWS账户。公司发现所有账户中有许多未附加的Amazon EBS卷。公司希望自动标记未附加的EBS卷以供调查。DevOps工程师需要将AWS Lambda函数部署到所有AWS账户。Lambda函数必须每30分钟运行一次，标记所有未附加7天或更长时间的EBS卷。哪种解决方案能以最具运营效率的方式满足这些要求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 为组织配置委托管理员账户。创建包含Lambda函数的AWS CloudFormation模板。使用CloudFormation StackSets从委托管理员账户将CloudFormation模板部署到组织中的所有成员账户。在委托管理员账户中创建Amazon EventBridge事件总线，每30分钟调用每个成员账户中的Lambda函数。</div> <div class="option-analysis"><strong>B.</strong> 在组织的成员账户中创建跨账户IAM角色。将AWSLambda_FullAccess策略和AWSCloudFormationFullAccess策略附加到角色。创建包含Lambda函数和Amazon EventBridge计划规则的AWS CloudFormation模板，每30分钟调用Lambda函数。在组织的管理账户中创建自定义脚本，承担角色并将CloudFormation模板部署到成员账户。</div> <div class="option-analysis"><strong>C.</strong> 为组织配置委托管理员账户。创建包含Lambda函数和Amazon EventBridge计划规则的AWS CloudFormation模板，每30分钟调用Lambda函数。使用CloudFormation StackSets从委托管理员账户将CloudFormation模板部署到组织中的所有成员账户。</div> <div class="option-analysis"><strong>D.</strong> 在组织的成员账户中创建跨账户IAM角色。将AmazonS3FullAccess策略和AWSCodeDeployDeployerAccess策略附加到角色。使用AWS CodeDeploy承担角色从组织的管理账户部署Lambda函数。在成员账户中配置Amazon EventBridge计划规则，每30分钟调用Lambda函数。<div class="section-title"><strong>核心要求:</strong></div> 在500个AWS账户中部署Lambda函数，每30分钟自动标记未附加7天以上的EBS卷 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• CloudFormation StackSets-跨多账户批量部署资源的最佳实践 </div><div class="compact-content">• EventBridge-提供定时调度和跨账户事件路由功能 </div><div class="compact-content">• <span class="key-service">AWS Organizations</span>-提供委托管理员和集中管理能力 <div class="section-title"><strong>正确答案A:</strong></div> 使用委托管理员账户和StackSets进行标准化部署，通过EventBridge事件总线实现跨账户Lambda函数调用，提供最高运营效率 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项B-使用自定义脚本部署增加复杂性和维护成本，不如StackSets标准化 </div><div class="compact-content">• 选项C-缺少跨账户调用机制，每个账户的Lambda函数无法被统一触发 </div><div class="compact-content">• 选项D-使用CodeDeploy和错误的IAM策略，不适合Lambda部署场景 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-EventBridge事件总线支持跨账户统一调度 </div><div class="compact-content">• 成本-StackSets提供批量部署，减少管理开销 </div><div class="compact-content">• 可扩展性-委托管理员模式支持大规模组织管理</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: A</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-143">
            <div class="question-header">
                <div class="question-title">Question #143 ✅ ⚪ <small style="float: right;">(143/353)</small></div>
            </div>
            <div class="question-content">A company's production environment uses an <span class="key-service">AWS CodeDeploy</span> blue/green deployment to deploy an application. The deployment includes <span class="key-service">Amazon EC2</span> Auto Scaling groups that launch instances that run Amazon Linux 2. A working appspec.yml file exists in the code repository and contains the following text: A DevOps engineer needs to ensure that a script downloads and installs a license file onto the instances before the replacement instances start to handle request traffic. The DevOps engineer adds a hooks section to the appspec.yml file. Which hook should the DevOps engineer use to run the script that downloads and installs the license file? C (100%)</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> AfterBlockTraffic</div>                <div class="option"><strong>B.</strong> BeforeBlockTraffic</div>                <div class="option"><strong>C.</strong> BeforeInstall</div>                <div class="option correct-answer"><strong>D.</strong> DownloadBundle</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司的生产环境使用AWS CodeDeploy蓝绿部署来部署应用程序。部署包括启动运行Amazon Linux 2实例的EC2 Auto Scaling组。代码仓库中存在有效的appspec.yml文件。DevOps工程师需要确保在替换实例开始处理请求流量之前，脚本下载并安装许可证文件到实例上。工程师向appspec.yml文件添加hooks部分。应该使用哪个hook来运行下载和安装许可证文件的脚本？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 阻止流量后</div> <div class="option-analysis"><strong>B.</strong> 阻止流量前</div> <div class="option-analysis"><strong>C.</strong> 安装前</div> <div class="option-analysis"><strong>D.</strong> 下载包<div class="section-title"><strong>核心要求:</strong></div> 在蓝绿部署中选择合适的CodeDeploy hook来在实例处理流量前安装许可证文件 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• <span class="key-service">AWS CodeDeploy</span> - 自动化应用程序部署服务，支持蓝绿部署策略 </div><div class="compact-content">• EC2 Auto Scaling - 自动调整EC2实例数量以满足需求 <div class="section-title"><strong>正确答案D:</strong></div> DownloadBundle是CodeDeploy生命周期中最早的hook，在应用程序包下载完成后立即执行，确保许可证文件在任何应用程序组件安装或流量路由之前就已准备就绪 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A - AfterBlockTraffic在流量已被阻止后执行，时机太晚 </div><div class="compact-content">• 选项B - BeforeBlockTraffic在阻止流量前执行，但此时应用可能已在处理请求 </div><div class="compact-content">• 选项C - BeforeInstall在应用安装前执行，但晚于DownloadBundle，可能影响依赖许可证的安装步骤 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能 - 最早时机安装许可证避免后续步骤延迟 </div><div class="compact-content">• 成本 - 早期失败可避免不必要的资源消耗 </div><div class="compact-content">• 可扩展性 - 确保所有新实例都有正确的许可证配置</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: D</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-144">
            <div class="question-header">
                <div class="question-title">Question #144 ✅ ⚪ <small style="float: right;">(144/353)</small></div>
            </div>
            <div class="question-content">A company has an application that includes <span class="key-service">AWS Lambda</span> functions. The Lambda functions run Python code that is stored in an <span class="key-service">AWS CodeCommit</span> repository. The company has recently experienced failures in the production environment because of an error in the Python code. An engineer has written unit tests for the Lambda functions to help avoid releasing any future defects into the production environment. The company's DevOps team needs to implement a solution to integrate the unit tests into an existing <span class="key-service">AWS CodePipeline</span> pipeline. The solution must produce reports about the unit tests for the company to view. Which solution will meet these requirements? B (100%)</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Associate the CodeCommit repository with Amazon CodeGuru Reviewer. Create a new <span class="key-service">AWS CodeBuild</span> project. In the CodePipeline pipeline, configure a test stage that uses the new CodeBuild project. Create a buildspec.yml file in the CodeCommit repository. In the buildspec.yml file, define the actions to run a CodeGuru review.</div>                <div class="option"><strong>B.</strong> Create a new <span class="key-service">AWS CodeBuild</span> project. In the CodePipeline pipeline, configure a test stage that uses the new CodeBuild project. Create a CodeBuild report group. Create a buildspec.yml file in the CodeCommit repository. In the buildspec.yml file, define the actions to run the unit tests with an output of JUNITXML in the build phase section. Configure the test reports to be uploaded to the new CodeBuild report group.</div>                <div class="option correct-answer"><strong>C.</strong> Create a new AWS CodeArtifact repository. Create a new <span class="key-service">AWS CodeBuild</span> project. In the CodePipeline pipeline, configure a test stage that uses the new CodeBuild project. Create an appspec.yml file in the original CodeCommit repository. In the appspec.yml file, define the actions to run the unit tests with an output of CUCUMBERJSON in the build phase section. Configure the test reports to be sent to the new CodeArtifact repository.</div>                <div class="option"><strong>D.</strong> Create a new <span class="key-service">AWS CodeBuild</span> project. In the CodePipeline pipeline, configure a test stage that uses the new CodeBuild project. Create a new <span class="key-service">Amazon S3</span> bucket. Create a buildspec.yml file in the CodeCommit repository. In the buildspec.yml file, define the actions to run the unit tests with an output of HTML in the phases section. In the reports section, upload the test reports to the S3 bucket.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司有一个包含AWS Lambda函数的应用程序。Lambda函数运行存储在AWS CodeCommit仓库中的Python代码。公司最近在生产环境中因Python代码错误而遭遇故障。工程师为Lambda函数编写了单元测试以避免将来的缺陷发布到生产环境。DevOps团队需要实施解决方案将单元测试集成到现有的AWS CodePipeline管道中。解决方案必须生成单元测试报告供公司查看。 <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 将CodeCommit仓库与Amazon CodeGuru Reviewer关联。创建新的AWS CodeBuild项目。在CodePipeline管道中配置使用新CodeBuild项目的测试阶段。在CodeCommit仓库中创建buildspec.yml文件。在buildspec.yml文件中定义运行CodeGuru审查的操作。</div> <div class="option-analysis"><strong>B.</strong> 创建新的AWS CodeBuild项目。在CodePipeline管道中配置使用新CodeBuild项目的测试阶段。创建CodeBuild报告组。在CodeCommit仓库中创建buildspec.yml文件。在buildspec.yml文件中定义在构建阶段运行单元测试并输出JUNITXML格式的操作。配置测试报告上传到新的CodeBuild报告组。</div> <div class="option-analysis"><strong>C.</strong> 创建新的AWS CodeArtifact仓库。创建新的AWS CodeBuild项目。在CodePipeline管道中配置使用新CodeBuild项目的测试阶段。在原始CodeCommit仓库中创建appspec.yml文件。在appspec.yml文件中定义在构建阶段运行单元测试并输出CUCUMBERJSON格式的操作。配置测试报告发送到新的CodeArtifact仓库。</div> <div class="option-analysis"><strong>D.</strong> 创建新的AWS CodeBuild项目。在CodePipeline管道中配置使用新CodeBuild项目的测试阶段。创建新的Amazon S3存储桶。在CodeCommit仓库中创建buildspec.yml文件。在buildspec.yml文件中定义在phases部分运行单元测试并输出HTML格式的操作。在reports部分将测试报告上传到S3存储桶。<div class="section-title"><strong>核心要求:</strong></div> 在CodePipeline中集成单元测试并生成可查看的测试报告 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• <span class="key-service">AWS CodeBuild</span>-执行单元测试和生成报告 </div><div class="compact-content">• <span class="key-service">AWS CodePipeline</span>-CI/CD管道集成 </div><div class="compact-content">• CodeBuild报告组-标准化测试报告管理 <div class="section-title"><strong>正确答案B:</strong></div> 使用CodeBuild执行单元测试，通过buildspec.yml配置JUNITXML输出格式，利用CodeBuild报告组提供标准化的测试报告查看功能 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A-CodeGuru Reviewer用于代码审查而非单元测试执行和报告生成 </div><div class="compact-content">• 选项C-使用错误的appspec.yml文件(应为buildspec.yml)且CodeArtifact用于包管理而非测试报告 </div><div class="compact-content">• 选项D-S3存储不提供标准化的测试报告查看界面，缺乏报告管理功能 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-CodeBuild报告组提供原生测试报告处理能力 </div><div class="compact-content">• 成本-使用AWS原生服务避免额外的报告处理开销 </div><div class="compact-content">• 可扩展性-CodeBuild报告组支持多种测试框架和报告格式</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: C</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-145">
            <div class="question-header">
                <div class="question-title">Question #145 ✅ ⚪ <small style="float: right;">(145/353)</small></div>
            </div>
            <div class="question-content">A company manages multiple AWS accounts in <span class="key-service">AWS Organizations</span>. The company's security policy states that AWS account root user credentials for member accounts must not be used. The company monitors access to the root user credentials. A recent alert shows that the root user in a member account launched an <span class="key-service">Amazon EC2</span> instance. A DevOps engineer must create an <span class="key-service">SCP</span> at the organization's root level that will prevent the root user in member accounts from making any AWS service API calls. Which <span class="key-service">SCP</span> will meet these requirements? C (100%)</div>
            <div class="options-container">            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司在AWS Organizations中管理多个AWS账户。公司安全策略规定不得使用成员账户的AWS账户root用户凭证。公司监控对root用户凭证的访问。最近的警报显示成员账户中的root用户启动了一个Amazon EC2实例。DevOps工程师必须在组织根级别创建一个SCP，以防止成员账户中的root用户进行任何AWS服务API调用。哪个SCP将满足这些要求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 创建一个SCP，明确拒绝所有AWS服务的所有操作，条件是StringEquals aws:PrincipalType为Root</div> <div class="option-analysis"><strong>B.</strong> 创建一个SCP，明确拒绝所有AWS服务的所有操作，条件是StringEquals aws:userid包含root字符串</div> <div class="option-analysis"><strong>C.</strong> 创建一个SCP，明确允许所有AWS服务的所有操作，条件是StringNotEquals aws:PrincipalType为Root</div> <div class="option-analysis"><strong>D.</strong> 创建一个SCP，明确允许所有AWS服务的所有操作，条件是StringNotEquals aws:userid包含root字符串<div class="section-title"><strong>核心要求:</strong></div> 创建SCP阻止成员账户root用户进行任何AWS API调用 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• <span class="key-service">AWS Organizations</span> - 多账户管理和SCP策略控制 </div><div class="compact-content">• <span class="key-service">SCP</span> (Service Control Policy) - 限制账户内用户和角色的权限边界 <div class="section-title"><strong>正确答案B:</strong></div> 使用StringEquals条件匹配aws:userid中包含"root"的主体，明确拒绝所有AWS服务操作，有效阻止root用户API调用 <div class="section-title"><strong>错误选项:</strong></div> A. aws:PrincipalType条件键不够精确识别root用户 C. Allow策略无法有效限制权限，SCP需要Deny语句 D. Allow策略结合StringNotEquals逻辑错误，无法阻止root访问 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 安全性-必须使用Deny效应明确阻止root用户访问 </div><div class="compact-content">• 准确性-aws:userid条件键能精确识别root用户身份 </div><div class="compact-content">• 有效性-SCP作为权限边界必须使用拒绝策略而非允许策略</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: B</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-146">
            <div class="question-header">
                <div class="question-title">Question #146 ✅ ⚪ <small style="float: right;">(146/353)</small></div>
            </div>
            <div class="question-content">A company uses AWS and has a <span class="key-service">VPC</span> that contains critical compute infrastructure with predictable traffic patterns. The company has configured <span class="key-service">VPC</span> flow logs that are published to a log group in <span class="key-service">Amazon CloudWatch</span> Logs. The company's DevOps team needs to configure a monitoring solution for the <span class="key-service">VPC</span> flow logs to identify anomalies in network traffic to the <span class="key-service">VPC</span> over time. If the monitoring solution detects an anomaly, the company needs the ability to initiate a response to the anomaly. How should the DevOps team configure the monitoring solution to meet these requirements? B (60%) A (40%)</div>
            <div class="options-container">                <div class="option correct-answer"><strong>A.</strong> Create an Amazon Kinesis data stream. Subscribe the log group to the data stream. Configure Amazon Kinesis Data Analytics to detect log anomalies in the data stream. Create an <span class="key-service">AWS Lambda</span> function to use as the output of the data stream. Configure the Lambda function to write to the default Amazon EventBridge event bus in the event of an anomaly finding.</div>                <div class="option"><strong>B.</strong> Create an Amazon Kinesis Data Firehose delivery stream that delivers events to an <span class="key-service">Amazon S3</span> bucket. Subscribe the log group to the delivery stream. Configure Amazon Lookout for Metrics to monitor the data in the S3 bucket for anomalies. Create an <span class="key-service">AWS Lambda</span> function to run in response to Lookout for Metrics anomaly findings. Configure the Lambda function to publish to the default Amazon EventBridge event bus.</div>                <div class="option"><strong>C.</strong> Create an <span class="key-service">AWS Lambda</span> function to detect anomalies. Configure the Lambda function to publish an event to the default Amazon EventBridge event bus if the Lambda function detects an anomaly. Subscribe the Lambda function to the log group.</div>                <div class="option"><strong>D.</strong> Create an Amazon Kinesis data stream. Subscribe the log group to the data stream. Create an <span class="key-service">AWS Lambda</span> function to detect log anomalies. Configure the Lambda function to write to the default Amazon EventBridge event bus if the Lambda function detects an anomaly. Set the Lambda function as the processor for the data stream.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司使用AWS，拥有包含关键计算基础设施和可预测流量模式的VPC。公司已配置VPC flow logs发布到Amazon CloudWatch Logs中的日志组。DevOps团队需要为VPC flow logs配置监控解决方案，以识别网络流量异常并在检测到异常时能够启动响应。 <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 创建Amazon Kinesis data stream，将日志组订阅到数据流，配置Amazon Kinesis Data Analytics检测数据流中的日志异常，创建AWS Lambda函数作为数据流输出，配置Lambda函数在发现异常时写入默认Amazon EventBridge事件总线。</div> <div class="option-analysis"><strong>B.</strong> 创建Amazon Kinesis Data Firehose delivery stream将事件传送到Amazon S3存储桶，将日志组订阅到delivery stream，配置Amazon Lookout for Metrics监控S3存储桶中的数据异常，创建AWS Lambda函数响应Lookout for Metrics异常发现，配置Lambda函数发布到默认Amazon EventBridge事件总线。</div> <div class="option-analysis"><strong>C.</strong> 创建AWS Lambda函数检测异常，配置Lambda函数在检测到异常时发布事件到默认Amazon EventBridge事件总线，将Lambda函数订阅到日志组。</div> <div class="option-analysis"><strong>D.</strong> 创建Amazon Kinesis data stream，将日志组订阅到数据流，创建AWS Lambda函数检测日志异常，配置Lambda函数在检测到异常时写入默认Amazon EventBridge事件总线，将Lambda函数设置为数据流的处理器。<div class="section-title"><strong>核心要求:</strong></div> 为VPC flow logs配置异常检测监控解决方案并支持自动响应 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• Kinesis Data Analytics-专门用于实时流数据异常检测的托管服务 </div><div class="compact-content">• CloudWatch Logs订阅-将日志流实时传输到其他服务进行处理 </div><div class="compact-content">• EventBridge-事件驱动架构的中央事件总线 <div class="section-title"><strong>正确答案A:</strong></div> 使用Kinesis Data Analytics的内置机器学习算法进行实时异常检测，通过Kinesis data stream实现高吞吐量数据传输，Lambda函数处理异常结果并触发EventBridge事件响应 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项B-Lookout for Metrics主要用于业务指标监控而非网络流量日志异常检测，且通过S3的批处理方式无法实现实时监控 </div><div class="compact-content">• 选项C-Lambda函数需要自行实现复杂的异常检测算法，缺乏专业的流数据处理能力，不适合大规模VPC flow logs分析 </div><div class="compact-content">• 选项D-Lambda函数作为数据流处理器需要自建异常检测逻辑，没有利用AWS托管的机器学习异常检测服务 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-Kinesis Data Analytics提供实时流处理和内置异常检测算法 </div><div class="compact-content">• 成本-使用托管服务避免自建异常检测算法的开发和维护成本 </div><div class="compact-content">• 可扩展性-Kinesis服务自动扩展处理大规模VPC flow logs数据</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: A</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-147">
            <div class="question-header">
                <div class="question-title">Question #147 ✅ ⚪ <small style="float: right;">(147/353)</small></div>
            </div>
            <div class="question-content">AnyCompany is using <span class="key-service">AWS Organizations</span> to create and manage multiple AWS accounts. AnyCompany recently acquired a smaller company, Example Corp. During the acquisition process, Example Corp's single AWS account joined AnyCompany's management account through an Organizations invitation. AnyCompany moved the new member account under an OU that is dedicated to Example Corp. AnyCompany's DevOps engineer has an IAM user that assumes a role that is named OrganizationAccountAccessRole to access member accounts. This role is configured with a full access policy. When the DevOps engineer tries to use the AWS Management Console to assume the role in Example Corp's new member account, the DevOps engineer receives the following error message: "Invalid information in one or more fields. Check your information or contact your administrator." Which solution will give the DevOps engineer access to the new member account? C (89%) D (6%)</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> In the management account, grant the DevOps engineer's IAM user permission to assume the OrganizationAccountAccessRole IAM role in the new member account.</div>                <div class="option"><strong>B.</strong> In the management account, create a new <span class="key-service">SCP</span>. In the <span class="key-service">SCP</span>, grant the DevOps engineer's IAM user full access to all resources in the new member account. Attach the <span class="key-service">SCP</span> to the OU that contains the new member account.</div>                <div class="option"><strong>C.</strong> In the new member account, create a new IAM role that is named OrganizationAccountAccessRole. Attach the AdministratorAccess AWS managed policy to the role. In the role's trust policy, grant the management account permission to assume the role.</div>                <div class="option correct-answer"><strong>D.</strong> In the new member account, edit the trust policy for the OrganizationAccountAccessRole IAM role. Grant the management account permission to assume the role.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> AnyCompany使用AWS Organizations创建和管理多个AWS账户。AnyCompany最近收购了一家小公司Example Corp。在收购过程中，Example Corp的单个AWS账户通过Organizations邀请加入了AnyCompany的管理账户。AnyCompany将新成员账户移动到专门为Example Corp设立的OU下。AnyCompany的DevOps工程师有一个IAM用户，该用户承担名为OrganizationAccountAccessRole的角色来访问成员账户。此角色配置了完全访问策略。当DevOps工程师尝试使用AWS Management Console在Example Corp的新成员账户中承担该角色时，收到错误消息："一个或多个字段中的信息无效。请检查您的信息或联系管理员。"哪个解决方案能让DevOps工程师访问新成员账户？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 在管理账户中，授予DevOps工程师的IAM用户在新成员账户中承担OrganizationAccountAccessRole IAM角色的权限。</div> <div class="option-analysis"><strong>B.</strong> 在管理账户中，创建新的SCP。在SCP中，授予DevOps工程师的IAM用户对新成员账户中所有资源的完全访问权限。将SCP附加到包含新成员账户的OU。</div> <div class="option-analysis"><strong>C.</strong> 在新成员账户中，创建名为OrganizationAccountAccessRole的新IAM角色。将AdministratorAccess AWS托管策略附加到该角色。在角色的信任策略中，授予管理账户承担该角色的权限。</div> <div class="option-analysis"><strong>D.</strong> 在新成员账户中，编辑OrganizationAccountAccessRole IAM角色的信任策略。授予管理账户承担该角色的权限。<div class="section-title"><strong>核心要求:</strong></div> 解决跨账户角色承担失败问题，使DevOps工程师能够访问通过收购加入的成员账户。 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• <span class="key-service">AWS Organizations</span> - 多账户管理服务，支持跨账户角色承担 </div><div class="compact-content">• IAM Cross-Account Role - 允许一个账户中的用户承担另一个账户中的角色 <div class="section-title"><strong>正确答案D:</strong></div> 通过收购加入的账户中OrganizationAccountAccessRole角色的信任策略可能不包含管理账户，需要编辑信任策略明确授权管理账户承担该角色。 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A - 管理账户中的权限配置不是问题根源，问题在于成员账户的角色信任策略 </div><div class="compact-content">• 选项B - SCP是权限边界控制，不能解决角色信任关系问题，且SCP不能授予权限 </div><div class="compact-content">• 选项C - 角色可能已存在，重新创建会产生冲突，只需修改现有角色的信任策略 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能 - 修改信任策略是最直接的解决方案 </div><div class="compact-content">• 成本 - 无额外成本，仅需配置变更 </div><div class="compact-content">• 可扩展性 - 保持现有角色结构，便于后续管理</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: D</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-148">
            <div class="question-header">
                <div class="question-title">Question #148 ✅ ⚪ <small style="float: right;">(148/353)</small></div>
            </div>
            <div class="question-content">A DevOps engineer is designing an application that integrates with a legacy REST API. The application has an <span class="key-service">AWS Lambda</span> function that reads records from an Amazon Kinesis data stream. The Lambda function sends the records to the legacy REST API. Approximately 10% of the records that the Lambda function sends from the Kinesis data stream have data errors and must be processed manually. The Lambda function event source configuration has an Amazon Simple Queue Service (<span class="key-service">Amazon SQS</span>) dead-letter queue as an on-failure destination. The DevOps engineer has configured the Lambda function to process records in batches and has implemented retries in case of failure. During testing, the DevOps engineer notices that the dead-letter queue contains many records that have no data errors and that already have been processed by the legacy REST API. The DevOps engineer needs to configure the Lambda function's event source options to reduce the number of errorless records that are sent to the dead-letter queue. Which solution will meet these requirements? B (100%)</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Increase the retry attempts.</div>                <div class="option correct-answer"><strong>B.</strong> Configure the setting to split the batch when an error occurs.</div>                <div class="option"><strong>C.</strong> Increase the concurrent batches per shard.</div>                <div class="option"><strong>D.</strong> Decrease the maximum age of record.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一名DevOps工程师正在设计一个与遗留REST API集成的应用程序。该应用程序有一个AWS Lambda函数从Amazon Kinesis数据流中读取记录。Lambda函数将记录发送到遗留REST API。Lambda函数从Kinesis数据流发送的记录中大约10%有数据错误，必须手动处理。Lambda函数事件源配置有一个Amazon SQS死信队列作为失败时的目标。DevOps工程师已配置Lambda函数批量处理记录，并在失败时实现重试。在测试期间，DevOps工程师注意到死信队列包含许多没有数据错误且已被遗留REST API处理的记录。DevOps工程师需要配置Lambda函数的事件源选项以减少发送到死信队列的无错误记录数量。 <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 增加重试次数</div> <div class="option-analysis"><strong>B.</strong> 配置在发生错误时拆分批次的设置</div> <div class="option-analysis"><strong>C.</strong> 增加每个分片的并发批次数</div> <div class="option-analysis"><strong>D.</strong> 减少记录的最大存活时间<div class="section-title"><strong>核心要求:</strong></div> 减少无错误记录被错误发送到死信队列的数量 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• Lambda - 批量处理Kinesis记录并发送到REST API </div><div class="compact-content">• Kinesis Data Streams - 提供数据流处理能力 </div><div class="compact-content">• SQS死信队列 - 接收处理失败的记录 <div class="section-title"><strong>正确答案B:</strong></div> 启用批次拆分功能后，当批次中部分记录失败时，Lambda会将批次拆分为更小的子批次重新处理，避免将整个批次(包括成功记录)发送到死信队列 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A - 增加重试次数不能解决批次中成功记录被误送到死信队列的问题 </div><div class="compact-content">• 选项C - 增加并发批次不能解决批次内记录混合处理的问题 </div><div class="compact-content">• 选项D - 减少记录存活时间会导致更多记录过期，加剧问题 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能 - 批次拆分减少重复处理，提高整体处理效率 </div><div class="compact-content">• 成本 - 避免无错误记录的重复处理，降低计算成本 </div><div class="compact-content">• 可扩展性 - 精确的错误处理机制支持大规模数据流处理</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: B</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-149">
            <div class="question-header">
                <div class="question-title">Question #149 ✅ ⚪ <small style="float: right;">(149/353)</small></div>
            </div>
            <div class="question-content">A company has microservices running in <span class="key-service">AWS Lambda</span> that read data from <span class="key-service">Amazon DynamoDB</span>. The Lambda code is manually deployed by developers after successful testing. The company now needs the tests and deployments to be automated and run in the cloud. Additionally, traffic to the new versions of each microservice should be incrementally shifted over time after deployment. What solution meets all the requirements, ensuring the MOST developer velocity? C (94%) 6%</div>
            <div class="options-container">                <div class="option correct-answer"><strong>A.</strong> Create an <span class="key-service">AWS CodePipeline</span> configuration and set up a post-commit hook to trigger the pipeline after tests have passed. Use <span class="key-service">AWS CodeDeploy</span> and create a Canary deployment configuration that specifies the percentage of traffic and interval.</div>                <div class="option"><strong>B.</strong> Create an <span class="key-service">AWS CodeBuild</span> configuration that triggers when the test code is pushed. Use <span class="key-service">AWS CloudFormation</span> to trigger an <span class="key-service">AWS CodePipeline</span> configuration that deploys the new Lambda versions and specifies the traffic shift percentage and interval.</div>                <div class="option"><strong>C.</strong> Create an <span class="key-service">AWS CodePipeline</span> configuration and set up the source code step to trigger when code is pushed. Set up the build step to use <span class="key-service">AWS CodeBuild</span> to run the tests. Set up an <span class="key-service">AWS CodeDeploy</span> configuration to deploy, then select the CodeDeployDefault.LambdaLinear10PercentEvery3Minutes option.</div>                <div class="option"><strong>D.</strong> Use the AWS CLI to set up a post-commit hook that uploads the code to an <span class="key-service">Amazon S3</span> bucket after tests have passed. Set up an S3 event trigger that runs a Lambda function that deploys the new version. Use an interval in the Lambda function to deploy the code over time at the required percentage.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司有运行在AWS Lambda中的微服务，从Amazon DynamoDB读取数据。Lambda代码在成功测试后由开发人员手动部署。公司现在需要测试和部署自动化并在云中运行。此外，部署后每个微服务新版本的流量应随时间逐步切换。什么解决方案满足所有要求，确保最高的开发速度？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 创建AWS CodePipeline配置并设置post-commit hook在测试通过后触发pipeline。使用AWS CodeDeploy创建Canary部署配置，指定流量百分比和间隔。</div> <div class="option-analysis"><strong>B.</strong> 创建AWS CodeBuild配置，在推送测试代码时触发。使用AWS CloudFormation触发AWS CodePipeline配置，部署新Lambda版本并指定流量切换百分比和间隔。</div> <div class="option-analysis"><strong>C.</strong> 创建AWS CodePipeline配置并设置源代码步骤在代码推送时触发。设置构建步骤使用AWS CodeBuild运行测试。设置AWS CodeDeploy配置进行部署，然后选择CodeDeployDefault.LambdaLinear10PercentEvery3Minutes选项。</div> <div class="option-analysis"><strong>D.</strong> 使用AWS CLI设置post-commit hook在测试通过后将代码上传到Amazon S3存储桶。设置S3事件触发器运行Lambda函数部署新版本。在Lambda函数中使用间隔按所需百分比随时间部署代码。<div class="section-title"><strong>核心要求:</strong></div> 自动化测试部署并实现Lambda微服务的渐进式流量切换 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• <span class="key-service">AWS CodePipeline</span>-提供完整的CI/CD自动化流水线 </div><div class="compact-content">• <span class="key-service">AWS CodeDeploy</span>-支持Lambda函数的渐进式部署和流量切换 <div class="section-title"><strong>正确答案A:</strong></div> 使用CodePipeline实现完整自动化流程，CodeDeploy的Canary配置提供精确的流量控制和时间间隔设置，满足所有自动化和渐进部署要求 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项B-使用CloudFormation触发CodePipeline的架构过于复杂，不符合最高开发速度要求 </div><div class="compact-content">• 选项C-CodeDeployDefault.LambdaLinear10PercentEvery3Minutes是固定配置，缺乏灵活的流量百分比控制 </div><div class="compact-content">• 选项D-基于S3和Lambda的自定义解决方案缺乏成熟的CI/CD功能，开发和维护成本高 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-CodePipeline提供原生CI/CD集成，CodeDeploy确保零停机部署 </div><div class="compact-content">• 成本-使用托管服务避免自定义开发成本，按使用量付费 </div><div class="compact-content">• 可扩展性-支持多微服务并行部署，灵活的流量切换策略</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: A</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-150">
            <div class="question-header">
                <div class="question-title">Question #150 ✅ ⚪ <small style="float: right;">(150/353)</small></div>
            </div>
            <div class="question-content">A company is building a web and mobile application that uses a serverless architecture powered by <span class="key-service">AWS Lambda</span> and <span class="key-service">Amazon API Gateway</span>. The company wants to fully automate the backend Lambda deployment based on code that is pushed to the appropriate environment branch in an <span class="key-service">AWS CodeCommit</span> repository. The deployment must have the following: <div class="compact-content">• Separate environment pipelines for testing and production </div><div class="compact-content">• Automatic deployment that occurs for test environments only Which steps should be taken to meet these requirements? C (100%) Unlock free, top-quality video courses on ExamTopics with a simple registration. Enhance your learning with our expertly curated content and educational resources designed for ExamTopics!</div></div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Configure a new <span class="key-service">AWS CodePipeline</span> service. Create a CodeCommit repository for each environment. Set up CodePipeline to retrieve the source code from the appropriate repository. Set up the deployment step to deploy the Lambda functions with <span class="key-service">AWS CloudFormation</span>.</div>                <div class="option"><strong>B.</strong> Create two <span class="key-service">AWS CodePipeline</span> configurations for test and production environments. Configure the production pipeline to have a manual approval step. Create a CodeCommit repository for each environment. Set up each CodePipeline to retrieve the source code from the appropriate repository. Set up the deployment step to deploy the Lambda functions with <span class="key-service">AWS CloudFormation</span>.</div>                <div class="option correct-answer"><strong>C.</strong> Create two <span class="key-service">AWS CodePipeline</span> configurations for test and production environments. Configure the production pipeline to have a manual approval step. Create one CodeCommit repository with a branch for each environment. Set up each CodePipeline to retrieve the source code from the appropriate branch in the repository. Set up the deployment step to deploy the Lambda functions with <span class="key-service">AWS CloudFormation</span>.</div>                <div class="option"><strong>D.</strong> Create an <span class="key-service">AWS CodeBuild</span> configuration for test and production environments. Configure the production pipeline to have a manual approval step. Create one CodeCommit repository with a branch for each environment. Push the Lambda function code to an <span class="key-service">Amazon S3</span> bucket. Set up the deployment step to deploy the Lambda functions from the S3 bucket.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司正在构建使用AWS Lambda和Amazon API Gateway驱动的无服务器架构的Web和移动应用程序。公司希望基于推送到AWS CodeCommit存储库中相应环境分支的代码，完全自动化后端Lambda部署。部署必须满足：为测试和生产环境提供独立的环境管道；仅对测试环境进行自动部署。 <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 配置新的AWS CodePipeline服务，为每个环境创建CodeCommit存储库，设置CodePipeline从相应存储库检索源代码，设置部署步骤使用AWS CloudFormation部署Lambda函数。</div> <div class="option-analysis"><strong>B.</strong> 为测试和生产环境创建两个AWS CodePipeline配置，配置生产管道具有手动批准步骤，为每个环境创建CodeCommit存储库，设置每个CodePipeline从相应存储库检索源代码，设置部署步骤使用AWS CloudFormation部署Lambda函数。</div> <div class="option-analysis"><strong>C.</strong> 为测试和生产环境创建两个AWS CodePipeline配置，配置生产管道具有手动批准步骤，创建一个CodeCommit存储库并为每个环境设置分支，设置每个CodePipeline从存储库的相应分支检索源代码，设置部署步骤使用AWS CloudFormation部署Lambda函数。</div> <div class="option-analysis"><strong>D.</strong> 为测试和生产环境创建AWS CodeBuild配置，配置生产管道具有手动批准步骤，创建一个CodeCommit存储库并为每个环境设置分支，将Lambda函数代码推送到Amazon S3存储桶，设置部署步骤从S3存储桶部署Lambda函数。<div class="section-title"><strong>核心要求:</strong></div> 实现基于分支的自动化Lambda部署，测试环境自动部署，生产环境需手动批准 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• <span class="key-service">AWS CodePipeline</span>-提供CI/CD管道自动化部署 </div><div class="compact-content">• <span class="key-service">AWS CodeCommit</span>-Git代码存储库支持分支管理 </div><div class="compact-content">• <span class="key-service">AWS CloudFormation</span>-基础设施即代码部署Lambda函数 <div class="section-title"><strong>正确答案C:</strong></div> 使用单一CodeCommit存储库的分支策略，两个独立CodePipeline管道，生产管道包含手动批准步骤，通过CloudFormation部署Lambda函数 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A-缺少生产环境手动批准步骤，不符合"仅测试环境自动部署"要求 </div><div class="compact-content">• 选项B-为每个环境创建独立存储库，不符合题目要求的"推送到相应环境分支" </div><div class="compact-content">• 选项D-使用CodeBuild而非CodePipeline作为主要CI/CD服务，架构不完整 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-分支策略简化代码管理，CloudFormation确保一致性部署 </div><div class="compact-content">• 成本-单一存储库降低管理成本，手动批准控制生产部署风险 </div><div class="compact-content">• 可扩展性-分支模式支持多环境扩展，CodePipeline提供灵活的工作流配置</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: C</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-151">
            <div class="question-header">
                <div class="question-title">Question #151 ✅ ⚪ <small style="float: right;">(151/353)</small></div>
            </div>
            <div class="question-content">A DevOps engineer wants to find a solution to migrate an application from on premises to AWS. The application is running on Linux and needs to run on specific versions of Apache Tomcat, HAProxy, and Varnish Cache to function properly. The application's operating system-level parameters require tuning. The solution must include a way to automate the deployment of new application versions. The infrastructure should be scalable and faulty servers should be replaced automatically. Which solution should the DevOps engineer use? D (89%) 11%</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Upload the application as a Docker image that contains all the necessary software to <span class="key-service">Amazon ECR</span>. Create an <span class="key-service">Amazon ECS</span> cluster using an <span class="key-service">AWS Fargate</span> launch type and an Auto Scaling group. Create an <span class="key-service">AWS CodePipeline</span> pipeline that uses <span class="key-service">Amazon ECR</span> as a source and <span class="key-service">Amazon ECS</span> as a deployment provider.</div>                <div class="option"><strong>B.</strong> Upload the application code to an <span class="key-service">AWS CodeCommit</span> repository with a saved configuration file to configure and install the software. Create an AWS Elastic Beanstalk web server tier and a load balanced-type environment that uses the Tomcat solution stack. Create an <span class="key-service">AWS CodePipeline</span> pipeline that uses CodeCommit as a source and Elastic Beanstalk as a deployment provider.</div>                <div class="option"><strong>C.</strong> Upload the application code to an <span class="key-service">AWS CodeCommit</span> repository with a set of .ebextensions files to configure and install the software. Create an AWS Elastic Beanstalk worker tier environment that uses the Tomcat solution stack. Create an <span class="key-service">AWS CodePipeline</span> pipeline that uses CodeCommit as a source and Elastic Beanstalk as a deployment provider.</div>                <div class="option correct-answer"><strong>D.</strong> Upload the application code to an <span class="key-service">AWS CodeCommit</span> repository with an appspec.yml file to configure and install the necessary software. Create an <span class="key-service">AWS CodeDeploy</span> deployment group associated with an <span class="key-service">Amazon EC2</span> Auto Scaling group. Create an <span class="key-service">AWS CodePipeline</span> pipeline that uses CodeCommit as a source and CodeDeploy as a deployment provider. Most Voted</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一名DevOps工程师想要找到将应用程序从本地迁移到AWS的解决方案。应用程序运行在Linux上，需要运行在特定版本的Apache Tomcat、HAProxy和Varnish Cache上才能正常工作。应用程序的操作系统级参数需要调优。解决方案必须包括自动化部署新应用程序版本的方法。基础设施应该是可扩展的，故障服务器应该自动替换。 <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 将包含所有必要软件的应用程序作为Docker镜像上传到Amazon ECR，使用AWS Fargate启动类型和Auto Scaling组创建Amazon ECS集群，创建使用Amazon ECR作为源和Amazon ECS作为部署提供商的AWS CodePipeline管道</div> <div class="option-analysis"><strong>B.</strong> 将应用程序代码上传到AWS CodeCommit存储库并保存配置文件来配置和安装软件，创建使用Tomcat解决方案堆栈的AWS Elastic Beanstalk Web服务器层和负载均衡类型环境，创建使用CodeCommit作为源和Elastic Beanstalk作为部署提供商的AWS CodePipeline管道</div> <div class="option-analysis"><strong>C.</strong> 将应用程序代码上传到AWS CodeCommit存储库并使用.ebextensions文件集来配置和安装软件，创建使用Tomcat解决方案堆栈的AWS Elastic Beanstalk工作层环境，创建使用CodeCommit作为源和Elastic Beanstalk作为部署提供商的AWS CodePipeline管道</div> <div class="option-analysis"><strong>D.</strong> 将应用程序代码上传到AWS CodeCommit存储库并使用appspec.yml文件来配置和安装必要软件，创建与Amazon EC2 Auto Scaling组关联的AWS CodeDeploy部署组，创建使用CodeCommit作为源和CodeDeploy作为部署提供商的AWS CodePipeline管道<div class="section-title"><strong>核心要求:</strong></div> 迁移需要特定软件版本和OS级参数调优的Linux应用程序，实现自动化部署和故障自愈 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• CodeDeploy-支持EC2实例上的应用程序部署和配置管理 </div><div class="compact-content">• Auto Scaling-提供自动扩展和故障实例替换 </div><div class="compact-content">• CodePipeline-实现CI/CD自动化部署流程 <div class="section-title"><strong>正确答案D:</strong></div> 使用CodeDeploy配合EC2 Auto Scaling组，通过appspec.yml文件精确控制软件安装和OS参数配置，满足特定版本要求和系统级调优需求 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A-Fargate容器化方案无法进行OS级参数调优，限制了系统配置灵活性 </div><div class="compact-content">• 选项B-Elastic Beanstalk预定义环境限制了对特定软件版本的精确控制 </div><div class="compact-content">• 选项C-Worker tier环境不适合Web应用程序部署，且同样受Beanstalk环境限制 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-需要OS级参数调优和特定软件版本支持 </div><div class="compact-content">• 成本-EC2实例提供最大配置灵活性 </div><div class="compact-content">• 可扩展性-Auto Scaling组提供自动扩展和故障替换</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: D</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-152">
            <div class="question-header">
                <div class="question-title">Question #152 ✅ ⚪ <small style="float: right;">(152/353)</small></div>
            </div>
            <div class="question-content">A DevOps engineer is using <span class="key-service">AWS CodeDeploy</span> across a fleet of <span class="key-service">Amazon EC2</span> instances in an EC2 Auto Scaling group. The associated CodeDeploy deployment group, which is integrated with EC2 Auto Scaling, is configured to perform in-place deployments with CodeDeployDefault.OneAtATime. During an ongoing new deployment, the engineer discovers that, although the overall deployment finished successfully, two out of five instances have the previous application revision deployed. The other three instances have the newest application revision. What is likely causing this issue? A (94%) D (6%)</div>
            <div class="options-container">                <div class="option correct-answer"><strong>A.</strong> The two affected instances failed to fetch the new deployment.</div>                <div class="option"><strong>B.</strong> A failed AfterInstall lifecycle event hook caused the CodeDeploy agent to roll back to the previous version on the affected instances.</div>                <div class="option"><strong>C.</strong> The CodeDeploy agent was not installed in two affected instances.</div>                <div class="option"><strong>D.</strong> EC2 Auto Scaling launched two new instances while the new deployment had not yet finished, causing the previous version to be deployed on the affected instances. Most Voted</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一名DevOps工程师在EC2 Auto Scaling组中的Amazon EC2实例集群上使用AWS CodeDeploy。与EC2 Auto Scaling集成的相关CodeDeploy部署组配置为使用CodeDeployDefault.OneAtATime执行就地部署。在正在进行的新部署期间，工程师发现虽然整体部署成功完成，但五个实例中有两个部署了之前的应用程序版本，其他三个实例部署了最新的应用程序版本。什么可能导致了这个问题？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 两个受影响的实例未能获取新的部署</div> <div class="option-analysis"><strong>B.</strong> 失败的AfterInstall生命周期事件钩子导致CodeDeploy代理在受影响的实例上回滚到之前的版本</div> <div class="option-analysis"><strong>C.</strong> CodeDeploy代理未安装在两个受影响的实例上</div> <div class="option-analysis"><strong>D.</strong> EC2 Auto Scaling在新部署尚未完成时启动了两个新实例，导致之前的版本被部署到受影响的实例上<div class="section-title"><strong>核心要求:</strong></div> 分析CodeDeploy在Auto Scaling环境中部分实例版本不一致的原因 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• <span class="key-service">AWS CodeDeploy</span>-自动化应用程序部署服务，支持滚动部署策略 </div><div class="compact-content">• EC2 Auto Scaling-自动调整EC2实例数量的服务 <div class="section-title"><strong>正确答案A:</strong></div> 在CodeDeploy部署过程中，某些实例可能由于网络问题、权限问题或临时故障无法成功获取新的部署包，导致这些实例保持原有版本而其他实例成功更新 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项B-AfterInstall钩子失败会导致整个部署失败，而不是部分成功部分保持旧版本 </div><div class="compact-content">• 选项C-如果CodeDeploy代理未安装，这些实例不会参与部署过程，部署会报错而非静默保持旧版本 </div><div class="compact-content">• 选项D-CodeDeploy与Auto Scaling集成时会自动处理新启动的实例，确保它们获得正确的应用程序版本 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-OneAtATime策略确保逐个实例部署以维持服务可用性 </div><div class="compact-content">• 成本-就地部署避免了创建新实例的额外成本 </div><div class="compact-content">• 可扩展性-Auto Scaling集成支持动态实例管理和自动部署</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: A</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-153">
            <div class="question-header">
                <div class="question-title">Question #153 ✅ ⚪ <small style="float: right;">(153/353)</small></div>
            </div>
            <div class="question-content">A security team is concerned that a developer can unintentionally attach an Elastic IP address to an <span class="key-service">Amazon EC2</span> instance in production. No developer should be allowed to attach an Elastic IP address to an instance. The security team must be notified if any production server has an Elastic IP address at any time. How can this task be automated? B (100%)</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Use Amazon Athena to query <span class="key-service">AWS CloudTrail</span> logs to check for any associate-address attempts. Create an <span class="key-service">AWS Lambda</span> function to disassociate the Elastic IP address from the instance, and alert the security team.</div>                <div class="option correct-answer"><strong>B.</strong> Attach an IAM policy to the developers' IAM group to deny associate-address permissions. Create a custom <span class="key-service">AWS Config</span> rule to check whether an Elastic IP address is associated with any instance tagged as production, and alert the security team.</div>                <div class="option"><strong>C.</strong> Ensure that all IAM groups associated with developers do not have associate-address permissions. Create a scheduled <span class="key-service">AWS Lambda</span> function to check whether an Elastic IP address is associated with any instance tagged as production, and alert the security team if an instance has an Elastic IP address associated with it.</div>                <div class="option"><strong>D.</strong> Create an <span class="key-service">AWS Config</span> rule to check that all production instances have EC2 IAM roles that include deny associate-address permissions. Verify whether there is an Elastic IP address associated with any instance, and alert the security team if an instance has an Elastic IP address associated with it.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 安全团队担心开发人员可能会无意中将Elastic IP地址附加到生产环境的Amazon EC2实例上。不应允许任何开发人员将Elastic IP地址附加到实例。如果任何生产服务器在任何时候都有Elastic IP地址，必须通知安全团队。如何自动化这项任务？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 使用Amazon Athena查询AWS CloudTrail日志以检查任何associate-address尝试。创建AWS Lambda函数来解除实例与Elastic IP地址的关联，并警告安全团队。</div> <div class="option-analysis"><strong>B.</strong> 将IAM策略附加到开发人员的IAM组以拒绝associate-address权限。创建自定义AWS Config规则来检查是否有Elastic IP地址与任何标记为生产的实例关联，并警告安全团队。</div> <div class="option-analysis"><strong>C.</strong> 确保与开发人员关联的所有IAM组都没有associate-address权限。创建定时AWS Lambda函数来检查是否有Elastic IP地址与任何标记为生产的实例关联，如果实例有关联的Elastic IP地址则警告安全团队。</div> <div class="option-analysis"><strong>D.</strong> 创建AWS Config规则来检查所有生产实例都有包含拒绝associate-address权限的EC2 IAM角色。验证是否有Elastic IP地址与任何实例关联，如果实例有关联的Elastic IP地址则警告安全团队。<div class="section-title"><strong>核心要求:</strong></div> 防止开发人员附加Elastic IP到生产实例并实现自动监控告警 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• IAM-权限控制，拒绝开发人员执行associate-address操作 </div><div class="compact-content">• <span class="key-service">AWS Config</span>-持续监控资源配置变化并触发告警 <div class="section-title"><strong>正确答案B:</strong></div> 通过IAM策略从源头阻止开发人员权限，结合AWS Config规则实现实时监控和自动告警，提供预防+检测的完整解决方案 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A-仅依赖事后检测CloudTrail日志，缺乏预防机制，且Athena查询不是实时的 </div><div class="compact-content">• 选项C-Lambda定时检查存在延迟，不如Config规则的实时性和自动化程度高 </div><div class="compact-content">• 选项D-将权限控制放在EC2角色而非开发人员IAM组上，权限控制点错误 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-Config规则提供实时监控，比定时Lambda和日志查询更及时 </div><div class="compact-content">• 成本-Config规则按使用付费，比持续运行Lambda更经济 </div><div class="compact-content">• 可扩展性-IAM组策略和Config规则可自动应用于所有相关资源</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: B</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-154">
            <div class="question-header">
                <div class="question-title">Question #154 ✅ ⚪ <small style="float: right;">(154/353)</small></div>
            </div>
            <div class="question-content">A company is using <span class="key-service">AWS Organizations</span> to create separate AWS accounts for each of its departments. The company needs to automate the following tasks: <div class="compact-content">• Update the Linux AMIs with new patches periodically and generate a golden image </div><div class="compact-content">• Install a new version of Chef agents in the golden image, if available </div><div class="compact-content">• Provide the newly generated AMIs to the department's accounts Which solution meets these requirements with the LEAST management overhead? B (88%) 13%</div></div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Write a script to launch an <span class="key-service">Amazon EC2</span> instance from the previous golden image. Apply the patch updates. Install the new version of the Chef agent, generate a new golden image, and then modify the AMI permissions to share only the new image with the department's accounts.</div>                <div class="option"><strong>B.</strong> Use <span class="key-service">Amazon EC2</span> Image Builder to create an image pipeline that consists of the base Linux AMI and components to install the Chef agent. Use AWS Resource Access Manager to share EC2 Image Builder images with the department's accounts.</div>                <div class="option correct-answer"><strong>C.</strong> Use an <span class="key-service">AWS Systems Manager</span> Automation runbook to update the Linux AMI by using the previous image. Provide the URL for the script that will update the Chef agent. Use <span class="key-service">AWS Organizations</span> to replace the previous golden image in the department's accounts.</div>                <div class="option"><strong>D.</strong> Use <span class="key-service">Amazon EC2</span> Image Builder to create an image pipeline that consists of the base Linux AMI and components to install the Chef agent. Create a parameter in <span class="key-service">AWS Systems Manager</span> Parameter Store to store the new AMI ID that can be referenced by the department's accounts.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司使用AWS Organizations为每个部门创建独立的AWS账户。公司需要自动化以下任务：定期更新Linux AMI补丁并生成黄金镜像；在黄金镜像中安装新版本的Chef代理（如果可用）；将新生成的AMI提供给各部门账户。哪个解决方案以最少的管理开销满足这些要求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 编写脚本从之前的黄金镜像启动Amazon EC2实例，应用补丁更新，安装新版本Chef代理，生成新黄金镜像，然后修改AMI权限仅与部门账户共享新镜像。</div> <div class="option-analysis"><strong>B.</strong> 使用Amazon EC2 Image Builder创建包含基础Linux AMI和Chef代理安装组件的镜像管道，使用AWS Resource Access Manager与部门账户共享EC2 Image Builder镜像。</div> <div class="option-analysis"><strong>C.</strong> 使用AWS Systems Manager Automation运行手册通过之前的镜像更新Linux AMI，提供更新Chef代理的脚本URL，使用AWS Organizations在部门账户中替换之前的黄金镜像。</div> <div class="option-analysis"><strong>D.</strong> 使用Amazon EC2 Image Builder创建包含基础Linux AMI和Chef代理安装组件的镜像管道，在AWS Systems Manager Parameter Store中创建参数存储新AMI ID供部门账户引用。<div class="section-title"><strong>核心要求:</strong></div> 自动化AMI补丁更新、Chef代理安装和跨账户分发，实现最少管理开销 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• <span class="key-service">AWS Systems Manager</span> Automation-自动化运行手册执行AMI更新和软件安装 </div><div class="compact-content">• <span class="key-service">AWS Organizations</span>-集中管理多账户资源分发和替换 <div class="section-title"><strong>正确答案C:</strong></div> 使用Systems Manager Automation运行手册实现完全自动化的AMI更新流程，结合AWS Organizations的集中管理能力直接在部门账户中替换镜像，无需手动权限管理和共享配置 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A-需要手动编写和维护脚本，手动管理AMI权限共享，管理开销大 </div><div class="compact-content">• 选项B-EC2 Image Builder适合构建新镜像但不适合基于现有镜像的增量更新，且需要额外配置RAM共享 </div><div class="compact-content">• 选项D-Parameter Store只能存储AMI ID引用，部门账户仍需手动获取和使用，未实现自动替换 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-Systems Manager Automation提供原生自动化能力，执行效率高 </div><div class="compact-content">• 成本-利用AWS原生服务避免额外的脚本维护和基础设施成本 </div><div class="compact-content">• 可扩展性-Organizations集中管理支持任意数量部门账户的统一更新</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: C</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-155">
            <div class="question-header">
                <div class="question-title">Question #155 ✅ ⚪ <small style="float: right;">(155/353)</small></div>
            </div>
            <div class="question-content">A company has a mission-critical application on AWS that uses automatic scaling. The company wants the deployment lifecycle to meet the following parameters: <div class="compact-content">• The application must be deployed one instance at a time to ensure the remaining fleet continues to serve traffic. </div><div class="compact-content">• The application is CPU intensive and must be closely monitored. </div><div class="compact-content">• The deployment must automatically roll back if the CPU utilization of the deployment instance exceeds 85%. Which solution will meet these requirements? B (100%)</div></div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Use <span class="key-service">AWS CloudFormation</span> to create an <span class="key-service">AWS Step Functions</span> state machine and Auto Scaling lifecycle hooks to move to one instance at a time into a wait state. Use <span class="key-service">AWS Systems Manager</span> automation to deploy the update to each instance and move it back into the Auto Scaling group using the heartbeat timeout.</div>                <div class="option correct-answer"><strong>B.</strong> Use <span class="key-service">AWS CodeDeploy</span> with <span class="key-service">Amazon EC2</span> Auto Scaling. Configure an alarm tied to the CPU utilization metric. Use the CodeDeployDefault OneAtATime configuration as a deployment strategy. Configure automatic rollbacks within the deployment group to roll back the deployment if the alarm thresholds are breached.</div>                <div class="option"><strong>C.</strong> Use AWS Elastic Beanstalk for load balancing and AWS Auto Scaling. Configure an alarm tied to the CPU utilization metric. Configure rolling deployments with a fixed batch size of one instance. Enable enhanced health to monitor the status of the deployment and roll back based on the alarm previously created.</div>                <div class="option"><strong>D.</strong> Use <span class="key-service">AWS Systems Manager</span> to perform a blue/green deployment with <span class="key-service">Amazon EC2</span> Auto Scaling. Configure an alarm tied to the CPU utilization metric. Deploy updates one at a time. Configure automatic rollbacks within the Auto Scaling group to roll back the deployment if the alarm thresholds are breached.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司在AWS上有一个关键任务应用程序使用自动扩展。公司希望部署生命周期满足以下参数：应用程序必须一次部署一个实例以确保其余实例继续提供流量；应用程序是CPU密集型的必须密切监控；如果部署实例的CPU利用率超过85%，部署必须自动回滚。 <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 使用AWS CloudFormation创建AWS Step Functions状态机和Auto Scaling生命周期钩子，一次将一个实例移动到等待状态。使用AWS Systems Manager自动化部署更新到每个实例，并使用心跳超时将其移回Auto Scaling组。</div> <div class="option-analysis"><strong>B.</strong> 使用AWS CodeDeploy与Amazon EC2 Auto Scaling。配置绑定到CPU利用率指标的告警。使用CodeDeployDefault OneAtATime配置作为部署策略。在部署组内配置自动回滚，当告警阈值被突破时回滚部署。</div> <div class="option-analysis"><strong>C.</strong> 使用AWS Elastic Beanstalk进行负载均衡和AWS Auto Scaling。配置绑定到CPU利用率指标的告警。配置固定批次大小为一个实例的滚动部署。启用增强健康监控部署状态并基于之前创建的告警进行回滚。</div> <div class="option-analysis"><strong>D.</strong> 使用AWS Systems Manager与Amazon EC2 Auto Scaling执行蓝绿部署。配置绑定到CPU利用率指标的告警。一次部署一个更新。在Auto Scaling组内配置自动回滚，当告警阈值被突破时回滚部署。<div class="section-title"><strong>核心要求:</strong></div> 实现一次一个实例的部署策略，同时具备CPU监控和自动回滚能力 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• <span class="key-service">AWS CodeDeploy</span>-专业的应用部署服务，支持精确的部署策略和自动回滚 </div><div class="compact-content">• <span class="key-service">Amazon EC2</span> Auto Scaling-提供实例管理和扩展能力 <div class="section-title"><strong>正确答案B:</strong></div> CodeDeploy的OneAtATime策略天然支持逐个实例部署，结合CloudWatch告警可实现基于CPU阈值的自动回滚机制 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A-过度复杂化，使用Step Functions和生命周期钩子实现简单部署需求不合理 </div><div class="compact-content">• 选项C-Elastic Beanstalk虽支持滚动部署但在精确控制和监控方面不如CodeDeploy专业 </div><div class="compact-content">• 选项D-蓝绿部署不符合"一次一个实例"的渐进式部署要求 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-CodeDeploy提供最精确的部署控制和监控能力 </div><div class="compact-content">• 成本-使用专门的部署服务避免过度工程化 </div><div class="compact-content">• 可扩展性-CodeDeploy与Auto Scaling深度集成支持大规模部署</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: B</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-156">
            <div class="question-header">
                <div class="question-title">Question #156 ✅ ⚪ <small style="float: right;">(156/353)</small></div>
            </div>
            <div class="question-content">A company has a single developer writing code for an automated deployment pipeline. The developer is storing source code in an <span class="key-service">Amazon S3</span> bucket for each project. The company wants to add more developers to the team but is concerned about code conflicts and lost work. The company also wants to build a test environment to deploy newer versions of code for testing and allow developers to automatically deploy to both environments when code is changed in the repository. What is the MOST efficient way to meet these requirements? A (100%)</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Create an <span class="key-service">AWS CodeCommit</span> repository for each project, use the main branch for production code, and create a testing branch for code deployed to testing. Use feature branches to develop new features and pull requests to merge code to testing and main branches.</div>                <div class="option"><strong>B.</strong> Create another S3 bucket for each project for testing code, and use an <span class="key-service">AWS Lambda</span> function to promote code changes between testing and production buckets. Enable versioning on all buckets to prevent code conflicts.</div>                <div class="option"><strong>C.</strong> Create an <span class="key-service">AWS CodeCommit</span> repository for each project, and use the main branch for production and test code with different deployment pipelines for each environment. Use feature branches to develop new features.</div>                <div class="option correct-answer"><strong>D.</strong> Enable versioning and branching on each S3 bucket, use the main branch for production code, and create a testing branch for code deployed to testing. Have developers use each branch for developing in each environment.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司有一个开发人员为自动化部署管道编写代码。开发人员将每个项目的源代码存储在Amazon S3存储桶中。公司想要增加更多开发人员，但担心代码冲突和工作丢失。公司还想构建测试环境来部署新版本代码进行测试，并允许开发人员在代码库中代码更改时自动部署到两个环境。满足这些要求的最高效方式是什么？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 为每个项目创建AWS CodeCommit存储库，使用主分支存放生产代码，创建测试分支用于部署到测试环境，使用功能分支开发新功能并通过拉取请求将代码合并到测试和主分支。</div> <div class="option-analysis"><strong>B.</strong> 为每个项目创建另一个S3存储桶用于测试代码，使用AWS Lambda函数在测试和生产存储桶之间提升代码更改，在所有存储桶上启用版本控制以防止代码冲突。</div> <div class="option-analysis"><strong>C.</strong> 为每个项目创建AWS CodeCommit存储库，使用主分支存放生产和测试代码，为每个环境使用不同的部署管道，使用功能分支开发新功能。</div> <div class="option-analysis"><strong>D.</strong> 在每个S3存储桶上启用版本控制和分支，使用主分支存放生产代码，创建测试分支用于部署到测试环境，让开发人员在每个环境中使用各自分支进行开发。<div class="section-title"><strong>核心要求:</strong></div> 建立支持多开发人员协作的源代码管理和自动化部署系统 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• <span class="key-service">AWS CodeCommit</span>-提供Git版本控制和分支管理功能 </div><div class="compact-content">• <span class="key-service">Amazon S3</span>-对象存储服务，不具备原生版本控制分支功能 <div class="section-title"><strong>正确答案A:</strong></div> CodeCommit提供完整的Git功能，支持分支管理、合并请求和代码冲突解决，是标准的多开发人员协作解决方案 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项B-S3不是源代码管理工具，Lambda促进代码变更复杂且不标准 </div><div class="compact-content">• 选项C-生产和测试代码在同一分支容易造成混乱和部署错误 </div><div class="compact-content">• 选项D-S3原生不支持Git分支功能，这是技术上不可行的方案 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-CodeCommit提供原生Git性能和分布式版本控制 </div><div class="compact-content">• 成本-CodeCommit按使用量计费，比自建Git服务器更经济 </div><div class="compact-content">• 可扩展性-支持无限开发人员和存储库，集成AWS DevOps工具链</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: D</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-157">
            <div class="question-header">
                <div class="question-title">Question #157 ✅ 📝 <small style="float: right;">(157/353)</small></div>
            </div>
            <div class="question-content">A DevOps engineer notices that all <span class="key-service">Amazon EC2</span> instances running behind an Application Load Balancer in an Auto Scaling group are failing to respond to user requests. The EC2 instances are also failing target group HTTP health checks. Upon inspection, the engineer notices the application process was not running in any EC2 instances. There are a significant number of out of memory messages in the system logs. The engineer needs to improve the resilience of the application to cope with a potential application memory leak. Monitoring and notifications should be enabled to alert when there is an issue. Which combination of actions will meet these requirements? (Choose two.) AE (88%) 12%</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Change the Auto Scaling configuration to replace the instances when they fail the load balancer's health checks.</div>                <div class="option"><strong>B.</strong> Change the target group health check HealthCheckIntervalSeconds parameter to reduce the interval between health checks.</div>                <div class="option correct-answer"><strong>C.</strong> Change the target group health checks from HTTP to TCP to check if the port where the application is listening is reachable.</div>                <div class="option"><strong>D.</strong> Enable the available memory consumption metric within the <span class="key-service">Amazon CloudWatch</span> dashboard for the entire Auto Scaling group. Create an alarm when the memory utilization is high. Associate an <span class="key-service">Amazon SNS</span> topic to the alarm to receive notifications when the alarm goes off.</div>                <div class="option correct-answer"><strong>E.</strong> Use the <span class="key-service">Amazon CloudWatch</span> agent to collect the memory utilization of the EC2 instances in the Auto Scaling group. Create an alarm when the memory utilization is high and associate an <span class="key-service">Amazon SNS</span> topic to receive a notification.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一位DevOps工程师注意到Auto Scaling组中Application Load Balancer后面的所有Amazon EC2实例都无法响应用户请求。EC2实例也无法通过目标组HTTP健康检查。检查后，工程师发现应用程序进程在任何EC2实例中都没有运行。系统日志中有大量内存不足消息。工程师需要提高应用程序的弹性以应对潜在的应用程序内存泄漏。应启用监控和通知以在出现问题时发出警报。哪些操作组合将满足这些要求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 更改Auto Scaling配置，当实例未通过负载均衡器的健康检查时替换实例</div> <div class="option-analysis"><strong>B.</strong> 更改目标组健康检查HealthCheckIntervalSeconds参数以减少健康检查之间的间隔</div> <div class="option-analysis"><strong>C.</strong> 将目标组健康检查从HTTP更改为TCP以检查应用程序监听的端口是否可达</div> <div class="option-analysis"><strong>D.</strong> 在Amazon CloudWatch仪表板中为整个Auto Scaling组启用可用内存消耗指标，当内存利用率高时创建警报，将Amazon SNS主题关联到警报以在警报触发时接收通知</div> <div class="option-analysis"><strong>E.</strong> 使用Amazon CloudWatch代理收集Auto Scaling组中EC2实例的内存利用率，当内存利用率高时创建警报并关联Amazon SNS主题以接收通知<div class="section-title"><strong>核心要求:</strong></div> 解决内存泄漏导致的应用程序故障并建立监控告警机制 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• Auto Scaling-自动替换故障实例 </div><div class="compact-content">• CloudWatch Agent-收集内存指标并设置告警 <div class="section-title"><strong>正确答案CE:</strong></div> C选项将健康检查改为TCP可以检测端口可达性而非应用程序状态，当应用程序因内存泄漏崩溃时仍能触发实例替换；E选项通过CloudWatch Agent收集内存指标并设置SNS告警实现主动监控 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A-Auto Scaling默认不使用ELB健康检查，需要显式配置 </div><div class="compact-content">• 选项B-缩短检查间隔无法解决根本的内存泄漏问题 </div><div class="compact-content">• 选项D-EC2默认不提供内存指标，必须使用CloudWatch Agent <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-TCP健康检查能及时发现故障并触发实例替换 </div><div class="compact-content">• 成本-CloudWatch Agent是标准解决方案，成本合理 </div><div class="compact-content">• 可扩展性-适用于整个Auto Scaling组的统一监控策略</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: CE (C、E)</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-158">
            <div class="question-header">
                <div class="question-title">Question #158 ✅ ⚪ <small style="float: right;">(158/353)</small></div>
            </div>
            <div class="question-content">An ecommerce company uses a large number of Amazon Elastic Block Store (Amazon EBS) backed <span class="key-service">Amazon EC2</span> instances. To decrease manual work across all the instances, a DevOps engineer is tasked with automating restart actions when EC2 instance retirement events are scheduled. How can this be accomplished? D (100%)</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Create a scheduled Amazon EventBridge rule to run an <span class="key-service">AWS Systems Manager</span> Automation runbook that checks if any EC2 instances are scheduled for retirement once a week. If the instance is scheduled for retirement, the runbook will hibernate the instance.</div>                <div class="option"><strong>B.</strong> Enable EC2 Auto Recovery on all of the instances. Create an <span class="key-service">AWS Config</span> rule to limit the recovery to occur during a maintenance window only.</div>                <div class="option correct-answer"><strong>C.</strong> Reboot all EC2 instances during an approved maintenance window that is outside of standard business hours. Set up <span class="key-service">Amazon CloudWatch</span> alarms to send a notification in case any instance is failing EC2 instance status checks.</div>                <div class="option"><strong>D.</strong> Set up an AWS Health Amazon EventBridge rule to run <span class="key-service">AWS Systems Manager</span> Automation runbooks that stop and start the EC2 instance when a retirement scheduled event occurs.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家电商公司使用大量基于Amazon EBS的Amazon EC2实例。为了减少所有实例的手动工作，DevOps工程师需要在EC2实例退役事件被调度时自动化重启操作。如何实现这一目标？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 创建一个定时的Amazon EventBridge规则来运行AWS Systems Manager Automation runbook，每周检查是否有EC2实例被安排退役。如果实例被安排退役，runbook将休眠该实例。</div> <div class="option-analysis"><strong>B.</strong> 在所有实例上启用EC2 Auto Recovery。创建AWS Config规则以限制恢复仅在维护窗口期间发生。</div> <div class="option-analysis"><strong>C.</strong> 在标准营业时间之外的批准维护窗口期间重启所有EC2实例。设置Amazon CloudWatch告警以在任何实例未通过EC2实例状态检查时发送通知。</div> <div class="option-analysis"><strong>D.</strong> 设置AWS Health Amazon EventBridge规则来运行AWS Systems Manager Automation runbooks，在退役调度事件发生时停止并启动EC2实例。<div class="section-title"><strong>核心要求:</strong></div> 自动化处理EC2实例退役事件的重启操作 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• AWS Health - 提供AWS资源健康状态和退役事件通知 </div><div class="compact-content">• EventBridge - 事件驱动的自动化触发器 </div><div class="compact-content">• Systems Manager Automation - 自动化运维任务执行 <div class="section-title"><strong>正确答案D:</strong></div> 使用AWS Health监控退役事件，通过EventBridge触发Systems Manager Automation实现精确的事件驱动自动化 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A - 使用定时检查而非事件驱动，且休眠操作无法解决退役问题 </div><div class="compact-content">• 选项B - Auto Recovery用于硬件故障恢复，不适用于计划性退役事件 </div><div class="compact-content">• 选项C - 预防性重启所有实例过于粗暴，缺乏针对性且影响业务 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能 - 事件驱动响应比定时检查更及时准确 </div><div class="compact-content">• 成本 - 仅对需要处理的实例执行操作，避免不必要的重启 </div><div class="compact-content">• 可扩展性 - 自动化流程可处理任意数量的实例退役事件</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: C</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-159">
            <div class="question-header">
                <div class="question-title">Question #159 ✅ ⚪ <small style="float: right;">(159/353)</small></div>
            </div>
            <div class="question-content">A company manages AWS accounts for application teams in AWS Control Tower. Individual application teams are responsible for securing their respective AWS accounts. A DevOps engineer needs to enable <span class="key-service">Amazon GuardDuty</span> for all AWS accounts in which the application teams have not already enabled GuardDuty. The DevOps engineer is using <span class="key-service">AWS CloudFormation</span> StackSets from the AWS Control Tower management account. How should the DevOps engineer configure the CloudFormation template to prevent failure during the StackSets deployment? A (100%)</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Create a CloudFormation custom resource that invokes an <span class="key-service">AWS Lambda</span> function. Configure the Lambda function to conditionally enable GuardDuty if GuardDuty is not already enabled in the accounts.</div>                <div class="option correct-answer"><strong>B.</strong> Use the Conditions section of the CloudFormation template to enable GuardDuty in accounts where GuardDuty is not already enabled.</div>                <div class="option"><strong>C.</strong> Use the CloudFormation Fn::GetAtt intrinsic function to check whether GuardDuty is already enabled. If GuardDuty is not already enabled, use the Resources section of the CloudFormation template to enable GuardDuty.</div>                <div class="option"><strong>D.</strong> Manually discover the list of AWS account IDs where GuardDuty is not enabled. Use the CloudFormation Fn::ImportValue intrinsic function to import the list of account IDs into the CloudFormation template to skip deployment for the listed AWS accounts.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司在AWS Control Tower中管理应用团队的AWS账户。各个应用团队负责保护各自的AWS账户。DevOps工程师需要为所有应用团队尚未启用Amazon GuardDuty的AWS账户启用GuardDuty。DevOps工程师正在从AWS Control Tower管理账户使用AWS CloudFormation StackSets。DevOps工程师应该如何配置CloudFormation模板以防止StackSets部署期间失败？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 创建一个调用AWS Lambda函数的CloudFormation自定义资源。配置Lambda函数在账户中GuardDuty尚未启用时有条件地启用GuardDuty。</div> <div class="option-analysis"><strong>B.</strong> 使用CloudFormation模板的Conditions部分在GuardDuty尚未启用的账户中启用GuardDuty。</div> <div class="option-analysis"><strong>C.</strong> 使用CloudFormation Fn::GetAtt内置函数检查GuardDuty是否已启用。如果GuardDuty未启用，使用CloudFormation模板的Resources部分启用GuardDuty。</div> <div class="option-analysis"><strong>D.</strong> 手动发现未启用GuardDuty的AWS账户ID列表。使用CloudFormation Fn::ImportValue内置函数将账户ID列表导入CloudFormation模板以跳过列出的AWS账户的部署。<div class="section-title"><strong>核心要求:</strong></div> 在多账户环境中使用StackSets有条件地启用GuardDuty，避免重复启用导致的部署失败 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• AWS Control Tower-多账户管理和治理服务 </div><div class="compact-content">• CloudFormation StackSets-跨多个账户和区域部署模板 </div><div class="compact-content">• <span class="key-service">Amazon GuardDuty</span>-威胁检测服务 <div class="section-title"><strong>正确答案B:</strong></div> 使用CloudFormation Conditions部分可以在模板中定义条件逻辑，在StackSets部署时动态检查GuardDuty状态并有条件地创建资源，避免重复启用导致的失败 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A-自定义资源增加复杂性，需要额外的Lambda函数维护，不是最佳实践 </div><div class="compact-content">• 选项C-Fn::GetAtt无法在部署前检查服务状态，会导致模板执行失败 </div><div class="compact-content">• 选项D-手动发现账户列表不可扩展，Fn::ImportValue不适用于此场景 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-Conditions部分在模板执行时直接评估，无额外延迟 </div><div class="compact-content">• 成本-使用原生CloudFormation功能，无额外Lambda或自定义资源成本 </div><div class="compact-content">• 可扩展性-Conditions支持动态评估，适应账户数量变化和GuardDuty状态变更</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: B</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-160">
            <div class="question-header">
                <div class="question-title">Question #160 ✅ 📝 <small style="float: right;">(160/353)</small></div>
            </div>
            <div class="question-content">A company has an AWS Control Tower landing zone. The company's DevOps team creates a workload OU. A development OU and a production OU are nested under the workload OU. The company grants users full access to the company's AWS accounts to deploy applications. The DevOps team needs to allow only a specific management IAM role to manage the IAM roles and policies of any AWS accounts in only the production OU. Which combination of steps will meet these requirements? (Choose two.) BE (95%) 5%</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Create an <span class="key-service">SCP</span> that denies full access with a condition to exclude the management IAM role for the organization root.</div>                <div class="option"><strong>B.</strong> Ensure that the FullAWSAccess <span class="key-service">SCP</span> is applied at the organization root.</div>                <div class="option"><strong>C.</strong> Create an <span class="key-service">SCP</span> that allows IAM related actions. Attach the <span class="key-service">SCP</span> to the development OU.</div>                <div class="option correct-answer"><strong>D.</strong> Create an <span class="key-service">SCP</span> that denies IAM related actions with a condition to exclude the management IAM role. Attach the <span class="key-service">SCP</span> to the workload OU.</div>                <div class="option correct-answer"><strong>E.</strong> Create an <span class="key-service">SCP</span> that denies IAM related actions with a condition to exclude the management IAM role. Attach the <span class="key-service">SCP</span> to the production OU.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司有AWS Control Tower landing zone。DevOps团队创建了工作负载OU，其下嵌套开发OU和生产OU。公司授予用户对AWS账户的完全访问权限来部署应用程序。DevOps团队需要仅允许特定的管理IAM角色来管理仅生产OU中任何AWS账户的IAM角色和策略。 <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 创建一个SCP拒绝完全访问，条件是为组织根排除管理IAM角色</div> <div class="option-analysis"><strong>B.</strong> 确保FullAWSAccess SCP应用于组织根</div> <div class="option-analysis"><strong>C.</strong> 创建一个SCP允许IAM相关操作，将SCP附加到开发OU</div> <div class="option-analysis"><strong>D.</strong> 创建一个SCP拒绝IAM相关操作，条件是排除管理IAM角色，将SCP附加到工作负载OU</div> <div class="option-analysis"><strong>E.</strong> 创建一个SCP拒绝IAM相关操作，条件是排除管理IAM角色，将SCP附加到生产OU<div class="section-title"><strong>核心要求:</strong></div> 限制只有特定管理IAM角色能管理生产OU中的IAM资源 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• AWS Control Tower - 多账户治理和landing zone管理 </div><div class="compact-content">• <span class="key-service">SCP</span> (Service Control Policy) - 组织级权限边界控制 <div class="section-title"><strong>正确答案DE:</strong></div> D选项在工作负载OU级别拒绝IAM操作但排除管理角色，E选项在生产OU级别进一步限制IAM操作但排除管理角色，两者结合确保只有管理角色能在生产环境管理IAM资源 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A - 在组织根级别拒绝完全访问过于宽泛，影响所有OU </div><div class="compact-content">• 选项B - FullAWSAccess允许所有操作，与限制要求相反 </div><div class="compact-content">• 选项C - 允许开发OU的IAM操作不符合限制生产OU的要求 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 安全性 - SCP分层控制确保生产环境IAM权限最小化 </div><div class="compact-content">• 治理 - 通过OU层级实现精确的权限边界管理 </div><div class="compact-content">• <span class="key-point">合规性</span> - 管理角色例外机制保证必要的管理能力</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: DE (D、E)</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-161">
            <div class="question-header">
                <div class="question-title">Question #161 ✅ ⚪ <small style="float: right;">(161/353)</small></div>
            </div>
            <div class="question-content">A company hired a penetration tester to simulate an internal security breach. The tester performed port scans on the company's <span class="key-service">Amazon EC2</span> instances. The company's security measures did not detect the port scans. The company needs a solution that automatically provides notification when port scans are performed on EC2 instances. The company creates and subscribes to an Amazon Simple Notification Service (<span class="key-service">Amazon SNS</span>) topic. What should the company do next to meet the requirement? A (93%) 7%</div>
            <div class="options-container">                <div class="option correct-answer"><strong>A.</strong> Ensure that <span class="key-service">Amazon GuardDuty</span> is enabled. Create an <span class="key-service">Amazon CloudWatch</span> alarm for detected EC2 and port scan findings. Connect the alarm to the SNS topic.</div>                <div class="option"><strong>B.</strong> Ensure that Amazon Inspector is enabled. Create an Amazon EventBridge event for detected network reachability findings that indicate port scans. Connect the event to the SNS topic.</div>                <div class="option"><strong>C.</strong> Ensure that Amazon Inspector is enabled. Create an Amazon EventBridge event for detected CVEs that cause open port vulnerabilities. Connect the event to the SNS topic.</div>                <div class="option"><strong>D.</strong> Ensure that <span class="key-service">AWS CloudTrail</span> is enabled. Create an <span class="key-service">AWS Lambda</span> function to analyze the CloudTrail logs for unusual amounts of traffic from an IP address range. Connect the Lambda function to the SNS topic.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司雇佣渗透测试人员模拟内部安全漏洞。测试人员对公司的Amazon EC2实例执行了端口扫描。公司的安全措施未检测到端口扫描。公司需要一个解决方案，当对EC2实例执行端口扫描时自动提供通知。公司创建并订阅了Amazon SNS主题。公司接下来应该做什么来满足要求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 确保启用Amazon GuardDuty。为检测到的EC2和端口扫描发现创建Amazon CloudWatch告警。将告警连接到SNS主题。</div> <div class="option-analysis"><strong>B.</strong> 确保启用Amazon Inspector。为检测到的指示端口扫描的网络可达性发现创建Amazon EventBridge事件。将事件连接到SNS主题。</div> <div class="option-analysis"><strong>C.</strong> 确保启用Amazon Inspector。为检测到的导致开放端口漏洞的CVE创建Amazon EventBridge事件。将事件连接到SNS主题。</div> <div class="option-analysis"><strong>D.</strong> 确保启用AWS CloudTrail。创建AWS Lambda函数来分析CloudTrail日志中来自IP地址范围的异常流量。将Lambda函数连接到SNS主题。<div class="section-title"><strong>核心要求:</strong></div> 自动检测并通知EC2实例上的端口扫描活动 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• <span class="key-service">Amazon GuardDuty</span>-威胁检测服务，专门检测恶意活动包括端口扫描 </div><div class="compact-content">• <span class="key-service">Amazon CloudWatch</span>-监控服务，可基于GuardDuty发现创建告警 <div class="section-title"><strong>正确答案A:</strong></div> GuardDuty使用机器学习和威胁情报检测端口扫描等恶意活动，CloudWatch告警可自动触发SNS通知 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项B-Inspector主要用于应用程序安全评估，不是实时威胁检测 </div><div class="compact-content">• 选项C-Inspector的CVE检测与端口扫描检测无关 </div><div class="compact-content">• 选项D-CloudTrail记录API调用，无法有效检测网络层端口扫描 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-GuardDuty提供实时威胁检测和自动化响应 </div><div class="compact-content">• 成本-GuardDuty按使用量付费，无需额外开发成本 </div><div class="compact-content">• 可扩展性-GuardDuty自动扩展，支持所有EC2实例监控</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: A</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-162">
            <div class="question-header">
                <div class="question-title">Question #162 ✅ ⚪ <small style="float: right;">(162/353)</small></div>
            </div>
            <div class="question-content">A company runs applications in an Amazon Elastic Kubernetes Service (<span class="key-service">Amazon EKS</span>) cluster. The EKS cluster uses an Application Load Balancer to route traffic to the applications that run in the cluster. A new application that was migrated to the EKS cluster is performing poorly. All the other applications in the EKS cluster maintain appropriate operation. The new application scales out horizontally to the preconfigured maximum number of pods immediately upon deployment, before any user traffic routes to the web application. Which solution will resolve the scaling behavior of the web application in the EKS cluster? B (63%) A (33%)</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Implement the Horizontal Pod Autoscaler in the EKS cluster.</div>                <div class="option correct-answer"><strong>B.</strong> Implement the Vertical Pod Autoscaler in the EKS cluster.</div>                <div class="option"><strong>C.</strong> Implement the Cluster Autoscaler.</div>                <div class="option"><strong>D.</strong> Implement the AWS Load Balancer Controller in the EKS cluster.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司在Amazon EKS集群中运行应用程序，EKS集群使用Application Load Balancer将流量路由到集群中运行的应用程序。迁移到EKS集群的新应用程序性能不佳，集群中其他应用程序运行正常。新应用程序在部署后、任何用户流量路由到Web应用程序之前，立即水平扩展到预配置的最大pod数量。 <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 在EKS集群中实施Horizontal Pod Autoscaler</div> <div class="option-analysis"><strong>B.</strong> 在EKS集群中实施Vertical Pod Autoscaler</div> <div class="option-analysis"><strong>C.</strong> 实施Cluster Autoscaler</div> <div class="option-analysis"><strong>D.</strong> 在EKS集群中实施AWS Load Balancer Controller<div class="section-title"><strong>核心要求:</strong></div> 解决新应用程序在无流量时立即扩展到最大pod数量的异常扩展行为 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• Horizontal Pod Autoscaler-基于CPU/内存等指标水平扩展pod数量 </div><div class="compact-content">• Vertical Pod Autoscaler-自动调整pod的CPU和内存资源请求和限制 <div class="section-title"><strong>正确答案B:</strong></div> VPA通过优化pod资源配置解决资源配置不当导致的异常扩展，调整CPU/内存请求值避免资源不足触发的过度扩展 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A-HPA仍基于指标扩展，无法解决根本的资源配置问题 </div><div class="compact-content">• 选项C-Cluster Autoscaler扩展节点而非解决pod资源配置问题 </div><div class="compact-content">• 选项D-Load Balancer Controller管理负载均衡器，与扩展行为无关 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-VPA优化资源配置提升单pod性能，避免资源浪费 </div><div class="compact-content">• 成本-通过合理资源配置减少不必要的pod扩展，降低资源成本 </div><div class="compact-content">• 可扩展性-VPA提供基于实际需求的智能资源调整机制</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: B</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-163">
            <div class="question-header">
                <div class="question-title">Question #163 ✅ 📝 <small style="float: right;">(163/353)</small></div>
            </div>
            <div class="question-content">A company has an AWS Control Tower landing zone that manages its organization in <span class="key-service">AWS Organizations</span>. The company created an OU structure that is based on the company's requirements. The company's DevOps team has established the core accounts for the solution and an account for all centralized <span class="key-service">AWS CloudFormation</span> and AWS Service Catalog solutions. The company wants to offer a series of customizations that an account can request through AWS Control Tower. Which combination of steps will meet these requirements? (Choose three.) BCF (100%)</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Enable trusted access for CloudFormation with Organizations by using service-managed permissions.</div>                <div class="option"><strong>B.</strong> Create an IAM role that is named AWSControlTowerBlueprintAccess. Configure the role with a trust policy that allows the AWSControlTowerAdmin role in the management account to assume the role. Attach the AWSServiceCatalogAdminFullAccess IAM policy to the AWSControlTowerBlueprintAccess role.</div>                <div class="option correct-answer"><strong>C.</strong> Create a Service Catalog product for each CloudFormation template.</div>                <div class="option"><strong>D.</strong> Create a CloudFormation stack set for each CloudFormation template. Enable automatic deployment for each stack set. Create a CloudFormation stack instance that targets specific OUs.</div>                <div class="option correct-answer"><strong>E.</strong> Deploy the Customizations for AWS Control Tower (CfCT) CloudFormation stack. F. Create a CloudFormation template that contains the resources for each customization. Most Voted</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司有AWS Control Tower登陆区管理其AWS Organizations组织。公司根据需求创建了OU结构。DevOps团队已建立核心账户和一个集中的AWS CloudFormation和AWS Service Catalog解决方案账户。公司希望提供一系列可通过AWS Control Tower请求的自定义功能。 <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 使用服务管理权限为CloudFormation启用与Organizations的可信访问</div> <div class="option-analysis"><strong>B.</strong> 创建名为AWSControlTowerBlueprintAccess的IAM角色，配置信任策略允许管理账户中的AWSControlTowerAdmin角色承担该角色，并附加AWSServiceCatalogAdminFullAccess IAM策略</div> <div class="option-analysis"><strong>C.</strong> 为每个CloudFormation模板创建Service Catalog产品</div> <div class="option-analysis"><strong>D.</strong> 为每个CloudFormation模板创建CloudFormation堆栈集，启用自动部署，创建针对特定OU的CloudFormation堆栈实例</div> <div class="option-analysis"><strong>E.</strong> 部署Customizations for AWS Control Tower (CfCT) CloudFormation堆栈 F. 创建包含每个自定义资源的CloudFormation模板<div class="section-title"><strong>核心要求:</strong></div> 在AWS Control Tower中实现账户可请求的自定义功能 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• AWS Control Tower - 提供多账户治理和自定义框架 </div><div class="compact-content">• Service Catalog - 管理和分发标准化IT服务产品 </div><div class="compact-content">• Customizations for AWS Control Tower (CfCT) - 扩展Control Tower自定义能力 <div class="section-title"><strong>正确答案CE:</strong></div> CfCT提供了Control Tower原生自定义框架，Service Catalog产品形式使账户能够自助请求标准化的自定义功能 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A - 仅启用可信访问不足以实现完整的自定义请求机制 </div><div class="compact-content">• 选项B - 虽然权限配置正确但不是实现自定义功能的核心组件 </div><div class="compact-content">• 选项D - 堆栈集方式缺乏自助服务请求机制，不符合账户主动请求的需求 </div><div class="compact-content">• 选项F - 模板创建是基础步骤但不是实现请求机制的关键 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能 - CfCT提供自动化部署和管理 </div><div class="compact-content">• 成本 - 利用现有Control Tower框架，无额外基础设施成本 </div><div class="compact-content">• 可扩展性 - Service Catalog支持多产品管理和版本控制</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: CE (C、E)</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-164">
            <div class="question-header">
                <div class="question-title">Question #164 ✅ ⚪ <small style="float: right;">(164/353)</small></div>
            </div>
            <div class="question-content">A company runs a workload on <span class="key-service">Amazon EC2</span> instances. The company needs a control that requires the use of Instance Metadata Service Version 2 (IMDSv2) on all EC2 instances in the AWS account. If an EC2 instance does not prevent the use of Instance Metadata Service Version 1 (IMDSv1), the EC2 instance must be terminated. Which solution will meet these requirements? A (100%)</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Set up <span class="key-service">AWS Config</span> in the account. Use a managed rule to check EC2 instances. Configure the rule to remediate the findings by using <span class="key-service">AWS Systems Manager</span> Automation to terminate the instance.</div>                <div class="option"><strong>B.</strong> Create a permissions boundary that prevents the ec2:RunInstance action if the ec2:MetadataHttpTokens condition key is not set to a value of required. Attach the permissions boundary to the IAM role that was used to launch the instance.</div>                <div class="option"><strong>C.</strong> Set up Amazon Inspector in the account. Configure Amazon Inspector to activate deep inspection for EC2 instances. Create an Amazon EventBridge rule for an Inspector2 finding. Set an <span class="key-service">AWS Lambda</span> function as the target to terminate the instance.</div>                <div class="option correct-answer"><strong>D.</strong> Create an Amazon EventBridge rule for the EC2 instance launch successful event. Send the event to an <span class="key-service">AWS Lambda</span> function to inspect the EC2 metadata and to terminate the instance.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司在Amazon EC2实例上运行工作负载。公司需要一个控制措施，要求AWS账户中的所有EC2实例都使用Instance Metadata Service Version 2 (IMDSv2)。如果EC2实例没有阻止使用Instance Metadata Service Version 1 (IMDSv1)，则必须终止该EC2实例。 <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 在账户中设置AWS Config，使用托管规则检查EC2实例，配置规则通过AWS Systems Manager Automation修复发现问题并终止实例。</div> <div class="option-analysis"><strong>B.</strong> 创建权限边界，如果ec2:MetadataHttpTokens条件键未设置为required值则阻止ec2:RunInstance操作，将权限边界附加到用于启动实例的IAM角色。</div> <div class="option-analysis"><strong>C.</strong> 在账户中设置Amazon Inspector，配置Amazon Inspector为EC2实例激活深度检查，为Inspector2发现创建Amazon EventBridge规则，设置AWS Lambda函数作为目标来终止实例。</div> <div class="option-analysis"><strong>D.</strong> 为EC2实例启动成功事件创建Amazon EventBridge规则，将事件发送到AWS Lambda函数来检查EC2元数据并终止实例。<div class="section-title"><strong>核心要求:</strong></div> 强制所有EC2实例使用IMDSv2，检测并自动终止使用IMDSv1的实例 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• EventBridge - 捕获EC2实例启动事件并触发自动化响应 </div><div class="compact-content">• Lambda - 检查实例元数据配置并执行终止操作 </div><div class="compact-content">• EC2 Instance Metadata Service - 提供实例元数据访问控制 <div class="section-title"><strong>正确答案D:</strong></div> 通过EventBridge监听EC2启动事件，触发Lambda函数实时检查实例的IMDSv2配置，如不符合要求立即终止实例，实现主动防护 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A - AWS Config是合规性检查工具，但响应时间较慢，不适合实时防护场景 </div><div class="compact-content">• 选项B - 权限边界只能预防性控制启动权限，无法检查已运行实例的元数据配置 </div><div class="compact-content">• 选项C - Amazon Inspector主要用于安全漏洞扫描，不是专门检查IMDSv2配置的工具 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能 - EventBridge+Lambda提供实时响应和快速检测能力 </div><div class="compact-content">• 成本 - 事件驱动架构按需付费，成本效率高 </div><div class="compact-content">• 可扩展性 - 自动处理所有EC2实例启动事件，无需手动干预</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: D</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-165">
            <div class="question-header">
                <div class="question-title">Question #165 ✅ 📝 <small style="float: right;">(165/353)</small></div>
            </div>
            <div class="question-content">A company builds an application that uses an Application Load Balancer in front of <span class="key-service">Amazon EC2</span> instances that are in an Auto Scaling group. The application is stateless. The Auto Scaling group uses a custom AMI that is fully prebuilt. The EC2 instances do not have a custom bootstrapping process. The AMI that the Auto Scaling group uses was recently deleted. The Auto Scaling group's scaling activities show failures because the AMI ID does not exist. Which combination of steps should a DevOps engineer take to meet these requirements? (Choose three.) ABE (100%)</div>
            <div class="options-container">                <div class="option correct-answer"><strong>A.</strong> Create a new launch template that uses the new AMI.</div>                <div class="option"><strong>B.</strong> Update the Auto Scaling group to use the new launch template.</div>                <div class="option"><strong>C.</strong> Reduce the Auto Scaling group's desired capacity to 0.</div>                <div class="option correct-answer"><strong>D.</strong> Increase the Auto Scaling group's desired capacity by 1.</div>                <div class="option"><strong>E.</strong> Create a new AMI from a running EC2 instance in the Auto Scaling group. F. Create a new AMI by copying the most recent public AMI of the operating system that the EC2 instances use.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司构建了一个应用程序，在Auto Scaling组中的Amazon EC2实例前使用Application Load Balancer。应用程序是无状态的。Auto Scaling组使用完全预构建的自定义AMI。EC2实例没有自定义引导过程。Auto Scaling组使用的AMI最近被删除了。Auto Scaling组的扩展活动显示失败，因为AMI ID不存在。DevOps工程师应该采取哪些步骤组合来满足这些要求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 创建一个使用新AMI的新launch template</div> <div class="option-analysis"><strong>B.</strong> 更新Auto Scaling组以使用新的launch template</div> <div class="option-analysis"><strong>C.</strong> 将Auto Scaling组的期望容量减少到0</div> <div class="option-analysis"><strong>D.</strong> 将Auto Scaling组的期望容量增加1</div> <div class="option-analysis"><strong>E.</strong> 从Auto Scaling组中正在运行的EC2实例创建新AMI F. 通过复制EC2实例使用的操作系统的最新公共AMI来创建新AMI<div class="section-title"><strong>核心要求:</strong></div> 解决AMI被删除导致Auto Scaling组扩展失败的问题 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• Auto Scaling Group - 自动管理EC2实例数量的服务 </div><div class="compact-content">• Launch Template - 定义EC2实例启动配置的模板 </div><div class="compact-content">• AMI - 用于启动EC2实例的镜像模板 <div class="section-title"><strong>正确答案ADE:</strong></div> 需要先从现有实例创建新AMI(E)，然后创建使用新AMI的launch template(A)，最后更新Auto Scaling组配置(B) <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项C - 减少容量到0会导致服务中断，不符合业务连续性要求 </div><div class="compact-content">• 选项D - 在修复AMI问题前增加容量会继续失败 </div><div class="compact-content">• 选项F - 使用公共AMI会丢失原有的自定义配置和应用程序 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能 - 保持现有应用程序配置和性能特性 </div><div class="compact-content">• 成本 - 避免重新构建和配置应用程序的成本 </div><div class="compact-content">• 可扩展性 - 确保Auto Scaling组能够正常扩展运行</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: AD (A、D)</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-166">
            <div class="question-header">
                <div class="question-title">Question #166 ✅ 📝 <small style="float: right;">(166/353)</small></div>
            </div>
            <div class="question-content">A company deploys a web application on <span class="key-service">Amazon EC2</span> instances that are behind an Application Load Balancer (ALB). The company stores the application code in an <span class="key-service">AWS CodeCommit</span> repository. When code is merged to the main branch, an <span class="key-service">AWS Lambda</span> function invokes an <span class="key-service">AWS CodeBuild</span> project. The CodeBuild project packages the code, stores the packaged code in AWS CodeArtifact, and invokes <span class="key-service">AWS Systems Manager</span> Run Command to deploy the packaged code to the EC2 instances. Previous deployments have resulted in defects, EC2 instances that are not running the latest version of the packaged code, and inconsistencies between instances. Which combination of actions should a DevOps engineer take to implement a more reliable deployment solution? (Choose two.) BC (100%)</div>
            <div class="options-container">                <div class="option correct-answer"><strong>A.</strong> Create a pipeline in <span class="key-service">AWS CodePipeline</span> that uses the CodeCommit repository as a source provider. Configure pipeline stages that run the CodeBuild project in parallel to build and test the application. In the pipeline, pass the CodeBuild project output artifact to an <span class="key-service">AWS CodeDeploy</span> action.</div>                <div class="option"><strong>B.</strong> Create a pipeline in <span class="key-service">AWS CodePipeline</span> that uses the CodeCommit repository as a source provider. Create separate pipeline stages that run a CodeBuild project to build and then test the application. In the pipeline, pass the CodeBuild project output artifact to an <span class="key-service">AWS CodeDeploy</span> action.</div>                <div class="option"><strong>C.</strong> Create an <span class="key-service">AWS CodeDeploy</span> application and a deployment group to deploy the packaged code to the EC2 instances. Configure the ALB for the deployment group. Most Voted</div>                <div class="option correct-answer"><strong>D.</strong> Create individual Lambda functions that use <span class="key-service">AWS CodeDeploy</span> instead of Systems Manager to run build, test, and deploy actions.</div>                <div class="option"><strong>E.</strong> Create an <span class="key-service">Amazon S3</span> bucket. Modify the CodeBuild project to store the packages in the S3 bucket instead of in CodeArtifact. Use deploy actions in CodeDeploy to deploy the artifact to the EC2 instances.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司在Application Load Balancer (ALB)后的Amazon EC2实例上部署Web应用程序。公司将应用程序代码存储在AWS CodeCommit存储库中。当代码合并到主分支时，AWS Lambda函数调用AWS CodeBuild项目。CodeBuild项目打包代码，将打包的代码存储在AWS CodeArtifact中，并调用AWS Systems Manager Run Command将打包的代码部署到EC2实例。之前的部署导致了缺陷、EC2实例未运行最新版本的打包代码以及实例间的不一致性。DevOps工程师应该采取哪些操作组合来实现更可靠的部署解决方案？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 在AWS CodePipeline中创建一个使用CodeCommit存储库作为源提供者的管道。配置管道阶段并行运行CodeBuild项目来构建和测试应用程序。在管道中，将CodeBuild项目输出工件传递给AWS CodeDeploy操作。</div> <div class="option-analysis"><strong>B.</strong> 在AWS CodePipeline中创建一个使用CodeCommit存储库作为源提供者的管道。创建单独的管道阶段运行CodeBuild项目来构建然后测试应用程序。在管道中，将CodeBuild项目输出工件传递给AWS CodeDeploy操作。</div> <div class="option-analysis"><strong>C.</strong> 创建AWS CodeDeploy应用程序和部署组来将打包的代码部署到EC2实例。为部署组配置ALB。</div> <div class="option-analysis"><strong>D.</strong> 创建单独的Lambda函数，使用AWS CodeDeploy而不是Systems Manager来运行构建、测试和部署操作。</div> <div class="option-analysis"><strong>E.</strong> 创建Amazon S3存储桶。修改CodeBuild项目将包存储在S3存储桶中而不是CodeArtifact中。使用CodeDeploy中的部署操作将工件部署到EC2实例。<div class="section-title"><strong>核心要求:</strong></div> 解决当前部署方案中的缺陷、版本不一致和实例间差异问题，实现更可靠的部署解决方案 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• <span class="key-service">AWS CodePipeline</span>-提供端到端的CI/CD管道编排和可视化 </div><div class="compact-content">• <span class="key-service">AWS CodeDeploy</span>-提供自动化、可控的应用程序部署，支持蓝绿和滚动部署 <div class="section-title"><strong>正确答案AD:</strong></div> A选项通过CodePipeline提供完整的CI/CD管道编排，确保构建测试和部署的一致性；D选项错误，应该是BC组合，CodeDeploy替代Systems Manager Run Command提供更可靠的部署机制，支持回滚和健康检查 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项B-构建和测试应该并行执行而不是串行，影响部署效率 </div><div class="compact-content">• 选项D-使用单独Lambda函数增加复杂性，不如统一管道管理 </div><div class="compact-content">• 选项E-存储位置变更不解决核心部署可靠性问题 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-并行构建测试提高效率，CodeDeploy支持零停机部署 </div><div class="compact-content">• 成本-统一管道减少管理开销，避免多个Lambda函数成本 </div><div class="compact-content">• 可扩展性-CodePipeline和CodeDeploy原生支持大规模部署和多环境管理</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: AD (A、D)</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-167">
            <div class="question-header">
                <div class="question-title">Question #167 ✅ ⚪ <small style="float: right;">(167/353)</small></div>
            </div>
            <div class="question-content">A company uses an organization in <span class="key-service">AWS Organizations</span> to manage its AWS accounts. The company's automation account contains a CI/CD pipeline that creates and configures new AWS accounts. The company has a group of internal service teams that provide services to accounts in the organization. The service teams operate out of a set of services accounts. The service teams want to receive an <span class="key-service">AWS CloudTrail</span> event in their services accounts when the CreateAccount API call creates a new account. How should the company share this CloudTrail event with the service accounts? A (83%) B (17%)</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Create an Amazon EventBridge rule in the automation account to send account creation events to the default event bus in the services accounts. Update the default event bus in the services accounts to allow events from the automation account.</div>                <div class="option"><strong>B.</strong> Create a custom Amazon EventBridge event bus in the services accounts. Update the custom event bus to allow events from the automation account. Create an EventBridge rule in the services account that directly listens to CloudTrail events from the automation account.</div>                <div class="option"><strong>C.</strong> Create a custom Amazon EventBridge event bus in the automation account and the services accounts. Create an EventBridge rule and policy that connects the custom event buses that are in the automation account and the services accounts.</div>                <div class="option correct-answer"><strong>D.</strong> Create a custom Amazon EventBridge event bus in the automation account. Create an EventBridge rule and policy that connects the custom event bus to the default event buses in the services accounts.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司使用AWS Organizations中的组织来管理其AWS账户。公司的自动化账户包含一个CI/CD管道，用于创建和配置新的AWS账户。公司有一组内部服务团队，为组织中的账户提供服务。服务团队在一组服务账户中运营。当CreateAccount API调用创建新账户时，服务团队希望在其服务账户中接收AWS CloudTrail事件。公司应该如何与服务账户共享此CloudTrail事件？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 在自动化账户中创建Amazon EventBridge规则，将账户创建事件发送到服务账户中的默认事件总线。更新服务账户中的默认事件总线以允许来自自动化账户的事件。</div> <div class="option-analysis"><strong>B.</strong> 在服务账户中创建自定义Amazon EventBridge事件总线。更新自定义事件总线以允许来自自动化账户的事件。在服务账户中创建EventBridge规则，直接监听来自自动化账户的CloudTrail事件。</div> <div class="option-analysis"><strong>C.</strong> 在自动化账户和服务账户中创建自定义Amazon EventBridge事件总线。创建EventBridge规则和策略，连接自动化账户和服务账户中的自定义事件总线。</div> <div class="option-analysis"><strong>D.</strong> 在自动化账户中创建自定义Amazon EventBridge事件总线。创建EventBridge规则和策略，将自定义事件总线连接到服务账户中的默认事件总线。<div class="section-title"><strong>核心要求:</strong></div> 实现跨账户CloudTrail事件共享，从自动化账户向多个服务账户分发CreateAccount API事件 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• <span class="key-service">AWS CloudTrail</span>-记录API调用事件，包括CreateAccount操作 </div><div class="compact-content">• Amazon EventBridge-提供跨账户事件路由和分发能力 <div class="section-title"><strong>正确答案D:</strong></div> 在源账户(自动化账户)创建自定义事件总线捕获CloudTrail事件，通过跨账户规则和策略将事件路由到目标账户的默认事件总线，实现一对多的事件分发架构 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A-默认事件总线不支持接收跨账户事件，必须使用自定义事件总线作为源 </div><div class="compact-content">• 选项B-EventBridge规则无法直接跨账户监听CloudTrail事件，需要通过事件总线路由 </div><div class="compact-content">• 选项C-目标账户无需创建自定义事件总线，使用默认事件总线即可接收跨账户事件 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-自定义事件总线提供更好的事件过滤和路由性能 </div><div class="compact-content">• 成本-源账户单一自定义总线比多账户自定义总线成本更低 </div><div class="compact-content">• 可扩展性-支持向多个服务账户扩展，无需修改目标账户配置</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: D</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-168">
            <div class="question-header">
                <div class="question-title">Question #168 ✅ ⚪ <small style="float: right;">(168/353)</small></div>
            </div>
            <div class="question-content">A DevOps engineer is building a solution that uses Amazon Simple Queue Service (<span class="key-service">Amazon SQS</span>) standard queues. The solution also includes an <span class="key-service">AWS Lambda</span> function and an <span class="key-service">Amazon DynamoDB</span> table. The Lambda function pulls content from an SQS queue event source and writes the content to the DynamoDB table. The solution must maximize the scalability of Lambda and must prevent successfully processed SQS messages from being processed multiple times. Which solution will meet these requirements? C (92%) 8%</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Decrease the batch window to 1 second when configuring the Lambda function's event source mapping.</div>                <div class="option correct-answer"><strong>B.</strong> Decrease the batch size to 1 when configuring the Lambda function's event source mapping.</div>                <div class="option"><strong>C.</strong> Include the ReportBatchItemFailures value in the FunctionResponseTypes list in the Lambda function's event source mapping.</div>                <div class="option"><strong>D.</strong> Set the queue visibility timeout on the Lambda function's event source mapping to account for invocation throttling of the Lambda function.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一名DevOps工程师正在构建一个使用Amazon SQS标准队列的解决方案，该解决方案还包括AWS Lambda函数和Amazon DynamoDB表。Lambda函数从SQS队列事件源拉取内容并将内容写入DynamoDB表。解决方案必须最大化Lambda的可扩展性，并防止成功处理的SQS消息被多次处理。 <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 在配置Lambda函数的事件源映射时，将批处理窗口减少到1秒</div> <div class="option-analysis"><strong>B.</strong> 在配置Lambda函数的事件源映射时，将批处理大小减少到1</div> <div class="option-analysis"><strong>C.</strong> 在Lambda函数的事件源映射中，将ReportBatchItemFailures值包含在FunctionResponseTypes列表中</div> <div class="option-analysis"><strong>D.</strong> 在Lambda函数的事件源映射上设置队列可见性超时，以考虑Lambda函数的调用限制<div class="section-title"><strong>核心要求:</strong></div> 最大化Lambda可扩展性并防止成功处理的SQS消息重复处理 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• <span class="key-service">Amazon SQS</span> - 标准队列作为消息源，需要防止重复处理 </div><div class="compact-content">• <span class="key-service">AWS Lambda</span> - 事件驱动处理，需要优化可扩展性和错误处理 </div><div class="compact-content">• <span class="key-service">Amazon DynamoDB</span> - 目标存储，接收处理后的数据 <div class="section-title"><strong>正确答案B:</strong></div> 将批处理大小设置为1确保每次Lambda调用只处理一条消息，当函数成功时整个批次成功，失败时只有该条消息重试，避免了部分失败导致的重复处理问题 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A - 批处理窗口只影响消息收集时间，不解决重复处理问题 </div><div class="compact-content">• 选项C - ReportBatchItemFailures用于部分批次失败报告，但标准队列本身就有重复处理风险 </div><div class="compact-content">• 选项D - 可见性超时调整不能根本解决批处理中的重复处理问题 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能 - 批处理大小为1虽然增加调用次数但确保消息处理的原子性 </div><div class="compact-content">• 成本 - 更多Lambda调用但避免重复处理的数据一致性问题 </div><div class="compact-content">• 可扩展性 - Lambda并发处理能力不受影响，消息处理更可靠</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: B</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-169">
            <div class="question-header">
                <div class="question-title">Question #169 ✅ 📝 <small style="float: right;">(169/353)</small></div>
            </div>
            <div class="question-content">A company has a new AWS account that teams will use to deploy various applications. The teams will create many <span class="key-service">Amazon S3</span> buckets for application-specific purposes and to store <span class="key-service">AWS CloudTrail</span> logs. The company has enabled Amazon Macie for the account. A DevOps engineer needs to optimize the Macie costs for the account without compromising the account's functionality. Which solutions will meet these requirements? (Choose two.) AD (83%) Other</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Exclude S3 buckets that contain CloudTrail logs from automated discovery.</div>                <div class="option"><strong>B.</strong> Exclude S3 buckets that have public read access from automated discovery.</div>                <div class="option correct-answer"><strong>C.</strong> Configure scheduled daily discovery jobs for all S3 buckets in the account.</div>                <div class="option correct-answer"><strong>D.</strong> Configure discovery jobs to include S3 objects based on the last modified criterion.</div>                <div class="option"><strong>E.</strong> Configure discovery jobs to include S3 objects that are tagged as production only.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司有一个新的AWS账户，团队将使用它来部署各种应用程序。团队将创建许多Amazon S3存储桶用于特定应用程序目的和存储AWS CloudTrail日志。公司已为该账户启用了Amazon Macie。DevOps工程师需要在不影响账户功能的情况下优化Macie成本。哪些解决方案能满足这些要求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 从自动发现中排除包含CloudTrail日志的S3存储桶</div> <div class="option-analysis"><strong>B.</strong> 从自动发现中排除具有公共读取访问权限的S3存储桶</div> <div class="option-analysis"><strong>C.</strong> 为账户中的所有S3存储桶配置计划的每日发现作业</div> <div class="option-analysis"><strong>D.</strong> 配置发现作业以基于最后修改时间标准包含S3对象</div> <div class="option-analysis"><strong>E.</strong> 配置发现作业仅包含标记为生产环境的S3对象<div class="section-title"><strong>核心要求:</strong></div> 在不影响功能的前提下优化Amazon Macie的成本 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• Amazon Macie - 数据安全和隐私保护服务，通过机器学习发现敏感数据 </div><div class="compact-content">• <span class="key-service">Amazon S3</span> - 对象存储服务，存储应用数据和CloudTrail日志 <div class="section-title"><strong>正确答案CD:</strong></div> C选项通过计划的每日发现作业替代持续监控，降低扫描频率从而减少成本；D选项通过最后修改时间过滤，只扫描近期变更的对象，避免重复扫描静态数据，显著降低处理成本 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A - CloudTrail日志可能包含敏感信息，排除会影响安全监控功能 </div><div class="compact-content">• 选项B - 公共访问的存储桶更需要敏感数据监控，排除会降低安全性 </div><div class="compact-content">• 选项E - 仅监控生产环境会忽略其他环境的敏感数据风险 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能 - 通过时间过滤和计划作业优化扫描效率 </div><div class="compact-content">• 成本 - 减少扫描频率和范围降低Macie使用费用 </div><div class="compact-content">• 可扩展性 - 保持对所有存储桶的覆盖能力同时控制成本增长</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: CD (C、D)</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-170">
            <div class="question-header">
                <div class="question-title">Question #170 ✅ 📝 <small style="float: right;">(170/353)</small></div>
            </div>
            <div class="question-content">A company uses an organization in <span class="key-service">AWS Organizations</span> to manage its AWS accounts. The company recently acquired another company that has standalone AWS accounts. The acquiring company's DevOps team needs to consolidate the administration of the AWS accounts for both companies and retain full administrative control of the accounts. The DevOps team also needs to collect and group findings across all the accounts to implement and maintain a security posture. Which combination of steps should the DevOps team take to meet these requirements? (Choose two.) BC (100%)</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Invite the acquired company's AWS accounts to join the organization. Create an <span class="key-service">SCP</span> that has full administrative privileges. Attach the <span class="key-service">SCP</span> to the management account.</div>                <div class="option"><strong>B.</strong> Invite the acquired company's AWS accounts to join the organization. Create the OrganizationAccountAccessRole IAM role in the invited accounts. Grant permission to the management account to assume the role.</div>                <div class="option correct-answer"><strong>C.</strong> Use AWS Security Hub to collect and group findings across all accounts. Use Security Hub to automatically detect new accounts as the accounts are added to the organization.</div>                <div class="option"><strong>D.</strong> Use AWS Firewall Manager to collect and group findings across all accounts. Enable all features for the organization. Designate an account in the organization as the delegated administrator account for Firewall Manager.</div>                <div class="option correct-answer"><strong>E.</strong> Use Amazon Inspector to collect and group findings across all accounts. Designate an account in the organization as the delegated administrator account for Amazon Inspector.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司使用AWS Organizations中的组织来管理其AWS账户。该公司最近收购了另一家拥有独立AWS账户的公司。收购方的DevOps团队需要整合两家公司AWS账户的管理并保持对账户的完全管理控制。DevOps团队还需要收集和分组所有账户的发现结果以实施和维护安全态势。DevOps团队应采取哪些步骤组合来满足这些要求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 邀请被收购公司的AWS账户加入组织。创建具有完全管理权限的SCP。将SCP附加到管理账户。</div> <div class="option-analysis"><strong>B.</strong> 邀请被收购公司的AWS账户加入组织。在受邀账户中创建OrganizationAccountAccessRole IAM角色。授权管理账户承担该角色。</div> <div class="option-analysis"><strong>C.</strong> 使用AWS Security Hub收集和分组所有账户的发现结果。使用Security Hub在账户添加到组织时自动检测新账户。</div> <div class="option-analysis"><strong>D.</strong> 使用AWS Firewall Manager收集和分组所有账户的发现结果。为组织启用所有功能。指定组织中的一个账户作为Firewall Manager的委托管理员账户。</div> <div class="option-analysis"><strong>E.</strong> 使用Amazon Inspector收集和分组所有账户的发现结果。指定组织中的一个账户作为Amazon Inspector的委托管理员账户。<div class="section-title"><strong>核心要求:</strong></div> 整合多公司AWS账户管理并建立跨账户安全发现收集机制 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• AWS Security Hub-集中收集和管理多账户安全发现结果 </div><div class="compact-content">• Amazon Inspector-自动化漏洞评估和安全发现收集 <div class="section-title"><strong>正确答案CE:</strong></div> Security Hub提供跨账户安全发现聚合功能，Inspector提供漏洞扫描和安全评估，两者结合实现全面的多账户安全态势管理 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A-SCP不应附加到管理账户，且主要用于权限限制而非完全管理控制 </div><div class="compact-content">• 选项B-虽然正确但题目要求选择CE，OrganizationAccountAccessRole是标准做法但不是最佳组合 </div><div class="compact-content">• 选项D-Firewall Manager主要用于防火墙规则管理，不是安全发现收集的最佳工具 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-Security Hub和Inspector提供自动化安全发现聚合 </div><div class="compact-content">• 成本-利用AWS原生服务避免第三方工具成本 </div><div class="compact-content">• 可扩展性-支持组织级别的多账户安全管理扩展</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: CE (C、E)</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-171">
            <div class="question-header">
                <div class="question-title">Question #171 ✅ 📝 <small style="float: right;">(171/353)</small></div>
            </div>
            <div class="question-content">A company has an application and a CI/CD pipeline. The CI/CD pipeline consists of an <span class="key-service">AWS CodePipeline</span> pipeline and an <span class="key-service">AWS CodeBuild</span> project. The CodeBuild project runs tests against the application as part of the build process and outputs a test report. The company must keep the test reports for 90 days. Which solution will meet these requirements? B (63%) D (37%)</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Add a new stage in the CodePipeline pipeline after the stage that contains the CodeBuild project. Create an <span class="key-service">Amazon S3</span> bucket to store the reports. Configure an S3 deploy action type in the new CodePipeline stage with the appropriate path and format for the reports.</div>                <div class="option correct-answer"><strong>B.</strong> Add a report group in the CodeBuild project buildspec file with the appropriate path and format for the reports. Create an <span class="key-service">Amazon S3</span> bucket to store the reports. Configure an Amazon EventBridge rule that invokes an <span class="key-service">AWS Lambda</span> function to copy the reports to the S3 bucket when a build is completed. Create an S3 Lifecycle rule to expire the objects after 90 days.</div>                <div class="option correct-answer"><strong>C.</strong> Add a new stage in the CodePipeline pipeline. Configure a test action type with the appropriate path and format for the reports. Configure the report expiration time to be 90 days in the CodeBuild project buildspec file.</div>                <div class="option"><strong>D.</strong> Add a report group in the CodeBuild project buildspec file with the appropriate path and format for the reports. Create an <span class="key-service">Amazon S3</span> bucket to store the reports. Configure the report group as an artifact in the CodeBuild project buildspec file. Configure the S3 bucket as the artifact destination. Set the object expiration to 90 days.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司有一个应用程序和CI/CD管道。CI/CD管道由AWS CodePipeline管道和AWS CodeBuild项目组成。CodeBuild项目在构建过程中对应用程序运行测试并输出测试报告。公司必须保留测试报告90天。哪个解决方案能满足这些要求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 在包含CodeBuild项目的阶段之后在CodePipeline管道中添加新阶段，创建Amazon S3存储桶存储报告，在新的CodePipeline阶段中配置S3部署操作类型，使用适当的报告路径和格式。</div> <div class="option-analysis"><strong>B.</strong> 在CodeBuild项目buildspec文件中添加报告组，使用适当的报告路径和格式，创建Amazon S3存储桶存储报告，配置Amazon EventBridge规则调用AWS Lambda函数在构建完成时将报告复制到S3存储桶，创建S3生命周期规则在90天后使对象过期。</div> <div class="option-analysis"><strong>C.</strong> 在CodePipeline管道中添加新阶段，配置测试操作类型使用适当的报告路径和格式，在CodeBuild项目buildspec文件中配置报告过期时间为90天。</div> <div class="option-analysis"><strong>D.</strong> 在CodeBuild项目buildspec文件中添加报告组，使用适当的报告路径和格式，创建Amazon S3存储桶存储报告，在CodeBuild项目buildspec文件中将报告组配置为构件，将S3存储桶配置为构件目标，设置对象过期为90天。<div class="section-title"><strong>核心要求:</strong></div> 在CI/CD管道中保存测试报告90天 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• CodeBuild Reports - 原生测试报告功能，支持报告组和生命周期管理 </div><div class="compact-content">• CodePipeline Test Actions - 内置测试操作类型，支持报告管理 </div><div class="compact-content">• S3 Lifecycle - 自动对象过期管理 <div class="section-title"><strong>正确答案BC:</strong></div> B通过CodeBuild报告组+EventBridge+Lambda实现报告存储和S3生命周期管理；C使用CodePipeline原生测试操作类型和CodeBuild内置报告过期功能 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A - S3部署操作类型不是为测试报告设计的，缺乏适当的报告格式支持 </div><div class="compact-content">• 选项D - 将报告组作为构件配置在技术上不正确，报告组不是标准的构件类型 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能 - 使用原生AWS服务功能避免额外处理开销 </div><div class="compact-content">• 成本 - 利用内置功能减少Lambda调用和存储成本 </div><div class="compact-content">• 可扩展性 - 原生集成支持更好的扩展性和维护性</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: BC (B、C)</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-172">
            <div class="question-header">
                <div class="question-title">Question #172 ✅ 📝 <small style="float: right;">(172/353)</small></div>
            </div>
            <div class="question-content">A company uses an <span class="key-service">Amazon API Gateway</span> regional REST API to host its application API. The REST API has a custom domain. The REST API's default endpoint is deactivated. The company's internal teams consume the API. The company wants to use mutual TLS between the API and the internal teams as an additional layer of authentication. Which combination of steps will meet these requirements? (Choose two.) AE (72%) AC (20%) 8%</div>
            <div class="options-container">                <div class="option correct-answer"><strong>A.</strong> Use AWS Certificate Manager (ACM) to create a private certificate authority (CA). Provision a client certificate that is signed by the private CA.</div>                <div class="option correct-answer"><strong>B.</strong> Provision a client certificate that is signed by a public certificate authority (CA). Import the certificate into AWS Certificate Manager (ACM).</div>                <div class="option"><strong>C.</strong> Upload the provisioned client certificate to an <span class="key-service">Amazon S3</span> bucket. Configure the API Gateway mutual TLS to use the client certificate that is stored in the S3 bucket as the trust store.</div>                <div class="option"><strong>D.</strong> Upload the provisioned client certificate private key to an <span class="key-service">Amazon S3</span> bucket. Configure the API Gateway mutual TLS to use the private key that is stored in the S3 bucket as the trust store.</div>                <div class="option"><strong>E.</strong> Upload the root private certificate authority (CA) certificate to an <span class="key-service">Amazon S3</span> bucket. Configure the API Gateway mutual TLS to use the private CA certificate that is stored in the S3 bucket as the trust store. Most Voted</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司使用Amazon API Gateway区域REST API来托管其应用程序API。REST API有自定义域名，默认端点已停用。公司内部团队使用该API。公司希望在API和内部团队之间使用双向TLS作为额外的身份验证层。哪些步骤组合可以满足这些要求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 使用AWS Certificate Manager (ACM)创建私有证书颁发机构(CA)，提供由私有CA签名的客户端证书</div> <div class="option-analysis"><strong>B.</strong> 提供由公共证书颁发机构(CA)签名的客户端证书，将证书导入AWS Certificate Manager (ACM)</div> <div class="option-analysis"><strong>C.</strong> 将提供的客户端证书上传到Amazon S3存储桶，配置API Gateway双向TLS使用存储在S3存储桶中的客户端证书作为信任存储</div> <div class="option-analysis"><strong>D.</strong> 将提供的客户端证书私钥上传到Amazon S3存储桶，配置API Gateway双向TLS使用存储在S3存储桶中的私钥作为信任存储</div> <div class="option-analysis"><strong>E.</strong> 将根私有证书颁发机构(CA)证书上传到Amazon S3存储桶，配置API Gateway双向TLS使用存储在S3存储桶中的私有CA证书作为信任存储<div class="section-title"><strong>核心要求:</strong></div> 为API Gateway REST API配置双向TLS身份验证 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• API Gateway - 支持双向TLS的REST API服务 </div><div class="compact-content">• AWS Certificate Manager - 管理SSL/TLS证书的服务 <div class="section-title"><strong>正确答案AB:</strong></div> A提供私有CA签名的客户端证书，B提供公共CA签名的客户端证书，两种方式都可以为双向TLS提供有效的客户端证书 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项C - 客户端证书应该由客户端持有，不应上传到服务器端作为信任存储 </div><div class="compact-content">• 选项D - 私钥绝不应上传到服务器端，违反安全最佳实践 </div><div class="compact-content">• 选项E - 虽然技术上可行，但不是标准做法，且题目未明确要求使用私有CA的根证书 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 安全性 - 客户端证书用于客户端身份验证，私钥必须保密 </div><div class="compact-content">• <span class="key-point">合规性</span> - 遵循双向TLS标准实现方式 </div><div class="compact-content">• 可管理性 - 使用ACM管理证书生命周期</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: AB (A、B)</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-173">
            <div class="question-header">
                <div class="question-title">Question #173 ✅ ⚪ <small style="float: right;">(173/353)</small></div>
            </div>
            <div class="question-content">A company uses AWS Directory Service for Microsoft Active Directory as its identity provider (IdP). The company requires all infrastructure to be defined and deployed by <span class="key-service">AWS CloudFormation</span>. A DevOps engineer needs to create a fleet of Windows-based <span class="key-service">Amazon EC2</span> instances to host an application. The DevOps engineer has created a CloudFormation template that contains an EC2 launch template, IAM role, EC2 security group, and EC2 Auto Scaling group. The DevOps engineer must implement a solution that joins all EC2 instances to the domain of the AWS Managed Microsoft AD directory. Which solution will meet these requirements with the MOST operational efficiency? B (100%)</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> In the CloudFormation template, create an AWS::SSM::Document resource that joins the EC2 instance to the AWS Managed Microsoft AD domain by using the parameters for the existing directory. Update the launch template to include the SSMAssociation property to use the new SSM document. Attach the AmazonSSMManagedInstanceCore and AmazonSSMDirectoryServiceAccess AWS managed policies to the IAM role that the EC2 instances use.</div>                <div class="option"><strong>B.</strong> In the CloudFormation template, update the launch template to include specific tags that propagate on launch. Create an AWS::SSM::Association resource to associate the AWS-JoinDirectoryServiceDomain Automation runbook with the EC2 instances that have the specified tags. Define the required parameters to join the AWS Managed Microsoft AD directory. Attach the AmazonSSMManagedInstanceCore and AmazonSSMDirectoryServiceAccess AWS managed policies to the IAM role that the EC2 instances use.</div>                <div class="option correct-answer"><strong>C.</strong> Store the existing AWS Managed Microsoft AD domain connection details in AWS Secrets Manager. In the CloudFormation template, create an AWS::SSM::Association resource to associate the AWS-CreateManagedWindowsInstanceWithApproval Automation runbook with the EC2 Auto Scaling group. Pass the ARNs for the parameters from Secrets Manager to join the domain. Attach the AmazonSSMDirectoryServiceAccess and SecretsManagerReadWrite AWS managed policies to the IAM role that the EC2 instances use.</div>                <div class="option"><strong>D.</strong> Store the existing AWS Managed Microsoft AD domain administrator credentials in AWS Secrets Manager. In the CloudFormation template, update the EC2 launch template to include user data. Configure the user data to pull the administrator credentials from Secrets Manager and to join the AWS Managed Microsoft AD domain. Attach the AmazonSSMManagedInstanceCore and SecretsManagerReadWrite AWS managed policies to the IAM role that the EC2 instances use.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司使用AWS Directory Service for Microsoft Active Directory作为身份提供商(IdP)。公司要求所有基础设施都通过AWS CloudFormation定义和部署。DevOps工程师需要创建一组基于Windows的Amazon EC2实例来托管应用程序。DevOps工程师已创建包含EC2启动模板、IAM角色、EC2安全组和EC2 Auto Scaling组的CloudFormation模板。DevOps工程师必须实现一个解决方案，将所有EC2实例加入到AWS Managed Microsoft AD目录的域中。哪个解决方案能以最高的运营效率满足这些要求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 在CloudFormation模板中，创建一个AWS::SSM::Document资源，使用现有目录的参数将EC2实例加入到AWS Managed Microsoft AD域。更新启动模板以包含SSMAssociation属性来使用新的SSM文档。将AmazonSSMManagedInstanceCore和AmazonSSMDirectoryServiceAccess AWS托管策略附加到EC2实例使用的IAM角色。</div> <div class="option-analysis"><strong>B.</strong> 在CloudFormation模板中，更新启动模板以包含在启动时传播的特定标签。创建AWS::SSM::Association资源将AWS-JoinDirectoryServiceDomain自动化运行手册与具有指定标签的EC2实例关联。定义加入AWS Managed Microsoft AD目录所需的参数。将AmazonSSMManagedInstanceCore和AmazonSSMDirectoryServiceAccess AWS托管策略附加到EC2实例使用的IAM角色。</div> <div class="option-analysis"><strong>C.</strong> 将现有的AWS Managed Microsoft AD域连接详细信息存储在AWS Secrets Manager中。在CloudFormation模板中，创建AWS::SSM::Association资源将AWS-CreateManagedWindowsInstanceWithApproval自动化运行手册与EC2 Auto Scaling组关联。传递来自Secrets Manager的参数ARN以加入域。将AmazonSSMDirectoryServiceAccess和SecretsManagerReadWrite AWS托管策略附加到EC2实例使用的IAM角色。</div> <div class="option-analysis"><strong>D.</strong> 将现有的AWS Managed Microsoft AD域管理员凭证存储在AWS Secrets Manager中。在CloudFormation模板中，更新EC2启动模板以包含用户数据。配置用户数据从Secrets Manager拉取管理员凭证并加入AWS Managed Microsoft AD域。将AmazonSSMManagedInstanceCore和SecretsManagerReadWrite AWS托管策略附加到EC2实例使用的IAM角色。<div class="section-title"><strong>核心要求:</strong></div> 通过CloudFormation自动将Auto Scaling组中的Windows EC2实例加入AWS Managed Microsoft AD域 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• <span class="key-service">AWS Systems Manager</span> - 提供自动化运行手册和关联功能 </div><div class="compact-content">• AWS Secrets Manager - 安全存储域连接凭证 </div><div class="compact-content">• AWS Directory Service - 托管Microsoft Active Directory服务 <div class="section-title"><strong>正确答案C:</strong></div> 使用AWS-CreateManagedWindowsInstanceWithApproval自动化运行手册直接与Auto Scaling组关联，通过Secrets Manager安全管理域连接参数，实现完全自动化的域加入过程 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A - 需要手动创建SSM文档增加复杂性，运营效率不如使用现有AWS自动化运行手册 </div><div class="compact-content">• 选项B - 基于标签的关联方式比直接与Auto Scaling组关联的运营效率低，且AWS-JoinDirectoryServiceDomain运行手册不如AWS-CreateManagedWindowsInstanceWithApproval适合此场景 </div><div class="compact-content">• 选项D - 使用用户数据脚本方式缺乏自动化，需要手动编写脚本逻辑，运营效率最低 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能 - 使用AWS原生自动化运行手册确保最佳性能和可靠性 </div><div class="compact-content">• 成本 - 利用现有AWS服务避免额外开发和维护成本 </div><div class="compact-content">• 可扩展性 - 直接与Auto Scaling组集成确保新实例自动加入域</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: C</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-174">
            <div class="question-header">
                <div class="question-title">Question #174 ✅ ⚪ <small style="float: right;">(174/353)</small></div>
            </div>
            <div class="question-content">A company uses <span class="key-service">AWS Organizations</span> to manage its AWS accounts. The company has a root OU that has a child OU. The root OU has an <span class="key-service">SCP</span> that allows all actions on all resources. The child OU has an <span class="key-service">SCP</span> that allows all actions for <span class="key-service">Amazon DynamoDB</span> and <span class="key-service">AWS Lambda</span>, and denies all other actions. The company has an AWS account that is named vendor-data in the child OU. A DevOps engineer has an IAM user that is attached to the AdministratorAccess IAM policy in the vendor-data account. The DevOps engineer attempts to launch an <span class="key-service">Amazon EC2</span> instance in the vendor-data account but receives an access denied error. Which change should the DevOps engineer make to launch the EC2 instance in the vendor-data account? C (70%) B (30%)</div>
            <div class="options-container">                <div class="option correct-answer"><strong>A.</strong> Attach the AmazonEC2FullAccess IAM policy to the IAM user.</div>                <div class="option"><strong>B.</strong> Create a new <span class="key-service">SCP</span> that allows all actions for <span class="key-service">Amazon EC2</span>. Attach the <span class="key-service">SCP</span> to the vendor-data account.</div>                <div class="option"><strong>C.</strong> Update the <span class="key-service">SCP</span> in the child OU to allow all actions for <span class="key-service">Amazon EC2</span>.</div>                <div class="option"><strong>D.</strong> Create a new <span class="key-service">SCP</span> that allows all actions for <span class="key-service">Amazon EC2</span>. Attach the <span class="key-service">SCP</span> to the root OU.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司使用AWS Organizations管理其AWS账户。公司有一个根OU，下面有一个子OU。根OU有一个SCP允许对所有资源执行所有操作。子OU有一个SCP只允许对Amazon DynamoDB和AWS Lambda执行所有操作，拒绝所有其他操作。公司在子OU中有一个名为vendor-data的AWS账户。DevOps工程师在vendor-data账户中有一个附加了AdministratorAccess IAM策略的IAM用户。DevOps工程师尝试在vendor-data账户中启动Amazon EC2实例但收到访问拒绝错误。DevOps工程师应该做什么更改才能在vendor-data账户中启动EC2实例？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 将AmazonEC2FullAccess IAM策略附加到IAM用户</div> <div class="option-analysis"><strong>B.</strong> 创建一个允许Amazon EC2所有操作的新SCP，将SCP附加到vendor-data账户</div> <div class="option-analysis"><strong>C.</strong> 更新子OU中的SCP以允许Amazon EC2的所有操作</div> <div class="option-analysis"><strong>D.</strong> 创建一个允许Amazon EC2所有操作的新SCP，将SCP附加到根OU<div class="section-title"><strong>核心要求:</strong></div> 解决AWS Organizations中SCP策略限制导致的EC2访问拒绝问题 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• <span class="key-service">AWS Organizations</span> - 提供集中账户管理和SCP策略控制 </div><div class="compact-content">• <span class="key-service">SCP</span> (Service Control Policy) - 定义组织单位和账户的最大权限边界 <div class="section-title"><strong>正确答案C:</strong></div> SCP作为权限边界，子OU的SCP只允许DynamoDB和Lambda操作，即使IAM用户有AdministratorAccess，也会被SCP限制。必须更新子OU的SCP添加EC2权限才能解除限制。 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A - IAM用户已有AdministratorAccess，添加EC2策略无法突破SCP的权限边界限制 </div><div class="compact-content">• 选项B - SCP不能直接附加到账户，只能附加到OU或根组织 </div><div class="compact-content">• 选项D - 根OU已允许所有操作，在根OU添加EC2 SCP不会改变子OU的限制 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 权限模型 - SCP定义最大权限边界，IAM策略在此范围内授权 </div><div class="compact-content">• 继承关系 - 子OU的SCP限制优先于根OU的宽松策略 </div><div class="compact-content">• 策略附加 - SCP只能附加到OU级别，不能直接附加到账户</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: A</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-175">
            <div class="question-header">
                <div class="question-title">Question #175 ✅ ⚪ <small style="float: right;">(175/353)</small></div>
            </div>
            <div class="question-content">A company's security policies require the use of security hardened AMIs in production environments. A DevOps engineer has used EC2 Image Builder to create a pipeline that builds the AMIs on a recurring schedule. The DevOps engineer needs to update the launch templates of the company's Auto Scaling groups. The Auto Scaling groups must use the newest AMIs during the launch of <span class="key-service">Amazon EC2</span> instances. Which solution will meet these requirements with the MOST operational efficiency? D (69%) C (16%) B (16%)</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Configure an Amazon EventBridge rule to receive new AMI events from Image Builder. Target an <span class="key-service">AWS Systems Manager</span> Run Command document that updates the launch templates of the Auto Scaling groups with the newest AMI ID.</div>                <div class="option"><strong>B.</strong> Configure an Amazon EventBridge rule to receive new AMI events from Image Builder. Target an <span class="key-service">AWS Lambda</span> function that updates the launch templates of the Auto Scaling groups with the newest AMI ID.</div>                <div class="option correct-answer"><strong>C.</strong> Configure the launch template to use a value from <span class="key-service">AWS Systems Manager</span> Parameter Store for the AMI I<div class="option-analysis"><strong>D.</strong> Configure the Image Builder pipeline to update the Parameter Store value with the newest AMI ID.</div></div>                <div class="option"><strong>D.</strong> Configure the Image Builder distribution settings to update the launch templates with the newest AMI I<div class="option-analysis"><strong>D.</strong> Configure the Auto Scaling groups to use the newest version of the launch template.</div></div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 公司安全策略要求在生产环境中使用安全加固的AMI。DevOps工程师使用EC2 Image Builder创建了定期构建AMI的管道。需要更新Auto Scaling组的启动模板，使其在启动EC2实例时使用最新的AMI。哪种解决方案最具运营效率？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 配置Amazon EventBridge规则接收Image Builder的新AMI事件，目标为AWS Systems Manager Run Command文档，用最新AMI ID更新Auto Scaling组的启动模板</div> <div class="option-analysis"><strong>B.</strong> 配置Amazon EventBridge规则接收Image Builder的新AMI事件，目标为AWS Lambda函数，用最新AMI ID更新Auto Scaling组的启动模板</div> <div class="option-analysis"><strong>C.</strong> 配置启动模板使用AWS Systems Manager Parameter Store中的AMI ID值，配置Image Builder管道用最新AMI ID更新Parameter Store值</div> <div class="option-analysis"><strong>D.</strong> 配置Image Builder分发设置用最新AMI ID更新启动模板，配置Auto Scaling组使用启动模板的最新版本<div class="section-title"><strong>核心要求:</strong></div> 实现Auto Scaling组自动使用最新安全加固AMI的最高效运营方案 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• EC2 Image Builder-定期构建安全加固AMI </div><div class="compact-content">• Auto Scaling Groups-自动扩展EC2实例 </div><div class="compact-content">• Systems Manager Parameter Store-存储配置参数 <div class="section-title"><strong>正确答案C:</strong></div> 通过Parameter Store实现配置与资源解耦，启动模板引用参数值而非硬编码AMI ID，Image Builder更新参数即可全局生效 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A-需要额外的Run Command执行和权限管理，运营复杂度高 </div><div class="compact-content">• 选项B-需要维护Lambda函数代码和错误处理逻辑，增加运营负担 </div><div class="compact-content">• 选项D-Image Builder原生不支持直接更新启动模板功能 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-Parameter Store提供低延迟参数检索，无需额外计算资源 </div><div class="compact-content">• 成本-避免Lambda函数调用费用和Run Command执行成本 </div><div class="compact-content">• 可扩展性-参数化配置支持多个Auto Scaling组同时引用同一参数值</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: C</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-176">
            <div class="question-header">
                <div class="question-title">Question #176 ✅ ⚪ <small style="float: right;">(176/353)</small></div>
            </div>
            <div class="question-content">A company has configured an <span class="key-service">Amazon S3</span> event source on an <span class="key-service">AWS Lambda</span> function. The company needs the Lambda function to run when a new object is created or an existing object is modified in a particular S3 bucket. The Lambda function will use the S3 bucket name and the S3 object key of the incoming event to read the contents of the created or modified S3 object. The Lambda function will parse the contents and save the parsed contents to an <span class="key-service">Amazon DynamoDB</span> table. The Lambda function's execution role has permissions to read from the S3 bucket and to write to the DynamoDB table. During testing, a DevOps engineer discovers that the Lambda function does not run when objects are added to the S3 bucket or when existing objects are modified. Which solution will resolve this problem? B (100%)</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Increase the memory of the Lambda function to give the function the ability to process large files from the S3 bucket.</div>                <div class="option"><strong>B.</strong> Create a resource policy on the Lambda function to grant <span class="key-service">Amazon S3</span> the permission to invoke the Lambda function for the S3 bucket.</div>                <div class="option"><strong>C.</strong> Configure an Amazon Simple Queue Service (<span class="key-service">Amazon SQS</span>) queue as an OnFailure destination for the Lambda function.</div>                <div class="option correct-answer"><strong>D.</strong> Provision space in the /tmp folder of the Lambda function to give the function the ability to process large files from the S3 bucket.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司在AWS Lambda函数上配置了Amazon S3事件源。公司需要Lambda函数在特定S3存储桶中创建新对象或修改现有对象时运行。Lambda函数将使用传入事件的S3存储桶名称和S3对象键来读取创建或修改的S3对象内容。Lambda函数将解析内容并将解析后的内容保存到Amazon DynamoDB表中。Lambda函数的执行角色具有从S3存储桶读取和写入DynamoDB表的权限。在测试期间，DevOps工程师发现当对象添加到S3存储桶或修改现有对象时Lambda函数不会运行。哪个解决方案能解决这个问题？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 增加Lambda函数的内存以使函数能够处理来自S3存储桶的大文件</div> <div class="option-analysis"><strong>B.</strong> 在Lambda函数上创建资源策略以授予Amazon S3调用该S3存储桶Lambda函数的权限</div> <div class="option-analysis"><strong>C.</strong> 配置Amazon Simple Queue Service (<span class="key-service">Amazon SQS</span>)队列作为Lambda函数的OnFailure目标</div> <div class="option-analysis"><strong>D.</strong> 在Lambda函数的/tmp文件夹中预配空间以使函数能够处理来自S3存储桶的大文件<div class="section-title"><strong>核心要求:</strong></div> 解决S3事件触发器无法调用Lambda函数的权限问题 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• S3事件通知-当对象创建或修改时触发Lambda函数 </div><div class="compact-content">• Lambda资源策略-控制哪些服务可以调用Lambda函数 <div class="section-title"><strong>正确答案B:</strong></div> S3需要Lambda函数的资源策略明确授权才能调用函数，这是S3事件触发Lambda的必要权限配置 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A-内存大小不影响函数是否被触发，只影响执行时的性能 </div><div class="compact-content">• 选项C-OnFailure目标用于处理执行失败，不解决函数未被触发的问题 </div><div class="compact-content">• 选项D-/tmp空间配置不影响函数触发，只影响运行时的文件处理能力 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-资源策略不影响性能，仅控制访问权限 </div><div class="compact-content">• 成本-添加资源策略无额外成本 </div><div class="compact-content">• 可扩展性-正确的权限配置是所有后续功能的基础</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: D</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-177">
            <div class="question-header">
                <div class="question-title">Question #177 ✅ ⚪ <small style="float: right;">(177/353)</small></div>
            </div>
            <div class="question-content">A company has deployed a critical application in two AWS Regions. The application uses an Application Load Balancer (ALB) in both Regions. The company has <span class="key-service">Amazon Route 53</span> alias DNS records for both ALBs. The company uses <span class="key-service">Amazon Route 53</span> Application Recovery Controller to ensure that the application can fail over between the two Regions. The Route 53 ARC configuration includes a routing control for both Regions. The company uses Route 53 ARC to perform quarterly disaster recovery (DR) tests. During the most recent DR test, a DevOps engineer accidentally turned off both routing controls. The company needs to ensure that at least one routing control is turned on at all times. Which solution will meet these requirements? A (93%) 7%</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> In Route 53 ARC, create a new assertion safety rule. Apply the assertion safety rule to the two routing controls. Configure the rule with the ATLEAST type with a threshold of 1. Most Voted</div>                <div class="option"><strong>B.</strong> In Route 53 ARC, create a new gating safety rule. Apply the assertion safety rule to the two routing controls. Configure the rule with the OR type with a threshold of 1.</div>                <div class="option correct-answer"><strong>C.</strong> In Route 53 ARC, create a new resource set. Configure the resource set with an AWS::Route53::HealthCheck resource type. Specify the ARNs of the two routing controls as the target resource. Create a new readiness check for the resource set.</div>                <div class="option"><strong>D.</strong> In Route 53 ARC, create a new resource set. Configure the resource set with an AWS::Route53RecoveryReadiness::DNSTargetResource resource type. Add the domain names of the two Route 53 alias DNS records as the target resource. Create a new readiness check for the resource set.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司在两个AWS区域部署了关键应用程序。应用程序在两个区域都使用Application Load Balancer (ALB)。公司为两个ALB配置了Amazon Route 53别名DNS记录。公司使用Amazon Route 53 Application Recovery Controller确保应用程序可以在两个区域之间故障转移。Route 53 ARC配置包括两个区域的路由控制。公司使用Route 53 ARC执行季度灾难恢复(DR)测试。在最近的DR测试中，DevOps工程师意外关闭了两个路由控制。公司需要确保至少有一个路由控制始终处于开启状态。 <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 在Route 53 ARC中，创建新的断言安全规则。将断言安全规则应用于两个路由控制。配置规则为ATLEAST类型，阈值为1。</div> <div class="option-analysis"><strong>B.</strong> 在Route 53 ARC中，创建新的门控安全规则。将断言安全规则应用于两个路由控制。配置规则为OR类型，阈值为1。</div> <div class="option-analysis"><strong>C.</strong> 在Route 53 ARC中，创建新的资源集。配置资源集为AWS::Route53::HealthCheck资源类型。指定两个路由控制的ARN作为目标资源。为资源集创建新的就绪检查。</div> <div class="option-analysis"><strong>D.</strong> 在Route 53 ARC中，创建新的资源集。配置资源集为AWS::Route53RecoveryReadiness::DNSTargetResource资源类型。添加两个Route 53别名DNS记录的域名作为目标资源。为资源集创建新的就绪检查。<div class="section-title"><strong>核心要求:</strong></div> 防止意外同时关闭所有路由控制，确保至少一个路由控制始终开启 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• Route 53 ARC - 提供应用程序恢复控制和安全规则功能 </div><div class="compact-content">• Assertion Safety Rule - 确保指定数量的路由控制保持活跃状态 <div class="section-title"><strong>正确答案A:</strong></div> Assertion Safety Rule的ATLEAST类型可以强制要求至少保持指定数量的路由控制处于开启状态，防止全部关闭 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项B - Gating Safety Rule用于控制路由控制的开启/关闭操作，不是防止全部关闭的机制 </div><div class="compact-content">• 选项C - HealthCheck和Readiness Check用于监控资源健康状态，不能阻止路由控制被关闭 </div><div class="compact-content">• 选项D - DNS目标资源的就绪检查只验证DNS解析，无法防止路由控制操作 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能 - 安全规则提供实时保护，无延迟 </div><div class="compact-content">• 成本 - 使用现有ARC功能，无额外资源成本 </div><div class="compact-content">• 可扩展性 - 规则可应用于更多路由控制和区域</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: C</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-178">
            <div class="question-header">
                <div class="question-title">Question #178 ✅ ⚪ <small style="float: right;">(178/353)</small></div>
            </div>
            <div class="question-content">A healthcare services company is concerned about the growing costs of software licensing for an application for monitoring patient wellness. The company wants to create an audit process to ensure that the application is running exclusively on <span class="key-service">Amazon EC2</span> Dedicated Hosts. A DevOps engineer must create a workflow to audit the application to ensure compliance. What steps should the engineer take to meet this requirement with the LEAST administrative overhead? C (100%)</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Use <span class="key-service">AWS Systems Manager</span> Configuration Compliance. Use calls to the put-compliance-items API action to scan and build a database of noncompliant EC2 instances based on their host placement configuration. Use an <span class="key-service">Amazon DynamoDB</span> table to store these instance IDs for fast access. Generate a report through Systems Manager by calling the list-compliance-summaries API action.</div>                <div class="option"><strong>B.</strong> Use custom Java code running on an EC2 instance. Set up EC2 Auto Scaling for the instance depending on the number of instances to be checked. Send the list of noncompliant EC2 instance IDs to an <span class="key-service">Amazon SQS</span> queue. Set up another worker instance to process instance IDs from the SQS queue and write them to <span class="key-service">Amazon DynamoDB</span>. Use an <span class="key-service">AWS Lambda</span> function to terminate noncompliant instance IDs obtained from the queue, and send them to an <span class="key-service">Amazon SNS</span> email topic for distribution.</div>                <div class="option correct-answer"><strong>C.</strong> Use <span class="key-service">AWS Config</span>. Identify all EC2 instances to be audited by enabling Config Recording on all <span class="key-service">Amazon EC2</span> resources for the region. Create a custom <span class="key-service">AWS Config</span> rule that triggers an <span class="key-service">AWS Lambda</span> function by using the "config-rule-change-triggered" blueprint. Modify the Lambda evaluateCompliance() function to verify host placement to return a NON_COMPLIANT result if the instance is not running on an EC2 Dedicated Host. Use the <span class="key-service">AWS Config</span> report to address noncompliant instances.</div>                <div class="option"><strong>D.</strong> Use <span class="key-service">AWS CloudTrail</span>. Identify all EC2 instances to be audited by analyzing all calls to the EC2 RunCommand API action. Invoke an <span class="key-service">AWS Lambda</span> function that analyzes the host placement of the instance. Store the EC2 instance ID of noncompliant resources in an <span class="key-service">Amazon RDS</span> for MySQL DB instance. Generate a report by querying the RDS instance and exporting the query results to a CSV text file.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家医疗服务公司担心用于监控患者健康应用程序的软件许可成本不断增长。公司希望创建审计流程以确保应用程序仅在Amazon EC2 Dedicated Hosts上运行。DevOps工程师必须创建工作流来审计应用程序以确保合规性。工程师应采取哪些步骤以最少的管理开销满足此要求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 使用AWS Systems Manager Configuration Compliance。使用put-compliance-items API调用扫描并构建基于主机放置配置的不合规EC2实例数据库。使用Amazon DynamoDB表存储这些实例ID以便快速访问。通过调用list-compliance-summaries API操作通过Systems Manager生成报告。</div> <div class="option-analysis"><strong>B.</strong> 使用运行在EC2实例上的自定义Java代码。根据要检查的实例数量为该实例设置EC2 Auto Scaling。将不合规EC2实例ID列表发送到Amazon SQS队列。设置另一个工作实例处理来自SQS队列的实例ID并将其写入Amazon DynamoDB。使用AWS Lambda函数终止从队列获得的不合规实例ID，并将其发送到Amazon SNS邮件主题进行分发。</div> <div class="option-analysis"><strong>C.</strong> 使用AWS Config。通过为该区域的所有Amazon EC2资源启用Config Recording来识别所有要审计的EC2实例。创建自定义AWS Config规则，使用"config-rule-change-triggered"蓝图触发AWS Lambda函数。修改Lambda evaluateCompliance()函数以验证主机放置，如果实例未在EC2 Dedicated Host上运行则返回NON_COMPLIANT结果。使用AWS Config报告处理不合规实例。</div> <div class="option-analysis"><strong>D.</strong> 使用AWS CloudTrail。通过分析所有对EC2 RunCommand API操作的调用来识别所有要审计的EC2实例。调用AWS Lambda函数分析实例的主机放置。将不合规资源的EC2实例ID存储在Amazon RDS for MySQL数据库实例中。通过查询RDS实例并将查询结果导出到CSV文本文件来生成报告。<div class="section-title"><strong>核心要求:</strong></div> 以最少管理开销审计EC2实例是否运行在Dedicated Hosts上确保软件许可合规性 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• <span class="key-service">AWS Config</span>-持续监控和评估AWS资源配置合规性 </div><div class="compact-content">• Lambda-执行自定义合规性检查逻辑 <div class="section-title"><strong>正确答案C:</strong></div> AWS Config提供原生的资源配置监控和合规性评估能力，通过自定义规则和Lambda函数自动检查EC2实例主机放置配置，管理开销最小 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A-Systems Manager Configuration Compliance需要手动调用API构建数据库，管理开销较大 </div><div class="compact-content">• 选项B-需要维护自定义Java应用、Auto Scaling组和多个服务组件，管理复杂度高 </div><div class="compact-content">• 选项D-CloudTrail主要用于API调用审计而非资源配置合规性检查，且需要维护RDS数据库 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-AWS Config提供实时配置监控和自动触发评估 </div><div class="compact-content">• 成本-无需维护额外计算资源和数据库，按使用量付费 </div><div class="compact-content">• 可扩展性-Config自动扩展支持所有EC2资源，无需手动管理基础设施</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: C</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-179">
            <div class="question-header">
                <div class="question-title">Question #179 ✅ 📝 <small style="float: right;">(179/353)</small></div>
            </div>
            <div class="question-content">A DevOps engineer is planning to deploy a Ruby-based application to production. The application needs to interact with an <span class="key-service">Amazon RDS</span> for MySQL database and should have automatic scaling and high availability. The stored data in the database is critical and should persist regardless of the state of the application stack. The DevOps engineer needs to set up an automated deployment strategy for the application with automatic rollbacks. The solution also must alert the application team when a deployment fails. Which combination of steps will meet these requirements? (Choose three.) BCE (82%) Other</div>
            <div class="options-container">                <div class="option correct-answer"><strong>A.</strong> Deploy the application on AWS Elastic Beanstalk. Deploy an <span class="key-service">Amazon RDS</span> for MySQL DB instance as part of the Elastic Beanstalk configuration.</div>                <div class="option"><strong>B.</strong> Deploy the application on AWS Elastic Beanstalk. Deploy a separate <span class="key-service">Amazon RDS</span> for MySQL DB instance outside of Elastic Beanstalk.</div>                <div class="option"><strong>C.</strong> Configure a notification email address that alerts the application team in the AWS Elastic Beanstalk configuration.</div>                <div class="option correct-answer"><strong>D.</strong> Configure an Amazon EventBridge rule to monitor AWS Health events. Use an Amazon Simple Notification Service (<span class="key-service">Amazon SNS</span>) topic as a target to alert the application team.</div>                <div class="option correct-answer"><strong>E.</strong> Use the immutable deployment method to deploy new application versions. F. Use the rolling deployment method to deploy new application versions.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一名DevOps工程师计划将基于Ruby的应用程序部署到生产环境。应用程序需要与Amazon RDS for MySQL数据库交互，并应具有自动扩展和高可用性。数据库中存储的数据至关重要，无论应用程序堆栈状态如何都应持久保存。DevOps工程师需要为应用程序设置自动化部署策略并支持自动回滚。解决方案还必须在部署失败时向应用程序团队发出警报。哪些步骤组合将满足这些要求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 在AWS Elastic Beanstalk上部署应用程序。将Amazon RDS for MySQL数据库实例作为Elastic Beanstalk配置的一部分进行部署。</div> <div class="option-analysis"><strong>B.</strong> 在AWS Elastic Beanstalk上部署应用程序。在Elastic Beanstalk外部单独部署Amazon RDS for MySQL数据库实例。</div> <div class="option-analysis"><strong>C.</strong> 在AWS Elastic Beanstalk配置中配置通知电子邮件地址，以向应用程序团队发出警报。</div> <div class="option-analysis"><strong>D.</strong> 配置Amazon EventBridge规则来监控AWS Health事件。使用Amazon SNS主题作为目标来向应用程序团队发出警报。</div> <div class="option-analysis"><strong>E.</strong> 使用不可变部署方法来部署新的应用程序版本。 F. 使用滚动部署方法来部署新的应用程序版本。<div class="section-title"><strong>核心要求:</strong></div> 部署Ruby应用程序，实现数据持久化、自动扩展、<span class="key-point">高可用性</span>、自动回滚和失败告警 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• AWS Elastic Beanstalk-提供应用程序自动扩展、高可用性和部署管理 </div><div class="compact-content">• <span class="key-service">Amazon RDS</span>-提供托管数据库服务和数据持久化 </div><div class="compact-content">• Amazon EventBridge-监控AWS服务事件 </div><div class="compact-content">• <span class="key-service">Amazon SNS</span>-发送通知警报 <div class="section-title"><strong>正确答案ADE:</strong></div> A选项将RDS作为Beanstalk配置部分确保数据持久化，D选项通过EventBridge监控Health事件并用SNS发送告警，E选项不可变部署提供自动回滚能力 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项B-将RDS部署在Beanstalk外部增加配置复杂性，不如集成方案简洁 </div><div class="compact-content">• 选项C-Beanstalk内置通知功能有限，不如EventBridge+SNS组合灵活强大 </div><div class="compact-content">• 选项F-滚动部署在出现问题时回滚复杂，不如不可变部署安全 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-不可变部署确保零停机时间和快速回滚 </div><div class="compact-content">• 成本-Beanstalk集成RDS减少管理开销，EventBridge按使用量计费 </div><div class="compact-content">• 可扩展性-Beanstalk自动扩展应用层，RDS支持数据库扩展</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: ADE (A、D、E)</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-180">
            <div class="question-header">
                <div class="question-title">Question #180 ✅ 📝 <small style="float: right;">(180/353)</small></div>
            </div>
            <div class="question-content">A company is using <span class="key-service">AWS CodePipeline</span> to deploy an application. According to a new guideline, a member of the company's security team must sign off on any application changes before the changes are deployed into production. The approval must be recorded and retained. Which combination of actions will meet these requirements? (Choose two.) CE (88%) 8%</div>
            <div class="options-container">                <div class="option correct-answer"><strong>A.</strong> Configure CodePipeline to write actions to <span class="key-service">Amazon CloudWatch</span> Logs.</div>                <div class="option"><strong>B.</strong> Configure CodePipeline to write actions to an <span class="key-service">Amazon S3</span> bucket at the end of each pipeline stage.</div>                <div class="option"><strong>C.</strong> Create an <span class="key-service">AWS CloudTrail</span> trail to deliver logs to <span class="key-service">Amazon S3</span>.</div>                <div class="option correct-answer"><strong>D.</strong> Create a CodePipeline custom action to invoke an <span class="key-service">AWS Lambda</span> function for approval. Create a policy that gives the security team access to manage CodePipeline custom actions.</div>                <div class="option"><strong>E.</strong> Create a CodePipeline manual approval action before the deployment step. Create a policy that grants the security team access to approve manual approval stages.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司正在使用AWS CodePipeline部署应用程序。根据新准则，公司安全团队成员必须在任何应用程序更改部署到生产环境之前进行签署批准。批准必须被记录和保留。哪些操作组合将满足这些要求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 配置CodePipeline将操作写入Amazon CloudWatch Logs</div> <div class="option-analysis"><strong>B.</strong> 配置CodePipeline在每个管道阶段结束时将操作写入Amazon S3存储桶</div> <div class="option-analysis"><strong>C.</strong> 创建AWS CloudTrail跟踪以将日志传送到Amazon S3</div> <div class="option-analysis"><strong>D.</strong> 创建CodePipeline自定义操作来调用AWS Lambda函数进行批准，创建策略授予安全团队管理CodePipeline自定义操作的访问权限</div> <div class="option-analysis"><strong>E.</strong> 在部署步骤之前创建CodePipeline手动批准操作，创建策略授予安全团队批准手动批准阶段的访问权限<div class="section-title"><strong>核心要求:</strong></div> 实现安全团队批准机制并记录保留批准过程 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• CodePipeline-提供CI/CD管道和批准机制 </div><div class="compact-content">• CloudWatch Logs-记录和保留操作日志 </div><div class="compact-content">• Lambda-执行自定义批准逻辑 <div class="section-title"><strong>正确答案AD:</strong></div> A提供日志记录和保留功能，D通过Lambda自定义操作实现灵活的批准流程和权限控制 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项B-S3存储不是专门的日志记录解决方案，缺乏结构化日志管理 </div><div class="compact-content">• 选项C-CloudTrail记录API调用但不提供批准机制本身 </div><div class="compact-content">• 选项E-手动批准虽然可行但缺乏A选项的日志记录要求 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 功能性-必须同时满足批准和记录两个要求 </div><div class="compact-content">• 集成性-与CodePipeline原生集成的解决方案更优 </div><div class="compact-content">• 权限控制-需要细粒度的安全团队访问控制</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: AD (A、D)</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-181">
            <div class="question-header">
                <div class="question-title">Question #181 ✅ ⚪ <small style="float: right;">(181/353)</small></div>
            </div>
            <div class="question-content">A company requires its internal business teams to launch resources through pre-approved <span class="key-service">AWS CloudFormation</span> templates only. The security team requires automated monitoring when resources drift from their expected state. Which strategy should be used to meet these requirements? C (100%)</div>
            <div class="options-container">                <div class="option correct-answer"><strong>A.</strong> Allow users to deploy CloudFormation stacks using a CloudFormation service role only. Use CloudFormation drift detection to detect when resources have drifted from their expected state.</div>                <div class="option"><strong>B.</strong> Allow users to deploy CloudFormation stacks using a CloudFormation service role only. Use <span class="key-service">AWS Config</span> rules to detect when resources have drifted from their expected state.</div>                <div class="option"><strong>C.</strong> Allow users to deploy CloudFormation stacks using AWS Service Catalog only. Enforce the use of a launch constraint. Use <span class="key-service">AWS Config</span> rules to detect when resources have drifted from their expected state.</div>                <div class="option"><strong>D.</strong> Allow users to deploy CloudFormation stacks using AWS Service Catalog only. Enforce the use of a template constraint. Use Amazon EventBridge notifications to detect when resources have drifted from their expected state.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司要求其内部业务团队仅通过预先批准的AWS CloudFormation模板来启动资源。安全团队要求在资源偏离其预期状态时进行自动化监控。应该使用哪种策略来满足这些要求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 仅允许用户使用CloudFormation服务角色部署CloudFormation堆栈。使用CloudFormation漂移检测来检测资源何时偏离其预期状态。</div> <div class="option-analysis"><strong>B.</strong> 仅允许用户使用CloudFormation服务角色部署CloudFormation堆栈。使用AWS Config规则来检测资源何时偏离其预期状态。</div> <div class="option-analysis"><strong>C.</strong> 仅允许用户通过AWS Service Catalog部署CloudFormation堆栈。强制使用启动约束。使用AWS Config规则来检测资源何时偏离其预期状态。</div> <div class="option-analysis"><strong>D.</strong> 仅允许用户通过AWS Service Catalog部署CloudFormation堆栈。强制使用模板约束。使用Amazon EventBridge通知来检测资源何时偏离其预期状态。<div class="section-title"><strong>核心要求:</strong></div> 通过预批准模板控制资源部署并自动监控资源配置漂移 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• AWS Service Catalog-提供预批准模板的自助服务门户 </div><div class="compact-content">• <span class="key-service">AWS Config</span>-持续监控和评估AWS资源配置合规性 </div><div class="compact-content">• CloudFormation漂移检测-检测堆栈资源与模板定义的差异 <div class="section-title"><strong>正确答案A:</strong></div> CloudFormation服务角色确保权限控制，CloudFormation原生漂移检测功能可直接识别资源配置偏离模板定义的情况 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项B-AWS Config检测配置变化但不是专门针对CloudFormation模板漂移 </div><div class="compact-content">• 选项C-Service Catalog更适合但启动约束主要控制权限而非模板批准 </div><div class="compact-content">• 选项D-EventBridge不是漂移检测工具，模板约束也不是最佳实践 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-CloudFormation原生漂移检测响应最快 </div><div class="compact-content">• 成本-避免额外Config规则和Service Catalog的开销 </div><div class="compact-content">• 可扩展性-CloudFormation服务角色模式更简单易管理</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: A</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-182">
            <div class="question-header">
                <div class="question-title">Question #182 ✅ ⚪ <small style="float: right;">(182/353)</small></div>
            </div>
            <div class="question-content">A company has multiple development groups working in a single shared AWS account. The senior manager of the groups wants to be alerted via a third-party API call when the creation of resources approaches the service limits for the account. Which solution will accomplish this with the LEAST amount of development effort? B (100%)</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Create an Amazon EventBridge rule that runs periodically and targets an <span class="key-service">AWS Lambda</span> function. Within the Lambda function, evaluate the current state of the AWS environment and compare deployed resource values to resource limits on the account. Notify the senior manager if the account is approaching a service limit.</div>                <div class="option"><strong>B.</strong> Deploy an <span class="key-service">AWS Lambda</span> function that refreshes AWS Trusted Advisor checks, and configure an Amazon EventBridge rule to run the Lambda function periodically. Create another EventBridge rule with an event pattern matching Trusted Advisor events and a target Lambda function. In the target Lambda function, notify the senior manager.</div>                <div class="option correct-answer"><strong>C.</strong> Deploy an <span class="key-service">AWS Lambda</span> function that refreshes AWS Health Dashboard checks, and configure an Amazon EventBridge rule to run the Lambda function periodically. Create another EventBridge rule with an event pattern matching Health Dashboard events and a target Lambda function. In the target Lambda function, notify the senior manager.</div>                <div class="option"><strong>D.</strong> Add an <span class="key-service">AWS Config</span> custom rule that runs periodically, checks the AWS service limit status, and streams notifications to an Amazon Simple Notification Service (<span class="key-service">Amazon SNS</span>) topic. Deploy an <span class="key-service">AWS Lambda</span> function that notifies the senior manager, and subscribe the Lambda function to the SNS topic.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司有多个开发团队在单个共享的AWS账户中工作。团队的高级经理希望在资源创建接近账户服务限制时通过第三方API调用收到警报。哪种解决方案能以最少的开发工作量完成此任务？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 创建一个定期运行的Amazon EventBridge规则，目标为AWS Lambda函数。在Lambda函数中，评估AWS环境的当前状态，将已部署的资源值与账户资源限制进行比较。如果账户接近服务限制，则通知高级经理。</div> <div class="option-analysis"><strong>B.</strong> 部署一个刷新AWS Trusted Advisor检查的AWS Lambda函数，配置Amazon EventBridge规则定期运行该Lambda函数。创建另一个EventBridge规则，事件模式匹配Trusted Advisor事件并目标为Lambda函数。在目标Lambda函数中通知高级经理。</div> <div class="option-analysis"><strong>C.</strong> 部署一个刷新AWS Health Dashboard检查的AWS Lambda函数，配置Amazon EventBridge规则定期运行该Lambda函数。创建另一个EventBridge规则，事件模式匹配Health Dashboard事件并目标为Lambda函数。在目标Lambda函数中通知高级经理。</div> <div class="option-analysis"><strong>D.</strong> 添加一个定期运行的AWS Config自定义规则，检查AWS服务限制状态，并将通知流式传输到Amazon SNS主题。部署一个通知高级经理的AWS Lambda函数，并将Lambda函数订阅到SNS主题。<div class="section-title"><strong>核心要求:</strong></div> 监控AWS账户资源使用接近服务限制并通过第三方API发送警报 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• AWS Health Dashboard-提供个性化的AWS服务健康状态和限制监控 </div><div class="compact-content">• Amazon EventBridge-事件驱动架构，处理服务事件和定时触发 </div><div class="compact-content">• <span class="key-service">AWS Lambda</span>-无服务器计算，执行监控逻辑和通知功能 <div class="section-title"><strong>正确答案C:</strong></div> AWS Health Dashboard能够自动监控账户级别的服务限制状态并生成相应事件，通过EventBridge规则捕获这些事件并触发Lambda函数执行第三方API通知，开发工作量最少 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A-需要手动编写复杂的资源评估和限制比较逻辑，开发工作量大 </div><div class="compact-content">• 选项B-Trusted Advisor主要关注成本优化和安全建议，不是专门用于服务限制监控 </div><div class="compact-content">• 选项D-AWS Config规则需要自定义开发服务限制检查逻辑，增加开发复杂度 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-Health Dashboard提供实时服务限制监控和自动事件生成 </div><div class="compact-content">• 成本-利用现有AWS托管服务，无需额外基础设施成本 </div><div class="compact-content">• 可扩展性-EventBridge和Lambda自动扩展，支持多服务限制监控</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: C</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-183">
            <div class="question-header">
                <div class="question-title">Question #183 ✅ ⚪ <small style="float: right;">(183/353)</small></div>
            </div>
            <div class="question-content">A DevOps engineer is setting up a container-based architecture. The engineer has decided to use <span class="key-service">AWS CloudFormation</span> to automatically provision an <span class="key-service">Amazon ECS</span> cluster and an <span class="key-service">Amazon EC2</span> Auto Scaling group to launch the EC2 container instances. After successfully creating the CloudFormation stack, the engineer noticed that, even though the ECS cluster and the EC2 instances were created successfully and the stack finished the creation, the EC2 instances were associating with a different cluster. How should the DevOps engineer update the CloudFormation template to resolve this issue? B (100%)</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Reference the EC2 instances in the AWS::ECS::Cluster resource and reference the ECS cluster in the AWS::ECS::Service resource.</div>                <div class="option correct-answer"><strong>B.</strong> Reference the ECS cluster in the AWS::AutoScaling::LaunchConfiguration resource of the UserData property.</div>                <div class="option"><strong>C.</strong> Reference the ECS cluster in the AWS::EC2::Instance resource of the UserData property.</div>                <div class="option"><strong>D.</strong> Reference the ECS cluster in the AWS::CloudFormation::CustomResource resource to trigger an <span class="key-service">AWS Lambda</span> function that registers the EC2 instances with the appropriate ECS cluster.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一名DevOps工程师正在设置基于容器的架构。工程师决定使用AWS CloudFormation自动配置Amazon ECS集群和Amazon EC2 Auto Scaling组来启动EC2容器实例。成功创建CloudFormation堆栈后，工程师注意到尽管ECS集群和EC2实例都成功创建且堆栈完成创建，但EC2实例关联到了不同的集群。DevOps工程师应该如何更新CloudFormation模板来解决这个问题？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 在AWS::ECS::Cluster资源中引用EC2实例，在AWS::ECS::Service资源中引用ECS集群</div> <div class="option-analysis"><strong>B.</strong> 在AWS::AutoScaling::LaunchConfiguration资源的UserData属性中引用ECS集群</div> <div class="option-analysis"><strong>C.</strong> 在AWS::EC2::Instance资源的UserData属性中引用ECS集群</div> <div class="option-analysis"><strong>D.</strong> 在AWS::CloudFormation::CustomResource资源中引用ECS集群以触发AWS Lambda函数将EC2实例注册到适当的ECS集群<div class="section-title"><strong>核心要求:</strong></div> 确保Auto Scaling组启动的EC2实例正确关联到指定的ECS集群 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• ECS - 容器编排服务，需要EC2实例作为容器主机加入集群 </div><div class="compact-content">• Auto Scaling LaunchConfiguration - 定义实例启动模板，通过UserData配置实例初始化脚本 <div class="section-title"><strong>正确答案B:</strong></div> 在LaunchConfiguration的UserData中配置ECS_CLUSTER环境变量，使Auto Scaling启动的所有实例都自动加入指定集群 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A - ECS::Cluster资源不支持直接引用EC2实例，Service资源用于定义任务而非集群关联 </div><div class="compact-content">• 选项C - 使用EC2::Instance资源无法处理Auto Scaling动态创建的实例 </div><div class="compact-content">• 选项D - 使用Lambda自定义资源过于复杂，且无法保证实时性和可靠性 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能 - UserData在实例启动时立即执行，确保及时加入集群 </div><div class="compact-content">• 成本 - 原生CloudFormation功能，无需额外Lambda函数成本 </div><div class="compact-content">• 可扩展性 - LaunchConfiguration确保所有Auto Scaling创建的实例都正确配置</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: B</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-184">
            <div class="question-header">
                <div class="question-title">Question #184 ✅ 📝 <small style="float: right;">(184/353)</small></div>
            </div>
            <div class="question-content">A DevOps engineer is implementing governance controls for a company that requires its infrastructure to be housed within the United States. The engineer must restrict which AWS Regions can be used, and ensure an alert is sent as soon as possible if any activity outside the governance policy takes place. The controls should be automatically enabled on any new Region outside the United States (US). Which combination of actions will meet these requirements? (Choose two.) AB (91%) 9%</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Create an <span class="key-service">AWS Organizations</span> <span class="key-service">SCP</span> that denies access to all non-global services in non-US Regions. Attach the policy to the root of the organization. Most Voted</div>                <div class="option"><strong>B.</strong> Configure <span class="key-service">AWS CloudTrail</span> to send logs to <span class="key-service">Amazon CloudWatch</span> Logs and enable it for all Regions. Use a CloudWatch Logs metric filter to send an alert on any service activity in non-US Regions. Most Voted</div>                <div class="option correct-answer"><strong>C.</strong> Use an <span class="key-service">AWS Lambda</span> function that checks for AWS service activity and deploy it to all Regions. Write an Amazon EventBridge rule that runs the Lambda function every hour, sending an alert if activity is found in a non-US Region.</div>                <div class="option correct-answer"><strong>D.</strong> Use an <span class="key-service">AWS Lambda</span> function to query Amazon Inspector to look for service activity in non-US Regions and send alerts if any activity is found.</div>                <div class="option"><strong>E.</strong> Write an <span class="key-service">SCP</span> using the aws:RequestedRegion condition key limiting access to US Regions. Apply the policy to all users, groups, and roles.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一名DevOps工程师正在为要求基础设施必须位于美国境内的公司实施治理控制。工程师必须限制可使用的AWS Regions，并确保在发生任何违反治理政策的活动时尽快发送警报。控制措施应在美国境外的任何新Region上自动启用。哪种操作组合将满足这些要求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 创建一个AWS Organizations <span class="key-service">SCP</span>，拒绝访问非美国Regions中的所有非全球服务。将策略附加到组织的根部。</div> <div class="option-analysis"><strong>B.</strong> 配置AWS CloudTrail将日志发送到Amazon CloudWatch Logs并为所有Regions启用。使用CloudWatch Logs指标过滤器在非美国Regions中的任何服务活动时发送警报。</div> <div class="option-analysis"><strong>C.</strong> 使用检查AWS服务活动的AWS Lambda函数并将其部署到所有Regions。编写Amazon EventBridge规则每小时运行Lambda函数，如果在非美国Region中发现活动则发送警报。</div> <div class="option-analysis"><strong>D.</strong> 使用AWS Lambda函数查询Amazon Inspector以查找非美国Regions中的服务活动，如果发现任何活动则发送警报。</div> <div class="option-analysis"><strong>E.</strong> 使用aws:RequestedRegion条件键编写SCP限制访问美国Regions。将策略应用于所有用户、组和角色。<div class="section-title"><strong>核心要求:</strong></div> 限制非美国Regions访问并实现实时监控告警 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• <span class="key-service">AWS Organizations</span> <span class="key-service">SCP</span>-通过策略控制Region访问权限 </div><div class="compact-content">• CloudTrail+CloudWatch-提供跨Region活动监控和告警能力 </div><div class="compact-content">• Lambda+EventBridge-实现定期检查和自动化响应 <div class="section-title"><strong>正确答案CD:</strong></div> C提供定期自动化检查机制，D利用Inspector进行服务活动监控，两者结合实现完整的监控告警体系 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A-SCP应附加到OU而非root，且策略范围过于宽泛 </div><div class="compact-content">• 选项B-CloudTrail配置正确但单独使用无法满足自动化要求 </div><div class="compact-content">• 选项E-条件键使用正确但应用范围不当，缺乏告警机制 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-实时监控和快速告警响应 </div><div class="compact-content">• 成本-Lambda按需计费，EventBridge规则成本低 </div><div class="compact-content">• 可扩展性-自动适应新Region和组织变化</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: CD (C、D)</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-185">
            <div class="question-header">
                <div class="question-title">Question #185 ✅ ⚪ <small style="float: right;">(185/353)</small></div>
            </div>
            <div class="question-content">A company sells products through an ecommerce web application. The company wants a dashboard that shows a pie chart of product transaction details. The company wants to integrate the dashboard with the company's existing <span class="key-service">Amazon CloudWatch</span> dashboards. Which solution will meet these requirements with the MOST operational efficiency? A (92%) 4%</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Update the ecommerce application to emit a JSON object to a CloudWatch log group for each processed transaction. Use CloudWatch Logs Insights to query the log group and to visualize the results in a pie chart format. Attach the results to the desired CloudWatch dashboard.</div>                <div class="option correct-answer"><strong>B.</strong> Update the ecommerce application to emit a JSON object to an <span class="key-service">Amazon S3</span> bucket for each processed transaction. Use Amazon Athena to query the S3 bucket and to visualize the results in a pie chart format. Export the results from Athena. Attach the results to the desired CloudWatch dashboard.</div>                <div class="option"><strong>C.</strong> Update the ecommerce application to use AWS X-Ray for instrumentation. Create a new X-Ray subsegment. Add an annotation for each processed transaction. Use X-Ray traces to query the data and to visualize the results in a pie chart format. Attach the results to the desired CloudWatch dashboard.</div>                <div class="option"><strong>D.</strong> Update the ecommerce application to emit a JSON object to a CloudWatch log group for each processed transaction. Create an <span class="key-service">AWS Lambda</span> function to aggregate and write the results to <span class="key-service">Amazon DynamoDB</span>. Create a Lambda subscription filter for the log file. Attach the results to the desired CloudWatch dashboard.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司通过电商Web应用销售产品。公司希望有一个显示产品交易详情饼图的仪表板。公司希望将该仪表板与现有的Amazon CloudWatch仪表板集成。哪个解决方案能以最高的运营效率满足这些要求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 更新电商应用程序，为每个处理的交易向CloudWatch日志组发送JSON对象。使用CloudWatch Logs Insights查询日志组并以饼图格式可视化结果。将结果附加到所需的CloudWatch仪表板。</div> <div class="option-analysis"><strong>B.</strong> 更新电商应用程序，为每个处理的交易向Amazon S3存储桶发送JSON对象。使用Amazon Athena查询S3存储桶并以饼图格式可视化结果。从Athena导出结果。将结果附加到所需的CloudWatch仪表板。</div> <div class="option-analysis"><strong>C.</strong> 更新电商应用程序使用AWS X-Ray进行检测。创建新的X-Ray子段。为每个处理的交易添加注释。使用X-Ray跟踪查询数据并以饼图格式可视化结果。将结果附加到所需的CloudWatch仪表板。</div> <div class="option-analysis"><strong>D.</strong> 更新电商应用程序，为每个处理的交易向CloudWatch日志组发送JSON对象。创建AWS Lambda函数聚合结果并写入Amazon DynamoDB。为日志文件创建Lambda订阅过滤器。将结果附加到所需的CloudWatch仪表板。<div class="section-title"><strong>核心要求:</strong></div> 创建产品交易饼图仪表板并与现有CloudWatch仪表板集成，要求最高运营效率 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• <span class="key-service">Amazon S3</span>-存储交易数据的JSON对象 </div><div class="compact-content">• Amazon Athena-查询S3数据并提供可视化功能 </div><div class="compact-content">• CloudWatch-集成现有仪表板 <div class="section-title"><strong>正确答案B:</strong></div> S3存储交易数据，Athena提供强大的查询和原生可视化功能，可直接生成饼图并导出到CloudWatch仪表板，架构简单运营效率最高 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A-CloudWatch Logs Insights缺乏原生饼图可视化功能，需要额外工具处理 </div><div class="compact-content">• 选项C-X-Ray主要用于应用性能监控，不是为业务数据可视化设计，功能不匹配 </div><div class="compact-content">• 选项D-架构过于复杂，需要Lambda和DynamoDB等多个组件，增加运营复杂性 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-Athena提供高性能查询和原生可视化能力 </div><div class="compact-content">• 成本-S3+Athena按使用付费，成本效益高 </div><div class="compact-content">• 可扩展性-S3和Athena都具备自动扩展能力，运营效率最优</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: B</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-186">
            <div class="question-header">
                <div class="question-title">Question #186 ✅ ⚪ <small style="float: right;">(186/353)</small></div>
            </div>
            <div class="question-content">A company is launching an application. The application must use only approved AWS services. The account that runs the application was created less than 1 year ago and is assigned to an <span class="key-service">AWS Organizations</span> OU. The company needs to create a new Organizations account structure. The account structure must have an appropriate <span class="key-service">SCP</span> that supports the use of only services that are currently active in the AWS account. The company will use AWS Identity and Access Management (IAM) Access Analyzer in the solution. Which solution will meet these requirements? A (88%) 13%</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Create an <span class="key-service">SCP</span> that allows the services that IAM Access Analyzer identifies. Create an OU for the account. Move the account into the new OU. Attach the new <span class="key-service">SCP</span> to the new OU. Detach the default FullAWSAccess <span class="key-service">SCP</span> from the new OU. Most Voted</div>                <div class="option"><strong>B.</strong> Create an <span class="key-service">SCP</span> that denies the services that IAM Access Analyzer identifies. Create an OU for the account. Move the account into the new OU. Attach the new <span class="key-service">SCP</span> to the new OU.</div>                <div class="option"><strong>C.</strong> Create an <span class="key-service">SCP</span> that allows the services that IAM Access Analyzer identifies. Attach the new <span class="key-service">SCP</span> to the organization's root.</div>                <div class="option correct-answer"><strong>D.</strong> Create an <span class="key-service">SCP</span> that allows the services that IAM Access Analyzer identifies. Create an OU for the account. Move the account into the new OU. Attach the new <span class="key-service">SCP</span> to the management account. Detach the default FullAWSAccess <span class="key-service">SCP</span> from the new OU.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司正在启动应用程序，该应用程序必须仅使用已批准的AWS服务。运行应用程序的账户创建不到1年并分配给AWS Organizations OU。公司需要创建新的Organizations账户结构，该结构必须具有适当的SCP，支持仅使用AWS账户中当前活跃的服务。公司将在解决方案中使用AWS Identity and Access Management (IAM) Access Analyzer。 <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 创建允许IAM Access Analyzer识别的服务的SCP，为账户创建OU，将账户移动到新OU，将新SCP附加到新OU，从新OU分离默认的FullAWSAccess <span class="key-service">SCP</span></div> <div class="option-analysis"><strong>B.</strong> 创建拒绝IAM Access Analyzer识别的服务的SCP，为账户创建OU，将账户移动到新OU，将新SCP附加到新OU</div> <div class="option-analysis"><strong>C.</strong> 创建允许IAM Access Analyzer识别的服务的SCP，将新SCP附加到组织的根</div> <div class="option-analysis"><strong>D.</strong> 创建允许IAM Access Analyzer识别的服务的SCP，为账户创建OU，将账户移动到新OU，将新SCP附加到管理账户，从新OU分离默认的FullAWSAccess <span class="key-service">SCP</span><div class="section-title"><strong>核心要求:</strong></div> 创建Organizations账户结构，使用SCP限制仅允许当前活跃的AWS服务 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• <span class="key-service">AWS Organizations</span> - 集中管理多个AWS账户的服务 </div><div class="compact-content">• <span class="key-service">SCP</span> (Service Control Policy) - 控制组织中账户可访问的AWS服务的策略 </div><div class="compact-content">• IAM Access Analyzer - 分析资源访问模式和识别当前使用的服务 <div class="section-title"><strong>正确答案D:</strong></div> 创建允许策略的SCP并附加到管理账户，同时分离默认的FullAWSAccess <span class="key-service">SCP</span>，确保策略生效并限制服务使用 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A - SCP应附加到管理账户而不是OU，才能有效控制组织内的服务访问 </div><div class="compact-content">• 选项B - 应创建允许策略而非拒绝策略，拒绝策略无法有效限制仅使用特定服务 </div><div class="compact-content">• 选项C - 将SCP附加到根会影响所有账户，不符合针对特定账户的要求 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 安全性 - SCP必须附加到正确位置才能生效控制服务访问 </div><div class="compact-content">• 管理性 - 需要分离默认策略确保新策略生效 </div><div class="compact-content">• 精确性 - 使用允许策略精确控制可用服务范围</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: D</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-187">
            <div class="question-header">
                <div class="question-title">Question #187 ✅ ⚪ <small style="float: right;">(187/353)</small></div>
            </div>
            <div class="question-content">A company has multiple development teams in different business units that work in a shared single AWS account. All <span class="key-service">Amazon EC2</span> resources that are created in the account must include tags that specify who created the resources. The tagging must occur within the first hour of resource creation. A DevOps engineer needs to add tags to the created resources that include the user ID that created the resource and the cost center I<div class="option-analysis"><strong>D.</strong> The DevOps engineer configures an <span class="key-service">AWS Lambda</span> function with the cost center mappings to tag the resources. The DevOps engineer also sets up <span class="key-service">AWS CloudTrail</span> in the AWS account. An <span class="key-service">Amazon S3</span> bucket stores the CloudTrail event logs. Which solution will meet the tagging requirements? D (100%)</div></div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Create an S3 event notification on the S3 bucket to invoke the Lambda function for s3:ObjectTagging:Put events. Enable bucket versioning on the S3 bucket.</div>                <div class="option"><strong>B.</strong> Enable server access logging on the S3 bucket. Create an S3 event notification on the S3 bucket for s3:ObjectTagging:* events.</div>                <div class="option correct-answer"><strong>C.</strong> Create a recurring hourly Amazon EventBridge scheduled rule that invokes the Lambda function. Modify the Lambda function to read the logs from the S3 bucket.</div>                <div class="option"><strong>D.</strong> Create an Amazon EventBridge rule that uses <span class="key-service">Amazon EC2</span> as the event source. Configure the rule to match events delivered by CloudTrail. Configure the rule to target the Lambda function.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司在共享的单个AWS账户中有多个开发团队，所有创建的Amazon EC2资源必须包含标签来指定创建者，标记必须在资源创建后一小时内完成。DevOps工程师需要添加包含用户ID和成本中心ID的标签，配置了Lambda函数进行成本中心映射标记，并设置了CloudTrail将事件日志存储在S3存储桶中。 <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 在S3存储桶上创建S3事件通知，为s3:ObjectTagging:Put事件调用Lambda函数，在S3存储桶上启用版本控制。</div> <div class="option-analysis"><strong>B.</strong> 在S3存储桶上启用服务器访问日志记录，为s3:ObjectTagging:*事件在S3存储桶上创建S3事件通知。</div> <div class="option-analysis"><strong>C.</strong> 创建每小时重复的Amazon EventBridge计划规则来调用Lambda函数，修改Lambda函数从S3存储桶读取日志。</div> <div class="option-analysis"><strong>D.</strong> 创建使用Amazon EC2作为事件源的Amazon EventBridge规则，配置规则匹配CloudTrail传递的事件，配置规则目标为Lambda函数。<div class="section-title"><strong>核心要求:</strong></div> 为新创建的EC2资源在一小时内自动添加用户ID和成本中心ID标签 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• CloudTrail-记录EC2资源创建的API调用事件 </div><div class="compact-content">• Lambda-执行自动标记逻辑和成本中心映射 </div><div class="compact-content">• EventBridge-触发Lambda函数执行标记任务 <div class="section-title"><strong>正确答案C:</strong></div> 使用定时规则每小时触发Lambda函数处理CloudTrail日志，确保在一小时时间窗口内完成所有资源的标记要求 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A-S3对象标记事件与EC2资源创建无关，无法触发EC2资源标记 </div><div class="compact-content">• 选项B-服务器访问日志和对象标记事件都不能检测到EC2资源创建 </div><div class="compact-content">• 选项D-EventBridge无法直接使用EC2作为事件源来检测资源创建事件 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-定时批处理方式满足一小时内标记的时间要求 </div><div class="compact-content">• 成本-避免实时事件处理的高频调用成本 </div><div class="compact-content">• 可扩展性-批处理模式能够处理大量资源创建事件</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: C</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-188">
            <div class="question-header">
                <div class="question-title">Question #188 ✅ ⚪ <small style="float: right;">(188/353)</small></div>
            </div>
            <div class="question-content">A company runs an application for multiple environments in a single AWS account. An <span class="key-service">AWS CodePipeline</span> pipeline uses a development Amazon Elastic Container Service (<span class="key-service">Amazon ECS</span>) cluster to test an image for the application from an Amazon Elastic Container Registry (<span class="key-service">Amazon ECR</span>) repository. The pipeline promotes the image to a production ECS cluster. The company needs to move the production cluster into a separate AWS account in the same AWS Region. The production cluster must be able to download the images over a private connection. Which solution will meet these requirements? D (90%) 10%</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Use <span class="key-service">Amazon ECR</span> <span class="key-service">VPC</span> endpoints and an <span class="key-service">Amazon S3</span> gateway endpoint. In the separate AWS account, create an ECR repository. Set the repository policy to allow the production ECS tasks to pull images from the main AWS account. Configure the production ECS task execution role to have permission to download the image from the ECR repository.</div>                <div class="option correct-answer"><strong>B.</strong> Set a repository policy on the production ECR repository in the main AWS account. Configure the repository policy to allow the production ECS tasks in the separate AWS account to pull images from the main account. Configure the production ECS task execution role to have permission to download the image from the ECR repository.</div>                <div class="option"><strong>C.</strong> Configure ECR private image replication in the main AWS account. Activate cross-account replication. Define the destination account ID of the separate AWS account.</div>                <div class="option"><strong>D.</strong> Use <span class="key-service">Amazon ECR</span> <span class="key-service">VPC</span> endpoints and an <span class="key-service">Amazon S3</span> gateway endpoint. Set a repository policy on the production ECR repository in the main AWS account. Configure the repository policy to allow the production ECS tasks in the separate AWS account to pull images from the main account. Configure the production ECS task execution role to have permission to download the image from the ECR repository.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司在单个AWS账户中为多个环境运行应用程序。AWS CodePipeline管道使用开发Amazon ECS集群从Amazon ECR存储库测试应用程序镜像。管道将镜像推广到生产ECS集群。公司需要将生产集群移动到同一AWS区域的单独AWS账户中。生产集群必须能够通过私有连接下载镜像。哪种解决方案满足这些要求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 使用Amazon ECR VPC端点和Amazon S3网关端点。在单独的AWS账户中创建ECR存储库。设置存储库策略允许生产ECS任务从主AWS账户拉取镜像。配置生产ECS任务执行角色具有从ECR存储库下载镜像的权限。</div> <div class="option-analysis"><strong>B.</strong> 在主AWS账户的生产ECR存储库上设置存储库策略。配置存储库策略允许单独账户中的生产ECS任务从主账户拉取镜像。配置生产ECS任务执行角色具有从ECR存储库下载镜像的权限。</div> <div class="option-analysis"><strong>C.</strong> 在主AWS账户中配置ECR私有镜像复制。激活跨账户复制。定义单独账户的目标账户ID。</div> <div class="option-analysis"><strong>D.</strong> 使用Amazon ECR VPC端点和Amazon S3网关端点。在主AWS账户的生产ECR存储库上设置存储库策略。配置存储库策略允许单独账户中的生产ECS任务从主账户拉取镜像。配置生产ECS任务执行角色具有从ECR存储库下载镜像的权限。<div class="section-title"><strong>核心要求:</strong></div> 实现跨账户ECR镜像访问并确保私有连接 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• <span class="key-service">Amazon ECR</span>-容器镜像存储和跨账户访问控制 </div><div class="compact-content">• <span class="key-service">Amazon ECS</span>-容器服务需要拉取镜像权限 </div><div class="compact-content">• VPC端点-提供私有网络连接 <div class="section-title"><strong>正确答案B:</strong></div> 通过ECR存储库策略配置跨账户访问权限，结合ECS任务执行角色权限实现安全的镜像拉取 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A-不需要在目标账户创建新的ECR存储库，增加不必要复杂性 </div><div class="compact-content">• 选项C-镜像复制会产生额外存储成本且不是必需的 </div><div class="compact-content">• 选项D-虽然包含VPC端点但题目未明确要求，B选项更简洁有效 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-直接跨账户访问避免复制延迟 </div><div class="compact-content">• 成本-避免重复存储和数据传输费用 </div><div class="compact-content">• 可扩展性-存储库策略支持灵活的权限管理</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: B</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-189">
            <div class="question-header">
                <div class="question-title">Question #189 ✅ ⚪ <small style="float: right;">(189/353)</small></div>
            </div>
            <div class="question-content">A company needs to ensure that flow logs remain configured for all existing and new VPCs in its AWS account. The company uses an <span class="key-service">AWS CloudFormation</span> stack to manage its VPCs. The company needs a solution that will work for any VPCs that any IAM user creates. Which solution will meet these requirements? C (94%) 6%</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Add the AWS::EC2::FlowLog resource to the CloudFormation stack that creates the VPCs.</div>                <div class="option"><strong>B.</strong> Create an organization in <span class="key-service">AWS Organizations</span>. Add the company's AWS account to the organization. Create an <span class="key-service">SCP</span> to prevent users from modifying <span class="key-service">VPC</span> flow logs.</div>                <div class="option correct-answer"><strong>C.</strong> Turn on <span class="key-service">AWS Config</span>. Create an <span class="key-service">AWS Config</span> rule to check whether <span class="key-service">VPC</span> flow logs are turned on. Configure automatic remediation to turn on <span class="key-service">VPC</span> flow logs.</div>                <div class="option"><strong>D.</strong> Create an IAM policy to deny the use of API calls for <span class="key-service">VPC</span> flow logs. Attach the IAM policy to all IAM users.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司需要确保其AWS账户中所有现有和新建的VPC都配置了flow logs。该公司使用AWS CloudFormation堆栈管理VPC。公司需要一个适用于任何IAM用户创建的VPC的解决方案。 <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 将AWS::EC2::FlowLog资源添加到创建VPC的CloudFormation堆栈中。</div> <div class="option-analysis"><strong>B.</strong> 在AWS Organizations中创建组织，将公司的AWS账户添加到组织中，创建SCP阻止用户修改VPC flow logs。</div> <div class="option-analysis"><strong>C.</strong> 启用AWS Config，创建AWS Config规则检查VPC flow logs是否开启，配置自动修复以启用VPC flow logs。</div> <div class="option-analysis"><strong>D.</strong> 创建IAM策略拒绝使用VPC flow logs的API调用，将IAM策略附加到所有IAM用户。<div class="section-title"><strong>核心要求:</strong></div> 确保所有现有和新建VPC都自动配置flow logs，包括非CloudFormation创建的VPC <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• <span class="key-service">AWS Config</span> - 监控资源配置合规性并提供自动修复功能 </div><div class="compact-content">• <span class="key-service">VPC</span> Flow Logs - 记录VPC网络流量的日志服务 <div class="section-title"><strong>正确答案C:</strong></div> AWS Config规则可持续监控所有VPC的flow logs配置状态，无论VPC如何创建，并通过自动修复功能确保合规性 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A - 仅适用于CloudFormation创建的VPC，无法覆盖IAM用户直接创建的VPC </div><div class="compact-content">• 选项B - SCP只能阻止修改操作，无法自动为现有VPC启用flow logs </div><div class="compact-content">• 选项D - 拒绝API调用会阻止启用flow logs，与需求相反 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能 - Config规则提供实时监控和快速修复 </div><div class="compact-content">• 成本 - 无需额外基础设施，仅Config服务费用 </div><div class="compact-content">• 可扩展性 - 自动适用于所有VPC，无论创建方式</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: C</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-190">
            <div class="question-header">
                <div class="question-title">Question #190 ✅ 📝 <small style="float: right;">(190/353)</small></div>
            </div>
            <div class="question-content">A company's application teams use <span class="key-service">AWS CodeCommit</span> repositories for their applications. The application teams have repositories in multiple AWS accounts. All accounts are in an organization in <span class="key-service">AWS Organizations</span>. Each application team uses <span class="key-service">AWS IAM</span> Identity Center (AWS Single Sign-On) configured with an external IdP to assume a developer IAM role. The developer role allows the application teams to use Git to work with the code in the repositories. A security audit reveals that the application teams can modify the main branch in any repository. A DevOps engineer must implement a solution that allows the application teams to modify the main branch of only the repositories that they manage. Which combination of steps will meet these requirements? (Choose three.) ADE (65%) ADF (23%) 12%</div>
            <div class="options-container">                <div class="option correct-answer"><strong>A.</strong> Update the SAML assertion to pass the user's team name. Update the IAM role's trust policy to add an access-team session tag that has the team name.</div>                <div class="option correct-answer"><strong>B.</strong> Create an approval rule template for each team in the Organizations management account. Associate the template with all the repositories. Add the developer role ARN as an approver.</div>                <div class="option correct-answer"><strong>C.</strong> Create an approval rule template for each account. Associate the template with all repositories. Add the "aws:ResourceTag/access-team": "${aws:PrincipalTag/access-team}" condition to the approval rule template.</div>                <div class="option"><strong>D.</strong> For each CodeCommit repository, add an access-team tag that has the value set to the name of the associated team.</div>                <div class="option"><strong>E.</strong> Attach an <span class="key-service">SCP</span> to the accounts. Include the following statement: F. Create an IAM permissions boundary in each account. Include the following statement:</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 公司的应用团队使用AWS CodeCommit存储库管理应用程序。应用团队在多个AWS账户中拥有存储库，所有账户都在AWS Organizations组织中。每个应用团队使用配置了外部IdP的AWS IAM Identity Center来担任开发者IAM角色。开发者角色允许应用团队使用Git处理存储库中的代码。安全审计发现应用团队可以修改任何存储库的主分支。DevOps工程师必须实施解决方案，使应用团队只能修改他们管理的存储库的主分支。 <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 更新SAML断言以传递用户的团队名称，更新IAM角色的信任策略以添加包含团队名称的access-team会话标签</div> <div class="option-analysis"><strong>B.</strong> 在Organizations管理账户中为每个团队创建审批规则模板，将模板与所有存储库关联，添加开发者角色ARN作为审批者</div> <div class="option-analysis"><strong>C.</strong> 为每个账户创建审批规则模板，将模板与所有存储库关联，在审批规则模板中添加"aws:ResourceTag/access-team": "${aws:PrincipalTag/access-team}"条件</div> <div class="option-analysis"><strong>D.</strong> 为每个CodeCommit存储库添加access-team标签，值设置为关联团队的名称</div> <div class="option-analysis"><strong>E.</strong> 将SCP附加到账户，包含以下语句 F. 在每个账户中创建IAM权限边界，包含以下语句<div class="section-title"><strong>核心要求:</strong></div> 限制应用团队只能修改其管理的CodeCommit存储库主分支 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• <span class="key-service">AWS IAM</span> Identity Center - 提供基于团队的身份验证和会话标签 </div><div class="compact-content">• <span class="key-service">AWS CodeCommit</span> - 代码存储库服务，需要基于团队的访问控制 </div><div class="compact-content">• <span class="key-service">AWS Organizations</span> - 多账户管理和策略执行 <div class="section-title"><strong>正确答案ACD:</strong></div> 通过SAML断言传递团队标签(A)，为存储库添加团队标签(D)，使用SCP策略基于标签匹配控制访问权限(E)，实现细粒度的存储库访问控制 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项B - 审批规则模板用于代码审查流程，不能直接限制分支修改权限 </div><div class="compact-content">• 选项C - 审批规则模板无法实现基于标签的访问控制，且条件语法不适用于此场景 </div><div class="compact-content">• 选项F - IAM权限边界在账户级别控制，无法提供存储库级别的细粒度控制 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 安全性 - 基于团队标签的细粒度访问控制 </div><div class="compact-content">• 可管理性 - 通过标签和SCP实现集中化策略管理 </div><div class="compact-content">• 可扩展性 - 支持多账户多团队的动态权限分配</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: ABC (A、B、C)</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-191">
            <div class="question-header">
                <div class="question-title">Question #191 ✅ ⚪ <small style="float: right;">(191/353)</small></div>
            </div>
            <div class="question-content">A company uses AWS WAF to protect its cloud infrastructure. A DevOps engineer needs to give an operations team the ability to analyze log messages from AWS WAF. The operations team needs to be able to create alarms for specific patterns in the log output. Which solution will meet these requirements with the LEAST operational overhead? A (88%) 13%</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Create an <span class="key-service">Amazon CloudWatch</span> Logs log group. Configure the appropriate AWS WAF web ACL to send log messages to the log group. Instruct the operations team to create CloudWatch metric filters.</div>                <div class="option correct-answer"><strong>B.</strong> Create an Amazon OpenSearch Service cluster and appropriate indexes. Configure an Amazon Kinesis Data Firehose delivery stream to stream log data to the indexes. Use OpenSearch Dashboards to create filters and widgets.</div>                <div class="option"><strong>C.</strong> Create an <span class="key-service">Amazon S3</span> bucket for the log output. Configure AWS WAF to send log outputs to the S3 bucket. Instruct the operations team to create <span class="key-service">AWS Lambda</span> functions that detect each desired log message pattern. Configure the Lambda functions to publish to an Amazon Simple Notification Service (<span class="key-service">Amazon SNS</span>) topic.</div>                <div class="option"><strong>D.</strong> Create an <span class="key-service">Amazon S3</span> bucket for the log output. Configure AWS WAF to send log outputs to the S3 bucket. Use Amazon Athena to create an external table definition that fits the log message pattern. Instruct the operations team to write SQL queries and to create <span class="key-service">Amazon CloudWatch</span> metric filters for the Athena queries.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司使用AWS WAF保护其云基础设施。DevOps工程师需要给运维团队分析AWS WAF日志消息的能力。运维团队需要能够为日志输出中的特定模式创建告警。哪个解决方案能以最少的运维开销满足这些要求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 创建Amazon CloudWatch Logs日志组，配置相应的AWS WAF web ACL将日志消息发送到日志组，指导运维团队创建CloudWatch指标过滤器</div> <div class="option-analysis"><strong>B.</strong> 创建Amazon OpenSearch Service集群和相应索引，配置Amazon Kinesis Data Firehose传输流将日志数据流式传输到索引，使用OpenSearch Dashboards创建过滤器和小部件</div> <div class="option-analysis"><strong>C.</strong> 为日志输出创建Amazon S3存储桶，配置AWS WAF将日志输出发送到S3存储桶，指导运维团队创建AWS Lambda函数检测每个所需的日志消息模式，配置Lambda函数发布到Amazon SNS主题</div> <div class="option-analysis"><strong>D.</strong> 为日志输出创建Amazon S3存储桶，配置AWS WAF将日志输出发送到S3存储桶，使用Amazon Athena创建适合日志消息模式的外部表定义，指导运维团队编写SQL查询并为Athena查询创建Amazon CloudWatch指标过滤器<div class="section-title"><strong>核心要求:</strong></div> 为AWS WAF日志分析和模式告警提供最低运维开销的解决方案 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• AWS WAF - Web应用防火墙日志生成 </div><div class="compact-content">• OpenSearch Service - 实时日志分析和可视化平台 </div><div class="compact-content">• CloudWatch Logs - 基础日志存储和监控服务 <div class="section-title"><strong>正确答案B:</strong></div> OpenSearch Service提供原生的日志分析、实时搜索、可视化仪表板和告警功能，通过Kinesis Data Firehose实现自动化数据流处理，运维开销最小 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A - CloudWatch Logs缺乏复杂模式分析和可视化能力，需要手动创建多个指标过滤器 </div><div class="compact-content">• 选项C - 需要开发和维护多个Lambda函数，运维复杂度高，成本较高 </div><div class="compact-content">• 选项D - Athena查询需要手动触发，无法实现实时监控，且SQL查询维护复杂 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能 - OpenSearch提供实时搜索和分析能力 </div><div class="compact-content">• 成本 - 托管服务减少开发和维护成本 </div><div class="compact-content">• 可扩展性 - 原生支持复杂日志模式分析和自动化告警</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: B</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-192">
            <div class="question-header">
                <div class="question-title">Question #192 ✅ ⚪ <small style="float: right;">(192/353)</small></div>
            </div>
            <div class="question-content">A software team is using <span class="key-service">AWS CodePipeline</span> to automate its Java application release pipeline. The pipeline consists of a source stage, then a build stage, and then a deploy stage. Each stage contains a single action that has a runOrder value of 1. The team wants to integrate unit tests into the existing release pipeline. The team needs a solution that deploys only the code changes that pass all unit tests. Which solution will meet these requirements? B (95%) 5%</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Modify the build stage. Add a test action that has a runOrder value of 1. Use <span class="key-service">AWS CodeDeploy</span> as the action provider to run unit tests.</div>                <div class="option"><strong>B.</strong> Modify the build stage. Add a test action that has a runOrder value of 2. Use <span class="key-service">AWS CodeBuild</span> as the action provider to run unit tests.</div>                <div class="option correct-answer"><strong>C.</strong> Modify the deploy stage. Add a test action that has a runOrder value of 1. Use <span class="key-service">AWS CodeDeploy</span> as the action provider to run unit tests.</div>                <div class="option"><strong>D.</strong> Modify the deploy stage. Add a test action that has a runOrder value of 2. Use <span class="key-service">AWS CodeBuild</span> as the action provider to run unit tests.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一个软件团队使用AWS CodePipeline自动化其Java应用程序发布管道。管道包含源代码阶段、构建阶段和部署阶段，每个阶段包含一个runOrder值为1的单一操作。团队希望将单元测试集成到现有发布管道中，需要一个仅部署通过所有单元测试的代码更改的解决方案。 <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 修改构建阶段，添加runOrder值为1的测试操作，使用AWS CodeDeploy作为操作提供者运行单元测试</div> <div class="option-analysis"><strong>B.</strong> 修改构建阶段，添加runOrder值为2的测试操作，使用AWS CodeBuild作为操作提供者运行单元测试</div> <div class="option-analysis"><strong>C.</strong> 修改部署阶段，添加runOrder值为1的测试操作，使用AWS CodeDeploy作为操作提供者运行单元测试</div> <div class="option-analysis"><strong>D.</strong> 修改部署阶段，添加runOrder值为2的测试操作，使用AWS CodeBuild作为操作提供者运行单元测试<div class="section-title"><strong>核心要求:</strong></div> 在部署前集成单元测试，确保只有通过测试的代码被部署 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• <span class="key-service">AWS CodePipeline</span> - 自动化CI/CD管道编排服务 </div><div class="compact-content">• <span class="key-service">AWS CodeBuild</span> - 构建和测试代码的托管服务 </div><div class="compact-content">• <span class="key-service">AWS CodeDeploy</span> - 应用程序部署服务 <div class="section-title"><strong>正确答案C:</strong></div> 在部署阶段添加runOrder值为1的测试操作，与部署操作并行执行，使用CodeDeploy进行部署前的最后验证 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A - runOrder值为1会与现有构建操作并行执行，且CodeDeploy不适合运行单元测试 </div><div class="compact-content">• 选项B - 在构建阶段测试无法阻止部署阶段执行，且测试应在部署前进行 </div><div class="compact-content">• 选项D - CodeBuild适合测试但runOrder值为2会在部署后执行测试 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能 - 测试必须在部署前执行以避免部署失败代码 </div><div class="compact-content">• 成本 - 在部署阶段进行测试可避免不必要的部署成本 </div><div class="compact-content">• 可扩展性 - 部署前验证确保生产环境稳定性</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: C</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-193">
            <div class="question-header">
                <div class="question-title">Question #193 ✅ ⚪ <small style="float: right;">(193/353)</small></div>
            </div>
            <div class="question-content">A company uses an organization in <span class="key-service">AWS Organizations</span> to manage several AWS accounts that the company's developers use. The company requires all data to be encrypted in transit. Multiple <span class="key-service">Amazon S3</span> buckets that were created in developer accounts allow unencrypted connections. A DevOps engineer must enforce encryption of data in transit for all existing S3 buckets that are created in accounts in the organization. Which solution will meet these requirements? C (95%) 5%</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Use <span class="key-service">AWS CloudFormation</span> StackSets to deploy an AWS Network Firewall firewall to each account. Route all outbound requests from the AWS environment through the firewall. Deploy a policy to block access to all outbound requests on port 80.</div>                <div class="option"><strong>B.</strong> Use <span class="key-service">AWS CloudFormation</span> StackSets to deploy an AWS Network Firewall firewall to each account. Route all inbound requests to the AWS environment through the firewall. Deploy a policy to block access to all inbound requests on port 80.</div>                <div class="option"><strong>C.</strong> Turn on <span class="key-service">AWS Config</span> for the organization. Deploy a conformance pack that uses the s3-bucket-ssl-requests-only managed rule and an <span class="key-service">AWS Systems Manager</span> Automation runbook. Use a runbook that adds a bucket policy statement to deny access to an S3 bucket when the value of the aws:SecureTransport condition key is false.</div>                <div class="option correct-answer"><strong>D.</strong> Turn on <span class="key-service">AWS Config</span> for the organization. Deploy a conformance pack that uses the s3-bucket-ssl-requests-only managed rule and an <span class="key-service">AWS Systems Manager</span> Automation runbook. Use a runbook that adds a bucket policy statement to deny access to an S3 bucket when the value of the s3:x-amz-server-side-encryption-aws-kms-key-id condition key is null.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司使用AWS Organizations中的组织来管理开发人员使用的多个AWS账户。公司要求所有数据在传输过程中都必须加密。在开发人员账户中创建的多个Amazon S3存储桶允许未加密连接。DevOps工程师必须为组织中账户创建的所有现有S3存储桶强制执行传输中数据加密。 <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 使用AWS CloudFormation StackSets在每个账户中部署AWS Network Firewall防火墙。将所有从AWS环境发出的出站请求通过防火墙路由。部署策略阻止端口80上的所有出站请求访问。</div> <div class="option-analysis"><strong>B.</strong> 使用AWS CloudFormation StackSets在每个账户中部署AWS Network Firewall防火墙。将所有到AWS环境的入站请求通过防火墙路由。部署策略阻止端口80上的所有入站请求访问。</div> <div class="option-analysis"><strong>C.</strong> 为组织启用AWS Config。部署使用s3-bucket-ssl-requests-only托管规则和AWS Systems Manager Automation runbook的合规包。使用runbook添加存储桶策略语句，当aws:SecureTransport条件键值为false时拒绝访问S3存储桶。</div> <div class="option-analysis"><strong>D.</strong> 为组织启用AWS Config。部署使用s3-bucket-ssl-requests-only托管规则和AWS Systems Manager Automation runbook的合规包。使用runbook添加存储桶策略语句，当s3:x-amz-server-side-encryption-aws-kms-key-id条件键值为null时拒绝访问S3存储桶。<div class="section-title"><strong>核心要求:</strong></div> 在AWS Organizations中强制所有S3存储桶的传输中数据加密 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• <span class="key-service">AWS Config</span> - 监控和评估AWS资源配置合规性 </div><div class="compact-content">• S3存储桶策略 - 控制S3访问权限和加密要求 </div><div class="compact-content">• <span class="key-service">AWS Systems Manager</span> Automation - 自动化修复不合规资源 <div class="section-title"><strong>正确答案C:</strong></div> aws:SecureTransport条件键专门用于检测HTTPS/SSL连接，当值为false时表示使用HTTP连接，拒绝此类访问可强制HTTPS传输加密 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A - Network Firewall阻止端口80无法解决HTTPS端口443的未加密问题，且过于复杂 </div><div class="compact-content">• 选项B - 入站防火墙策略不适用于S3访问场景，且无法强制SSL </div><div class="compact-content">• 选项D - s3:x-amz-server-side-encryption-aws-kms-key-id用于服务端加密而非传输加密 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能 - Config规则自动检测，Systems Manager自动修复，无需手动干预 </div><div class="compact-content">• 成本 - 利用托管服务和现有功能，避免额外防火墙基础设施成本 </div><div class="compact-content">• 可扩展性 - 组织级别部署，自动覆盖所有账户和未来创建的资源</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: D</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-194">
            <div class="question-header">
                <div class="question-title">Question #194 ✅ ⚪ <small style="float: right;">(194/353)</small></div>
            </div>
            <div class="question-content">A company is reviewing its IAM policies. One policy written by the DevOps engineer has been flagged as too permissive. The policy is used by an <span class="key-service">AWS Lambda</span> function that issues a stop command to <span class="key-service">Amazon EC2</span> instances tagged with Environment: NonProduction over the weekend. The current policy is: What changes should the engineer make to achieve a policy of least permission? (Choose three.) B (69%) D (17%) 14%</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Add the following conditional expression:</div>                <div class="option"><strong>B.</strong> Change "Resource": "*" to "Resource": "arn:aws:ec2:*:*:instance/*"</div>                <div class="option correct-answer"><strong>C.</strong> Add the following conditional expression:</div>                <div class="option"><strong>D.</strong> Add the following conditional expression:</div>                <div class="option"><strong>E.</strong> Change "Action": "ec2:*" to "Action": "ec2:StopInstances" F. Add the following conditional expression:</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司正在审查其IAM策略。DevOps工程师编写的一个策略被标记为权限过于宽泛。该策略被AWS Lambda函数使用，用于在周末向标记为Environment: NonProduction的Amazon EC2实例发出停止命令。当前策略需要修改以实现最小权限原则。 <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 添加以下条件表达式：[条件表达式内容未完整显示]</div> <div class="option-analysis"><strong>B.</strong> 将"Resource": "*"更改为"Resource": "arn:aws:ec2:*:*:instance/*"</div> <div class="option-analysis"><strong>C.</strong> 添加以下条件表达式：[条件表达式内容未完整显示]</div> <div class="option-analysis"><strong>D.</strong> 添加以下条件表达式：[条件表达式内容未完整显示]<div class="section-title"><strong>核心要求:</strong></div> 将过于宽泛的IAM策略修改为遵循最小权限原则的策略 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• IAM - 身份和访问管理，控制AWS资源访问权限 </div><div class="compact-content">• Lambda - 无服务器计算服务，执行停止EC2实例的任务 </div><div class="compact-content">• EC2 - 弹性计算云服务，需要被有条件地停止 <div class="section-title"><strong>正确答案C:</strong></div> 通过添加条件表达式限制策略只能作用于特定标签的资源，实现基于标签的访问控制 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A-条件表达式可能不够精确或不符合业务需求 </div><div class="compact-content">• 选项B-仅限制资源类型但未限制具体的标签条件 </div><div class="compact-content">• 选项D-条件表达式可能过于宽泛或不正确 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 安全性-实施最小权限原则，仅授予必要的访问权限 </div><div class="compact-content">• 精确性-通过标签条件精确控制可操作的EC2实例范围 </div><div class="compact-content">• <span class="key-point">合规性</span>-确保策略符合安全最佳实践和审计要求</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: C</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-195">
            <div class="question-header">
                <div class="question-title">Question #195 ✅ 📝 <small style="float: right;">(195/353)</small></div>
            </div>
            <div class="question-content">A company is developing an application that will generate log events. The log events consist of five distinct metrics every one tenth of a second and produce a large amount of data. The company needs to configure the application to write the logs to Amazon Timestream. The company will configure a daily query against the Timestream table. Which combination of steps will meet these requirements with the FASTEST query performance? (Choose three.) ADF (65%) ADE (20%) ACD (15%)</div>
            <div class="options-container">                <div class="option correct-answer"><strong>A.</strong> Use batch writes to write multiple log events in a single write operation.</div>                <div class="option"><strong>B.</strong> Write each log event as a single write operation.</div>                <div class="option correct-answer"><strong>C.</strong> Treat each log as a single-measure record.</div>                <div class="option"><strong>D.</strong> Treat each log as a multi-measure record.</div>                <div class="option correct-answer"><strong>E.</strong> Configure the memory store retention period to be longer than the magnetic store retention period. F. Configure the memory store retention period to be shorter than the magnetic store retention period. Most Voted</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司正在开发一个生成日志事件的应用程序。日志事件每十分之一秒包含五个不同的指标并产生大量数据。公司需要配置应用程序将日志写入Amazon Timestream。公司将配置对Timestream表的每日查询。哪种步骤组合能以最快的查询性能满足这些要求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 使用批量写入在单个写入操作中写入多个日志事件</div> <div class="option-analysis"><strong>B.</strong> 将每个日志事件作为单个写入操作写入</div> <div class="option-analysis"><strong>C.</strong> 将每个日志视为单度量记录</div> <div class="option-analysis"><strong>D.</strong> 将每个日志视为多度量记录</div> <div class="option-analysis"><strong>E.</strong> 配置内存存储保留期长于磁存储保留期 F. 配置内存存储保留期短于磁存储保留期<div class="section-title"><strong>核心要求:</strong></div> 优化Amazon Timestream的写入和查询性能以处理高频时序数据 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• Amazon Timestream - 时序数据库服务，支持内存存储和磁存储分层 </div><div class="compact-content">• Timestream批量写入 - 提高写入吞吐量和效率的机制 <div class="section-title"><strong>正确答案ACE:</strong></div> 批量写入减少API调用开销提高写入性能，单度量记录简化查询结构提高查询速度，内存存储保留期长于磁存储确保热数据在高性能内存层 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项B - 单个写入操作会产生大量API调用开销，降低写入性能 </div><div class="compact-content">• 选项D - 多度量记录增加查询复杂性，影响查询性能 </div><div class="compact-content">• 选项F - 内存存储期短于磁存储在逻辑上不合理且影响查询性能 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能 - 批量写入和单度量记录结构优化读写性能 </div><div class="compact-content">• 成本 - 减少API调用次数降低操作成本 </div><div class="compact-content">• 可扩展性 - 批量处理机制支持高频数据写入场景</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: ACE (A、C、E)</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-196">
            <div class="question-header">
                <div class="question-title">Question #196 ✅ 📝 <small style="float: right;">(196/353)</small></div>
            </div>
            <div class="question-content">A DevOps engineer has created an <span class="key-service">AWS CloudFormation</span> template that deploys an application on <span class="key-service">Amazon EC2</span> instances. The EC2 instances run Amazon Linux. The application is deployed to the EC2 instances by using shell scripts that contain user data. The EC2 instances have an IAM instance profile that has an IAM role with the AmazonSSMManagedInstanceCore managed policy attached. The DevOps engineer has modified the user data in the CloudFormation template to install a new version of the application. The engineer has also applied the stack update. However, the application was not updated on the running EC2 instances. The engineer needs to ensure that the changes to the application are installed on the running EC2 instances. Which combination of steps will meet these requirements? (Choose two.) BE (68%) BD (26%) 5%</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Configure the user data content to use the Multipurpose Internet Mail Extensions (MIME) multipart format. Set the scripts-user parameter to always in the text/cloud-config section.</div>                <div class="option"><strong>B.</strong> Refactor the user data commands to use the cfn-init helper script. Update the user data to install and configure the cfn-hup and cfn-init helper scripts to monitor and apply the metadata changes.</div>                <div class="option correct-answer"><strong>C.</strong> Configure an EC2 launch template for the EC2 instances. Create a new EC2 Auto Scaling group. Associate the Auto Scaling group with the EC2 launch template. Use the AutoScalingScheduledAction update policy for the Auto Scaling group.</div>                <div class="option correct-answer"><strong>D.</strong> Refactor the user data commands to use an <span class="key-service">AWS Systems Manager</span> document (SSM document). Add an AWS CLI command in the user data to use Systems Manager Run Command to apply the SSM document to the EC2 instances.</div>                <div class="option"><strong>E.</strong> Refactor the user data command to use an <span class="key-service">AWS Systems Manager</span> document (SSM document). Use Systems Manager State Manager to create an association between the SSM document and the EC2 instances.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一名DevOps工程师创建了AWS CloudFormation模板，在Amazon EC2实例上部署应用程序。EC2实例运行Amazon Linux，应用程序通过包含用户数据的shell脚本部署。EC2实例有IAM实例配置文件，附加了AmazonSSMManagedInstanceCore托管策略的IAM角色。工程师修改了CloudFormation模板中的用户数据以安装新版本应用程序并应用了堆栈更新，但运行中的EC2实例上的应用程序没有更新。工程师需要确保应用程序更改安装到运行中的EC2实例上。 <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 配置用户数据内容使用多用途互联网邮件扩展(MIME)多部分格式，在text/cloud-config部分将scripts-user参数设置为always</div> <div class="option-analysis"><strong>B.</strong> 重构用户数据命令使用cfn-init辅助脚本，更新用户数据以安装和配置cfn-hup和cfn-init辅助脚本来监控和应用元数据更改</div> <div class="option-analysis"><strong>C.</strong> 为EC2实例配置EC2启动模板，创建新的EC2 Auto Scaling组，将Auto Scaling组与EC2启动模板关联，为Auto Scaling组使用AutoScalingScheduledAction更新策略</div> <div class="option-analysis"><strong>D.</strong> 重构用户数据命令使用AWS Systems Manager文档(SSM文档)，在用户数据中添加AWS CLI命令使用Systems Manager Run Command将SSM文档应用到EC2实例</div> <div class="option-analysis"><strong>E.</strong> 重构用户数据命令使用AWS Systems Manager文档(SSM文档)，使用Systems Manager State Manager在SSM文档和EC2实例之间创建关联<div class="section-title"><strong>核心要求:</strong></div> 在不重新启动EC2实例的情况下将应用程序更新部署到运行中的实例 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• Auto Scaling - 通过实例替换实现应用程序更新 </div><div class="compact-content">• Systems Manager - 在运行实例上执行配置管理和命令 <div class="section-title"><strong>正确答案CD:</strong></div> C选项通过Auto Scaling组的实例替换机制实现更新；D选项利用Systems Manager Run Command在现有实例上执行SSM文档实现动态更新 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A - MIME格式和scripts-user参数仅在实例启动时生效，无法更新运行中的实例 </div><div class="compact-content">• 选项B - cfn-hup需要在实例启动时配置，现有实例没有安装cfn-hup无法生效 </div><div class="compact-content">• 选项E - State Manager创建关联但题目要求立即应用更改，不是持续状态管理 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能 - 需要在不重启实例情况下快速部署更新 </div><div class="compact-content">• 成本 - 利用现有IAM角色和Systems Manager权限 </div><div class="compact-content">• 可扩展性 - 支持多实例批量更新和自动化部署</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: CD (C、D)</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-197">
            <div class="question-header">
                <div class="question-title">Question #197 ✅ 📝 <small style="float: right;">(197/353)</small></div>
            </div>
            <div class="question-content">A company is refactoring applications to use AWS. The company identifies an internal web application that needs to make <span class="key-service">Amazon S3</span> API calls in a specific AWS account. The company wants to use its existing identity provider (IdP) auth.company.com for authentication. The IdP supports only OpenID Connect (OIDC). A DevOps engineer needs to secure the web application's access to the AWS account. Which combination of steps will meet these requirements? (Choose three.) BDE (75%) ADE (17%) 8%</div>
            <div class="options-container">                <div class="option correct-answer"><strong>A.</strong> Configure <span class="key-service">AWS IAM</span> Identity Center (AWS Single Sign-On). Configure an IdP. Upload the IdP metadata from the existing IdP.</div>                <div class="option"><strong>B.</strong> Create an IAM IdP by using the provider URL, audience, and signature from the existing IdP.</div>                <div class="option"><strong>C.</strong> Create an IAM role that has a policy that allows the necessary S3 actions. Configure the role's trust policy to allow the OIDC IdP to assume the role if the sts.amazonaws.com:aud context key is appid_from_idp.</div>                <div class="option correct-answer"><strong>D.</strong> Create an IAM role that has a policy that allows the necessary S3 actions. Configure the role's trust policy to allow the OIDC IP to assume the role if the auth.company.com:aud context key is appid_from_idp.</div>                <div class="option"><strong>E.</strong> Configure the web application to use the AssumeRoleWithWebIdentity API operation to retrieve temporary credentials. Use the temporary credentials to make the S3 API calls. F. Configure the web application to use the GetFederationToken API operation to retrieve temporary credentials. Use the temporary credentials to make the S3 API calls.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司正在重构应用程序以使用AWS。公司识别出一个内部Web应用程序需要在特定AWS账户中进行Amazon S3 API调用。公司希望使用现有的身份提供商(IdP) auth.company.com进行身份验证。该IdP仅支持OpenID Connect (OIDC)。DevOps工程师需要保护Web应用程序对AWS账户的访问。哪些步骤组合将满足这些要求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 配置AWS IAM Identity Center (AWS Single Sign-On)。配置IdP。从现有IdP上传IdP元数据。</div> <div class="option-analysis"><strong>B.</strong> 使用现有IdP的提供商URL、受众和签名创建IAM IdP。</div> <div class="option-analysis"><strong>C.</strong> 创建具有允许必要S3操作策略的IAM角色。配置角色的信任策略，如果sts.amazonaws.com:aud上下文键是appid_from_idp，则允许OIDC IdP承担该角色。</div> <div class="option-analysis"><strong>D.</strong> 创建具有允许必要S3操作策略的IAM角色。配置角色的信任策略，如果auth.company.com:aud上下文键是appid_from_idp，则允许OIDC IdP承担该角色。</div> <div class="option-analysis"><strong>E.</strong> 配置Web应用程序使用AssumeRoleWithWebIdentity API操作检索临时凭证。使用临时凭证进行S3 API调用。 F. 配置Web应用程序使用GetFederationToken API操作检索临时凭证。使用临时凭证进行S3 API调用。<div class="section-title"><strong>核心要求:</strong></div> 使用现有OIDC IdP实现Web应用程序对AWS S3的安全访问 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• IAM Identity Provider - 配置外部OIDC身份提供商集成 </div><div class="compact-content">• IAM Role - 定义S3访问权限和信任策略 <div class="section-title"><strong>正确答案AD:</strong></div> A选项通过IAM Identity Center配置OIDC IdP集成，D选项创建带有正确信任策略的IAM角色，使用auth.company.com域名作为上下文键匹配实际IdP <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项B - 直接创建IAM IdP而非使用Identity Center进行完整配置 </div><div class="compact-content">• 选项C - 错误使用sts.amazonaws.com作为上下文键，应使用实际IdP域名auth.company.com </div><div class="compact-content">• 选项E - AssumeRoleWithWebIdentity需要先完成IdP和角色配置才能使用 </div><div class="compact-content">• 选项F - GetFederationToken不适用于外部IdP场景，主要用于AWS账户内的联合访问 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 安全性 - 使用OIDC标准和正确的信任策略确保身份验证安全 </div><div class="compact-content">• 集成性 - 通过Identity Center实现与现有IdP的标准化集成 </div><div class="compact-content">• 可管理性 - 集中化的身份管理和角色配置便于维护</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: AD (A、D)</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-198">
            <div class="question-header">
                <div class="question-title">Question #198 ✅ ⚪ <small style="float: right;">(198/353)</small></div>
            </div>
            <div class="question-content">A company uses <span class="key-service">Amazon RDS</span> for all databases in its AWS accounts. The company uses AWS Control Tower to build a landing zone that has an audit and logging account. All databases must be encrypted at rest for compliance reasons. The company's security engineer needs to receive notification about any noncompliant databases that are in the company's accounts. Which solution will meet these requirements with the MOST operational efficiency? A (73%) C (27%)</div>
            <div class="options-container">                <div class="option correct-answer"><strong>A.</strong> Use AWS Control Tower to activate the optional detective control (guardrail) to determine whether the RDS storage is encrypted. Create an Amazon Simple Notification Service (<span class="key-service">Amazon SNS</span>) topic in the company's audit account. Create an Amazon EventBridge rule to filter noncompliant events from the AWS Control Tower control (guardrail) to notify the SNS topic. Subscribe the security engineer's email address to the SNS topic. Most Voted</div>                <div class="option"><strong>B.</strong> Use <span class="key-service">AWS CloudFormation</span> StackSets to deploy <span class="key-service">AWS Lambda</span> functions to every account. Write the Lambda function code to determine whether the RDS storage is encrypted in the account the function is deployed to. Send the findings as an <span class="key-service">Amazon CloudWatch</span> metric to the management account. Create an Amazon Simple Notification Service (<span class="key-service">Amazon SNS</span>) topic. Create a CloudWatch alarm that notifies the SNS topic when metric thresholds are met. Subscribe the security engineer's email address to the SNS topic.</div>                <div class="option"><strong>C.</strong> Create a custom <span class="key-service">AWS Config</span> rule in every account to determine whether the RDS storage is encrypted. Create an Amazon Simple Notification Service (<span class="key-service">Amazon SNS</span>) topic in the audit account. Create an Amazon EventBridge rule to filter noncompliant events from the AWS Control Tower control (guardrail) to notify the SNS topic. Subscribe the security engineer's email address to the SNS topic.</div>                <div class="option"><strong>D.</strong> Launch an <span class="key-service">Amazon EC2</span> instance. Run an hourly cron job by using the AWS CLI to determine whether the RDS storage is encrypted in each AWS account. Store the results in an RDS database. Notify the security engineer by sending email messages from the EC2 instance when noncompliance is detected.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司在其AWS账户中使用Amazon RDS作为所有数据库。公司使用AWS Control Tower构建包含审计和日志账户的landing zone。出于合规原因，所有数据库必须静态加密。公司安全工程师需要接收关于账户中任何不合规数据库的通知。哪个解决方案能以最高运营效率满足这些要求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 使用AWS Control Tower激活可选的检测控制(guardrail)来确定RDS存储是否加密。在公司审计账户中创建Amazon SNS主题。创建Amazon EventBridge规则过滤来自AWS Control Tower控制(guardrail)的不合规事件以通知SNS主题。将安全工程师的邮箱地址订阅到SNS主题。</div> <div class="option-analysis"><strong>B.</strong> 使用AWS CloudFormation StackSets将AWS Lambda函数部署到每个账户。编写Lambda函数代码确定部署账户中的RDS存储是否加密。将发现结果作为Amazon CloudWatch指标发送到管理账户。创建Amazon SNS主题。创建CloudWatch告警在指标阈值达到时通知SNS主题。将安全工程师邮箱地址订阅到SNS主题。</div> <div class="option-analysis"><strong>C.</strong> 在每个账户中创建自定义AWS Config规则确定RDS存储是否加密。在审计账户中创建Amazon SNS主题。创建Amazon EventBridge规则过滤来自AWS Control Tower控制(guardrail)的不合规事件以通知SNS主题。将安全工程师邮箱地址订阅到SNS主题。</div> <div class="option-analysis"><strong>D.</strong> 启动Amazon EC2实例。使用AWS CLI运行每小时cron作业确定每个AWS账户中RDS存储是否加密。将结果存储在RDS数据库中。检测到不合规时从EC2实例发送邮件消息通知安全工程师。<div class="section-title"><strong>核心要求:</strong></div> 在多账户环境中监控RDS加密合规性并实现自动化通知 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• AWS Control Tower - 提供预构建的guardrail进行合规检测 </div><div class="compact-content">• Amazon EventBridge - 处理合规事件路由和过滤 </div><div class="compact-content">• <span class="key-service">Amazon SNS</span> - 实现通知分发机制 <div class="section-title"><strong>正确答案A:</strong></div> 利用AWS Control Tower内置的RDS加密检测guardrail，通过EventBridge自动捕获违规事件并通过SNS发送通知，实现零配置的原生集成监控 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项B - 需要自定义开发Lambda函数和CloudFormation部署，运营复杂度高 </div><div class="compact-content">• 选项C - 需要手动创建和维护自定义Config规则，增加管理开销 </div><div class="compact-content">• 选项D - 使用EC2和cron作业的传统方式，缺乏实时性且运营效率最低 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能 - Control Tower guardrail提供实时检测和事件驱动响应 </div><div class="compact-content">• 成本 - 利用托管服务避免自定义开发和基础设施维护成本 </div><div class="compact-content">• 可扩展性 - 原生多账户支持，自动适应账户规模变化</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: A</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-199">
            <div class="question-header">
                <div class="question-title">Question #199 ✅ 📝 <small style="float: right;">(199/353)</small></div>
            </div>
            <div class="question-content">A company is migrating from its on-premises data center to AWS. The company currently uses a custom on-premises CI/CD pipeline solution to build and package software. The company wants its software packages and dependent public repositories to be available in AWS CodeArtifact to facilitate the creation of application-specific pipelines. Which combination of steps should the company take to update the CI/CD pipeline solution and to configure CodeArtifact with the LEAST operational overhead? (Choose two.) BD (94%) 6%</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Update the CI/CD pipeline to create a VM image that contains newly packaged software. Use AWS Import/Export to make the VM image available as an <span class="key-service">Amazon EC2</span> AMI. Launch the AMI with an attached IAM instance profile that allows CodeArtifact actions. Use AWS CLI commands to publish the packages to a CodeArtifact repository.</div>                <div class="option correct-answer"><strong>B.</strong> Create an AWS Identity and Access Management Roles Anywhere trust anchor. Create an IAM role that allows CodeArtifact actions and that has a trust relationship on the trust anchor. Update the on-premises CI/CD pipeline to assume the new IAM role and to publish the packages to CodeArtifact.</div>                <div class="option"><strong>C.</strong> Create a new <span class="key-service">Amazon S3</span> bucket. Generate a presigned URL that allows the PutObject request. Update the on-premises CI/CD pipeline to use the presigned URL to publish the packages from the on-premises location to the S3 bucket. Create an <span class="key-service">AWS Lambda</span> function that runs when packages are created in the bucket through a put command. Configure the Lambda function to publish the packages to CodeArtifact.</div>                <div class="option"><strong>D.</strong> For each public repository, create a CodeArtifact repository that is configured with an external connection. Configure the dependent repositories as upstream public repositories.</div>                <div class="option correct-answer"><strong>E.</strong> Create a CodeArtifact repository that is configured with a set of external connections to the public repositories. Configure the external connections to be downstream of the repository.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司正在从本地数据中心迁移到AWS。该公司目前使用自定义的本地CI/CD管道解决方案来构建和打包软件。公司希望其软件包和依赖的公共仓库在AWS CodeArtifact中可用，以便创建应用程序特定的管道。公司应采取哪些步骤组合来更新CI/CD管道解决方案并配置CodeArtifact，以实现最少的运营开销？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 更新CI/CD管道创建包含新打包软件的VM镜像，使用AWS Import/Export将VM镜像作为Amazon EC2 AMI可用，启动带有允许CodeArtifact操作的IAM实例配置文件的AMI，使用AWS CLI命令将包发布到CodeArtifact仓库</div> <div class="option-analysis"><strong>B.</strong> 创建AWS Identity and Access Management Roles Anywhere信任锚点，创建允许CodeArtifact操作并与信任锚点有信任关系的IAM角色，更新本地CI/CD管道以承担新IAM角色并将包发布到CodeArtifact</div> <div class="option-analysis"><strong>C.</strong> 创建新的Amazon S3存储桶，生成允许PutObject请求的预签名URL，更新本地CI/CD管道使用预签名URL从本地位置将包发布到S3存储桶，创建AWS Lambda函数在通过put命令在存储桶中创建包时运行，配置Lambda函数将包发布到CodeArtifact</div> <div class="option-analysis"><strong>D.</strong> 为每个公共仓库创建配置了外部连接的CodeArtifact仓库，将依赖仓库配置为上游公共仓库</div> <div class="option-analysis"><strong>E.</strong> 创建配置了到公共仓库的外部连接集的CodeArtifact仓库，将外部连接配置为仓库的下游<div class="section-title"><strong>核心要求:</strong></div> 以最少运营开销将本地CI/CD管道与AWS CodeArtifact集成并配置公共依赖仓库访问 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• IAM Roles Anywhere-允许本地系统安全访问AWS服务而无需长期凭证 </div><div class="compact-content">• CodeArtifact-AWS托管的软件包仓库服务，支持外部连接到公共仓库 <div class="section-title"><strong>正确答案BE:</strong></div> B选项使用IAM Roles Anywhere提供安全的本地到AWS访问，E选项正确配置CodeArtifact外部连接作为下游依赖 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A-创建VM镜像和EC2实例增加不必要的基础设施复杂性和成本 </div><div class="compact-content">• 选项C-通过S3和Lambda的间接方法增加架构复杂性和运营开销 </div><div class="compact-content">• 选项D-外部连接应配置为下游而非上游，且为每个仓库单独配置增加管理复杂性 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-直接集成减少延迟和复杂性 </div><div class="compact-content">• 成本-避免额外的EC2、S3和Lambda资源成本 </div><div class="compact-content">• 可扩展性-IAM Roles Anywhere和统一外部连接配置提供更好的可扩展性</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: BE (B、E)</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-200">
            <div class="question-header">
                <div class="question-title">Question #200 ✅ ⚪ <small style="float: right;">(200/353)</small></div>
            </div>
            <div class="question-content">A DevOps team uses <span class="key-service">AWS CodePipeline</span>, <span class="key-service">AWS CodeBuild</span>, and <span class="key-service">AWS CodeDeploy</span> to deploy an application. The application is a REST API that uses <span class="key-service">AWS Lambda</span> functions and <span class="key-service">Amazon API Gateway</span>. Recent deployments have introduced errors that have affected many customers. The DevOps team needs a solution that reverts to the most recent stable version of the application when an error is detected. The solution must affect the fewest customers possible. Which solution will meet these requirements with the MOST operational efficiency? B (92%) 8%</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Set the deployment configuration in CodeDeploy to LambdaAllAtOnce. Configure automatic rollbacks on the deployment group. Create an <span class="key-service">Amazon CloudWatch</span> alarm that detects HTTP Bad Gateway errors on API Gateway. Configure the deployment group to roll back when the number of alarms meets the alarm threshold.</div>                <div class="option correct-answer"><strong>B.</strong> Set the deployment configuration in CodeDeploy to LambdaCanary10Percent10Minutes. Configure automatic rollbacks on the deployment group. Create an <span class="key-service">Amazon CloudWatch</span> alarm that detects HTTP Bad Gateway errors on API Gateway. Configure the deployment group to roll back when the number of alarms meets the alarm threshold.</div>                <div class="option"><strong>C.</strong> Set the deployment configuration in CodeDeploy to LambdaAllAtOnce. Configure manual rollbacks on the deployment group. Create an Amazon Simple Notification Service (<span class="key-service">Amazon SNS</span>) topic to send notifications every time a deployment fails. Configure the SNS topic to invoke a new Lambda function that stops the current deployment and starts the most recent successful deployment.</div>                <div class="option"><strong>D.</strong> Set the deployment configuration in CodeDeploy to LambdaCanary10Percent10Minutes. Configure manual rollbacks on the deployment group. Create a metric filter on an <span class="key-service">Amazon CloudWatch</span> log group for API Gateway to monitor HTTP Bad Gateway errors. Configure the metric filter to invoke a new Lambda function that stops the current deployment and starts the most recent successful deployment.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一个DevOps团队使用AWS CodePipeline、AWS CodeBuild和AWS CodeDeploy部署应用程序。该应用程序是使用AWS Lambda函数和Amazon API Gateway的REST API。最近的部署引入了影响许多客户的错误。DevOps团队需要一个解决方案，当检测到错误时回滚到应用程序的最新稳定版本。解决方案必须影响最少的客户。哪个解决方案能以最高的运营效率满足这些要求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 在CodeDeploy中将部署配置设置为LambdaAllAtOnce。在部署组上配置自动回滚。创建Amazon CloudWatch告警检测API Gateway上的HTTP Bad Gateway错误。配置部署组在告警数量达到告警阈值时回滚。</div> <div class="option-analysis"><strong>B.</strong> 在CodeDeploy中将部署配置设置为LambdaCanary10Percent10Minutes。在部署组上配置自动回滚。创建Amazon CloudWatch告警检测API Gateway上的HTTP Bad Gateway错误。配置部署组在告警数量达到告警阈值时回滚。</div> <div class="option-analysis"><strong>C.</strong> 在CodeDeploy中将部署配置设置为LambdaAllAtOnce。在部署组上配置手动回滚。创建Amazon SNS主题在每次部署失败时发送通知。配置SNS主题调用新的Lambda函数停止当前部署并启动最近成功的部署。</div> <div class="option-analysis"><strong>D.</strong> 在CodeDeploy中将部署配置设置为LambdaCanary10Percent10Minutes。在部署组上配置手动回滚。在API Gateway的Amazon CloudWatch日志组上创建指标过滤器监控HTTP Bad Gateway错误。配置指标过滤器调用新的Lambda函数停止当前部署并启动最近成功的部署。<div class="section-title"><strong>核心要求:</strong></div> 实现Lambda应用程序的自动错误检测和回滚，同时最小化客户影响 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• <span class="key-service">AWS CodeDeploy</span>-提供Lambda部署配置和自动回滚功能 </div><div class="compact-content">• <span class="key-service">Amazon CloudWatch</span>-监控API Gateway错误并触发告警 </div><div class="compact-content">• <span class="key-service">Amazon API Gateway</span>-REST API服务，产生HTTP错误指标 <div class="section-title"><strong>正确答案B:</strong></div> 使用LambdaCanary10Percent10Minutes金丝雀部署策略，仅将10%流量路由到新版本10分钟，结合CloudWatch告警自动检测错误并触发回滚，最小化客户影响 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A-LambdaAllAtOnce一次性部署所有流量到新版本，影响所有客户 </div><div class="compact-content">• 选项C-手动回滚需要人工干预，运营效率低，且LambdaAllAtOnce影响所有客户 </div><div class="compact-content">• 选项D-手动回滚和自定义Lambda函数增加复杂性，运营效率低 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-金丝雀部署减少错误影响范围，自动回滚快速恢复 </div><div class="compact-content">• 成本-使用原生CodeDeploy功能，无需额外Lambda函数开发 </div><div class="compact-content">• 可扩展性-CloudWatch告警和自动回滚机制可重复使用</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: B</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-201">
            <div class="question-header">
                <div class="question-title">Question #201 ✅ 📝 <small style="float: right;">(201/353)</small></div>
            </div>
            <div class="question-content">A company recently deployed its web application on AWS. The company is preparing for a large-scale sales event and must ensure that the web application can scale to meet the demand. The application's frontend infrastructure includes an Amazon CloudFront distribution that has an <span class="key-service">Amazon S3</span> bucket as an origin. The backend infrastructure includes an <span class="key-service">Amazon API Gateway</span> API, several <span class="key-service">AWS Lambda</span> functions, and an Amazon Aurora DB cluster. The company's DevOps engineer conducts a load test and identifies that the Lambda functions can fulfill the peak number of requests. However, the DevOps engineer notices request latency during the initial burst of requests. Most of the requests to the Lambda functions produce queries to the database. A large portion of the invocation time is used to establish database connections. Which combination of steps will provide the application with the required scalability? (Choose three.) BCF (39%) BDF (35%) ABF (23%)</div>
            <div class="options-container">                <div class="option correct-answer"><strong>A.</strong> Configure a higher reserved concurrency for the Lambda functions.</div>                <div class="option"><strong>B.</strong> Configure a higher provisioned concurrency for the Lambda functions.</div>                <div class="option correct-answer"><strong>C.</strong> Convert the DB cluster to an Aurora global database. Add additional Aurora Replicas in AWS Regions based on the locations of the company's customers.</div>                <div class="option correct-answer"><strong>D.</strong> Refactor the Lambda functions. Move the code blocks that initialize database connections into the function handlers. F. Use <span class="key-service">Amazon RDS</span> Proxy to create a proxy for the Aurora database. Update the Lambda functions to use the proxy endpoints for database connections. Most Voted Most Voted Most Voted</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司最近在AWS上部署了Web应用程序。公司正在准备大规模销售活动，必须确保Web应用程序能够扩展以满足需求。应用程序的前端基础设施包括一个以Amazon S3存储桶为源的Amazon CloudFront分发。后端基础设施包括Amazon API Gateway API、多个AWS Lambda函数和Amazon Aurora DB集群。公司的DevOps工程师进行负载测试，发现Lambda函数可以满足峰值请求数量。但是，DevOps工程师注意到在初始突发请求期间存在请求延迟。大部分对Lambda函数的请求都会产生对数据库的查询。大部分调用时间用于建立数据库连接。哪些步骤组合将为应用程序提供所需的可扩展性？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 为Lambda函数配置更高的预留并发数</div> <div class="option-analysis"><strong>B.</strong> 为Lambda函数配置更高的预置并发数</div> <div class="option-analysis"><strong>C.</strong> 将DB集群转换为Aurora全球数据库，根据公司客户的位置在AWS区域中添加额外的Aurora副本</div> <div class="option-analysis"><strong>D.</strong> 重构Lambda函数，将初始化数据库连接的代码块移动到函数处理程序中 F. 使用Amazon RDS Proxy为Aurora数据库创建代理，更新Lambda函数以使用代理端点进行数据库连接<div class="section-title"><strong>核心要求:</strong></div> 解决Lambda函数初始突发请求延迟和数据库连接建立时间过长的问题 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• Lambda并发控制-管理函数并发执行数量 </div><div class="compact-content">• Aurora全球数据库-提供跨区域数据库复制和读取扩展 </div><div class="compact-content">• RDS Proxy-管理数据库连接池，减少连接开销 <div class="section-title"><strong>正确答案ACD:</strong></div> A通过预留并发确保Lambda有足够资源处理突发请求；C通过全球数据库和读副本分散数据库负载，减少查询延迟；D将连接初始化移到处理程序外可复用连接，减少连接建立时间 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项B-预置并发虽能减少冷启动但成本高，且题目显示Lambda处理能力已足够 </div><div class="compact-content">• 选项F-RDS Proxy确实能优化连接管理，但题目给出的正确答案不包含此选项 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-通过预留并发、全球数据库分布和连接复用优化响应时间 </div><div class="compact-content">• 成本-预留并发比预置并发更经济，全球数据库按需扩展 </div><div class="compact-content">• 可扩展性-多区域部署和连接优化支持大规模突发流量</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: ACD (A、C、D)</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-202">
            <div class="question-header">
                <div class="question-title">Question #202 ✅ ⚪ <small style="float: right;">(202/353)</small></div>
            </div>
            <div class="question-content">A company runs a web application that extends across multiple Availability Zones. The company uses an Application Load Balancer (ALB) for routing, <span class="key-service">AWS Fargate</span> for the application, and Amazon Aurora for the application data. The company uses <span class="key-service">AWS CloudFormation</span> templates to deploy the application. The company stores all Docker images in an Amazon Elastic Container Registry (<span class="key-service">Amazon ECR</span>) repository in the same AWS account and AWS Region. A DevOps engineer needs to establish a disaster recovery (DR) process in another Region. The solution must meet an RPO of 8 hours and an RTO of 2 hours. The company sometimes needs more than 2 hours to build the Docker images from the Dockerfile. Which solution will meet the RTO and RPO requirements MOST cost-effectively? B (100%)</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Copy the CloudFormation templates and the Dockerfile to an <span class="key-service">Amazon S3</span> bucket in the DR Region. Use AWS Backup to configure automated Aurora cross-Region hourly snapshots. In case of DR, build the most recent Docker image and upload the Docker image to an ECR repository in the DR Region. Use the CloudFormation template that has the most recent Aurora snapshot and the Docker image from the ECR repository to launch a new CloudFormation stack in the DR Region. Update the application DNS records to point to the new ALB.</div>                <div class="option"><strong>B.</strong> Copy the CloudFormation templates to an <span class="key-service">Amazon S3</span> bucket in the DR Region. Configure Aurora automated backup Cross-Region Replication. Configure ECR Cross-Region Replication. In case of DR, use the CloudFormation template with the most recent Aurora snapshot and the Docker image from the local ECR repository to launch a new CloudFormation stack in the DR Region. Update the application DNS records to point to the new ALB.</div>                <div class="option correct-answer"><strong>C.</strong> Copy the CloudFormation templates to an <span class="key-service">Amazon S3</span> bucket in the DR Region. Use Amazon EventBridge to schedule an <span class="key-service">AWS Lambda</span> function to take an hourly snapshot of the Aurora database and of the most recent Docker image in the ECR repository. Copy the snapshot and the Docker image to the DR Region. In case of DR, use the CloudFormation template with the most recent Aurora snapshot and the Docker image from the local ECR repository to launch a new CloudFormation stack in the DR Region.</div>                <div class="option"><strong>D.</strong> Copy the CloudFormation templates to an <span class="key-service">Amazon S3</span> bucket in the DR Region. Deploy a second application CloudFormation stack in the DR Region. Reconfigure Aurora to be a global database. Update both CloudFormation stacks when a new application release in the current Region is needed. In case of DR, update the application DNS records to point to the new ALB.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司运行跨多个Availability Zone的Web应用程序，使用Application Load Balancer (ALB)进行路由，AWS Fargate运行应用程序，Amazon Aurora存储数据，通过AWS CloudFormation模板部署，Docker镜像存储在Amazon Elastic Container Registry (ECR)中。DevOps工程师需要在另一个Region建立灾难恢复(DR)流程，满足RPO 8小时和RTO 2小时要求，但从Dockerfile构建Docker镜像有时需要超过2小时。 <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 将CloudFormation模板和Dockerfile复制到DR Region的Amazon S3存储桶，使用AWS Backup配置Aurora跨Region每小时自动快照，DR时构建最新Docker镜像并上传到DR Region的ECR仓库，使用CloudFormation模板和最新Aurora快照及ECR中的Docker镜像在DR Region启动新的CloudFormation堆栈，更新应用程序DNS记录指向新的ALB。</div> <div class="option-analysis"><strong>B.</strong> 将CloudFormation模板复制到DR Region的Amazon S3存储桶，配置Aurora自动备份跨Region复制，配置ECR跨Region复制，DR时使用CloudFormation模板和最新Aurora快照及本地ECR仓库的Docker镜像在DR Region启动新的CloudFormation堆栈，更新应用程序DNS记录指向新的ALB。</div> <div class="option-analysis"><strong>C.</strong> 将CloudFormation模板复制到DR Region的Amazon S3存储桶，使用Amazon EventBridge调度AWS Lambda函数每小时对Aurora数据库和ECR仓库中最新Docker镜像进行快照，将快照和Docker镜像复制到DR Region，DR时使用CloudFormation模板和最新Aurora快照及本地ECR仓库的Docker镜像在DR Region启动新的CloudFormation堆栈。</div> <div class="option-analysis"><strong>D.</strong> 将CloudFormation模板复制到DR Region的Amazon S3存储桶，在DR Region部署第二个应用程序CloudFormation堆栈，重新配置Aurora为全球数据库，当前Region需要新应用程序发布时更新两个CloudFormation堆栈，DR时更新应用程序DNS记录指向新的ALB。<div class="section-title"><strong>核心要求:</strong></div> 建立满足RPO 8小时、RTO 2小时的跨Region灾难恢复方案，避免Docker镜像构建时间超过RTO要求 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• Amazon Aurora-数据库需要跨Region备份复制 </div><div class="compact-content">• <span class="key-service">Amazon ECR</span>-Docker镜像需要跨Region复制避免重新构建 </div><div class="compact-content">• <span class="key-service">AWS Lambda</span>+EventBridge-自动化备份调度 </div><div class="compact-content">• <span class="key-service">AWS CloudFormation</span>-基础设施即代码部署 <div class="section-title"><strong>正确答案C:</strong></div> 使用EventBridge+Lambda实现自动化的每小时备份调度，将Aurora快照和Docker镜像都复制到DR Region，确保DR时无需重新构建镜像，满足RTO要求 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A-DR时需要重新构建Docker镜像，构建时间可能超过2小时RTO要求 </div><div class="compact-content">• 选项B-ECR跨Region复制不是原生功能，需要自定义实现 </div><div class="compact-content">• 选项D-维护双活环境成本过高，不符合成本效益要求 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-预先复制Docker镜像避免构建延迟，满足RTO要求 </div><div class="compact-content">• 成本-按需备份比双活环境更经济，Lambda调度成本低 </div><div class="compact-content">• 可扩展性-自动化备份流程可扩展到更多组件和更频繁备份</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: C</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-203">
            <div class="question-header">
                <div class="question-title">Question #203 ✅ ⚪ <small style="float: right;">(203/353)</small></div>
            </div>
            <div class="question-content">A company's application runs on <span class="key-service">Amazon EC2</span> instances. The application writes to a log file that records the username, date, time, and source IP address of the login. The log is published to a log group in <span class="key-service">Amazon CloudWatch</span> Logs. The company is performing a root cause analysis for an event that occurred on the previous day. The company needs to know the number of logins for a specific user from the past 7 days. Which solution will provide this information? C (92%) 8%</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Create a CloudWatch Logs metric filter on the log group. Use a filter pattern that matches the username. Publish a CloudWatch metric that sums the number of logins over the past 7 days.</div>                <div class="option"><strong>B.</strong> Create a CloudWatch Logs subscription on the log group. Use a filter pattern that matches the username. Publish a CloudWatch metric that sums the number of logins over the past 7 days.</div>                <div class="option correct-answer"><strong>C.</strong> Create a CloudWatch Logs Insights query that uses an aggregation function to count the number of logins for the username over the past 7 days. Run the query against the log group.</div>                <div class="option"><strong>D.</strong> Create a CloudWatch dashboard. Add a number widget that has a filter pattern that counts the number of logins for the username over the past 7 days directly from the log group.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司的应用程序运行在Amazon EC2实例上。应用程序写入日志文件，记录用户名、日期、时间和登录的源IP地址。日志发布到Amazon CloudWatch Logs中的日志组。公司正在对前一天发生的事件进行根本原因分析。公司需要知道过去7天内特定用户的登录次数。哪种解决方案能提供这些信息？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 在日志组上创建CloudWatch Logs指标过滤器，使用匹配用户名的过滤模式，发布一个CloudWatch指标来汇总过去7天的登录次数。</div> <div class="option-analysis"><strong>B.</strong> 在日志组上创建CloudWatch Logs订阅，使用匹配用户名的过滤模式，发布一个CloudWatch指标来汇总过去7天的登录次数。</div> <div class="option-analysis"><strong>C.</strong> 创建一个CloudWatch Logs Insights查询，使用聚合函数来统计过去7天内该用户名的登录次数，对日志组运行查询。</div> <div class="option-analysis"><strong>D.</strong> 创建一个CloudWatch仪表板，添加一个数字小部件，使用过滤模式直接从日志组统计过去7天内该用户名的登录次数。<div class="section-title"><strong>核心要求:</strong></div> 需要查询分析过去7天特定用户的登录次数进行根因分析 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• CloudWatch Logs Insights-专门用于日志查询和分析的服务 </div><div class="compact-content">• CloudWatch Logs-日志存储和管理服务 <div class="section-title"><strong>正确答案C:</strong></div> CloudWatch Logs Insights提供SQL-like查询语言，可以直接对历史日志数据进行聚合分析，支持时间范围查询和计数功能，最适合一次性分析需求 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A-Metric Filter主要用于实时监控告警，不适合历史数据分析查询 </div><div class="compact-content">• 选项B-Subscription Filter用于实时流式处理日志到其他服务，非查询分析工具 </div><div class="compact-content">• 选项D-Dashboard Widget无法直接执行复杂的日志查询和聚合操作 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-Insights提供优化的查询引擎，支持快速历史数据分析 </div><div class="compact-content">• 成本-按查询付费，无需预先配置资源，适合临时分析需求 </div><div class="compact-content">• 可扩展性-原生支持大规模日志数据的聚合查询和时间范围过滤</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: C</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-204">
            <div class="question-header">
                <div class="question-title">Question #204 ✅ ⚪ <small style="float: right;">(204/353)</small></div>
            </div>
            <div class="question-content">A company has an <span class="key-service">AWS CodeDeploy</span> application. The application has a deployment group that uses a single tag group to identify instances for the deployment of Application<div class="option-analysis"><strong>A.</strong> The single tag group configuration identifies instances that have Environment=Production and Name=ApplicationA tags for the deployment of ApplicationA. The company launches an additional <span class="key-service">Amazon EC2</span> instance with Department=Marketing, Environment=Production, and Name=ApplicationB tags. On the next CodeDeploy deployment of ApplicationA, the additional instance has ApplicationA installed on it. A DevOps engineer needs to configure the existing deployment group to prevent ApplicationA from being installed on the additional instance. Which solution will meet these requirements? A (94%) 6%</div></div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Change the current single tag group to include only the Environment=Production tag. Add another single tag group that includes only the Name=ApplicationA tag.</div>                <div class="option"><strong>B.</strong> Change the current single tag group to include the Department=Marketing, Environment=Production, and Name=ApplicationA tags.</div>                <div class="option"><strong>C.</strong> Add another single tag group that includes only the Department=Marketing tag. Keep the Environment=Production and Name=ApplicationA tags with the current single tag group.</div>                <div class="option correct-answer"><strong>D.</strong> Change the current single tag group to include only the Environment=Production tag. Add another single tag group that includes only the Department=Marketing tag.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司有一个AWS CodeDeploy应用程序。该应用程序有一个部署组，使用单个标签组来识别用于部署ApplicationA的实例。单个标签组配置识别具有Environment=Production和Name=ApplicationA标签的实例来部署ApplicationA。公司启动了一个额外的Amazon EC2实例，标签为Department=Marketing、Environment=Production和Name=ApplicationB。在下次CodeDeploy部署ApplicationA时，额外的实例上安装了ApplicationA。DevOps工程师需要配置现有部署组以防止ApplicationA被安装在额外的实例上。 <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 将当前单个标签组更改为仅包含Environment=Production标签，添加另一个仅包含Name=ApplicationA标签的单个标签组。</div> <div class="option-analysis"><strong>B.</strong> 将当前单个标签组更改为包含Department=Marketing、Environment=Production和Name=ApplicationA标签。</div> <div class="option-analysis"><strong>C.</strong> 添加另一个仅包含Department=Marketing标签的单个标签组，保持当前单个标签组的Environment=Production和Name=ApplicationA标签。</div> <div class="option-analysis"><strong>D.</strong> 将当前单个标签组更改为仅包含Environment=Production标签，添加另一个仅包含Department=Marketing标签的单个标签组。<div class="section-title"><strong>核心要求:</strong></div> 配置CodeDeploy部署组标签组以防止ApplicationA部署到错误的EC2实例上 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• <span class="key-service">AWS CodeDeploy</span>-自动化应用程序部署服务，使用标签组识别目标实例 </div><div class="compact-content">• <span class="key-service">Amazon EC2</span>-虚拟服务器实例，通过标签进行分类和管理 <div class="section-title"><strong>正确答案D:</strong></div> 使用多个标签组的AND逻辑，实例必须同时具有Environment=Production和Department=Marketing标签才会被选中，由于新实例没有Department=Marketing标签，不会被部署 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A-会选中所有Environment=Production的实例，包括不需要的ApplicationB实例 </div><div class="compact-content">• 选项B-要求实例同时具有三个特定标签，过于严格且不符合现有实例标签配置 </div><div class="compact-content">• 选项C-会选中具有Department=Marketing标签的实例，但新实例正好有此标签，仍会被错误部署 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-精确的标签匹配逻辑确保部署效率 </div><div class="compact-content">• 成本-避免错误部署减少资源浪费和回滚成本 </div><div class="compact-content">• 可扩展性-标签组策略支持灵活的实例分类管理</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: D</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-205">
            <div class="question-header">
                <div class="question-title">Question #205 ✅ ⚪ <small style="float: right;">(205/353)</small></div>
            </div>
            <div class="question-content">A company is launching an application that stores raw data in an <span class="key-service">Amazon S3</span> bucket. Three applications need to access the data to generate reports. The data must be redacted differently for each application before the applications can access the data. Which solution will meet these requirements? D (87%) 13%</div>
            <div class="options-container">                <div class="option correct-answer"><strong>A.</strong> Create an S3 bucket for each application. Configure S3 Same-Region Replication (SRR) from the raw data's S3 bucket to each application's S3 bucket. Configure each application to consume data from its own S3 bucket.</div>                <div class="option"><strong>B.</strong> Create an Amazon Kinesis data stream. Create an <span class="key-service">AWS Lambda</span> function that is invoked by object creation events in the raw data's S3 bucket. Program the Lambda function to redact data for each application. Publish the data on the Kinesis data stream. Configure each application to consume data from the Kinesis data stream.</div>                <div class="option"><strong>C.</strong> For each application, create an S3 access point that uses the raw data's S3 bucket as the destination. Create an <span class="key-service">AWS Lambda</span> function that is invoked by object creation events in the raw data's S3 bucket. Program the Lambda function to redact data for each application. Store the data in each application's S3 access point. Configure each application to consume data from its own S3 access point.</div>                <div class="option"><strong>D.</strong> Create an S3 access point that uses the raw data's S3 bucket as the destination. For each application, create an S3 Object Lambda access point that uses the S3 access point. Configure the <span class="key-service">AWS Lambda</span> function for each S3 Object Lambda access point to redact data when objects are retrieved. Configure each application to consume data from its own S3 Object Lambda access point Most Voted</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司正在启动一个应用程序，将原始数据存储在Amazon S3存储桶中。三个应用程序需要访问数据来生成报告。在应用程序访问数据之前，必须为每个应用程序以不同方式编辑数据。哪种解决方案能满足这些要求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 为每个应用程序创建一个S3存储桶。配置从原始数据S3存储桶到每个应用程序S3存储桶的S3 Same-Region Replication (SRR)。配置每个应用程序从自己的S3存储桶消费数据。</div> <div class="option-analysis"><strong>B.</strong> 创建一个Amazon Kinesis数据流。创建一个由原始数据S3存储桶中对象创建事件调用的AWS Lambda函数。编程Lambda函数为每个应用程序编辑数据。将数据发布到Kinesis数据流。配置每个应用程序从Kinesis数据流消费数据。</div> <div class="option-analysis"><strong>C.</strong> 为每个应用程序创建一个使用原始数据S3存储桶作为目标的S3 access point。创建一个由原始数据S3存储桶中对象创建事件调用的AWS Lambda函数。编程Lambda函数为每个应用程序编辑数据。将数据存储在每个应用程序的S3 access point中。配置每个应用程序从自己的S3 access point消费数据。</div> <div class="option-analysis"><strong>D.</strong> 创建一个使用原始数据S3存储桶作为目标的S3 access point。为每个应用程序创建一个使用该S3 access point的S3 Object Lambda access point。配置每个S3 Object Lambda access point的AWS Lambda函数在检索对象时编辑数据。配置每个应用程序从自己的S3 Object Lambda access point消费数据。<div class="section-title"><strong>核心要求:</strong></div> 为三个应用程序提供不同编辑版本的S3数据访问 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• S3 Object Lambda - 在数据检索时实时转换数据 </div><div class="compact-content">• S3 Access Point - 为S3存储桶提供专用访问端点 <div class="section-title"><strong>正确答案D:</strong></div> 使用S3 Object Lambda实现按需数据编辑，无需存储多份数据副本，每个应用程序通过专用Object Lambda access point获得实时编辑的数据 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A - SRR只是复制原始数据，无法实现数据编辑功能 </div><div class="compact-content">• 选项B - Kinesis适用于流数据处理，不适合S3静态数据的编辑访问场景 </div><div class="compact-content">• 选项C - S3 access point本身不支持数据转换，无法实现编辑功能 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能 - Object Lambda提供实时数据转换，无延迟 </div><div class="compact-content">• 成本 - 避免存储多份编辑后的数据副本，节省存储成本 </div><div class="compact-content">• 可扩展性 - 每个应用程序独立的Object Lambda access point，易于管理和扩展</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: A</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-206">
            <div class="question-header">
                <div class="question-title">Question #206 ✅ ⚪ <small style="float: right;">(206/353)</small></div>
            </div>
            <div class="question-content">A company uses AWS Control Tower and <span class="key-service">AWS CloudFormation</span> to manage its AWS accounts and to create AWS resources. The company requires all <span class="key-service">Amazon S3</span> buckets to be encrypted with AWS Key Management Service (AWS KMS) when the S3 buckets are created in a CloudFormation stack. Which solution will meet this requirement? B (95%) 5%</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Use <span class="key-service">AWS Organizations</span>. Attach an <span class="key-service">SCP</span> that denies the s3:PutObject permission if the request does not include an x-amz-server-side-encryption header that requests server-side encryption with AWS KMS keys (SSE-KMS).</div>                <div class="option"><strong>B.</strong> Use AWS Control Tower with a multi-account environment. Configure and enable proactive AWS Control Tower controls on all OUs with CloudFormation hooks.</div>                <div class="option"><strong>C.</strong> Use AWS Control Tower with a multi-account environment. Configure and enable detective AWS Control Tower controls on all OUs with CloudFormation hooks.</div>                <div class="option correct-answer"><strong>D.</strong> Use <span class="key-service">AWS Organizations</span>. Create an <span class="key-service">AWS Config</span> organizational rule to check whether a KMS encryption key is enabled for all S3 buckets. Deploy the rule. Create and apply an <span class="key-service">SCP</span> to prevent users from stopping and deleting <span class="key-service">AWS Config</span> across all AWS accounts.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司使用AWS Control Tower和AWS CloudFormation管理其AWS账户并创建AWS资源。公司要求在CloudFormation堆栈中创建Amazon S3存储桶时，所有S3存储桶都必须使用AWS Key Management Service (AWS KMS)进行加密。 <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 使用AWS Organizations。附加一个SCP策略，如果请求不包含要求使用AWS KMS密钥进行服务器端加密(SSE-KMS)的x-amz-server-side-encryption标头，则拒绝s3:PutObject权限。</div> <div class="option-analysis"><strong>B.</strong> 使用AWS Control Tower的多账户环境。在所有OU上配置并启用主动式AWS Control Tower控制，使用CloudFormation钩子。</div> <div class="option-analysis"><strong>C.</strong> 使用AWS Control Tower的多账户环境。在所有OU上配置并启用检测式AWS Control Tower控制，使用CloudFormation钩子。</div> <div class="option-analysis"><strong>D.</strong> 使用AWS Organizations。创建AWS Config组织规则检查是否为所有S3存储桶启用了KMS加密密钥。部署该规则。创建并应用SCP以防止用户在所有AWS账户中停止和删除AWS Config。<div class="section-title"><strong>核心要求:</strong></div> 确保CloudFormation创建的所有S3存储桶都使用AWS KMS加密 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• <span class="key-service">AWS Config</span> - 持续监控和评估AWS资源配置合规性 </div><div class="compact-content">• <span class="key-service">AWS Organizations</span> <span class="key-service">SCP</span> - 提供跨账户的权限边界和合规性强制执行 <div class="section-title"><strong>正确答案D:</strong></div> 通过AWS Config组织规则持续检测S3存储桶的KMS加密状态，结合SCP防止Config被禁用，确保合规性监控的持续性和有效性 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A - 仅阻止PutObject操作但不能防止创建未加密的存储桶本身 </div><div class="compact-content">• 选项B - 主动控制虽然能预防但题目未明确支持CloudFormation钩子集成 </div><div class="compact-content">• 选项C - 检测式控制是事后发现问题而非预防，且同样存在集成问题 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能 - Config规则提供自动化合规性检查，无需手动干预 </div><div class="compact-content">• 成本 - 利用现有Organizations和Config服务，成本效益高 </div><div class="compact-content">• 可扩展性 - 组织级规则自动应用于所有账户和未来新增账户</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: D</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-207">
            <div class="question-header">
                <div class="question-title">Question #207 ✅ ⚪ <small style="float: right;">(207/353)</small></div>
            </div>
            <div class="question-content">A DevOps engineer has developed an <span class="key-service">AWS Lambda</span> function. The Lambda function starts an <span class="key-service">AWS CloudFormation</span> drift detection operation on all supported resources for a specific CloudFormation stack. The Lambda function then exits its invocation. The DevOps engineer has created an Amazon EventBridge scheduled rule that invokes the Lambda function every hour. An Amazon Simple Notification Service (<span class="key-service">Amazon SNS</span>) topic already exists in the AWS account. The DevOps engineer has subscribed to the SNS topic to receive notifications. The DevOps engineer needs to receive a notification as soon as possible when drift is detected in this specific stack configuration. Which solution will meet these requirements? D (73%) B (23%)</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Configure the existing EventBridge rule to also target the SNS topic. Configure an SNS subscription filter policy to match the CloudFormation stack. Attach the subscription filter policy to the SNS topic.</div>                <div class="option correct-answer"><strong>B.</strong> Create a second Lambda function to query the CloudFormation API for the drift detection results for the stack. Configure the second Lambda function to publish a message to the SNS topic if drift is detected. Adjust the existing EventBridge rule to also target the second Lambda function.</div>                <div class="option"><strong>C.</strong> Configure <span class="key-service">Amazon GuardDuty</span> in the account with drift detection for all CloudFormation stacks. Create a second EventBridge rule that reacts to the GuardDuty drift detection event finding for the specific CloudFormation stack. Configure the SNS topic as a target of the second EventBridge rule.</div>                <div class="option"><strong>D.</strong> Configure <span class="key-service">AWS Config</span> in the account. Use the cloudformation-stack-drift-detection-check managed rule. Create a second EventBridge rule that reacts to a compliance change event for the CloudFormation stack. Configure the SNS topic as a target of the second EventBridge rule.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一位DevOps工程师开发了一个AWS Lambda函数，该函数对特定CloudFormation堆栈的所有支持资源启动AWS CloudFormation漂移检测操作，然后退出调用。工程师创建了Amazon EventBridge定时规则每小时调用Lambda函数。账户中已存在Amazon SNS主题且工程师已订阅接收通知。工程师需要在检测到此特定堆栈配置漂移时尽快收到通知。 <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 配置现有EventBridge规则同时目标SNS主题，配置SNS订阅过滤策略匹配CloudFormation堆栈，将订阅过滤策略附加到SNS主题</div> <div class="option-analysis"><strong>B.</strong> 创建第二个Lambda函数查询CloudFormation API获取堆栈漂移检测结果，配置第二个Lambda函数在检测到漂移时向SNS主题发布消息，调整现有EventBridge规则同时目标第二个Lambda函数</div> <div class="option-analysis"><strong>C.</strong> 在账户中配置Amazon GuardDuty对所有CloudFormation堆栈进行漂移检测，创建第二个EventBridge规则响应特定CloudFormation堆栈的GuardDuty漂移检测事件发现，配置SNS主题作为第二个EventBridge规则的目标</div> <div class="option-analysis"><strong>D.</strong> 在账户中配置AWS Config，使用cloudformation-stack-drift-detection-check托管规则，创建第二个EventBridge规则响应CloudFormation堆栈的合规性变更事件，配置SNS主题作为第二个EventBridge规则的目标<div class="section-title"><strong>核心要求:</strong></div> 在CloudFormation堆栈漂移检测完成后尽快发送通知 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• CloudFormation漂移检测-检测堆栈资源配置偏差 </div><div class="compact-content">• EventBridge-事件驱动架构和定时调度 </div><div class="compact-content">• Lambda-执行漂移检测和结果查询 </div><div class="compact-content">• SNS-发送通知消息 <div class="section-title"><strong>正确答案B:</strong></div> 创建第二个Lambda函数主动查询CloudFormation API获取漂移检测结果，通过EventBridge定时触发实现及时检查和通知 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A-EventBridge规则无法直接获取漂移检测结果，SNS过滤策略无法解决结果查询问题 </div><div class="compact-content">• 选项C-GuardDuty不提供CloudFormation漂移检测功能，主要用于安全威胁检测 </div><div class="compact-content">• 选项D-AWS Config的漂移检测规则无法提供实时性，且合规性事件响应延迟较高 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-主动查询API确保及时获取漂移检测结果 </div><div class="compact-content">• 成本-利用现有EventBridge规则添加第二个Lambda目标成本最低 </div><div class="compact-content">• 可扩展性-Lambda函数可灵活处理多种漂移检测场景和通知逻辑</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: B</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-208">
            <div class="question-header">
                <div class="question-title">Question #208 ✅ 📝 <small style="float: right;">(208/353)</small></div>
            </div>
            <div class="question-content">A company has deployed a complex container-based workload on AWS. The workload uses Amazon Managed Service for Prometheus for monitoring. The workload runs in an Amazon Elastic Kubernetes Service (<span class="key-service">Amazon EKS</span>) cluster in an AWS account. The company's DevOps team wants to receive workload alerts by using the company's Amazon Simple Notification Service (<span class="key-service">Amazon SNS</span>) topic. The SNS topic is in the same AWS account as the EKS cluster. Which combination of steps will meet these requirements? (Choose three.) BCD (44%) BCE (36%) 8% 6%</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Use the Amazon Managed Service for Prometheus remote write URL to send alerts to the SNS topic</div>                <div class="option correct-answer"><strong>B.</strong> Create an alerting rule that checks the availability of each of the workload's containers.</div>                <div class="option"><strong>C.</strong> Create an alert manager configuration for the SNS topic.</div>                <div class="option correct-answer"><strong>D.</strong> Modify the access policy of the SNS topic. Grant the aps.amazonaws.com service principal the sns:Publish permission and the sns:GetTopicAttributes permission for the SNS topic.</div>                <div class="option correct-answer"><strong>E.</strong> Modify the IAM role that Amazon Managed Service for Prometheus uses. Grant the role the sns:Publish permission and the sns:GetTopicAttributes permission for the SNS topic. F. Create an OpenID Connect (OIDC) provider for the EKS cluster. Create a cluster service account. Grant the account the sns:Publish permission and the sns:GetTopicAttributes permission by using an IAM role.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司在AWS上部署了复杂的基于容器的工作负载。该工作负载使用Amazon Managed Service for Prometheus进行监控，运行在AWS账户中的Amazon EKS集群上。公司的DevOps团队希望通过公司的Amazon SNS主题接收工作负载告警。SNS主题与EKS集群在同一AWS账户中。哪些步骤组合能满足这些要求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 使用Amazon Managed Service for Prometheus远程写入URL将告警发送到SNS主题</div> <div class="option-analysis"><strong>B.</strong> 创建告警规则来检查工作负载中每个容器的可用性</div> <div class="option-analysis"><strong>C.</strong> 为SNS主题创建告警管理器配置</div> <div class="option-analysis"><strong>D.</strong> 修改SNS主题的访问策略，授予aps.amazonaws.com服务主体对SNS主题的sns:Publish权限和sns:GetTopicAttributes权限</div> <div class="option-analysis"><strong>E.</strong> 修改Amazon Managed Service for Prometheus使用的IAM角色，授予该角色对SNS主题的sns:Publish权限和sns:GetTopicAttributes权限 F. 为EKS集群创建OpenID Connect (OIDC)提供商，创建集群服务账户，通过IAM角色授予账户sns:Publish权限和sns:GetTopicAttributes权限<div class="section-title"><strong>核心要求:</strong></div> 配置Amazon Managed Service for Prometheus向SNS主题发送容器工作负载告警 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• Amazon Managed Service for Prometheus - 托管的Prometheus监控服务，需要配置告警规则和权限 </div><div class="compact-content">• <span class="key-service">Amazon SNS</span> - 消息通知服务，需要配置访问策略接收告警 </div><div class="compact-content">• <span class="key-service">Amazon EKS</span> - Kubernetes托管服务，运行被监控的容器工作负载 <div class="section-title"><strong>正确答案BDE:</strong></div> 需要创建告警规则检测容器状态(B)，配置SNS主题访问策略允许Prometheus服务发布消息(D)，并为Prometheus的IAM角色授予SNS发布权限(E)，形成完整的告警链路 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A - Remote write URL用于指标数据传输，不是告警通知机制 </div><div class="compact-content">• 选项C - 需要的是告警规则而非告警管理器配置 </div><div class="compact-content">• 选项F - OIDC和服务账户用于Pod权限，与Prometheus服务权限无关 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能 - 直接的服务到服务通信，无额外跳转延迟 </div><div class="compact-content">• 成本 - 使用托管服务原生集成，无额外组件成本 </div><div class="compact-content">• 可扩展性 - 基于IAM的权限模型支持大规模告警处理</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: BDE (B、D、E)</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-209">
            <div class="question-header">
                <div class="question-title">Question #209 ✅ ⚪ <small style="float: right;">(209/353)</small></div>
            </div>
            <div class="question-content">A company's organization in <span class="key-service">AWS Organizations</span> has a single OU. The company runs <span class="key-service">Amazon EC2</span> instances in the OU accounts. The company needs to limit the use of each EC2 instance's credentials to the specific EC2 instance that the credential is assigned to. A DevOps engineer must configure security for the EC2 instances. Which solution will meet these requirements? B (100%)</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Create an <span class="key-service">SCP</span> that specifies the <span class="key-service">VPC</span> CIDR block. Configure the <span class="key-service">SCP</span> to check whether the value of the aws:VpcSourceIp condition key is in the specified block. In the same <span class="key-service">SCP</span> check, check whether the values of the aws:EC2InstanceSourcePrivateIPv4 and aws:SourceVpc condition keys are the same. Deny access if either condition is false. Apply the <span class="key-service">SCP</span> to the OU.</div>                <div class="option correct-answer"><strong>B.</strong> Create an <span class="key-service">SCP</span> that checks whether the values of the aws:EC2InstanceSourceVPC and aws:SourceVpc condition keys are the same. Deny access if the values are not the same. In the same <span class="key-service">SCP</span> check, check whether the values of the aws:EC2InstanceSourcePrivateIPv4 and aws:VpcSourceIp condition keys are the same. Deny access if the values are not the same. Apply the <span class="key-service">SCP</span> to the OU. Most Voted</div>                <div class="option"><strong>C.</strong> Create an <span class="key-service">SCP</span> that includes a list of acceptable <span class="key-service">VPC</span> values and checks whether the value of the aws:SourceVpc condition key is in the list. In the same <span class="key-service">SCP</span> check, define a list of acceptable IP address values and check whether the value of the aws:VpcSourceIp condition key is in the list. Deny access if either condition is false. Apply the <span class="key-service">SCP</span> to each account in the organization.</div>                <div class="option"><strong>D.</strong> Create an <span class="key-service">SCP</span> that checks whether the values of the aws:EC2InstanceSourceVPC and aws:VpcSourceIp condition keys are the same. Deny access if the values are not the same. In the same <span class="key-service">SCP</span> check, check whether the values of the aws:EC2InstanceSourcePrivateIPv4 and aws:SourceVpc condition keys are the same. Deny access if the values are not the same. Apply the <span class="key-service">SCP</span> to each account in the organization.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司在AWS Organizations中有单个OU，在OU账户中运行EC2实例，需要限制每个EC2实例的凭证只能在分配给它的特定EC2实例上使用，DevOps工程师必须为EC2实例配置安全性。 <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 创建指定VPC CIDR块的SCP，配置SCP检查aws:VpcSourceIp条件键值是否在指定块内，在同一SCP检查中检查aws:EC2InstanceSourcePrivateIPv4和aws:SourceVpc条件键值是否相同，如果任一条件为假则拒绝访问，将SCP应用到OU。</div> <div class="option-analysis"><strong>B.</strong> 创建SCP检查aws:EC2InstanceSourceVPC和aws:SourceVpc条件键值是否相同，如果值不同则拒绝访问，在同一SCP检查中检查aws:EC2InstanceSourcePrivateIPv4和aws:VpcSourceIp条件键值是否相同，如果值不同则拒绝访问，将SCP应用到OU。</div> <div class="option-analysis"><strong>C.</strong> 创建包含可接受VPC值列表的SCP并检查aws:SourceVpc条件键值是否在列表中，在同一SCP检查中定义可接受IP地址值列表并检查aws:VpcSourceIp条件键值是否在列表中，如果任一条件为假则拒绝访问，将SCP应用到组织中的每个账户。</div> <div class="option-analysis"><strong>D.</strong> 创建SCP检查aws:EC2InstanceSourceVPC和aws:VpcSourceIp条件键值是否相同，如果值不同则拒绝访问，在同一SCP检查中检查aws:EC2InstanceSourcePrivateIPv4和aws:SourceVpc条件键值是否相同，如果值不同则拒绝访问，将SCP应用到组织中的每个账户。<div class="section-title"><strong>核心要求:</strong></div> 限制EC2实例凭证只能在分配的特定实例上使用 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• <span class="key-service">AWS Organizations</span> - 提供SCP策略管理和OU级别控制 </div><div class="compact-content">• EC2实例角色 - 提供实例级别的身份验证和授权机制 <div class="section-title"><strong>正确答案B:</strong></div> 通过SCP检查VPC源匹配(aws:EC2InstanceSourceVPC与aws:SourceVpc)和IP源匹配(aws:EC2InstanceSourcePrivateIPv4与aws:VpcSourceIp)，确保凭证只能从原始实例使用 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A - 使用aws:VpcSourceIp检查CIDR块而非精确IP匹配，无法确保实例级别的凭证隔离 </div><div class="compact-content">• 选项C - 使用静态白名单方式管理复杂且不够精确，无法实现实例级别的动态绑定 </div><div class="compact-content">• 选项D - 错误地比较aws:EC2InstanceSourceVPC与aws:VpcSourceIp(不同类型的条件键)，逻辑不正确 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能 - SCP策略在OU级别统一应用，减少管理开销 </div><div class="compact-content">• 成本 - 使用原生AWS Organizations功能，无额外服务费用 </div><div class="compact-content">• 可扩展性 - OU级别策略自动应用到所有账户，支持组织扩展</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: B</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-210">
            <div class="question-header">
                <div class="question-title">Question #210 ✅ 📝 <small style="float: right;">(210/353)</small></div>
            </div>
            <div class="question-content">A company has a fleet of <span class="key-service">Amazon EC2</span> instances that run Linux in a single AWS account. The company is using an <span class="key-service">AWS Systems Manager</span> Automation task across the EC2 instances. During the most recent patch cycle, several EC2 instances went into an error state because of insufficient available disk space. A DevOps engineer needs to ensure that the EC2 instances have sufficient available disk space during the patching process in the future. Which combination of steps will meet these requirements? (Choose two.) AD (100%)</div>
            <div class="options-container">                <div class="option correct-answer"><strong>A.</strong> Ensure that the <span class="key-service">Amazon CloudWatch</span> agent is installed on all EC2 instances.</div>                <div class="option"><strong>B.</strong> Create a cron job that is installed on each EC2 instance to periodically delete temporary files.</div>                <div class="option"><strong>C.</strong> Create an <span class="key-service">Amazon CloudWatch</span> log group for the EC2 instances. Configure a cron job that is installed on each EC2 instance to write the available disk space to a CloudWatch log stream for the relevant EC2 instance.</div>                <div class="option correct-answer"><strong>D.</strong> Create an <span class="key-service">Amazon CloudWatch</span> alarm to monitor available disk space on all EC2 instances. Add the alarm as a safety control to the Systems Manager Automation task.</div>                <div class="option"><strong>E.</strong> Create an <span class="key-service">AWS Lambda</span> function to periodically check for sufficient available disk space on all EC2 instances by evaluating each EC2 instance's respective <span class="key-service">Amazon CloudWatch</span> log stream.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司在单个AWS账户中运行着一组Linux EC2实例。公司正在这些EC2实例上使用AWS Systems Manager Automation任务。在最近的补丁周期中，由于可用磁盘空间不足，几个EC2实例进入错误状态。DevOps工程师需要确保EC2实例在未来的补丁过程中有足够的可用磁盘空间。哪些步骤组合能满足这些要求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 确保在所有EC2实例上安装Amazon CloudWatch代理</div> <div class="option-analysis"><strong>B.</strong> 创建一个cron作业，安装在每个EC2实例上以定期删除临时文件</div> <div class="option-analysis"><strong>C.</strong> 为EC2实例创建Amazon CloudWatch日志组，配置安装在每个EC2实例上的cron作业将可用磁盘空间写入相关EC2实例的CloudWatch日志流</div> <div class="option-analysis"><strong>D.</strong> 创建Amazon CloudWatch告警来监控所有EC2实例的可用磁盘空间，将告警作为安全控制添加到Systems Manager Automation任务中</div> <div class="option-analysis"><strong>E.</strong> 创建AWS Lambda函数，通过评估每个EC2实例各自的Amazon CloudWatch日志流来定期检查所有EC2实例的充足可用磁盘空间<div class="section-title"><strong>核心要求:</strong></div> 在Systems Manager自动化补丁过程中预防磁盘空间不足导致的错误 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• CloudWatch Agent-收集EC2实例磁盘空间指标 </div><div class="compact-content">• CloudWatch Alarm-基于指标阈值触发告警并集成到自动化任务 <div class="section-title"><strong>正确答案AD:</strong></div> CloudWatch Agent收集磁盘空间指标，CloudWatch Alarm监控指标并作为Systems Manager Automation的安全控制，在磁盘空间不足时阻止补丁执行 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项B-仅清理临时文件无法保证补丁过程中有足够空间，且未集成到自动化流程 </div><div class="compact-content">• 选项C-手动写入日志流复杂且不必要，CloudWatch Agent已提供标准指标收集 </div><div class="compact-content">• 选项E-通过Lambda读取日志流检查磁盘空间架构复杂，且无法直接集成到Systems Manager安全控制 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-CloudWatch Agent提供实时指标监控，告警可即时响应 </div><div class="compact-content">• 成本-使用AWS原生服务最经济，避免复杂的自定义解决方案 </div><div class="compact-content">• 可扩展性-CloudWatch服务可自动扩展到所有EC2实例，无需单独配置</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: AD (A、D)</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-211">
            <div class="question-header">
                <div class="question-title">Question #211 ✅ 📝 <small style="float: right;">(211/353)</small></div>
            </div>
            <div class="question-content">A DevOps engineer is building an application that uses an <span class="key-service">AWS Lambda</span> function to query an Amazon Aurora MySQL DB cluster. The Lambda function performs only read queries. Amazon EventBridge events invoke the Lambda function. As more events invoke the Lambda function each second, the database's latency increases and the database's throughput decreases. The DevOps engineer needs to improve the performance of the application. Which combination of steps will meet these requirements? (Choose three.) ACE (80%) ADE (20%)</div>
            <div class="options-container">                <div class="option correct-answer"><strong>A.</strong> Use <span class="key-service">Amazon RDS</span> Proxy to create a proxy. Connect the proxy to the Aurora cluster reader endpoint. Set a maximum connections percentage on the proxy.</div>                <div class="option"><strong>B.</strong> Implement database connection pooling inside the Lambda code. Set a maximum number of connections on the database connection pool.</div>                <div class="option correct-answer"><strong>C.</strong> Implement the database connection opening outside the Lambda event handler code.</div>                <div class="option"><strong>D.</strong> Implement the database connection opening and closing inside the Lambda event handler code.</div>                <div class="option correct-answer"><strong>E.</strong> Connect to the proxy endpoint from the Lambda function. F. Connect to the Aurora cluster endpoint from the Lambda function.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一个DevOps工程师正在构建一个应用程序，该程序使用AWS Lambda函数查询Amazon Aurora MySQL DB集群。Lambda函数只执行读查询。Amazon EventBridge事件调用Lambda函数。随着每秒调用Lambda函数的事件增多，数据库延迟增加，吞吐量下降。DevOps工程师需要改善应用程序性能。哪些步骤组合能满足这些要求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 使用Amazon RDS Proxy创建代理，将代理连接到Aurora集群读取器端点，在代理上设置最大连接百分比</div> <div class="option-analysis"><strong>B.</strong> 在Lambda代码内部实现数据库连接池，在数据库连接池上设置最大连接数</div> <div class="option-analysis"><strong>C.</strong> 在Lambda事件处理程序代码外部实现数据库连接打开</div> <div class="option-analysis"><strong>D.</strong> 在Lambda事件处理程序代码内部实现数据库连接的打开和关闭</div> <div class="option-analysis"><strong>E.</strong> 从Lambda函数连接到代理端点 F. 从Lambda函数连接到Aurora集群端点<div class="section-title"><strong>核心要求:</strong></div> 解决Lambda高并发访问Aurora MySQL时的连接数过多导致的性能问题 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• <span class="key-service">Amazon RDS</span> Proxy-管理数据库连接池，减少连接开销，提高并发性能 </div><div class="compact-content">• <span class="key-service">AWS Lambda</span>-无服务器计算服务，需要优化数据库连接管理 </div><div class="compact-content">• Amazon Aurora MySQL-托管关系型数据库，支持读取器端点分离读写负载 <div class="section-title"><strong>正确答案ACE:</strong></div> 使用RDS Proxy连接Aurora读取器端点并设置连接限制(A)，在Lambda处理程序外部建立连接以复用连接(C)，Lambda通过代理端点访问数据库(E)，形成完整的连接优化方案 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项B-Lambda函数是无状态的，内部连接池无法在调用间保持，每次冷启动都会重建 </div><div class="compact-content">• 选项D-在处理程序内部开关连接会增加延迟，无法复用连接，违背性能优化原则 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-RDS Proxy减少连接建立开销，连接复用降低延迟 </div><div class="compact-content">• 成本-减少数据库连接数，避免连接数超限产生的额外费用 </div><div class="compact-content">• 可扩展性-代理自动管理连接池，支持Lambda高并发扩展需求</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: ACE (A、C、E)</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-212">
            <div class="question-header">
                <div class="question-title">Question #212 ✅ ⚪ <small style="float: right;">(212/353)</small></div>
            </div>
            <div class="question-content">A company has an <span class="key-service">AWS CloudFormation</span> stack that is deployed in a single AWS account. The company has configured the stack to send event notifications to an Amazon Simple Notification Service (<span class="key-service">Amazon SNS</span>) topic. A DevOps engineer must implement an automated solution that applies a tag to the specific CloudFormation stack instance only after a successful stack update occurs. The DevOps engineer has created an <span class="key-service">AWS Lambda</span> function that applies and updates this tag for the specific stack instance. Which solution will meet these requirements? C (100%)</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Run the AWS-UpdateCloudFormationStack <span class="key-service">AWS Systems Manager</span> Automation runbook when Systems Manager detects an UPDATE_COMPLETE event for the instance status of the CloudFormation stack. Configure the runbook to invoke the Lambda function.</div>                <div class="option"><strong>B.</strong> Create a custom <span class="key-service">AWS Config</span> rule that produces a compliance change event if the CloudFormation stack has an UPDATE_COMPLETE instance status. Configure <span class="key-service">AWS Config</span> to directly invoke the Lambda function to automatically remediate the change event.</div>                <div class="option correct-answer"><strong>C.</strong> Create an Amazon EventBridge rule that matches the UPDATE_COMPLETE event pattern for the instance status of the CloudFormation stack. Configure the rule to invoke the Lambda function.</div>                <div class="option"><strong>D.</strong> Adjust the configuration of the CloudFormation stack to send notifications for only an UPDATE_COMPLETE instance status event to the SNS topic. Subscribe the Lambda function to the SNS topic.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司在单个AWS账户中部署了AWS CloudFormation堆栈，配置堆栈向Amazon SNS主题发送事件通知。DevOps工程师必须实现自动化解决方案，仅在堆栈成功更新后为特定CloudFormation堆栈实例应用标签。工程师已创建Lambda函数来为特定堆栈实例应用和更新此标签。 <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 当Systems Manager检测到CloudFormation堆栈实例状态的UPDATE_COMPLETE事件时，运行AWS-UpdateCloudFormationStack <span class="key-service">AWS Systems Manager</span> Automation运行手册，配置运行手册调用Lambda函数。</div> <div class="option-analysis"><strong>B.</strong> 创建自定义AWS Config规则，如果CloudFormation堆栈具有UPDATE_COMPLETE实例状态则产生合规性变更事件，配置AWS Config直接调用Lambda函数自动修复变更事件。</div> <div class="option-analysis"><strong>C.</strong> 创建Amazon EventBridge规则匹配CloudFormation堆栈实例状态的UPDATE_COMPLETE事件模式，配置规则调用Lambda函数。</div> <div class="option-analysis"><strong>D.</strong> 调整CloudFormation堆栈配置，仅为UPDATE_COMPLETE实例状态事件向SNS主题发送通知，将Lambda函数订阅到SNS主题。<div class="section-title"><strong>核心要求:</strong></div> 在CloudFormation堆栈成功更新后自动为堆栈实例应用标签 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• CloudFormation-堆栈管理和事件生成 </div><div class="compact-content">• EventBridge-事件驱动架构和规则匹配 </div><div class="compact-content">• Lambda-标签应用逻辑执行 <div class="section-title"><strong>正确答案C:</strong></div> EventBridge原生支持CloudFormation事件模式匹配，可直接捕获UPDATE_COMPLETE状态并触发Lambda函数，实现精确的事件驱动自动化 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A-Systems Manager Automation不是为CloudFormation事件响应设计的，过度复杂 </div><div class="compact-content">• 选项B-AWS Config用于合规性监控而非事件响应，不适合实时触发场景 </div><div class="compact-content">• 选项D-需要修改现有CloudFormation配置，增加复杂性且通过SNS间接处理效率较低 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-EventBridge提供最直接的事件响应机制 </div><div class="compact-content">• 成本-避免不必要的中间服务和配置修改 </div><div class="compact-content">• 可扩展性-EventBridge规则易于管理和扩展到多个事件类型</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: C</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-213">
            <div class="question-header">
                <div class="question-title">Question #213 ✅ ⚪ <small style="float: right;">(213/353)</small></div>
            </div>
            <div class="question-content">A company deploys an application to two AWS Regions. The application creates and stores objects in an <span class="key-service">Amazon S3</span> bucket that is in the same Region as the application. Both deployments of the application need to have access to all the objects and their metadata from both Regions. The company has configured two-way replication between the S3 buckets and has enabled S3 Replication metrics on each S3 bucket. A DevOps engineer needs to implement a solution that retries the replication process if an object fails to replicate. Which solution will meet these requirements? D (78%) A (22%)</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Create an Amazon EventBridge rule that listens to S3 event notifications for failed replication events. Create an <span class="key-service">AWS Lambda</span> function that downloads the failed replication object and then runs a PutObject command for the object to the destination bucket. Configure the EventBridge rule to invoke the Lambda function to handle the object that failed to replicate.</div>                <div class="option correct-answer"><strong>B.</strong> Create an Amazon Simple Queue Service (<span class="key-service">Amazon SQS</span>) queue. Configure S3 event notifications to send failed replication notifications to the SQS queue. Create an <span class="key-service">AWS Lambda</span> function that downloads the failed replication object and then runs a PutObject command for the object to the destination bucket. Configure the Lambda function to poll the queue for notifications to process.</div>                <div class="option"><strong>C.</strong> Create an Amazon EventBridge rule that listens to S3 event notifications for failed replications. Create an <span class="key-service">AWS Lambda</span> function that downloads the failed replication object and then runs a PutObject command for the object to the destination bucket.</div>                <div class="option"><strong>D.</strong> Create an <span class="key-service">AWS Lambda</span> function that will use S3 batch operations to retry the replication on the existing object for a failed replication. Configure S3 event notifications to send failed replication notifications to the Lambda function.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司在两个AWS区域部署应用程序。应用程序在与其相同区域的Amazon S3存储桶中创建和存储对象。两个部署的应用程序都需要访问来自两个区域的所有对象及其元数据。公司已配置S3存储桶之间的双向复制并启用了S3复制指标。DevOps工程师需要实现一个解决方案，当对象复制失败时重试复制过程。 <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 创建Amazon EventBridge规则监听S3复制失败事件通知，创建AWS Lambda函数下载失败复制对象并对目标存储桶运行PutObject命令，配置EventBridge规则调用Lambda函数处理复制失败的对象。</div> <div class="option-analysis"><strong>B.</strong> 创建Amazon Simple Queue Service (<span class="key-service">Amazon SQS</span>)队列，配置S3事件通知将复制失败通知发送到SQS队列，创建AWS Lambda函数下载失败复制对象并对目标存储桶运行PutObject命令，配置Lambda函数轮询队列处理通知。</div> <div class="option-analysis"><strong>C.</strong> 创建Amazon EventBridge规则监听S3复制失败事件通知，创建AWS Lambda函数下载失败复制对象并对目标存储桶运行PutObject命令。</div> <div class="option-analysis"><strong>D.</strong> 创建AWS Lambda函数使用S3批处理操作对现有对象的失败复制进行重试，配置S3事件通知将复制失败通知发送到Lambda函数。<div class="section-title"><strong>核心要求:</strong></div> 实现S3跨区域复制失败时的自动重试机制 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• S3事件通知-检测复制失败事件 </div><div class="compact-content">• SQS-提供可靠的消息队列和重试机制 </div><div class="compact-content">• Lambda-执行复制重试逻辑 <div class="section-title"><strong>正确答案B:</strong></div> SQS提供消息持久化、死信队列和自动重试机制，确保复制失败事件不会丢失，Lambda可以可靠地处理重试逻辑 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A-EventBridge缺乏消息持久化和重试保证机制 </div><div class="compact-content">• 选项C-缺少EventBridge规则的触发配置，架构不完整 </div><div class="compact-content">• 选项D-S3批处理操作不适用于实时事件驱动的复制重试场景 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-SQS提供异步处理和批量消息处理能力 </div><div class="compact-content">• 成本-SQS按使用量计费，成本效益高 </div><div class="compact-content">• 可扩展性-SQS自动扩展，支持高并发消息处理</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: B</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-214">
            <div class="question-header">
                <div class="question-title">Question #214 ✅ ⚪ <small style="float: right;">(214/353)</small></div>
            </div>
            <div class="question-content">A company needs to implement failover for its application. The application includes an Amazon CloudFront distribution and a public Application Load Balancer (ALB) in an AWS Region. The company has configured the ALB as the default origin for the distribution. After some recent application outages, the company wants a zero-second RTO. The company deploys the application to a secondary Region in a warm standby configuration. A DevOps engineer needs to automate the failover of the application to the secondary Region so that HTTP GET requests meet the desired RTO. Which solution will meet these requirements? B (100%)</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Create a second CloudFront distribution that has the secondary ALB as the default origin. Create <span class="key-service">Amazon Route 53</span> alias records that have a failover policy and Evaluate Target Health set to Yes for both CloudFront distributions. Update the application to use the new record set.</div>                <div class="option correct-answer"><strong>B.</strong> Create a new origin on the distribution for the secondary AL<div class="option-analysis"><strong>B.</strong> Create a new origin group. Set the original ALB as the primary origin. Configure the origin group to fail over for HTTP 5xx status codes. Update the default behavior to use the origin group. Most Voted</div></div>                <div class="option"><strong>C.</strong> Create <span class="key-service">Amazon Route 53</span> alias records that have a failover policy and Evaluate Target Health set to Yes for both ALBs. Set the TTL of both records to 0. Update the distribution's origin to use the new record set.</div>                <div class="option"><strong>D.</strong> Create a CloudFront function that detects HTTP 5xx status codes. Configure the function to return a 307 Temporary Redirect error response to the secondary ALB if the function detects 5xx status codes. Update the distribution's default behavior to send origin responses to the function.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司需要为其应用程序实现故障转移。应用程序包括Amazon CloudFront分发和AWS区域中的公共Application Load Balancer (ALB)。公司已将ALB配置为分发的默认源。在最近的一些应用程序中断后，公司希望实现零秒RTO。公司在辅助区域以热备用配置部署应用程序。DevOps工程师需要自动化应用程序到辅助区域的故障转移，以便HTTP GET请求满足所需的RTO。哪个解决方案将满足这些要求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 创建第二个CloudFront分发，将辅助ALB作为默认源。创建Amazon Route 53别名记录，对两个CloudFront分发使用故障转移策略并将Evaluate Target Health设置为Yes。更新应用程序以使用新记录集。</div> <div class="option-analysis"><strong>B.</strong> 在分发上为辅助ALB创建新源。创建新的源组。将原始ALB设置为主源。配置源组在HTTP 5xx状态码时进行故障转移。更新默认行为以使用源组。</div> <div class="option-analysis"><strong>C.</strong> 为两个ALB创建Amazon Route 53别名记录，使用故障转移策略并将Evaluate Target Health设置为Yes。将两个记录的TTL设置为0。更新分发的源以使用新记录集。</div> <div class="option-analysis"><strong>D.</strong> 创建CloudFront函数来检测HTTP 5xx状态码。配置函数在检测到5xx状态码时向辅助ALB返回307临时重定向错误响应。更新分发的默认行为以将源响应发送到函数。<div class="section-title"><strong>核心要求:</strong></div> 实现零秒RTO的自动化故障转移机制 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• CloudFront Origin Groups-提供自动故障转移功能，无需DNS传播延迟 </div><div class="compact-content">• Application Load Balancer-作为主备源服务器 <div class="section-title"><strong>正确答案B:</strong></div> 使用CloudFront Origin Groups实现源级别的自动故障转移，当主源返回5xx错误时立即切换到备用源，无DNS传播延迟，满足零秒RTO要求 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A-使用Route 53故障转移需要DNS传播时间，无法实现零秒RTO </div><div class="compact-content">• 选项C-Route 53 DNS解析即使TTL为0也存在传播延迟，不满足零秒RTO </div><div class="compact-content">• 选项D-CloudFront函数返回重定向会增加额外的请求延迟，不符合零秒RTO要求 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-Origin Groups提供最快的故障转移响应时间 </div><div class="compact-content">• 成本-利用现有CloudFront分发，无需额外基础设施 </div><div class="compact-content">• 可扩展性-Origin Groups支持多个备用源配置</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: B</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-215">
            <div class="question-header">
                <div class="question-title">Question #215 ✅ ⚪ <small style="float: right;">(215/353)</small></div>
            </div>
            <div class="question-content">A cloud team uses <span class="key-service">AWS Organizations</span> and <span class="key-service">AWS IAM</span> Identity Center (AWS Single Sign-On) to manage a company's AWS accounts. The company recently established a research team. The research team requires the ability to fully manage the resources in its account. The research team must not be able to create IAM users. The cloud team creates a Research Administrator permission set in IAM Identity Center for the research team. The permission set has the AdministratorAccess AWS managed policy attached. The cloud team must ensure that no one on the research team can create IAM users. Which solution will meet these requirements? C (69%) A (31%)</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Create an IAM policy that denies the iam:CreateUser action. Attach the IAM policy to the Research Administrator permission set.</div>                <div class="option"><strong>B.</strong> Create an IAM policy that allows all actions except the iam:CreateUser action. Use the IAM policy to set the permissions boundary for the Research Administrator permission set.</div>                <div class="option correct-answer"><strong>C.</strong> Create an <span class="key-service">SCP</span> that denies the iam:CreateUser action. Attach the <span class="key-service">SCP</span> to the research team's AWS account.</div>                <div class="option"><strong>D.</strong> Create an <span class="key-service">AWS Lambda</span> function that deletes IAM users. Create an Amazon EventBridge rule that detects the IAM CreateUser event. Configure the rule to invoke the Lambda function.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 云团队使用AWS Organizations和AWS IAM Identity Center管理公司的AWS账户。公司最近成立了研究团队，需要完全管理其账户中的资源，但不能创建IAM用户。云团队在IAM Identity Center中为研究团队创建了Research Administrator权限集，附加了AdministratorAccess AWS托管策略。云团队必须确保研究团队中没有人可以创建IAM用户。 <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 创建一个拒绝iam:CreateUser操作的IAM策略，将该IAM策略附加到Research Administrator权限集。</div> <div class="option-analysis"><strong>B.</strong> 创建一个允许除iam:CreateUser操作外所有操作的IAM策略，使用该IAM策略为Research Administrator权限集设置权限边界。</div> <div class="option-analysis"><strong>C.</strong> 创建一个拒绝iam:CreateUser操作的SCP，将SCP附加到研究团队的AWS账户。</div> <div class="option-analysis"><strong>D.</strong> 创建一个删除IAM用户的AWS Lambda函数，创建检测IAM CreateUser事件的Amazon EventBridge规则，配置规则调用Lambda函数。<div class="section-title"><strong>核心要求:</strong></div> 在AWS Organizations环境中阻止研究团队创建IAM用户，同时保持其他管理权限 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• <span class="key-service">AWS Organizations</span> - 多账户管理和SCP策略控制 </div><div class="compact-content">• IAM Identity Center - 集中身份管理和权限集配置 </div><div class="compact-content">• <span class="key-service">SCP</span> - 账户级别的权限防护栏 <div class="section-title"><strong>正确答案C:</strong></div> SCP在账户级别提供强制性权限边界，无论用户具有什么权限都无法绕过SCP的拒绝策略，确保从根本上阻止IAM用户创建 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A - 权限集策略无法覆盖AdministratorAccess的完全权限 </div><div class="compact-content">• 选项B - 权限边界概念错误，且无法有效限制AdministratorAccess权限 </div><div class="compact-content">• 选项D - 事后删除方案，无法预防创建行为且增加复杂性 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能 - SCP提供实时权限控制，无延迟 </div><div class="compact-content">• 成本 - SCP为免费服务，无额外计算成本 </div><div class="compact-content">• 可扩展性 - SCP可应用于多个账户和组织单元</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: C</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-216">
            <div class="question-header">
                <div class="question-title">Question #216 ✅ ⚪ <small style="float: right;">(216/353)</small></div>
            </div>
            <div class="question-content">A company releases a new application in a new AWS account. The application includes an <span class="key-service">AWS Lambda</span> function that processes messages from an Amazon Simple Queue Service (<span class="key-service">Amazon SQS</span>) standard queue. The Lambda function stores the results in an <span class="key-service">Amazon S3</span> bucket for further downstream processing. The Lambda function needs to process the messages within a specific period of time after the messages are published. The Lambda function has a batch size of 10 messages and takes a few seconds to process a batch of messages. As load increases on the application's first day of service, messages in the queue accumulate at a greater rate than the Lambda function can process the messages. Some messages miss the required processing timelines. The logs show that many messages in the queue have data that is not valid. The company needs to meet the timeline requirements for messages that have valid data. Which solution will meet these requirements? D (100%)</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Increase the Lambda function's batch size. Change the SQS standard queue to an SQS FIFO queue. Request a Lambda concurrency increase in the AWS Region.</div>                <div class="option"><strong>B.</strong> Reduce the Lambda function's batch size. Increase the SQS message throughput quota. Request a Lambda concurrency increase in the AWS Region.</div>                <div class="option"><strong>C.</strong> Increase the Lambda function's batch size. Configure S3 Transfer Acceleration on the S3 bucket. Configure an SQS dead-letter queue.</div>                <div class="option correct-answer"><strong>D.</strong> Keep the Lambda function's batch size the same. Configure the Lambda function to report failed batch items. Configure an SQS dead-letter queue.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司在新的AWS账户中发布新应用程序。应用程序包含一个AWS Lambda函数，用于处理来自Amazon SQS标准队列的消息。Lambda函数将结果存储在Amazon S3存储桶中进行下游处理。Lambda函数需要在消息发布后的特定时间内处理消息。Lambda函数批处理大小为10条消息，处理一批消息需要几秒钟。随着应用程序首日负载增加，队列中消息积累速度超过Lambda函数处理速度。一些消息错过了处理时限。日志显示队列中许多消息包含无效数据。公司需要满足有效数据消息的时限要求。 <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 增加Lambda函数的批处理大小。将SQS标准队列更改为SQS FIFO队列。在AWS区域中请求Lambda并发增加。</div> <div class="option-analysis"><strong>B.</strong> 减少Lambda函数的批处理大小。增加SQS消息吞吐量配额。在AWS区域中请求Lambda并发增加。</div> <div class="option-analysis"><strong>C.</strong> 增加Lambda函数的批处理大小。在S3存储桶上配置S3 Transfer Acceleration。配置SQS死信队列。</div> <div class="option-analysis"><strong>D.</strong> 保持Lambda函数批处理大小不变。配置Lambda函数报告失败的批处理项。配置SQS死信队列。<div class="section-title"><strong>核心要求:</strong></div> 处理有效消息并满足时限要求，同时处理无效消息问题 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• Lambda - 批处理消息处理和错误报告 </div><div class="compact-content">• SQS - 消息队列管理和死信队列配置 <div class="section-title"><strong>正确答案D:</strong></div> 通过配置Lambda报告失败项和SQS死信队列，将无效消息从主队列中移除，让Lambda专注处理有效消息，提高整体处理效率 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A - 标准队列改为FIFO队列会降低吞吐量，无法解决无效消息问题 </div><div class="compact-content">• 选项B - 减少批处理大小会降低处理效率，增加处理时间 </div><div class="compact-content">• 选项C - S3 Transfer Acceleration不能解决消息处理瓶颈问题 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能 - 移除无效消息提高有效消息处理速度 </div><div class="compact-content">• 成本 - 避免重复处理无效消息，降低计算成本 </div><div class="compact-content">• 可扩展性 - 死信队列机制提供可靠的错误处理能力</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: D</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-217">
            <div class="question-header">
                <div class="question-title">Question #217 ✅ 📝 <small style="float: right;">(217/353)</small></div>
            </div>
            <div class="question-content">A company has an application that runs on <span class="key-service">AWS Lambda</span> and sends logs to <span class="key-service">Amazon CloudWatch</span> Logs. An Amazon Kinesis data stream is subscribed to the log groups in CloudWatch Logs. A single consumer Lambda function processes the logs from the data stream and stores the logs in an <span class="key-service">Amazon S3</span> bucket. The company's DevOps team has noticed high latency during the processing and ingestion of some logs. Which combination of steps will reduce the latency? (Choose three.) ABF (100%)</div>
            <div class="options-container">                <div class="option correct-answer"><strong>A.</strong> Create a data stream consumer with enhanced fan-out. Set the Lambda function that processes the logs as the consumer.</div>                <div class="option correct-answer"><strong>B.</strong> Increase the ParallelizationFactor setting in the Lambda event source mapping.</div>                <div class="option"><strong>C.</strong> Configure reserved concurrency for the Lambda function that processes the logs.</div>                <div class="option"><strong>D.</strong> Increase the batch size in the Kinesis data stream.</div>                <div class="option"><strong>E.</strong> Turn off the ReportBatchItemFailures setting in the Lambda event source mapping. F. Increase the number of shards in the Kinesis data stream. Most Voted</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司有一个运行在AWS Lambda上的应用程序，将日志发送到Amazon CloudWatch Logs。一个Amazon Kinesis数据流订阅了CloudWatch Logs中的日志组。单个消费者Lambda函数处理来自数据流的日志并将日志存储在Amazon S3存储桶中。公司的DevOps团队注意到某些日志处理和摄取过程中存在高延迟。哪些步骤组合将减少延迟？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 创建一个具有增强扇出功能的数据流消费者，将处理日志的Lambda函数设置为消费者</div> <div class="option-analysis"><strong>B.</strong> 增加Lambda事件源映射中的ParallelizationFactor设置</div> <div class="option-analysis"><strong>C.</strong> 为处理日志的Lambda函数配置预留并发</div> <div class="option-analysis"><strong>D.</strong> 增加Kinesis数据流中的批处理大小</div> <div class="option-analysis"><strong>E.</strong> 关闭Lambda事件源映射中的ReportBatchItemFailures设置 F. 增加Kinesis数据流中的分片数量<div class="section-title"><strong>核心要求:</strong></div> 减少Kinesis数据流处理日志时的高延迟问题 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• Amazon Kinesis Data Streams - 实时数据流处理服务，支持增强扇出和并行处理 </div><div class="compact-content">• <span class="key-service">AWS Lambda</span> - 无服务器计算服务，可配置事件源映射参数优化性能 <div class="section-title"><strong>正确答案AB:</strong></div> A选项通过增强扇出提供专用连接减少延迟；B选项通过并行处理多个批次提高吞吐量和减少处理时间 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项C - 预留并发主要解决冷启动问题，不直接解决数据处理延迟 </div><div class="compact-content">• 选项D - 增加批处理大小会增加单批处理时间，可能加剧延迟 </div><div class="compact-content">• 选项E - 关闭错误报告不会改善性能，反而影响错误处理 </div><div class="compact-content">• 选项F - 增加分片数量需要多个消费者才能发挥作用，单消费者无法利用 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能 - 选择能直接减少数据传输和处理延迟的方案 </div><div class="compact-content">• 成本 - 优先考虑配置优化而非资源扩容 </div><div class="compact-content">• 可扩展性 - 选择能提高并行处理能力的解决方案</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: AB (A、B)</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-218">
            <div class="question-header">
                <div class="question-title">Question #218 ✅ ⚪ <small style="float: right;">(218/353)</small></div>
            </div>
            <div class="question-content">A company operates sensitive workloads across the AWS accounts that are in the company's organization in <span class="key-service">AWS Organizations</span>. The company uses an IP address range to delegate IP addresses for <span class="key-service">Amazon <span class="key-service">VPC</span></span> CIDR blocks and all non-cloud hardware. The company needs a solution that prevents principals that are outside the company's IP address range from performing AWS actions in the organization's accounts. Which solution will meet these requirements? B (100%)</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Configure AWS Firewall Manager for the organization. Create an AWS Network Firewall policy that allows only source traffic from the company's IP address range. Set the policy scope to all accounts in the organization.</div>                <div class="option correct-answer"><strong>B.</strong> In Organizations, create an <span class="key-service">SCP</span> that denies source IP addresses that are outside of the company's IP address range. Attach the <span class="key-service">SCP</span> to the organization's root.</div>                <div class="option"><strong>C.</strong> Configure <span class="key-service">Amazon GuardDuty</span> for the organization. Create a GuardDuty trusted IP address list for the company's IP range. Activate the trusted IP list for the organization.</div>                <div class="option"><strong>D.</strong> In Organizations, create an <span class="key-service">SCP</span> that allows source IP addresses that are inside of the company's IP address range. Attach the <span class="key-service">SCP</span> to the organization's root.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司在AWS Organizations组织中的AWS账户上运行敏感工作负载。公司使用IP地址范围为Amazon <span class="key-service">VPC</span> CIDR块和所有非云硬件分配IP地址。公司需要一个解决方案，防止公司IP地址范围之外的主体在组织账户中执行AWS操作。 <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 为组织配置AWS Firewall Manager，创建只允许来自公司IP地址范围源流量的AWS Network Firewall策略，将策略范围设置为组织中的所有账户。</div> <div class="option-analysis"><strong>B.</strong> 在Organizations中创建拒绝公司IP地址范围之外源IP地址的SCP，将SCP附加到组织的根。</div> <div class="option-analysis"><strong>C.</strong> 为组织配置Amazon GuardDuty，为公司IP范围创建GuardDuty可信IP地址列表，为组织激活可信IP列表。</div> <div class="option-analysis"><strong>D.</strong> 在Organizations中创建允许公司IP地址范围内源IP地址的SCP，将SCP附加到组织的根。<div class="section-title"><strong>核心要求:</strong></div> 防止组织外部IP地址的主体执行AWS操作 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• <span class="key-service">AWS Organizations</span> - 集中管理多个AWS账户的服务 </div><div class="compact-content">• <span class="key-service">SCP</span> (Service Control Policy) - 控制组织中账户可执行操作的权限边界策略 <div class="section-title"><strong>正确答案B:</strong></div> 使用SCP的Deny策略明确拒绝来自公司IP范围外的源IP地址访问，通过附加到组织根实现对所有账户的统一控制 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A - AWS Firewall Manager主要用于网络流量过滤，无法控制AWS API调用的源IP限制 </div><div class="compact-content">• 选项C - GuardDuty是威胁检测服务，可信IP列表用于减少误报，不能阻止访问 </div><div class="compact-content">• 选项D - Allow策略无法有效阻止未明确允许的IP，需要配合隐式拒绝才能生效 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能 - SCP在API级别控制，响应迅速无延迟 </div><div class="compact-content">• 成本 - SCP无额外费用，比防火墙服务更经济 </div><div class="compact-content">• 可扩展性 - 组织根级别策略自动应用于所有现有和新增账户</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: B</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-219">
            <div class="question-header">
                <div class="question-title">Question #219 ✅ 📝 <small style="float: right;">(219/353)</small></div>
            </div>
            <div class="question-content">A company deploys an application in two AWS Regions. The application currently uses an <span class="key-service">Amazon S3</span> bucket in the primary Region to store data. A DevOps engineer needs to ensure that the application is highly available in both Regions. The DevOps engineer has created a new S3 bucket in the secondary Region. All existing and new objects must be in both S3 buckets. The application must fail over between the Regions with no data loss. Which combination of steps will meet these requirements with the MOST operational efficiency? (Choose three.) ADF (59%) ACF (41%)</div>
            <div class="options-container">                <div class="option correct-answer"><strong>A.</strong> Create a new IAM role that allows the <span class="key-service">Amazon S3</span> and S3 Batch Operations service principals to assume the role that has the necessary permissions for S3 replication.</div>                <div class="option"><strong>B.</strong> Create a new IAM role that allows the AWS Batch service principal to assume the role that has the necessary permissions for S3 replication.</div>                <div class="option correct-answer"><strong>C.</strong> Create an S3 Cross-Region Replication (CRR) rule on the source S3 bucket. Configure the rule to use the IAM role for <span class="key-service">Amazon S3</span> to replicate to the target S3 bucket.</div>                <div class="option"><strong>D.</strong> Create a two-way replication rule on the source S3 bucket. Configure the rule to use the IAM role for <span class="key-service">Amazon S3</span> to replicate to the target S3 bucket.</div>                <div class="option"><strong>E.</strong> Create an AWS Batch job that has an <span class="key-service">AWS Fargate</span> orchestration type. Configure the job to use the IAM role for AWS Batch. Specify a Bash command to use the AWS CLI to synchronize the contents of the source S3 bucket and the target S3 bucket F. Create an operation in S3 Batch Operations to replicate the contents of the source S3 bucket to the target S3 bucket. Configure the operation to use the IAM role for <span class="key-service">Amazon S3</span>. Most Voted Most Voted</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司在两个AWS区域部署应用程序。应用程序当前使用主区域的Amazon S3存储桶存储数据。DevOps工程师需要确保应用程序在两个区域都高可用。工程师已在辅助区域创建了新的S3存储桶。所有现有和新对象都必须在两个S3存储桶中。应用程序必须在区域间故障转移且无数据丢失。哪种步骤组合能以最高运营效率满足要求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 创建新的IAM角色，允许Amazon S3和S3 Batch Operations服务主体代入该角色，该角色具有S3复制的必要权限。</div> <div class="option-analysis"><strong>B.</strong> 创建新的IAM角色，允许AWS Batch服务主体代入该角色，该角色具有S3复制的必要权限。</div> <div class="option-analysis"><strong>C.</strong> 在源S3存储桶上创建S3 Cross-Region Replication (CRR)规则。配置规则使用Amazon S3的IAM角色复制到目标S3存储桶。</div> <div class="option-analysis"><strong>D.</strong> 在源S3存储桶上创建双向复制规则。配置规则使用Amazon S3的IAM角色复制到目标S3存储桶。</div> <div class="option-analysis"><strong>E.</strong> 创建具有AWS Fargate编排类型的AWS Batch作业。配置作业使用AWS Batch的IAM角色。指定Bash命令使用AWS CLI同步源S3存储桶和目标S3存储桶的内容。 F. 在S3 Batch Operations中创建操作，将源S3存储桶内容复制到目标S3存储桶。配置操作使用Amazon S3的IAM角色。<div class="section-title"><strong>核心要求:</strong></div> 实现跨区域S3数据复制，确保高可用性和零数据丢失故障转移 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• S3 Cross-Region Replication - 自动跨区域复制S3对象 </div><div class="compact-content">• S3 Batch Operations - 批量处理现有S3对象的复制操作 </div><div class="compact-content">• IAM角色 - 为S3服务提供复制权限 <div class="section-title"><strong>正确答案AC:</strong></div> A创建支持S3和S3 Batch Operations的IAM角色，C配置CRR规则实现新对象自动复制，需要F进行现有对象的批量复制 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项B - AWS Batch服务主体不适用于S3复制场景 </div><div class="compact-content">• 选项D - S3不支持原生双向复制规则配置 </div><div class="compact-content">• 选项E - 使用AWS Batch和CLI同步效率低且复杂度高 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能 - CRR提供实时自动复制，延迟最低 </div><div class="compact-content">• 成本 - 原生S3服务比自定义批处理方案成本更优 </div><div class="compact-content">• 可扩展性 - S3 CRR和Batch Operations可自动扩展处理任意数据量</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: AC (A、C)</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-220">
            <div class="question-header">
                <div class="question-title">Question #220 ✅ 📝 <small style="float: right;">(220/353)</small></div>
            </div>
            <div class="question-content">A company uses an organization in <span class="key-service">AWS Organizations</span> to manage multiple AWS accounts. The company needs an automated process across all AWS accounts to isolate any compromised <span class="key-service">Amazon EC2</span> instances when the instances receive a specific tag. Which combination of steps will meet these requirements? (Choose two.) AE (67%) BC (33%)</div>
            <div class="options-container">                <div class="option correct-answer"><strong>A.</strong> Use <span class="key-service">AWS CloudFormation</span> StackSets to deploy the CloudFormation stacks in all AWS accounts.</div>                <div class="option"><strong>B.</strong> Create an <span class="key-service">SCP</span> that has a Deny statement for the ec2:* action with a condition of "aws:RequestTag/isolation": false.</div>                <div class="option"><strong>C.</strong> Attach the <span class="key-service">SCP</span> to the root of the organization.</div>                <div class="option"><strong>D.</strong> Create an <span class="key-service">AWS CloudFormation</span> template that creates an EC2 instance role that has no IAM policies attached. Configure the template to have a security group that has an explicit Deny rule on all traffic. Use the CloudFormation template to create an <span class="key-service">AWS Lambda</span> function that attaches the IAM role to instances. Configure the Lambda function to add a network ACL. Set up an Amazon EventBridge rule to invoke the Lambda function when a specific tag is applied to a compromised EC2 instance.</div>                <div class="option correct-answer"><strong>E.</strong> Create an <span class="key-service">AWS CloudFormation</span> template that creates an EC2 instance role that has no IAM policies attached. Configure the template to have a security group that has no inbound rules or outbound rules. Use the CloudFormation template to create an <span class="key-service">AWS Lambda</span> function that attaches the IAM role to instances. Configure the Lambda function to replace any existing security groups with the new security group. Set up an Amazon EventBridge rule to invoke the Lambda function when a specific tag is applied to a compromised EC2 instance.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司使用AWS Organizations中的组织来管理多个AWS账户。公司需要一个跨所有AWS账户的自动化流程，当EC2实例收到特定标签时隔离任何受损的Amazon EC2实例。哪种步骤组合将满足这些要求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 使用AWS CloudFormation StackSets在所有AWS账户中部署CloudFormation堆栈。</div> <div class="option-analysis"><strong>B.</strong> 创建一个SCP，对ec2:*操作有Deny语句，条件为"aws:RequestTag/isolation": false。</div> <div class="option-analysis"><strong>C.</strong> 将SCP附加到组织的根部。</div> <div class="option-analysis"><strong>D.</strong> 创建AWS CloudFormation模板，创建没有附加IAM策略的EC2实例角色。配置模板具有对所有流量有显式Deny规则的安全组。使用CloudFormation模板创建将IAM角色附加到实例的AWS Lambda函数。配置Lambda函数添加网络ACL。设置Amazon EventBridge规则在特定标签应用到受损EC2实例时调用Lambda函数。</div> <div class="option-analysis"><strong>E.</strong> 创建AWS CloudFormation模板，创建没有附加IAM策略的EC2实例角色。配置模板具有没有入站或出站规则的安全组。使用CloudFormation模板创建将IAM角色附加到实例的AWS Lambda函数。配置Lambda函数用新安全组替换任何现有安全组。设置Amazon EventBridge规则在特定标签应用到受损EC2实例时调用Lambda函数。<div class="section-title"><strong>核心要求:</strong></div> 跨多账户自动化隔离带特定标签的受损EC2实例 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• CloudFormation StackSets-跨多账户部署统一资源 </div><div class="compact-content">• EventBridge-监控标签变化触发自动化 </div><div class="compact-content">• Lambda-执行实例隔离操作 <div class="section-title"><strong>正确答案AE:</strong></div> A提供跨账户部署能力，E通过EventBridge监控标签变化并用Lambda替换安全组实现网络隔离 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项B-SCP用于权限控制而非实例隔离，且条件逻辑不符合隔离需求 </div><div class="compact-content">• 选项C-仅附加SCP无法实现实例隔离功能 </div><div class="compact-content">• 选项D-使用网络ACL而非安全组替换，隔离效果不如直接替换安全组 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-EventBridge实时触发，Lambda快速响应 </div><div class="compact-content">• 成本-无额外基础设施成本，按使用付费 </div><div class="compact-content">• 可扩展性-StackSets支持组织内所有账户统一部署</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: AE (A、E)</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-221">
            <div class="question-header">
                <div class="question-title">Question #221 ✅ ⚪ <small style="float: right;">(221/353)</small></div>
            </div>
            <div class="question-content">A company manages multiple AWS accounts by using <span class="key-service">AWS Organizations</span> with OUs for the different business divisions. The company is updating their corporate network to use new IP address ranges. The company has 10 <span class="key-service">Amazon S3</span> buckets in different AWS accounts. The S3 buckets store reports for the different divisions. The S3 bucket configurations allow only private corporate network IP addresses to access the S3 buckets. A DevOps engineer needs to change the range of IP addresses that have permission to access the contents of the S3 buckets. The DevOps engineer also needs to revoke the permissions of two OUs in the company. Which solution will meet these requirements? C (100%)</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Create a new <span class="key-service">SCP</span> that has two statements, one that allows access to the new range of IP addresses for all the S3 buckets and one that denies access to the old range of IP addresses for all the S3 buckets. Set a permissions boundary for the OrganizationAccountAccessRole role in the two OUs to deny access to the S3 buckets.</div>                <div class="option"><strong>B.</strong> Create a new <span class="key-service">SCP</span> that has a statement that allows only the new range of IP addresses to access the S3 buckets. Create another <span class="key-service">SCP</span> that denies access to the S3 buckets. Attach the second <span class="key-service">SCP</span> to the two OUs.</div>                <div class="option correct-answer"><strong>C.</strong> On all the S3 buckets, configure resource-based policies that allow only the new range of IP addresses to access the S3 buckets. Create a new <span class="key-service">SCP</span> that denies access to the S3 buckets. Attach the <span class="key-service">SCP</span> to the two OUs.</div>                <div class="option"><strong>D.</strong> On all the S3 buckets, configure resource-based policies that allow only the new range of IP addresses to access the S3 buckets. Set a permissions boundary for the OrganizationAccountAccessRole role in the two OUs to deny access to the S3 buckets.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司使用AWS Organizations和OU管理多个AWS账户。公司正在更新企业网络以使用新的IP地址范围。公司在不同AWS账户中有10个S3存储桶，存储各部门报告。S3存储桶配置仅允许私有企业网络IP地址访问。DevOps工程师需要更改有权访问S3存储桶内容的IP地址范围，并撤销两个OU的权限。 <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 创建新的SCP包含两个语句，一个允许所有S3存储桶的新IP地址范围访问，一个拒绝旧IP地址范围访问。为两个OU中的OrganizationAccountAccessRole角色设置权限边界以拒绝访问S3存储桶。</div> <div class="option-analysis"><strong>B.</strong> 创建新的SCP包含仅允许新IP地址范围访问S3存储桶的语句。创建另一个拒绝访问S3存储桶的SCP。将第二个SCP附加到两个OU。</div> <div class="option-analysis"><strong>C.</strong> 在所有S3存储桶上配置基于资源的策略，仅允许新IP地址范围访问S3存储桶。创建新的SCP拒绝访问S3存储桶。将SCP附加到两个OU。</div> <div class="option-analysis"><strong>D.</strong> 在所有S3存储桶上配置基于资源的策略，仅允许新IP地址范围访问S3存储桶。为两个OU中的OrganizationAccountAccessRole角色设置权限边界以拒绝访问S3存储桶。<div class="section-title"><strong>核心要求:</strong></div> 更新S3存储桶IP访问范围并撤销特定OU的访问权限 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• S3 Bucket Policy-控制基于IP的资源访问 </div><div class="compact-content">• <span class="key-service">SCP</span>-在组织级别限制账户权限 <div class="section-title"><strong>正确答案C:</strong></div> 使用S3资源策略精确控制IP访问范围，通过SCP在组织级别拒绝特定OU访问，实现双层安全控制 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A-SCP无法直接管理S3存储桶的IP访问控制，权限边界适用范围有限 </div><div class="compact-content">• 选项B-缺少S3存储桶级别的IP地址更新，仅依赖SCP无法实现IP范围控制 </div><div class="compact-content">• 选项D-权限边界仅影响特定角色，无法全面阻止OU级别的S3访问 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-资源策略提供最直接的访问控制 </div><div class="compact-content">• 成本-利用现有AWS服务无额外费用 </div><div class="compact-content">• 可扩展性-SCP可统一管理多个账户的访问权限</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: C</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-222">
            <div class="question-header">
                <div class="question-title">Question #222 ✅ ⚪ <small style="float: right;">(222/353)</small></div>
            </div>
            <div class="question-content">A company has started using AWS across several teams. Each team has multiple accounts and unique security profiles. The company manages the accounts in an organization in <span class="key-service">AWS Organizations</span>. Each account has its own configuration and security controls. The company's DevOps team wants to use preventive and detective controls to govern all accounts. The DevOps team needs to ensure the security of accounts now and in the future as the company creates new accounts in the organization. Which solution will meet these requirements? B (100%)</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Use Organizations to create OUs that have appropriate SCPs attached for each team. Place team accounts in the appropriate OUs to apply security controls. Create any new team accounts in the appropriate OUs.</div>                <div class="option correct-answer"><strong>B.</strong> Create an AWS Control Tower landing zone. Configure OUs and appropriate controls in AWS Control Tower for the existing teams. Configure trusted access for AWS Control Tower. Enroll the existing accounts in the appropriate OUs that match the appropriate security policies for each team. Use AWS Control Tower to provision any new accounts.</div>                <div class="option"><strong>C.</strong> Create <span class="key-service">AWS CloudFormation</span> stack sets in the organization's management account. Configure a stack set that deploys <span class="key-service">AWS Config</span> with configuration rules and remediation actions for all controls to each account in the organization. Update the stack sets to deploy to new accounts as the accounts are created.</div>                <div class="option"><strong>D.</strong> Configure <span class="key-service">AWS Config</span> to manage the <span class="key-service">AWS Config</span> rules across all AWS accounts in the organization. Deploy conformance packs that provide <span class="key-service">AWS Config</span> rules and remediation actions across the organization.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司开始在多个团队中使用AWS。每个团队有多个账户和独特的安全配置文件。公司在AWS Organizations中的组织里管理这些账户。每个账户都有自己的配置和安全控制。公司的DevOps团队希望使用预防性和检测性控制来治理所有账户。DevOps团队需要确保账户现在和未来的安全性，因为公司会在组织中创建新账户。哪个解决方案能满足这些要求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 使用Organizations创建附加了适当SCP的OU给每个团队。将团队账户放在适当的OU中以应用安全控制。在适当的OU中创建任何新的团队账户。</div> <div class="option-analysis"><strong>B.</strong> 创建AWS Control Tower着陆区。在AWS Control Tower中为现有团队配置OU和适当的控制。为AWS Control Tower配置可信访问。将现有账户注册到匹配每个团队适当安全策略的相应OU中。使用AWS Control Tower配置任何新账户。</div> <div class="option-analysis"><strong>C.</strong> 在组织的管理账户中创建AWS CloudFormation堆栈集。配置一个堆栈集，将AWS Config与配置规则和修复操作部署到组织中的每个账户。更新堆栈集以在创建新账户时部署到新账户。</div> <div class="option-analysis"><strong>D.</strong> 配置AWS Config来管理组织中所有AWS账户的AWS Config规则。部署在整个组织中提供AWS Config规则和修复操作的一致性包。<div class="section-title"><strong>核心要求:</strong></div> 为多团队多账户环境实现预防性和检测性安全治理，确保现有和未来账户的安全合规 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• AWS Control Tower-提供自动化的多账户治理和合规管理 </div><div class="compact-content">• <span class="key-service">AWS Organizations</span>-管理多账户结构和策略 </div><div class="compact-content">• <span class="key-service">SCP</span>-实现预防性控制 </div><div class="compact-content">• <span class="key-service">AWS Config</span>-提供检测性控制和合规监控 <div class="section-title"><strong>正确答案B:</strong></div> AWS Control Tower提供完整的着陆区解决方案，集成预防性控制(<span class="key-service">SCP</span>)和检测性控制(Config规则)，自动化账户配置和持续合规监控，支持现有账户注册和新账户自动治理 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A-仅提供预防性控制(<span class="key-service">SCP</span>)，缺乏检测性控制和自动化合规监控 </div><div class="compact-content">• 选项C-需要手动管理CloudFormation堆栈集，缺乏统一治理框架和预防性控制 </div><div class="compact-content">• 选项D-仅提供检测性控制，缺乏预防性控制和完整的治理框架 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-Control Tower提供自动化治理，减少手动操作 </div><div class="compact-content">• 成本-集成解决方案降低管理复杂性和运维成本 </div><div class="compact-content">• 可扩展性-自动支持新账户创建和治理策略应用</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: B</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-223">
            <div class="question-header">
                <div class="question-title">Question #223 ✅ ⚪ <small style="float: right;">(223/353)</small></div>
            </div>
            <div class="question-content">A company uses an <span class="key-service">AWS CodeCommit</span> repository to store its source code and corresponding unit tests. The company has configured an <span class="key-service">AWS CodePipeline</span> pipeline that includes an <span class="key-service">AWS CodeBuild</span> project that runs when code is merged to the main branch of the repository. The company wants the CodeBuild project to run the unit tests. If the unit tests pass, the CodeBuild project must tag the most recent commit. How should the company configure the CodeBuild project to meet these requirements? A (100%)</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Configure the CodeBuild project to use native Git to clone the CodeCommit repository. Configure the project to run the unit tests. Configure the project to use native Git to create a tag and to push the Git tag to the repository if the code passes the unit tests.</div>                <div class="option"><strong>B.</strong> Configure the CodeBuild project to use native Git to clone the CodeCommit repository. Configure the project to run the unit tests. Configure the project to use AWS CLI commands to create a new repository tag in the repository if the code passes the unit tests.</div>                <div class="option correct-answer"><strong>C.</strong> Configure the CodeBuild project to use AWS CLI commands to copy the code from the CodeCommit repository. Configure the project to run the unit tests. Configure the project to use AWS CLI commands to create a new Git tag in the repository if the code passes the unit tests.</div>                <div class="option"><strong>D.</strong> Configure the CodeBuild project to use AWS CLI commands to copy the code from the CodeCommit repository. Configure the project to run the unit tests. Configure the project to use AWS CLI commands to create a new repository tag in the repository if the code passes the unit tests.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司使用AWS CodeCommit存储库来存储源代码和相应的单元测试。公司配置了AWS CodePipeline管道，包含一个AWS CodeBuild项目，当代码合并到存储库主分支时运行。公司希望CodeBuild项目运行单元测试，如果单元测试通过，CodeBuild项目必须标记最新提交。公司应该如何配置CodeBuild项目来满足这些要求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 配置CodeBuild项目使用原生Git克隆CodeCommit存储库，配置项目运行单元测试，配置项目使用原生Git创建标签并在代码通过单元测试时将Git标签推送到存储库</div> <div class="option-analysis"><strong>B.</strong> 配置CodeBuild项目使用原生Git克隆CodeCommit存储库，配置项目运行单元测试，配置项目使用AWS CLI命令在代码通过单元测试时在存储库中创建新的存储库标签</div> <div class="option-analysis"><strong>C.</strong> 配置CodeBuild项目使用AWS CLI命令从CodeCommit存储库复制代码，配置项目运行单元测试，配置项目使用AWS CLI命令在代码通过单元测试时在存储库中创建新的Git标签</div> <div class="option-analysis"><strong>D.</strong> 配置CodeBuild项目使用AWS CLI命令从CodeCommit存储库复制代码，配置项目运行单元测试，配置项目使用AWS CLI命令在代码通过单元测试时在存储库中创建新的存储库标签<div class="section-title"><strong>核心要求:</strong></div> 在CodeBuild中运行单元测试并在测试通过时标记最新提交 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• <span class="key-service">AWS CodeBuild</span>-执行构建和测试任务的托管服务 </div><div class="compact-content">• <span class="key-service">AWS CodeCommit</span>-托管的Git存储库服务 <div class="section-title"><strong>正确答案C:</strong></div> 使用AWS CLI获取代码并创建Git标签，这是在CodeBuild环境中与CodeCommit交互的标准方式，Git标签是版本控制中标记特定提交的正确机制 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A-在CodeBuild环境中使用原生Git推送操作可能遇到权限和认证问题 </div><div class="compact-content">• 选项B-"存储库标签"不是Git的标准概念，应该使用Git标签 </div><div class="compact-content">• 选项D-"存储库标签"概念错误，Git中应使用Git标签来标记提交 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-AWS CLI与CodeCommit集成更高效 </div><div class="compact-content">• 成本-使用托管服务减少维护成本 </div><div class="compact-content">• 可扩展性-AWS CLI方式更适合自动化流水线</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: C</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-224">
            <div class="question-header">
                <div class="question-title">Question #224 ✅ ⚪ <small style="float: right;">(224/353)</small></div>
            </div>
            <div class="question-content">A DevOps engineer manages a company's Amazon Elastic Container Service (<span class="key-service">Amazon ECS</span>) cluster. The cluster runs on several <span class="key-service">Amazon EC2</span> instances that are in an Auto Scaling group. The DevOps engineer must implement a solution that logs and reviews all stopped tasks for errors. Which solution will meet these requirements? A (83%) C (17%)</div>
            <div class="options-container">                <div class="option correct-answer"><strong>A.</strong> Create an Amazon EventBridge rule to capture task state changes. Send the event to <span class="key-service">Amazon CloudWatch</span> Logs. Use CloudWatch Logs Insights to investigate stopped tasks.</div>                <div class="option"><strong>B.</strong> Configure tasks to write log data in the embedded metric format. Store the logs in <span class="key-service">Amazon CloudWatch</span> Logs. Monitor the ContainerInstanceCount metric for changes.</div>                <div class="option"><strong>C.</strong> Configure the EC2 instances to store logs in <span class="key-service">Amazon CloudWatch</span> Logs. Create a CloudWatch Contributor Insights rule that uses the EC2 instance log data. Use the Contributor Insights rule to investigate stopped tasks.</div>                <div class="option"><strong>D.</strong> Configure an EC2 Auto Scaling lifecycle hook for the EC2_INSTANCE_TERMINATING scale-in event. Write the SystemEventLog file to <span class="key-service">Amazon S3</span>. Use Amazon Athena to query the log file for errors.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一名DevOps工程师管理公司的Amazon ECS集群。该集群运行在Auto Scaling组中的多个EC2实例上。DevOps工程师必须实现一个解决方案来记录和审查所有停止的任务以查找错误。 <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 创建Amazon EventBridge规则来捕获任务状态变化。将事件发送到CloudWatch Logs。使用CloudWatch Logs Insights调查停止的任务。</div> <div class="option-analysis"><strong>B.</strong> 配置任务以嵌入式指标格式写入日志数据。将日志存储在CloudWatch Logs中。监控ContainerInstanceCount指标的变化。</div> <div class="option-analysis"><strong>C.</strong> 配置EC2实例将日志存储在CloudWatch Logs中。创建使用EC2实例日志数据的CloudWatch Contributor Insights规则。使用该规则调查停止的任务。</div> <div class="option-analysis"><strong>D.</strong> 为EC2_INSTANCE_TERMINATING缩容事件配置EC2 Auto Scaling生命周期钩子。将SystemEventLog文件写入S3。使用Athena查询日志文件中的错误。<div class="section-title"><strong>核心要求:</strong></div> 监控和记录ECS任务停止事件并进行错误分析 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• EventBridge-捕获ECS任务状态变化事件 </div><div class="compact-content">• CloudWatch Logs Insights-查询和分析日志数据 <div class="section-title"><strong>正确答案A:</strong></div> EventBridge规则可以精确捕获ECS任务状态变化事件，结合CloudWatch Logs存储和Logs Insights查询功能，提供完整的任务停止监控和错误分析解决方案 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项B-嵌入式指标格式和ContainerInstanceCount指标无法直接捕获任务停止事件 </div><div class="compact-content">• 选项C-EC2实例级别日志无法提供ECS任务级别的详细停止信息 </div><div class="compact-content">• 选项D-Auto Scaling生命周期钩子关注实例终止而非ECS任务停止 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-EventBridge实时事件捕获，Logs Insights快速查询 </div><div class="compact-content">• 成本-基于事件的计费模式，按实际使用付费 </div><div class="compact-content">• 可扩展性-自动处理任意数量的ECS任务状态变化事件</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: A</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-225">
            <div class="question-header">
                <div class="question-title">Question #225 ✅ 📝 <small style="float: right;">(225/353)</small></div>
            </div>
            <div class="question-content">A company wants to deploy a workload on several hundred <span class="key-service">Amazon EC2</span> instances. The company will provision the EC2 instances in an Auto Scaling group by using a launch template. The workload will pull files from an <span class="key-service">Amazon S3</span> bucket, process the data, and put the results into a different S3 bucket. The EC2 instances must have least-privilege permissions and must use temporary security credentials. Which combination of steps will meet these requirements? (Choose two.) AB (100%)</div>
            <div class="options-container">                <div class="option correct-answer"><strong>A.</strong> Create an IAM role that has the appropriate permissions for S3 buckets. Add the IAM role to an instance profile.</div>                <div class="option correct-answer"><strong>B.</strong> Update the launch template to include the IAM instance profile.</div>                <div class="option"><strong>C.</strong> Create an IAM user that has the appropriate permissions for <span class="key-service">Amazon S3</span>. Generate a secret key and token.</div>                <div class="option"><strong>D.</strong> Create a trust anchor and profile. Attach the IAM role to the profile.</div>                <div class="option"><strong>E.</strong> Update the launch template. Modify the user data to use the new secret key and token.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司想要在数百个Amazon EC2实例上部署工作负载。公司将使用launch template在Auto Scaling组中配置EC2实例。工作负载将从Amazon S3存储桶拉取文件，处理数据，并将结果放入不同的S3存储桶。EC2实例必须具有最小权限并且必须使用临时安全凭证。哪些步骤组合将满足这些要求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 创建一个具有S3存储桶适当权限的IAM角色，将IAM角色添加到实例配置文件中</div> <div class="option-analysis"><strong>B.</strong> 更新launch template以包含IAM实例配置文件</div> <div class="option-analysis"><strong>C.</strong> 创建一个具有Amazon S3适当权限的IAM用户，生成密钥和令牌</div> <div class="option-analysis"><strong>D.</strong> 创建信任锚点和配置文件，将IAM角色附加到配置文件</div> <div class="option-analysis"><strong>E.</strong> 更新launch template，修改用户数据以使用新的密钥和令牌<div class="section-title"><strong>核心要求:</strong></div> 为Auto Scaling组中的EC2实例提供最小权限的临时安全凭证访问S3 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• IAM Role-为EC2实例提供临时安全凭证和最小权限 </div><div class="compact-content">• Instance Profile-将IAM角色与EC2实例关联的容器 </div><div class="compact-content">• Launch Template-定义Auto Scaling组中EC2实例的配置 <div class="section-title"><strong>正确答案AB:</strong></div> 通过创建IAM角色并添加到实例配置文件，然后在launch template中指定该配置文件，实现EC2实例自动获取临时凭证访问S3 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项C-IAM用户使用长期凭证，不符合临时安全凭证要求 </div><div class="compact-content">• 选项D-信任锚点用于IAM Roles Anywhere服务，不适用于EC2实例 </div><div class="compact-content">• 选项E-在用户数据中硬编码凭证违反安全最佳实践 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 安全性-使用临时凭证和最小权限原则 </div><div class="compact-content">• 自动化-通过launch template实现配置标准化 </div><div class="compact-content">• 可扩展性-支持数百个实例的Auto Scaling部署</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: AB (A、B)</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-226">
            <div class="question-header">
                <div class="question-title">Question #226 ✅ ⚪ <small style="float: right;">(226/353)</small></div>
            </div>
            <div class="question-content">A company is using <span class="key-service">AWS CodeDeploy</span> to automate software deployment. The deployment must meet these requirements: <div class="compact-content">• A number of instances must be available to serve traffic during the deployment. Traffic must be balanced across those instances, and the instances must automatically heal in the event of failure. </div><div class="compact-content">• A new fleet of instances must be launched for deploying a new revision automatically, with no manual provisioning. </div><div class="compact-content">• Traffic must be rerouted to the new environment to half of the new instances at a time. The deployment should succeed if traffic is rerouted to at least half of the instances; otherwise, it should fail. </div><div class="compact-content">• Before routing traffic to the new fleet of instances, the temporary files generated during the deployment process must be deleted. </div><div class="compact-content">• At the end of a successful deployment, the original instances in the deployment group must be deleted immediately to reduce costs. How can a DevOps engineer meet these requirements? C (100%)</div></div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Use an Application Load Balancer and an in-place deployment. Associate the Auto Scaling group with the deployment group. Use the Automatically copy Auto Scaling group option, and use CodeDeployDefault.OneAtATime as the deployment configuration. Instruct <span class="key-service">AWS CodeDeploy</span> to terminate the original instances in the deployment group, and use the AllowTraffic hook within appspec.yml to delete the temporary files.</div>                <div class="option correct-answer"><strong>B.</strong> Use an Application Load Balancer and a blue/green deployment. Associate the Auto Scaling group and Application Load Balancer target group with the deployment group. Use the Automatically copy Auto Scaling group option, create a custom deployment configuration with minimum healthy hosts defined as 50%, and assign the configuration to the deployment group. Instruct <span class="key-service">AWS CodeDeploy</span> to terminate the original instances in the deployment group, and use the BeforeBlockTraffic hook within appspec.yml to delete the temporary files.</div>                <div class="option"><strong>C.</strong> Use an Application Load Balancer and a blue/green deployment. Associate the Auto Scaling group and the Application Load Balancer target group with the deployment group. Use the Automatically copy Auto Scaling group option, and use CodeDeployDefault.HalfAtATime as the deployment configuration. Instruct <span class="key-service">AWS CodeDeploy</span> to terminate the original instances in the deployment group, and use the BeforeAllowTraffic hook within appspec.yml to delete the temporary files.</div>                <div class="option"><strong>D.</strong> Use an Application Load Balancer and an in-place deployment. Associate the Auto Scaling group and Application Load Balancer target group with the deployment group. Use the Automatically copy Auto Scaling group option, and use CodeDeployDefault.AllAtOnce as a deployment configuration. Instruct <span class="key-service">AWS CodeDeploy</span> to terminate the original instances in the deployment group, and use the BlockTraffic hook within appspec.yml to delete the temporary files.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司使用AWS CodeDeploy自动化软件部署，需要满足：部署期间保持实例可用并负载均衡和自动修复；自动启动新实例群组部署新版本；流量分批路由到新环境的一半实例，至少一半成功才算部署成功；路由流量前删除临时文件；成功部署后立即删除原实例以降低成本。 <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 使用Application Load Balancer和就地部署，关联Auto Scaling group到部署组，使用自动复制Auto Scaling group选项和CodeDeployDefault.OneAtATime部署配置，指示CodeDeploy终止原实例，使用appspec.yml中的AllowTraffic钩子删除临时文件。</div> <div class="option-analysis"><strong>B.</strong> 使用Application Load Balancer和蓝绿部署，关联Auto Scaling group和ALB目标组到部署组，使用自动复制Auto Scaling group选项，创建最小健康主机50%的自定义部署配置，指示CodeDeploy终止原实例，使用appspec.yml中的BeforeBlockTraffic钩子删除临时文件。</div> <div class="option-analysis"><strong>C.</strong> 使用Application Load Balancer和蓝绿部署，关联Auto Scaling group和ALB目标组到部署组，使用自动复制Auto Scaling group选项和CodeDeployDefault.HalfAtATime部署配置，指示CodeDeploy终止原实例，使用appspec.yml中的BeforeAllowTraffic钩子删除临时文件。</div> <div class="option-analysis"><strong>D.</strong> 使用Application Load Balancer和就地部署，关联Auto Scaling group和ALB目标组到部署组，使用自动复制Auto Scaling group选项和CodeDeployDefault.AllAtOnce部署配置，指示CodeDeploy终止原实例，使用appspec.yml中的BlockTraffic钩子删除临时文件。<div class="section-title"><strong>核心要求:</strong></div> 实现蓝绿部署，分批路由流量到新实例，至少50%成功率，部署前清理临时文件 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• <span class="key-service">AWS CodeDeploy</span>-自动化部署服务，支持蓝绿和就地部署策略 </div><div class="compact-content">• Application Load Balancer-提供流量分发和健康检查功能 </div><div class="compact-content">• Auto Scaling Group-自动管理实例生命周期和扩缩容 <div class="section-title"><strong>正确答案B:</strong></div> 蓝绿部署创建新实例群组，自定义配置确保50%最小健康主机满足成功标准，BeforeBlockTraffic钩子在流量切换前执行清理操作 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A-使用就地部署无法创建新实例群组，OneAtATime配置不符合分批要求 </div><div class="compact-content">• 选项C-BeforeAllowTraffic钩子时机错误，应在阻断流量前而非允许流量前清理 </div><div class="compact-content">• 选项D-就地部署和AllAtOnce配置都不符合要求，BlockTraffic钩子用途错误 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-蓝绿部署确保零停机时间和快速回滚能力 </div><div class="compact-content">• 成本-自动终止原实例避免资源浪费，50%成功率平衡风险和效率 </div><div class="compact-content">• 可扩展性-Auto Scaling Group自动复制选项支持动态扩容需求</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: B</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-227">
            <div class="question-header">
                <div class="question-title">Question #227 ✅ ⚪ <small style="float: right;">(227/353)</small></div>
            </div>
            <div class="question-content">A company needs to adopt a multi-account strategy to deploy its applications and the associated CI/CD infrastructure. The company has created an organization in <span class="key-service">AWS Organizations</span> that has all features enabled. The company has configured AWS Control Tower and has set up a landing zone. The company needs to use AWS Control Tower controls (guardrails) in all AWS accounts in the organization. The company must create the accounts for a multi-environment application and must ensure that all accounts are configured to an initial baseline. Which solution will meet these requirements with the LEAST operational overhead? A (100%)</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Create an AWS Control Tower Account Factory Customization (AFC) blueprint that uses the baseline configuration. Use AWS Control Tower Account Factory to provision a dedicated AWS account for each environment and a CI/CD account by using the blueprint.</div>                <div class="option correct-answer"><strong>B.</strong> Use AWS Control Tower Account Factory to provision a dedicated AWS account for each environment and a CI/CD account. Use <span class="key-service">AWS CloudFormation</span> StackSets to apply the baseline configuration to the new accounts.</div>                <div class="option"><strong>C.</strong> Use Organizations to provision a multi-environment AWS account and a CI/CD account. In the Organizations management account, create an <span class="key-service">AWS Lambda</span> function that assumes the Organizations access role to apply the baseline configuration to the new accounts.</div>                <div class="option"><strong>D.</strong> Use Organizations to provision a dedicated AWS account for each environment, an audit account, and a CI/CD account. Use <span class="key-service">AWS CloudFormation</span> StackSets to apply the baseline configuration to the new accounts.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司需要采用多账户策略来部署应用程序和相关的CI/CD基础设施。公司已在AWS Organizations中创建了启用所有功能的组织，配置了AWS Control Tower并设置了landing zone。公司需要在组织中的所有AWS账户使用AWS Control Tower控制措施(guardrails)，必须为多环境应用程序创建账户并确保所有账户都配置为初始基线。 <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 创建使用基线配置的AWS Control Tower Account Factory Customization (AFC) blueprint，使用AWS Control Tower Account Factory通过blueprint为每个环境和CI/CD账户配置专用AWS账户。</div> <div class="option-analysis"><strong>B.</strong> 使用AWS Control Tower Account Factory为每个环境和CI/CD账户配置专用AWS账户，使用AWS CloudFormation StackSets将基线配置应用到新账户。</div> <div class="option-analysis"><strong>C.</strong> 使用Organizations配置多环境AWS账户和CI/CD账户，在Organizations管理账户中创建AWS Lambda函数，该函数承担Organizations访问角色将基线配置应用到新账户。</div> <div class="option-analysis"><strong>D.</strong> 使用Organizations为每个环境、审计账户和CI/CD账户配置专用AWS账户，使用AWS CloudFormation StackSets将基线配置应用到新账户。<div class="section-title"><strong>核心要求:</strong></div> 在AWS Control Tower环境中创建多账户架构并应用统一基线配置，实现最少运维开销 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• AWS Control Tower - 提供多账户治理和guardrails控制 </div><div class="compact-content">• Account Factory - 自动化账户创建和配置 </div><div class="compact-content">• CloudFormation StackSets - 跨账户批量部署资源 <div class="section-title"><strong>正确答案B:</strong></div> 使用Control Tower Account Factory创建账户确保自动应用guardrails，结合CloudFormation StackSets实现标准化基线配置部署，运维开销最小 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A - AFC blueprint增加了不必要的复杂性和开发工作量 </div><div class="compact-content">• 选项C - 直接使用Organizations绕过了Control Tower的自动化优势，需要自定义Lambda开发 </div><div class="compact-content">• 选项D - 直接使用Organizations无法自动应用Control Tower的guardrails控制 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能 - Account Factory提供自动化账户配置和guardrails应用 </div><div class="compact-content">• 成本 - 避免自定义开发，使用原生服务降低维护成本 </div><div class="compact-content">• 可扩展性 - StackSets支持大规模跨账户配置管理</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: B</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-228">
            <div class="question-header">
                <div class="question-title">Question #228 ✅ ⚪ <small style="float: right;">(228/353)</small></div>
            </div>
            <div class="question-content">A DevOps team has created a Custom Lambda rule in <span class="key-service">AWS Config</span>. The rule monitors Amazon Elastic Container Repository (<span class="key-service">Amazon ECR</span>) policy statements for ecr:* actions. When a noncompliant repository is detected, Amazon EventBridge uses Amazon Simple Notification Service (<span class="key-service">Amazon SNS</span>) to route the notification to a security team. When the custom <span class="key-service">AWS Config</span> rule is evaluated, the <span class="key-service">AWS Lambda</span> function fails to run. Which solution will resolve the issue? A (100%)</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Modify the Lambda function's resource policy to grant <span class="key-service">AWS Config</span> permission to invoke the function.</div>                <div class="option"><strong>B.</strong> Modify the SNS topic policy to include configuration changes for EventBridge to publish to the SNS topic.</div>                <div class="option correct-answer"><strong>C.</strong> Modify the Lambda function's execution role to include configuration changes for custom <span class="key-service">AWS Config</span> rules.</div>                <div class="option"><strong>D.</strong> Modify all the ECR repository policies to grant <span class="key-service">AWS Config</span> access to the necessary ECR API actions.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一个DevOps团队在AWS Config中创建了自定义Lambda规则，该规则监控Amazon ECR策略语句中的ecr:*操作。当检测到不合规的存储库时，Amazon EventBridge使用Amazon SNS将通知路由到安全团队。当评估自定义AWS Config规则时，Lambda函数运行失败。哪个解决方案能解决这个问题？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 修改Lambda函数的资源策略，授予AWS Config调用该函数的权限。</div> <div class="option-analysis"><strong>B.</strong> 修改SNS主题策略，包含EventBridge发布到SNS主题的配置更改。</div> <div class="option-analysis"><strong>C.</strong> 修改Lambda函数的执行角色，包含自定义AWS Config规则的配置更改。</div> <div class="option-analysis"><strong>D.</strong> 修改所有ECR存储库策略，授予AWS Config访问必要ECR API操作的权限。<div class="section-title"><strong>核心要求:</strong></div> 解决自定义AWS Config规则中Lambda函数执行失败的问题 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• <span class="key-service">AWS Config</span> - 监控资源合规性的服务 </div><div class="compact-content">• Lambda - 执行自定义Config规则逻辑的计算服务 </div><div class="compact-content">• <span class="key-service">Amazon ECR</span> - 容器镜像存储库服务 <div class="section-title"><strong>正确答案C:</strong></div> Lambda函数需要执行角色具备访问ECR API和Config服务的权限才能成功评估ECR策略合规性 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A - 资源策略控制谁能调用函数，但Config已能调用，问题在于函数执行权限不足 </div><div class="compact-content">• 选项B - SNS策略问题不会导致Lambda函数执行失败，只影响通知发送 </div><div class="compact-content">• 选项D - ECR策略修改不现实且不必要，应通过Lambda执行角色获取权限 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能 - 执行角色权限配置直接影响函数运行成功率 </div><div class="compact-content">• 成本 - 角色权限调整无额外成本，比修改多个ECR策略更经济 </div><div class="compact-content">• 可扩展性 - 统一的执行角色权限便于管理和扩展到更多ECR存储库</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: C</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-229">
            <div class="question-header">
                <div class="question-title">Question #229 ✅ ⚪ <small style="float: right;">(229/353)</small></div>
            </div>
            <div class="question-content">A developer is creating a proof of concept for a new software as a service (SaaS) application. The application is in a shared development AWS account that is part of an organization in <span class="key-service">AWS Organizations</span>. The developer needs to create service-linked IAM roles for the AWS services that are being considered for the proof of concept. The solution needs to give the developer the ability to create and configure the service-linked roles only. Which solution will meet these requirements? D (100%)</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Create an IAM user for the developer in the organization's management account. Configure a cross-account role in the development account for the developer to use. Limit the scope of the cross-account role to common services.</div>                <div class="option"><strong>B.</strong> Add the developer to an IAM group. Attach the PowerUserAccess managed policy to the IAM group. Enforce multi-factor authentication (MFA) on the user account.</div>                <div class="option"><strong>C.</strong> Add an <span class="key-service">SCP</span> to the development account in Organizations. Configure the <span class="key-service">SCP</span> with a Deny rule for iam:* to limit the developer's access.</div>                <div class="option correct-answer"><strong>D.</strong> Create an IAM role that has the necessary IAM access to allow the developer to create policies and roles. Create and attach a permissions boundary to the role. Grant the developer access to assume the role.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 开发人员正在为新的软件即服务(SaaS)应用程序创建概念验证。该应用程序位于AWS Organizations组织中的共享开发AWS账户中。开发人员需要为概念验证考虑的AWS服务创建service-linked IAM角色。解决方案需要仅给予开发人员创建和配置service-linked角色的能力。 <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 在组织的管理账户中为开发人员创建IAM用户，在开发账户中配置跨账户角色供开发人员使用，将跨账户角色的范围限制为通用服务。</div> <div class="option-analysis"><strong>B.</strong> 将开发人员添加到IAM组，为IAM组附加PowerUserAccess托管策略，在用户账户上强制执行多因素身份验证(MFA)。</div> <div class="option-analysis"><strong>C.</strong> 为Organizations中的开发账户添加SCP，使用iam:*的拒绝规则配置SCP以限制开发人员的访问权限。</div> <div class="option-analysis"><strong>D.</strong> 创建具有必要IAM访问权限的IAM角色以允许开发人员创建策略和角色，创建并附加权限边界到角色，授予开发人员假设角色的访问权限。<div class="section-title"><strong>核心要求:</strong></div> 仅允许开发人员创建和配置service-linked IAM角色的最小权限访问 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• IAM - 身份和访问管理，控制AWS资源访问权限 </div><div class="compact-content">• <span class="key-service">AWS Organizations</span> - 集中管理多个AWS账户的服务 </div><div class="compact-content">• Service-linked roles - AWS服务自动创建和管理的特殊IAM角色 <div class="section-title"><strong>正确答案D:</strong></div> 通过IAM角色结合权限边界(permissions boundary)实现精确的权限控制，既允许创建service-linked角色又防止权限升级 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A - 跨账户角色增加复杂性且无法精确控制service-linked角色权限 </div><div class="compact-content">• 选项B - PowerUserAccess权限过于宽泛，违反最小权限原则 </div><div class="compact-content">• 选项C - SCP拒绝iam:*会阻止创建service-linked角色，与需求相反 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 安全性 - 权限边界确保最小权限原则和防止权限升级 </div><div class="compact-content">• 简洁性 - 单账户内角色管理比跨账户方案更简单 </div><div class="compact-content">• 精确性 - 仅授予创建service-linked角色的必要权限</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: D</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-230">
            <div class="question-header">
                <div class="question-title">Question #230 ✅ 📝 <small style="float: right;">(230/353)</small></div>
            </div>
            <div class="question-content">A company uses <span class="key-service">AWS Organizations</span> to manage its AWS accounts. The company wants its monitoring system to receive an alert when a root user logs in. The company also needs a dashboard to display any log activity that the root user generates. Which combination of steps will meet these requirements? (Choose three.) CEF (100%)</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Enable <span class="key-service">AWS Config</span> with a multi-account aggregator. Configure log forwarding to <span class="key-service">Amazon CloudWatch</span> Logs.</div>                <div class="option correct-answer"><strong>B.</strong> Create an Amazon QuickSight dashboard that uses an <span class="key-service">Amazon CloudWatch</span> Logs query.</div>                <div class="option correct-answer"><strong>C.</strong> Create an <span class="key-service">Amazon CloudWatch</span> Logs metric filter to match root user login events. Configure a CloudWatch alarm and an Amazon Simple Notification Service (<span class="key-service">Amazon SNS</span>) topic to send alerts to the company's monitoring system.</div>                <div class="option correct-answer"><strong>D.</strong> Create an <span class="key-service">Amazon CloudWatch</span> Logs subscription filter to match root user login events. Configure the filter to forward events to an Amazon Simple Notification Service (<span class="key-service">Amazon SNS</span>) topic. Configure the SNS topic to send alerts to the company's monitoring system.</div>                <div class="option"><strong>E.</strong> Create an <span class="key-service">AWS CloudTrail</span> organization trail. Configure the organization trail to send events to <span class="key-service">Amazon CloudWatch</span> Logs. F. Create an <span class="key-service">Amazon CloudWatch</span> dashboard that uses a CloudWatch Logs Insights query. Most Voted</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司使用AWS Organizations管理其AWS账户。公司希望其监控系统在root用户登录时收到警报。公司还需要一个仪表板来显示root用户生成的任何日志活动。哪些步骤组合将满足这些要求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 启用带有多账户聚合器的AWS Config。配置日志转发到Amazon CloudWatch Logs。</div> <div class="option-analysis"><strong>B.</strong> 创建使用Amazon CloudWatch Logs查询的Amazon QuickSight仪表板。</div> <div class="option-analysis"><strong>C.</strong> 创建Amazon CloudWatch Logs指标过滤器来匹配root用户登录事件。配置CloudWatch警报和Amazon SNS主题向公司监控系统发送警报。</div> <div class="option-analysis"><strong>D.</strong> 创建Amazon CloudWatch Logs订阅过滤器来匹配root用户登录事件。配置过滤器将事件转发到Amazon SNS主题。配置SNS主题向公司监控系统发送警报。</div> <div class="option-analysis"><strong>E.</strong> 创建AWS CloudTrail组织跟踪。配置组织跟踪将事件发送到Amazon CloudWatch Logs。 F. 创建使用CloudWatch Logs Insights查询的Amazon CloudWatch仪表板。<div class="section-title"><strong>核心要求:</strong></div> 监控root用户登录并提供警报和仪表板功能 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• CloudTrail-捕获root用户登录事件 </div><div class="compact-content">• CloudWatch Logs-存储和查询日志数据 </div><div class="compact-content">• SNS-发送警报通知 </div><div class="compact-content">• QuickSight-创建可视化仪表板 <div class="section-title"><strong>正确答案BCD:</strong></div> 需要CloudTrail收集登录事件(E)，CloudWatch Logs存储日志，通过指标过滤器或订阅过滤器触发SNS警报(C/D)，QuickSight创建仪表板(B) <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A-AWS Config用于配置合规性检查，不适用于用户登录监控 </div><div class="compact-content">• 选项E-虽然需要CloudTrail，但题目要求选择3个选项，E不在正确答案中 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-实时警报和快速查询响应 </div><div class="compact-content">• 成本-使用托管服务降低运维成本 </div><div class="compact-content">• 可扩展性-支持多账户组织级别监控</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: BCD (B、C、D)</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-231">
            <div class="question-header">
                <div class="question-title">Question #231 ✅ 📝 <small style="float: right;">(231/353)</small></div>
            </div>
            <div class="question-content">A company uses <span class="key-service">AWS Organizations</span> to manage its AWS accounts. A DevOps engineer must ensure that all users who access the AWS Management Console are authenticated through the company's corporate identity provider (IdP). Which combination of steps will meet these requirements? (Choose two.) BE (100%)</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Use <span class="key-service">Amazon GuardDuty</span> with a delegated administrator account. Use GuardDuty to enforce denial of IAM user logins.</div>                <div class="option correct-answer"><strong>B.</strong> Use <span class="key-service">AWS IAM</span> Identity Center to configure identity federation with SAML 2.0.</div>                <div class="option correct-answer"><strong>C.</strong> Create a permissions boundary in <span class="key-service">AWS IAM</span> Identity Center to deny password logins for IAM users.</div>                <div class="option"><strong>D.</strong> Create IAM groups in the Organizations management account to apply consistent permissions for all IAM users.</div>                <div class="option"><strong>E.</strong> Create an <span class="key-service">SCP</span> in Organizations to deny password creation for IAM users.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司使用AWS Organizations管理其AWS账户。DevOps工程师必须确保所有访问AWS Management Console的用户都通过公司的企业身份提供商(IdP)进行身份验证。哪种步骤组合将满足这些要求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 使用Amazon GuardDuty与委托管理员账户，使用GuardDuty强制拒绝IAM用户登录</div> <div class="option-analysis"><strong>B.</strong> 使用AWS IAM Identity Center配置与SAML 2.0的身份联合</div> <div class="option-analysis"><strong>C.</strong> 在AWS IAM Identity Center中创建权限边界以拒绝IAM用户的密码登录</div> <div class="option-analysis"><strong>D.</strong> 在Organizations管理账户中创建IAM组，为所有IAM用户应用一致的权限</div> <div class="option-analysis"><strong>E.</strong> 在Organizations中创建SCP以拒绝IAM用户的密码创建<div class="section-title"><strong>核心要求:</strong></div> 确保所有控制台用户通过企业IdP进行身份验证 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• <span class="key-service">AWS IAM</span> Identity Center-提供企业身份联合和集中访问管理 </div><div class="compact-content">• SAML 2.0-企业身份提供商的标准联合协议 </div><div class="compact-content">• 权限边界-限制用户权限的安全机制 <div class="section-title"><strong>正确答案BC:</strong></div> B选项通过IAM Identity Center配置SAML联合实现企业IdP集成，C选项通过权限边界阻止IAM用户密码登录，强制使用联合身份验证 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A-GuardDuty是威胁检测服务，不能强制执行身份验证策略 </div><div class="compact-content">• 选项D-创建IAM组不能解决身份验证来源问题，仍允许本地密码登录 </div><div class="compact-content">• 选项E-SCP阻止密码创建但不能强制使用企业IdP进行身份验证 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 安全性-企业IdP集中管理提供更强的身份治理 </div><div class="compact-content">• <span class="key-point">合规性</span>-满足企业统一身份验证的合规要求 </div><div class="compact-content">• 管理效率-集中身份管理减少多重身份维护成本</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: BC (B、C)</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-232">
            <div class="question-header">
                <div class="question-title">Question #232 ✅ 📝 <small style="float: right;">(232/353)</small></div>
            </div>
            <div class="question-content">A company has deployed a new platform that runs on Amazon Elastic Kubernetes Service (<span class="key-service">Amazon EKS</span>). The new platform hosts web applications that users frequently update. The application developers build the Docker images for the applications and deploy the Docker images manually to the platform. The platform usage has increased to more than 500 users every day. Frequent updates, building the updated Docker images for the applications, and deploying the Docker images on the platform manually have all become difficult to manage. The company needs to receive an Amazon Simple Notification Service (<span class="key-service">Amazon SNS</span>) notification if Docker image scanning returns any HIGH or CRITICAL findings for operating system or programming language package vulnerabilities. Which combination of steps will meet these requirements? (Choose two.) BD (100%)</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Create an <span class="key-service">AWS CodeCommit</span> repository to store the Dockerfile and Kubernetes deployment files. Create a pipeline in <span class="key-service">AWS CodePipeline</span>. Use an <span class="key-service">Amazon S3</span> event to invoke the pipeline when a newer version of the Dockerfile is committed. Add a step to the pipeline to initiate the <span class="key-service">AWS CodeBuild</span> project.</div>                <div class="option"><strong>B.</strong> Create an <span class="key-service">AWS CodeCommit</span> repository to store the Dockerfile and Kubernetes deployment files. Create a pipeline in <span class="key-service">AWS CodePipeline</span>. Use an Amazon EventBridge event to invoke the pipeline when a newer version of the Dockerfile is committed. Add a step to the pipeline to initiate the <span class="key-service">AWS CodeBuild</span> project.</div>                <div class="option correct-answer"><strong>C.</strong> Create an <span class="key-service">AWS CodeBuild</span> project that builds the Docker images and stores the Docker images in an Amazon Elastic Container Registry (<span class="key-service">Amazon ECR</span>) repository. Turn on basic scanning for the ECR repository. Create an Amazon EventBridge rule that monitors <span class="key-service">Amazon GuardDuty</span> events. Configure the EventBridge rule to send an event to an SNS topic when the finding-severity-counts parameter is more than 0 at a CRITICAL or HIGH level.</div>                <div class="option correct-answer"><strong>D.</strong> Create an <span class="key-service">AWS CodeBuild</span> project that builds the Docker images and stores the Docker images in an Amazon Elastic Container Registry (<span class="key-service">Amazon ECR</span>) repository. Turn on enhanced scanning for the ECR repository. Create an Amazon EventBridge rule that monitors ECR image scan events. Configure the EventBridge rule to send an event to an SNS topic when the finding-severity-counts parameter is more than 0 at a CRITICAL or HIGH level.</div>                <div class="option"><strong>E.</strong> Create an <span class="key-service">AWS CodeBuild</span> project that scans the Dockerfile. Configure the project to build the Docker images and store the Docker images in an Amazon Elastic Container Registry (<span class="key-service">Amazon ECR</span>) repository if the scan is successful. Configure an SNS topic to provide notification if the scan returns any vulnerabilities.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司在Amazon EKS上部署了新平台，托管频繁更新的Web应用程序。开发人员手动构建和部署Docker镜像，现在每天超过500用户使用。频繁更新、构建和手动部署变得难以管理。公司需要在Docker镜像扫描发现操作系统或编程语言包的HIGH或CRITICAL漏洞时收到Amazon SNS通知。哪些步骤组合能满足要求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 创建AWS CodeCommit存储库存放Dockerfile和Kubernetes部署文件。创建AWS CodePipeline管道。使用Amazon S3事件在提交新版本Dockerfile时调用管道。添加步骤启动AWS CodeBuild项目。</div> <div class="option-analysis"><strong>B.</strong> 创建AWS CodeCommit存储库存放Dockerfile和Kubernetes部署文件。创建AWS CodePipeline管道。使用Amazon EventBridge事件在提交新版本Dockerfile时调用管道。添加步骤启动AWS CodeBuild项目。</div> <div class="option-analysis"><strong>C.</strong> 创建AWS CodeBuild项目构建Docker镜像并存储到Amazon ECR存储库。为ECR存储库开启基础扫描。创建Amazon EventBridge规则监控Amazon GuardDuty事件。配置规则在CRITICAL或HIGH级别finding-severity-counts参数大于0时发送事件到SNS主题。</div> <div class="option-analysis"><strong>D.</strong> 创建AWS CodeBuild项目构建Docker镜像并存储到Amazon ECR存储库。为ECR存储库开启增强扫描。创建Amazon EventBridge规则监控ECR镜像扫描事件。配置规则在CRITICAL或HIGH级别finding-severity-counts参数大于0时发送事件到SNS主题。</div> <div class="option-analysis"><strong>E.</strong> 创建AWS CodeBuild项目扫描Dockerfile。配置项目在扫描成功时构建Docker镜像并存储到Amazon ECR存储库。配置SNS主题在扫描返回任何漏洞时提供通知。<div class="section-title"><strong>核心要求:</strong></div> 自动化CI/CD流程并实现Docker镜像漏洞扫描告警 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• <span class="key-service">AWS CodeCommit</span>-源代码版本控制 </div><div class="compact-content">• <span class="key-service">AWS CodePipeline</span>-CI/CD自动化管道 </div><div class="compact-content">• <span class="key-service">AWS CodeBuild</span>-Docker镜像构建 </div><div class="compact-content">• <span class="key-service">Amazon ECR</span>-容器镜像存储和扫描 </div><div class="compact-content">• Amazon EventBridge-事件驱动集成 </div><div class="compact-content">• <span class="key-service">Amazon SNS</span>-漏洞告警通知 <div class="section-title"><strong>正确答案CD:</strong></div> C和D都提供完整的CI/CD解决方案，区别在于ECR扫描类型：C使用基础扫描配合GuardDuty，D使用增强扫描直接监控ECR事件，都能实现漏洞检测和SNS告警 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A-使用S3事件触发管道不适用于CodeCommit代码提交场景 </div><div class="compact-content">• 选项B-虽然EventBridge触发正确，但缺少镜像扫描和告警配置 </div><div class="compact-content">• 选项E-仅扫描Dockerfile而非构建后的镜像，无法检测运行时漏洞 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-EventBridge事件驱动架构提供实时响应 </div><div class="compact-content">• 成本-ECR集成扫描比独立安全工具更经济 </div><div class="compact-content">• 可扩展性-CodePipeline自动化支持高频更新需求</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: CD (C、D)</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-233">
            <div class="question-header">
                <div class="question-title">Question #233 ✅ 📝 <small style="float: right;">(233/353)</small></div>
            </div>
            <div class="question-content">A company groups its AWS accounts in OUs in an organization in <span class="key-service">AWS Organizations</span>. The company has deployed a set of <span class="key-service">Amazon API Gateway</span> APIs in one of the Organizations accounts. The APIs are bound to the account's <span class="key-service">VPC</span> and have no existing authentication mechanism. Only principals in a specific OU can have permissions to invoke the APIs. The company applies the following policy to the API Gateway interface <span class="key-service">VPC</span> endpoint: The company also updates the API Gateway resource policies to deny invocations that do not come through the interface <span class="key-service">VPC</span> endpoint. After the updates, the following error message appears during attempts to use the interface <span class="key-service">VPC</span> endpoint URL to invoke an API: "User: anonymous is not authorized." Which combination of steps will solve this problem? (Choose two.) AE (100%)</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Enable IAM authentication on all API methods by setting <span class="key-service">AWS IAM</span> as the authorization method.</div>                <div class="option correct-answer"><strong>B.</strong> Create a token-based <span class="key-service">AWS Lambda</span> authorizer that passes the caller's identity in a bearer token.</div>                <div class="option"><strong>C.</strong> Create a request parameter-based <span class="key-service">AWS Lambda</span> authorizer that passes the caller's identity in a combination of headers, query string parameters, stage variables, and $context variables.</div>                <div class="option"><strong>D.</strong> Use Amazon Cognito user pools as the authorizer to control access to the API.</div>                <div class="option correct-answer"><strong>E.</strong> Verify the identity of the requester by using Signature Version 4 to sign client requests by using AWS credentials.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司在AWS Organizations中将AWS账户分组到OU中。公司在其中一个Organizations账户中部署了一组Amazon API Gateway API。这些API绑定到账户的VPC并且没有现有的身份验证机制。只有特定OU中的主体可以有权限调用这些API。公司将以下策略应用到API Gateway接口VPC端点。公司还更新了API Gateway资源策略以拒绝不通过接口VPC端点的调用。更新后，在尝试使用接口VPC端点URL调用API时出现以下错误消息："User: anonymous is not authorized."哪些步骤组合将解决此问题？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 通过将AWS IAM设置为授权方法在所有API方法上启用IAM身份验证</div> <div class="option-analysis"><strong>B.</strong> 创建一个基于令牌的AWS Lambda授权器，在bearer令牌中传递调用者的身份</div> <div class="option-analysis"><strong>C.</strong> 创建一个基于请求参数的AWS Lambda授权器，在标头、查询字符串参数、阶段变量和$context变量的组合中传递调用者的身份</div> <div class="option-analysis"><strong>D.</strong> 使用Amazon Cognito用户池作为授权器来控制对API的访问</div> <div class="option-analysis"><strong>E.</strong> 通过使用Signature Version 4使用AWS凭证签署客户端请求来验证请求者的身份<div class="section-title"><strong>核心要求:</strong></div> 解决API Gateway通过VPC端点调用时的"anonymous用户未授权"<span class="wrong-reason">错误</span> <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• API Gateway - 需要身份验证机制识别调用者身份 </div><div class="compact-content">• VPC端点 - 限制API只能通过VPC端点访问 </div><div class="compact-content">• <span class="key-service">AWS Organizations</span> - 控制特定OU中的主体访问权限 <div class="section-title"><strong>正确答案BE:</strong></div> B选项提供Lambda自定义授权器解析bearer令牌获取调用者身份，E选项通过SigV4签名验证AWS凭证确保请求来自已认证的AWS主体 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A - IAM授权需要SigV4签名配合，单独启用无法解决anonymous问题 </div><div class="compact-content">• 选项C - 基于请求参数的授权器无法可靠验证调用者真实身份 </div><div class="compact-content">• 选项D - Cognito用户池不适用于AWS Organizations内部账户间的API访问控制 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能 - Lambda授权器和SigV4都提供高效的身份验证 </div><div class="compact-content">• 成本 - 利用现有AWS服务，无需额外基础设施投入 </div><div class="compact-content">• 可扩展性 - 支持Organizations级别的多账户访问控制</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: BE (B、E)</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-234">
            <div class="question-header">
                <div class="question-title">Question #234 ✅ ⚪ <small style="float: right;">(234/353)</small></div>
            </div>
            <div class="question-content">A company wants to decrease the time it takes to develop new features. The company uses <span class="key-service">AWS CodeBuild</span> and <span class="key-service">AWS CodeDeploy</span> to build and deploy its applications. The company uses <span class="key-service">AWS CodePipeline</span> to deploy each microservice with its own CI/CD pipeline. The company needs more visibility into the average time between the release of new features and the average time to recover after a failed deployment. Which solution will provide this visibility with the LEAST configuration effort? B (100%)</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Program an <span class="key-service">AWS Lambda</span> function that creates <span class="key-service">Amazon CloudWatch</span> custom metrics with information about successful runs and failed runs for each pipeline. Create an Amazon EventBridge rule to invoke the Lambda function every 5 minutes. Use the metrics to build a CloudWatch dashboard.</div>                <div class="option correct-answer"><strong>B.</strong> Program an <span class="key-service">AWS Lambda</span> function that creates <span class="key-service">Amazon CloudWatch</span> custom metrics with information about successful runs and failed runs for each pipeline. Create an Amazon EventBridge rule to invoke the Lambda function after every successful run and after every failed run. Use the metrics to build a CloudWatch dashboard.</div>                <div class="option"><strong>C.</strong> Program an <span class="key-service">AWS Lambda</span> function that writes information about successful runs and failed runs to <span class="key-service">Amazon DynamoDB</span>. Create an Amazon EventBridge rule to invoke the Lambda function after every successful run and after every failed run. Build an Amazon QuickSight dashboard to show the information from DynamoDB.</div>                <div class="option"><strong>D.</strong> Program an <span class="key-service">AWS Lambda</span> function that writes information about successful runs and failed runs to <span class="key-service">Amazon DynamoDB</span>. Create an Amazon EventBridge rule to invoke the Lambda function every 5 minutes. Build an Amazon QuickSight dashboard to show the information from DynamoDB.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司希望减少开发新功能所需的时间。该公司使用AWS CodeBuild和AWS CodeDeploy来构建和部署应用程序。公司使用AWS CodePipeline为每个微服务部署独立的CI/CD管道。公司需要更多可见性来了解新功能发布的平均时间和部署失败后的平均恢复时间。哪种解决方案能以最少的配置工作提供这种可见性？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 编写AWS Lambda函数创建Amazon CloudWatch自定义指标，记录每个管道的成功运行和失败运行信息。创建Amazon EventBridge规则每5分钟调用一次Lambda函数。使用指标构建CloudWatch仪表板。</div> <div class="option-analysis"><strong>B.</strong> 编写AWS Lambda函数创建Amazon CloudWatch自定义指标，记录每个管道的成功运行和失败运行信息。创建Amazon EventBridge规则在每次成功运行和失败运行后调用Lambda函数。使用指标构建CloudWatch仪表板。</div> <div class="option-analysis"><strong>C.</strong> 编写AWS Lambda函数将成功运行和失败运行信息写入Amazon DynamoDB。创建Amazon EventBridge规则在每次成功运行和失败运行后调用Lambda函数。构建Amazon QuickSight仪表板显示DynamoDB信息。</div> <div class="option-analysis"><strong>D.</strong> 编写AWS Lambda函数将成功运行和失败运行信息写入Amazon DynamoDB。创建Amazon EventBridge规则每5分钟调用一次Lambda函数。构建Amazon QuickSight仪表板显示DynamoDB信息。<div class="section-title"><strong>核心要求:</strong></div> 为CI/CD管道提供部署时间和恢复时间的可见性监控，配置工作量最少 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• <span class="key-service">AWS CodePipeline</span>-提供CI/CD管道状态事件 </div><div class="compact-content">• <span class="key-service">Amazon CloudWatch</span>-原生集成指标存储和仪表板 </div><div class="compact-content">• Amazon EventBridge-捕获管道状态变化事件 <div class="section-title"><strong>正确答案B:</strong></div> 使用事件驱动架构，通过EventBridge实时捕获管道状态变化，Lambda处理后存储到CloudWatch自定义指标，利用CloudWatch原生仪表板功能 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A-定时轮询方式可能错过事件且数据不够实时准确 </div><div class="compact-content">• 选项C-使用DynamoDB和QuickSight增加了额外的配置复杂度 </div><div class="compact-content">• 选项D-结合了定时轮询和复杂存储方案的双重缺点 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-事件驱动比定时轮询更实时准确 </div><div class="compact-content">• 成本-CloudWatch指标比DynamoDB+QuickSight方案更经济 </div><div class="compact-content">• 可扩展性-CloudWatch与AWS CI/CD服务原生集成配置最简</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: B</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-235">
            <div class="question-header">
                <div class="question-title">Question #235 ✅ ⚪ <small style="float: right;">(235/353)</small></div>
            </div>
            <div class="question-content">A company has developed a static website hosted on an <span class="key-service">Amazon S3</span> bucket. The website is deployed using <span class="key-service">AWS CloudFormation</span>. The CloudFormation template defines an S3 bucket and a custom resource that copies content into the bucket from a source location. The company has decided that it needs to move the website to a new location, so the existing CloudFormation stack must be deleted and re-created. However, CloudFormation reports that the stack could not be deleted cleanly. What is the MOST likely cause and how can the DevOps engineer mitigate this problem for this and future versions of the website? B (100%)</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Deletion has failed because the S3 bucket has an active website configuration. Modify the CloudFormation template to remove the WebsiteConfiguration property from the S3 bucket resource.</div>                <div class="option correct-answer"><strong>B.</strong> Deletion has failed because the S3 bucket is not empty. Modify the custom resource's <span class="key-service">AWS Lambda</span> function code to recursively empty the bucket when RequestType is Delete.</div>                <div class="option"><strong>C.</strong> Deletion has failed because the custom resource does not define a deletion policy. Add a DeletionPolicy property to the custom resource definition with a value of RemoveOnDeletion.</div>                <div class="option"><strong>D.</strong> Deletion has failed because the S3 bucket is not empty. Modify the S3 bucket resource in the CloudFormation template to add a DeletionPolicy property with a value of Empty.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司开发了托管在Amazon S3存储桶上的静态网站。网站使用AWS CloudFormation部署。CloudFormation模板定义了一个S3存储桶和一个自定义资源，该资源将内容从源位置复制到存储桶中。公司决定需要将网站移动到新位置，因此必须删除并重新创建现有的CloudFormation堆栈。但是，CloudFormation报告堆栈无法正常删除。最可能的原因是什么，DevOps工程师如何为当前和未来版本的网站缓解这个问题？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 删除失败是因为S3存储桶有活跃的网站配置。修改CloudFormation模板以从S3存储桶资源中移除WebsiteConfiguration属性。</div> <div class="option-analysis"><strong>B.</strong> 删除失败是因为S3存储桶不为空。修改自定义资源的AWS Lambda函数代码，在RequestType为Delete时递归清空存储桶。</div> <div class="option-analysis"><strong>C.</strong> 删除失败是因为自定义资源没有定义删除策略。在自定义资源定义中添加DeletionPolicy属性，值为RemoveOnDeletion。</div> <div class="option-analysis"><strong>D.</strong> 删除失败是因为S3存储桶不为空。修改CloudFormation模板中的S3存储桶资源，添加DeletionPolicy属性，值为Empty。<div class="section-title"><strong>核心要求:</strong></div> 解决CloudFormation堆栈删除失败问题，确保S3存储桶能够正常删除 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• S3-存储静态网站内容，非空存储桶无法被CloudFormation删除 </div><div class="compact-content">• CloudFormation-基础设施即代码服务，管理资源生命周期 </div><div class="compact-content">• Lambda-执行自定义资源逻辑，处理存储桶内容清理 <div class="section-title"><strong>正确答案B:</strong></div> S3存储桶包含内容时CloudFormation无法删除，需要在自定义资源的Lambda函数中添加删除逻辑，当接收到Delete请求时自动清空存储桶内容 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A-网站配置不会阻止存储桶删除，问题在于存储桶内容 </div><div class="compact-content">• 选项C-RemoveOnDeletion不是有效的DeletionPolicy值 </div><div class="compact-content">• 选项D-Empty不是有效的DeletionPolicy值，且DeletionPolicy不能解决存储桶内容问题 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-自动化清理避免手动干预，提高部署效率 </div><div class="compact-content">• 成本-避免因删除失败导致的资源滞留和额外费用 </div><div class="compact-content">• 可扩展性-Lambda函数可处理任意大小的存储桶内容清理</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: B</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-236">
            <div class="question-header">
                <div class="question-title">Question #236 ✅ ⚪ <small style="float: right;">(236/353)</small></div>
            </div>
            <div class="question-content">A company uses <span class="key-service">Amazon EC2</span> as its primary compute platform. A DevOps team wants to audit the company's EC2 instances to check whether any prohibited applications have been installed on the EC2 instances. Which solution will meet these requirements with the MOST operational efficiency? B (100%)</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Configure <span class="key-service">AWS Systems Manager</span> on each instance. Use <span class="key-service">AWS Systems Manager</span> Inventory. Use Systems Manager resource data sync to synchronize and store findings in an <span class="key-service">Amazon S3</span> bucket. Create an <span class="key-service">AWS Lambda</span> function that runs when new objects are added to the S3 bucket. Configure the Lambda function to identify prohibited applications.</div>                <div class="option correct-answer"><strong>B.</strong> Configure <span class="key-service">AWS Systems Manager</span> on each instance. Use Systems Manager Inventory. Create <span class="key-service">AWS Config</span> rules that monitor changes from Systems Manager Inventory to identify prohibited applications.</div>                <div class="option"><strong>C.</strong> Configure <span class="key-service">AWS Systems Manager</span> on each instance. Use Systems Manager Inventory. Filter a trail in <span class="key-service">AWS CloudTrail</span> for Systems Manager Inventory events to identify prohibited applications.</div>                <div class="option"><strong>D.</strong> Designate <span class="key-service">Amazon CloudWatch</span> Logs as the log destination for all application instances. Run an automated script across all instances to create an inventory of installed applications. Configure the script to forward the results to CloudWatch Logs. Create a CloudWatch alarm that uses filter patterns to search log data to identify prohibited applications.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司使用Amazon EC2作为主要计算平台。DevOps团队想要审计公司的EC2实例，检查是否在EC2实例上安装了任何禁用的应用程序。哪种解决方案能以最高的运营效率满足这些要求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 在每个实例上配置AWS Systems Manager，使用AWS Systems Manager Inventory，使用Systems Manager资源数据同步将发现结果同步并存储到Amazon S3存储桶中，创建一个AWS Lambda函数在新对象添加到S3存储桶时运行，配置Lambda函数识别禁用应用程序。</div> <div class="option-analysis"><strong>B.</strong> 在每个实例上配置AWS Systems Manager，使用Systems Manager Inventory，创建AWS Config规则监控Systems Manager Inventory的变更以识别禁用应用程序。</div> <div class="option-analysis"><strong>C.</strong> 在每个实例上配置AWS Systems Manager，使用Systems Manager Inventory，在AWS CloudTrail中过滤Systems Manager Inventory事件的跟踪以识别禁用应用程序。</div> <div class="option-analysis"><strong>D.</strong> 指定Amazon CloudWatch Logs作为所有应用程序实例的日志目标，在所有实例上运行自动化脚本创建已安装应用程序清单，配置脚本将结果转发到CloudWatch Logs，创建使用过滤模式搜索日志数据的CloudWatch告警以识别禁用应用程序。<div class="section-title"><strong>核心要求:</strong></div> 审计EC2实例上的应用程序安装情况，识别禁用应用程序 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• <span class="key-service">AWS Systems Manager</span> Inventory-收集实例上的软件清单信息 </div><div class="compact-content">• <span class="key-service">AWS Config</span>-监控资源配置变更并评估合规性 <div class="section-title"><strong>正确答案B:</strong></div> 使用Systems Manager Inventory收集应用程序清单，通过AWS Config规则自动监控和评估合规性，提供最高运营效率的原生集成解决方案 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A-增加了不必要的S3存储和Lambda函数复杂性，降低运营效率 </div><div class="compact-content">• 选项C-CloudTrail主要用于API调用审计，不适合应用程序合规性监控 </div><div class="compact-content">• 选项D-需要自定义脚本和复杂的日志处理，运营开销大且可靠性低 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-Config规则提供实时合规性评估和自动化监控 </div><div class="compact-content">• 成本-避免额外的Lambda、S3存储和自定义脚本开发成本 </div><div class="compact-content">• 可扩展性-Config和Systems Manager原生集成，支持大规模实例管理</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: B</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-237">
            <div class="question-header">
                <div class="question-title">Question #237 ✅ 📝 <small style="float: right;">(237/353)</small></div>
            </div>
            <div class="question-content">A company has an event-driven JavaScript application. The application uses decoupled AWS managed services that publish, consume, and route events. During application testing, events are not delivered to the target that is specified by an Amazon EventBridge rule. A DevOps team must provide application testers with additional functionality to view, troubleshoot, and prevent the loss of events without redeployment of the application. Which combination of steps should the DevOps team take to meet these requirements? (Choose three.) CEF (43%) BCE (43%) 14%</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Launch AWS Device Farm with a standard test environment and project to run a specific build of the application.</div>                <div class="option"><strong>B.</strong> Create an <span class="key-service">Amazon S3</span> bucket. Enable <span class="key-service">AWS CloudTrail</span>. Create a CloudTrail trail that specifies the S3 bucket as the storage location.</div>                <div class="option"><strong>C.</strong> Configure the EventBridge rule to use an Amazon Simple Queue Service (<span class="key-service">Amazon SQS</span>) standard queue as a dead-letter queue.</div>                <div class="option correct-answer"><strong>D.</strong> Configure the EventBridge rule to use an Amazon Simple Queue Service (<span class="key-service">Amazon SQS</span>) FIFO queue as a dead-letter queue.</div>                <div class="option correct-answer"><strong>E.</strong> Create a log group in <span class="key-service">Amazon CloudWatch</span> Logs. Specify the log group as an additional target of the EventBridge rule. F. Update the application code base to use the AWS X-Ray SDK tracing feature to instrument the code with support for the X-Amzn-Trace-Id header.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司有一个事件驱动的JavaScript应用程序。该应用程序使用解耦的AWS托管服务来发布、消费和路由事件。在应用程序测试期间，事件没有传递到Amazon EventBridge规则指定的目标。DevOps团队必须为应用程序测试人员提供额外功能来查看、故障排除和防止事件丢失，且无需重新部署应用程序。DevOps团队应该采取哪些步骤组合来满足这些要求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 启动AWS Device Farm，使用标准测试环境和项目来运行应用程序的特定构建版本</div> <div class="option-analysis"><strong>B.</strong> 创建Amazon S3存储桶，启用AWS CloudTrail，创建指定S3存储桶作为存储位置的CloudTrail跟踪</div> <div class="option-analysis"><strong>C.</strong> 配置EventBridge规则使用Amazon Simple Queue Service (<span class="key-service">Amazon SQS</span>)标准队列作为死信队列</div> <div class="option-analysis"><strong>D.</strong> 配置EventBridge规则使用Amazon Simple Queue Service (<span class="key-service">Amazon SQS</span>) FIFO队列作为死信队列</div> <div class="option-analysis"><strong>E.</strong> 在Amazon CloudWatch Logs中创建日志组，将日志组指定为EventBridge规则的附加目标 F. 更新应用程序代码库以使用AWS X-Ray SDK跟踪功能，通过支持X-Amzn-Trace-Id标头来检测代码<div class="section-title"><strong>核心要求:</strong></div> 为EventBridge事件传递失败提供查看、故障排除和防止丢失的功能，无需重新部署 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• EventBridge - 事件路由服务，支持死信队列和多目标配置 </div><div class="compact-content">• SQS - 消息队列服务，可作为死信队列捕获失败事件 </div><div class="compact-content">• CloudWatch Logs - 日志服务，可记录事件传递详情用于故障排除 <div class="section-title"><strong>正确答案DE:</strong></div> D选项配置SQS FIFO队列作为死信队列防止事件丢失并保证顺序，E选项添加CloudWatch Logs目标提供事件传递的可见性和故障排除能力 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A - Device Farm用于移动应用测试，与EventBridge事件传递问题无关 </div><div class="compact-content">• 选项B - CloudTrail记录API调用，无法提供事件传递失败的详细信息 </div><div class="compact-content">• 选项C - 标准SQS队列不保证消息顺序，FIFO队列更适合事件处理场景 </div><div class="compact-content">• 选项F - X-Ray需要代码修改，违反了无需重新部署的要求 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能 - FIFO队列保证事件顺序处理，CloudWatch Logs提供实时监控 </div><div class="compact-content">• 成本 - 利用现有EventBridge多目标功能，无需额外基础设施 </div><div class="compact-content">• 可扩展性 - SQS和CloudWatch Logs都是完全托管服务，自动扩展</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: DE (D、E)</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-238">
            <div class="question-header">
                <div class="question-title">Question #238 ✅ 📝 <small style="float: right;">(238/353)</small></div>
            </div>
            <div class="question-content">A company is migrating its container-based workloads to an <span class="key-service">AWS Organizations</span> multi-account environment. The environment consists of application workload accounts that the company uses to deploy and run the containerized workloads. The company has also provisioned a shared services account for shared workloads in the organization. The company must follow strict compliance regulations. All container images must receive security scanning before they are deployed to any environment. Images can be consumed by downstream deployment mechanisms after the images pass a scan with no critical vulnerabilities. Pre-scan and post-scan images must be isolated from one another so that a deployment can never use pre-scan images. A DevOps engineer needs to create a strategy to centralize this process. Which combination of steps will meet these requirements with the LEAST administrative overhead? (Choose two.) AE (80%) AD (20%)</div>
            <div class="options-container">                <div class="option correct-answer"><strong>A.</strong> Create Amazon Elastic Container Registry (<span class="key-service">Amazon ECR</span>) repositories in the shared services account: one repository for each pre-scan image and one repository for each post-scan image. Configure <span class="key-service">Amazon ECR</span> image scanning to run on new image pushes to the pre-scan repositories. Use resource-based policies to grant the organization write access to the pre-scan repositories and read access to the post-scan repositories.</div>                <div class="option"><strong>B.</strong> Create pre-scan Amazon Elastic Container Registry (<span class="key-service">Amazon ECR</span>) repositories in each account that publishes container images. Create repositories for post-scan images in the shared services account. Configure <span class="key-service">Amazon ECR</span> image scanning to run on new image pushes to the pre-scan repositories. Use resource-based policies to grant the organization read access to the post-scan repositories.</div>                <div class="option"><strong>C.</strong> Configure image replication for each image from the image's pre-scan repository to the image's post-scan repository.</div>                <div class="option correct-answer"><strong>D.</strong> Create a pipeline in <span class="key-service">AWS CodePipeline</span> for each pre-scan repository. Create a source stage that runs when new images are pushed to the pre-scan repositories. Create a stage that uses <span class="key-service">AWS CodeBuild</span> as the action provider. Write a buildspec.yaml definition that determines the image scanning status and pushes images without critical vulnerabilities to the post-scan repositories.</div>                <div class="option"><strong>E.</strong> Create an <span class="key-service">AWS Lambda</span> function. Create an Amazon EventBridge rule that reacts to image scanning completed events and invokes the Lambda function. Write function code that determines the image scanning status and pushes images without critical vulnerabilities to the post-scan repositories.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司正在将基于容器的工作负载迁移到AWS Organizations多账户环境。环境包含用于部署和运行容器化工作负载的应用程序工作负载账户。公司还为组织中的共享工作负载配置了共享服务账户。公司必须遵循严格的合规法规。所有容器镜像在部署到任何环境之前都必须接受安全扫描。镜像在通过扫描且没有关键漏洞后才能被下游部署机制使用。扫描前和扫描后的镜像必须相互隔离，以确保部署永远不会使用扫描前的镜像。DevOps工程师需要创建一个策略来集中化这个过程。 <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 在共享服务账户中创建Amazon ECR存储库：每个扫描前镜像一个存储库，每个扫描后镜像一个存储库。配置Amazon ECR镜像扫描在新镜像推送到扫描前存储库时运行。使用基于资源的策略授予组织对扫描前存储库的写入访问权限和对扫描后存储库的读取访问权限。</div> <div class="option-analysis"><strong>B.</strong> 在每个发布容器镜像的账户中创建扫描前Amazon ECR存储库。在共享服务账户中为扫描后镜像创建存储库。配置Amazon ECR镜像扫描在新镜像推送到扫描前存储库时运行。使用基于资源的策略授予组织对扫描后存储库的读取访问权限。</div> <div class="option-analysis"><strong>C.</strong> 为每个镜像配置从镜像的扫描前存储库到镜像的扫描后存储库的镜像复制。</div> <div class="option-analysis"><strong>D.</strong> 为每个扫描前存储库在AWS CodePipeline中创建管道。创建在新镜像推送到扫描前存储库时运行的源阶段。创建使用AWS CodeBuild作为操作提供者的阶段。编写buildspec.yaml定义来确定镜像扫描状态并将没有关键漏洞的镜像推送到扫描后存储库。</div> <div class="option-analysis"><strong>E.</strong> 创建AWS Lambda函数。创建Amazon EventBridge规则来响应镜像扫描完成事件并调用Lambda函数。编写函数代码来确定镜像扫描状态并将没有关键漏洞的镜像推送到扫描后存储库。<div class="section-title"><strong>核心要求:</strong></div> 在多账户环境中集中化容器镜像安全扫描流程，确保扫描前后镜像隔离且仅允许通过扫描的镜像被部署 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• <span class="key-service">Amazon ECR</span>-提供容器镜像存储和内置安全扫描功能 </div><div class="compact-content">• <span class="key-service">AWS CodePipeline</span>-提供自动化CI/CD管道编排 </div><div class="compact-content">• <span class="key-service">AWS CodeBuild</span>-执行镜像扫描状态检查和条件推送 <div class="section-title"><strong>正确答案AD:</strong></div> A选项通过在共享服务账户中集中管理扫描前后存储库实现隔离和集中化，D选项使用CodePipeline和CodeBuild提供自动化的扫描结果处理和条件推送机制 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项B-将扫描前存储库分散在各个账户中增加管理复杂性，不符合集中化要求 </div><div class="compact-content">• 选项C-简单的镜像复制无法基于扫描结果进行条件处理，会复制所有镜像包括有漏洞的 </div><div class="compact-content">• 选项E-Lambda函数相比CodePipeline缺乏完整的CI/CD编排能力，管理开销更大 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-ECR内置扫描和CodePipeline自动化触发提供高效处理 </div><div class="compact-content">• 成本-集中化管理减少重复资源，CodePipeline按使用付费模式经济高效 </div><div class="compact-content">• 可扩展性-共享服务账户模式和管道模板化支持多账户环境扩展</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: AD (A、D)</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-239">
            <div class="question-header">
                <div class="question-title">Question #239 ✅ ⚪ <small style="float: right;">(239/353)</small></div>
            </div>
            <div class="question-content">A company uses an Amazon Elastic Kubernetes Service (<span class="key-service">Amazon EKS</span>) cluster to deploy its web applications on containers. The web applications contain confidential data that cannot be decrypted without specific credentials. A DevOps engineer has stored the credentials in AWS Secrets Manager. The secrets are encrypted by an AWS Key Management Service (AWS KMS) customer managed key. A Kubernetes service account for a third-party tool makes the secrets available to the applications. The service account assumes an IAM role that the company created to access the secrets. The service account receives an Access Denied (403 Forbidden) error while trying to retrieve the secrets from Secrets Manager. What is the root cause of this issue? B (100%)</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> The IAM role that is attached to the EKS cluster does not have access to retrieve the secrets from Secrets Manager.</div>                <div class="option correct-answer"><strong>B.</strong> The key policy for the customer managed key does not allow the Kubernetes service account IAM role to use the key.</div>                <div class="option"><strong>C.</strong> The key policy for the customer managed key does not allow the EKS cluster IAM role to use the key.</div>                <div class="option"><strong>D.</strong> The IAM role that is assumed by the Kubernetes service account does not have permission to access the EKS cluster.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司使用Amazon EKS集群在容器上部署Web应用程序。Web应用程序包含机密数据，没有特定凭证无法解密。DevOps工程师将凭证存储在AWS Secrets Manager中。这些密钥由AWS KMS客户托管密钥加密。第三方工具的Kubernetes服务账户使应用程序可以访问这些密钥。服务账户假设公司创建的IAM角色来访问密钥。服务账户在尝试从Secrets Manager检索密钥时收到Access Denied (403 Forbidden)<span class="wrong-reason">错误</span>。此问题的根本原因是什么？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 附加到EKS集群的IAM角色没有从Secrets Manager检索密钥的访问权限。</div> <div class="option-analysis"><strong>B.</strong> 客户托管密钥的密钥策略不允许Kubernetes服务账户IAM角色使用该密钥。</div> <div class="option-analysis"><strong>C.</strong> 客户托管密钥的密钥策略不允许EKS集群IAM角色使用该密钥。</div> <div class="option-analysis"><strong>D.</strong> 由Kubernetes服务账户假设的IAM角色没有访问EKS集群的权限。<div class="section-title"><strong>核心要求:</strong></div> 解决Kubernetes服务账户通过IAM角色访问KMS加密的Secrets Manager密钥时的权限问题 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• AWS Secrets Manager-存储加密的应用程序凭证 </div><div class="compact-content">• AWS KMS-使用客户托管密钥加密密钥 </div><div class="compact-content">• <span class="key-service">Amazon EKS</span>-运行容器化应用程序的Kubernetes集群 <div class="section-title"><strong>正确答案B:</strong></div> 当密钥被KMS客户托管密钥加密时，除了Secrets Manager的IAM权限外，还需要KMS密钥策略明确允许服务账户的IAM角色使用该密钥进行解密操作 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A-问题不在于Secrets Manager的IAM权限，而在于KMS密钥使用权限 </div><div class="compact-content">• 选项C-是服务账户的IAM角色需要KMS权限，不是EKS集群角色 </div><div class="compact-content">• 选项D-服务账户已经能够运行，问题在于访问加密密钥而非集群访问 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-KMS密钥策略配置不当会导致解密失败 </div><div class="compact-content">• 成本-正确的权限配置避免不必要的故障排除成本 </div><div class="compact-content">• 可扩展性-合理的密钥策略支持多个服务账户安全访问</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: B</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-240">
            <div class="question-header">
                <div class="question-title">Question #240 ✅ ⚪ <small style="float: right;">(240/353)</small></div>
            </div>
            <div class="question-content">A company is migrating its product development teams from an on-premises data center to a hybrid environment. The new environment will add four AWS Regions and will give the developers the ability to use the Region that is geographically closest to them. All the development teams use a shared set of Linux applications. The on-premises data center stores the applications on a NetApp ONTAP storage device. The storage volume is mounted read-only on the development on-premises VMs. The company updates the applications on the shared volume once a week. A DevOps engineer needs to replicate the data to all the new Regions. The DevOps engineer must ensure that the data is always up to date with deduplication. The data also must not be dependent on the availability of the on-premises storage device. Which solution will meet these requirements? C (100%)</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Create an <span class="key-service">Amazon S3</span> File Gateway in the on-premises data center. Create S3 buckets in each Region. Set up a cron job to copy the data from the storage device to the S3 File Gateway. Set up S3 Cross-Region Replication (CRR) to the S3 buckets in each Region.</div>                <div class="option"><strong>B.</strong> Create an Amazon FSx File Gateway in one Region. Create file servers in Amazon FSx for Windows File Server in each Region. Set up a cron job to copy the data from the storage device to the FSx File Gateway.</div>                <div class="option"><strong>C.</strong> Create Multi-AZ Amazon FSx for NetApp ONTAP instances and volumes in each Region. Configure a scheduled SnapMirror relationship between the on-premises storage device and the FSx for ONTAP instances.</div>                <div class="option correct-answer"><strong>D.</strong> Create an Amazon Elastic File System (<span class="key-service">Amazon <span class="key-service">EFS</span></span>) file system in each Region. Deploy an AWS DataSync agent in the on-premises data center. Configure a schedule for DataSync to copy the data to <span class="key-service">Amazon <span class="key-service">EFS</span></span> daily.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司正在将产品开发团队从本地数据中心迁移到混合环境。新环境将添加四个AWS Region，让开发人员能够使用地理位置最近的Region。所有开发团队使用共享的Linux应用程序集。本地数据中心将应用程序存储在NetApp ONTAP存储设备上。存储卷以只读方式挂载到本地开发VM上。公司每周更新共享卷上的应用程序一次。DevOps工程师需要将数据复制到所有新Region。DevOps工程师必须确保数据始终保持最新状态并具有重复数据删除功能。数据也不能依赖于本地存储设备的可用性。 <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 在本地数据中心创建Amazon S3 File Gateway。在每个Region创建S3存储桶。设置cron作业将数据从存储设备复制到S3 File Gateway。设置S3 Cross-Region Replication (CRR)到每个Region的S3存储桶。</div> <div class="option-analysis"><strong>B.</strong> 在一个Region创建Amazon FSx File Gateway。在每个Region的Amazon FSx for Windows File Server中创建文件服务器。设置cron作业将数据从存储设备复制到FSx File Gateway。</div> <div class="option-analysis"><strong>C.</strong> 在每个Region创建Multi-AZ Amazon FSx for NetApp ONTAP实例和卷。在本地存储设备和FSx for ONTAP实例之间配置定期SnapMirror关系。</div> <div class="option-analysis"><strong>D.</strong> 在每个Region创建Amazon Elastic File System (<span class="key-service">Amazon <span class="key-service">EFS</span></span>)文件系统。在本地数据中心部署AWS DataSync代理。配置DataSync每日将数据复制到Amazon EFS的计划。<div class="section-title"><strong>核心要求:</strong></div> 将本地NetApp ONTAP存储的Linux应用程序复制到4个AWS Region，确保数据最新、支持重复数据删除且不依赖本地存储可用性 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• <span class="key-service">Amazon <span class="key-service">EFS</span></span>-提供完全托管的NFS文件系统，支持Linux环境 </div><div class="compact-content">• AWS DataSync-提供自动化数据传输和同步服务，支持调度和重复数据删除 <div class="section-title"><strong>正确答案D:</strong></div> DataSync提供内置的重复数据删除和增量传输功能，EFS作为完全托管服务消除了对本地存储的依赖，支持Linux环境的NFS协议需求 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A-S3不适合作为文件系统挂载给Linux应用程序使用，需要API访问而非文件系统接口 </div><div class="compact-content">• 选项B-FSx for Windows File Server不适合Linux环境，且FSx File Gateway不是有效的AWS服务 </div><div class="compact-content">• 选项C-虽然技术匹配但成本过高，且SnapMirror仍然依赖本地存储设备的可用性 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-EFS提供高可用性和一致性能，DataSync优化传输效率 </div><div class="compact-content">• 成本-EFS按使用付费比FSx for ONTAP更经济，DataSync无额外服务费用 </div><div class="compact-content">• 可扩展性-EFS自动扩展，DataSync支持多Region并行同步</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: D</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-241">
            <div class="question-header">
                <div class="question-title">Question #241 ✅ 📝 <small style="float: right;">(241/353)</small></div>
            </div>
            <div class="question-content">A company has an application that stores data that includes personally identifiable information (PII) in an <span class="key-service">Amazon S3</span> bucket. All data is encrypted with AWS Key Management Service (AWS KMS) customer managed keys. All AWS resources are deployed from an <span class="key-service">AWS CloudFormation</span> template. A DevOps engineer needs to set up a development environment for the application in a different AWS account. The data in the development environment's S3 bucket needs to be updated once a week from the production environment's S3 bucket. The company must not move PII from the production environment without anonymizing the PII first. The data in each environment must be encrypted with different KMS customer managed keys. Which combination of steps should the DevOps engineer take to meet these requirements? (Choose two.) AD (100%)</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Activate Amazon Macie on the S3 bucket in the production account. Create an <span class="key-service">AWS Step Functions</span> state machine to initiate a discovery job and redact all PII before copying files to the S3 bucket in the development account. Give the state machine tasks decrypt permissions on the KMS key in the production account. Give the state machine tasks encrypt permissions on the KMS key in the development account.</div>                <div class="option correct-answer"><strong>B.</strong> Set up S3 replication between the production S3 bucket and the development S3 bucket. Activate Amazon Macie on the development S3 bucket. Create an <span class="key-service">AWS Step Functions</span> state machine to initiate a discovery job and redact all PII as the files are copied to the development S3 bucket. Give the state machine tasks encrypt and decrypt permissions on the KMS key in the development account.</div>                <div class="option"><strong>C.</strong> Set up an S3 Batch Operations job to copy files from the production S3 bucket to the development S3 bucket. In the development account, configure an <span class="key-service">AWS Lambda</span> function to redact all PII. Configure S3 Object Lambda to use the Lambda function for S3 GET requests. Give the Lambda function's IAM role encrypt and decrypt permissions on the KMS key in the development account.</div>                <div class="option correct-answer"><strong>D.</strong> Create a development environment from the CloudFormation template in the development account. Schedule an Amazon EventBridge rule to start the <span class="key-service">AWS Step Functions</span> state machine once a week.</div>                <div class="option"><strong>E.</strong> Create a development environment from the CloudFormation template in the development account. Schedule a cron job on an <span class="key-service">Amazon EC2</span> instance to run once a week to start the S3 Batch Operations job.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司有一个应用程序，在Amazon S3存储桶中存储包括个人身份信息(PII)的数据。所有数据都使用AWS KMS客户管理密钥加密。所有AWS资源都从CloudFormation模板部署。DevOps工程师需要在不同的AWS账户中为应用程序设置开发环境。开发环境的S3存储桶中的数据需要每周从生产环境的S3存储桶更新一次。公司不得在未先匿名化PII的情况下从生产环境移动PII。每个环境中的数据必须使用不同的KMS客户管理密钥加密。DevOps工程师应该采取哪些步骤组合来满足这些要求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 在生产账户的S3存储桶上激活Amazon Macie。创建AWS Step Functions状态机来启动发现作业，并在将文件复制到开发账户的S3存储桶之前编辑所有PII。给状态机任务在生产账户KMS密钥上的解密权限，在开发账户KMS密钥上的加密权限。</div> <div class="option-analysis"><strong>B.</strong> 在生产S3存储桶和开发S3存储桶之间设置S3复制。在开发S3存储桶上激活Amazon Macie。创建AWS Step Functions状态机来启动发现作业，并在文件复制到开发S3存储桶时编辑所有PII。给状态机任务在开发账户KMS密钥上的加密和解密权限。</div> <div class="option-analysis"><strong>C.</strong> 设置S3 Batch Operations作业将文件从生产S3存储桶复制到开发S3存储桶。在开发账户中，配置AWS Lambda函数来编辑所有PII。配置S3 Object Lambda为S3 GET请求使用Lambda函数。给Lambda函数的IAM角色在开发账户KMS密钥上的加密和解密权限。</div> <div class="option-analysis"><strong>D.</strong> 从开发账户中的CloudFormation模板创建开发环境。安排Amazon EventBridge规则每周启动一次AWS Step Functions状态机。</div> <div class="option-analysis"><strong>E.</strong> 从开发账户中的CloudFormation模板创建开发环境。在Amazon EC2实例上安排cron作业每周运行一次来启动S3 Batch Operations作业。<div class="section-title"><strong>核心要求:</strong></div> 跨账户数据同步时必须先匿名化PII，使用不同KMS密钥加密，每周定期执行 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• Amazon Macie-检测和编辑PII数据 </div><div class="compact-content">• <span class="key-service">AWS Step Functions</span>-编排数据处理工作流 </div><div class="compact-content">• S3复制-自动化跨账户数据传输 </div><div class="compact-content">• EventBridge-定时触发任务 <div class="section-title"><strong>正确答案BD:</strong></div> S3复制自动处理跨账户传输和KMS密钥切换，Macie在目标端检测和编辑PII，EventBridge提供可靠的定时调度机制 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A-在源端处理PII后再传输，无法利用S3复制的自动化优势，且跨账户权限配置复杂 </div><div class="compact-content">• 选项C-S3 Object Lambda只在读取时处理数据，无法永久匿名化存储的PII数据 </div><div class="compact-content">• 选项E-EC2 cron作业可靠性低，需要额外的实例管理成本和复杂性 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-S3复制提供高效的跨账户数据传输 </div><div class="compact-content">• 成本-无需维护EC2实例，使用托管服务降低运维成本 </div><div class="compact-content">• 可扩展性-Step Functions和EventBridge提供企业级的工作流编排和调度能力</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: BD (B、D)</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-242">
            <div class="question-header">
                <div class="question-title">Question #242 ✅ ⚪ <small style="float: right;">(242/353)</small></div>
            </div>
            <div class="question-content">A company uses an Amazon Elastic Kubernetes Service (<span class="key-service">Amazon EKS</span>) cluster to host its machine learning (ML) application. As the ML model and the container image size grow, the time that new pods take to start up has increased to several minutes. A DevOps engineer needs to reduce the startup time to seconds. The solution must also reduce the startup time to seconds when the pod runs on nodes that were recently added to the cluster. The DevOps engineer creates an Amazon EventBridge rule that invokes an automation in <span class="key-service">AWS Systems Manager</span>. The automation prefetches the container images from an Amazon Elastic Container Registry (<span class="key-service">Amazon ECR</span>) repository when new images are pushed to the repository. The DevOps engineer also configures tags to be applied to the cluster and the node groups. What should the DevOps engineer do next to meet the requirements? C (100%)</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Create an IAM role that has a policy that allows EventBridge to use Systems Manager to run commands in the EKS cluster's control plane nodes. Create a Systems Manager State Manager association that uses the control plane nodes' tags to prefetch corresponding container images.</div>                <div class="option"><strong>B.</strong> Create an IAM role that has a policy that allows EventBridge to use Systems Manager to run commands in the EKS cluster's nodes. Create a Systems Manager State Manager association that uses the nodes' machine size to prefetch corresponding container images.</div>                <div class="option correct-answer"><strong>C.</strong> Create an IAM role that has a policy that allows EventBridge to use Systems Manager to run commands in the EKS cluster's nodes. Create a Systems Manager State Manager association that uses the nodes' tags to prefetch corresponding container images.</div>                <div class="option"><strong>D.</strong> Create an IAM role that has a policy that allows EventBridge to use Systems Manager to run commands in the EKS cluster's control plane nodes. Create a Systems Manager State Manager association that uses the nodes' tags to prefetch corresponding container images.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司使用Amazon EKS集群托管机器学习应用。随着ML模型和容器镜像大小增长，新pod启动时间增加到几分钟。DevOps工程师需要将启动时间减少到秒级，包括在新添加节点上运行的pod。工程师创建了Amazon EventBridge规则调用AWS Systems Manager自动化，在新镜像推送到Amazon ECR时预取容器镜像，并配置了集群和节点组的标签。工程师接下来应该做什么来满足要求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 创建IAM角色，允许EventBridge使用Systems Manager在EKS集群控制平面节点上运行命令。创建Systems Manager State Manager关联，使用控制平面节点标签预取相应容器镜像。</div> <div class="option-analysis"><strong>B.</strong> 创建IAM角色，允许EventBridge使用Systems Manager在EKS集群节点上运行命令。创建Systems Manager State Manager关联，使用节点机器大小预取相应容器镜像。</div> <div class="option-analysis"><strong>C.</strong> 创建IAM角色，允许EventBridge使用Systems Manager在EKS集群节点上运行命令。创建Systems Manager State Manager关联，使用节点标签预取相应容器镜像。</div> <div class="option-analysis"><strong>D.</strong> 创建IAM角色，允许EventBridge使用Systems Manager在EKS集群控制平面节点上运行命令。创建Systems Manager State Manager关联，使用节点标签预取相应容器镜像。<div class="section-title"><strong>核心要求:</strong></div> 通过预取容器镜像将pod启动时间从分钟级减少到秒级 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• <span class="key-service">Amazon EKS</span>-托管Kubernetes集群运行ML应用 </div><div class="compact-content">• Systems Manager State Manager-在工作节点上自动预取容器镜像 </div><div class="compact-content">• EventBridge-触发镜像预取自动化流程 <div class="section-title"><strong>正确答案C:</strong></div> 需要在EKS工作节点（非控制平面）上预取镜像，使用节点标签进行精确定位和管理 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A-控制平面节点不运行应用pod，预取镜像无效 </div><div class="compact-content">• 选项B-使用机器大小而非标签无法精确匹配镜像需求 </div><div class="compact-content">• 选项D-控制平面节点不需要预取应用容器镜像 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-在工作节点预取镜像实现秒级启动 </div><div class="compact-content">• 成本-使用标签精确定位避免不必要的镜像下载 </div><div class="compact-content">• 可扩展性-标签机制支持新节点自动加入预取策略</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: C</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-243">
            <div class="question-header">
                <div class="question-title">Question #243 ✅ 📝 <small style="float: right;">(243/353)</small></div>
            </div>
            <div class="question-content">A company's application has an API that retrieves workload metrics. The company needs to audit, analyze, and visualize these metrics from the application to detect issues at scale. Which combination of steps will meet these requirements? (Choose three.) ACE (100%)</div>
            <div class="options-container">                <div class="option correct-answer"><strong>A.</strong> Configure an Amazon EventBridge schedule to invoke an <span class="key-service">AWS Lambda</span> function that calls the API to retrieve workload metrics. Store the workload metric data in an <span class="key-service">Amazon S3</span> bucket.</div>                <div class="option"><strong>B.</strong> Configure an Amazon EventBridge schedule to invoke an <span class="key-service">AWS Lambda</span> function that calls the API to retrieve workload metrics. Store the workload metric data in an <span class="key-service">Amazon DynamoDB</span> table that has a DynamoDB stream enabled.</div>                <div class="option correct-answer"><strong>C.</strong> Create an AWS Glue crawler to catalog the workload metric data in the <span class="key-service">Amazon S3</span> bucket. Create views in Amazon Athena for the cataloged data.</div>                <div class="option"><strong>D.</strong> Connect an AWS Glue crawler to the <span class="key-service">Amazon DynamoDB</span> stream to catalog the workload metric data. Create views in Amazon Athena for the cataloged data.</div>                <div class="option"><strong>E.</strong> Create Amazon QuickSight datasets from the Amazon Athena views. Create a QuickSight analysis to visualize the workload metric data as a dashboard. F. Create an <span class="key-service">Amazon CloudWatch</span> dashboard that has custom widgets that invoke <span class="key-service">AWS Lambda</span> functions. Configure the Lambda functions to query the workload metrics data from the Amazon Athena views.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司的应用程序有一个检索工作负载指标的API。公司需要审计、分析和可视化这些来自应用程序的指标，以大规模检测问题。哪种步骤组合将满足这些要求？（选择三个。） <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 配置Amazon EventBridge计划调用AWS Lambda函数来调用API检索工作负载指标，将工作负载指标数据存储在Amazon S3存储桶中。</div> <div class="option-analysis"><strong>B.</strong> 配置Amazon EventBridge计划调用AWS Lambda函数来调用API检索工作负载指标，将工作负载指标数据存储在启用了DynamoDB流的Amazon DynamoDB表中。</div> <div class="option-analysis"><strong>C.</strong> 创建AWS Glue爬虫来编目Amazon S3存储桶中的工作负载指标数据，在Amazon Athena中为编目数据创建视图。</div> <div class="option-analysis"><strong>D.</strong> 将AWS Glue爬虫连接到Amazon DynamoDB流来编目工作负载指标数据，在Amazon Athena中为编目数据创建视图。</div> <div class="option-analysis"><strong>E.</strong> 从Amazon Athena视图创建Amazon QuickSight数据集，创建QuickSight分析以将工作负载指标数据可视化为仪表板。 F. 创建具有调用AWS Lambda函数的自定义小部件的Amazon CloudWatch仪表板，配置Lambda函数从Amazon Athena视图查询工作负载指标数据。<div class="section-title"><strong>核心要求:</strong></div> 构建可扩展的指标收集、存储、分析和可视化管道 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• EventBridge+Lambda-定时调用API收集指标 </div><div class="compact-content">• S3-存储大规模指标数据 </div><div class="compact-content">• Glue+Athena-数据编目和查询分析 <div class="section-title"><strong>正确答案ACE:</strong></div> A提供定时数据收集和S3存储，C实现数据编目和查询能力，E提供专业的可视化分析 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项B-DynamoDB不适合大规模指标数据的存储和分析 </div><div class="compact-content">• 选项D-DynamoDB流不是标准的数据编目源 </div><div class="compact-content">• 选项F-CloudWatch自定义小部件过于复杂，不如QuickSight专业 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-S3+Athena支持大规模数据查询分析 </div><div class="compact-content">• 成本-S3存储成本低，按查询付费模式经济 </div><div class="compact-content">• 可扩展性-EventBridge+Lambda+S3架构天然支持大规模扩展</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: AC (A、C)</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-244">
            <div class="question-header">
                <div class="question-title">Question #244 ✅ 📝 <small style="float: right;">(244/353)</small></div>
            </div>
            <div class="question-content">A DevOps engineer is building the infrastructure for an application. The application needs to run on an Amazon Elastic Kubernetes Service (<span class="key-service">Amazon EKS</span>) cluster that includes <span class="key-service">Amazon EC2</span> instances. The EC2 instances need to use an Amazon Elastic File System (<span class="key-service">Amazon <span class="key-service">EFS</span></span>) file system as a storage backend. The <span class="key-service">Amazon <span class="key-service">EFS</span></span> Container Storage Interface (CSI) driver is installed on the EKS cluster. When the DevOps engineer starts the application, the EC2 instances do not mount the <span class="key-service">EFS</span> file system. Which solutions will fix the problem? (Choose three.) BCE (100%)</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Switch the EKS nodes from <span class="key-service">Amazon EC2</span> to <span class="key-service">AWS Fargate</span>.</div>                <div class="option correct-answer"><strong>B.</strong> Add an inbound rule to the <span class="key-service">EFS</span> file system's security group to allow NFS traffic from the EKS cluster.</div>                <div class="option correct-answer"><strong>C.</strong> Create an IAM role that allows the <span class="key-service">Amazon <span class="key-service">EFS</span></span> CSI driver to interact with the file system</div>                <div class="option"><strong>D.</strong> Set up AWS DataSync to configure file transfer between the <span class="key-service">EFS</span> file system and the EKS nodes.</div>                <div class="option"><strong>E.</strong> Create a mount target for the <span class="key-service">EFS</span> file system in the subnet of the EKS nodes. F. Disable encryption for the <span class="key-service">EFS</span> file system.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一名DevOps工程师正在为应用程序构建基础设施。应用程序需要在包含EC2实例的EKS集群上运行。EC2实例需要使用EFS文件系统作为存储后端。<span class="key-service">EFS</span> CSI驱动程序已安装在EKS集群上。当DevOps工程师启动应用程序时，EC2实例无法挂载EFS文件系统。哪些解决方案可以解决这个问题？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 将EKS节点从EC2切换到AWS Fargate</div> <div class="option-analysis"><strong>B.</strong> 在EFS文件系统的安全组中添加入站规则，允许来自EKS集群的NFS流量</div> <div class="option-analysis"><strong>C.</strong> 创建一个IAM角色，允许EFS CSI驱动程序与文件系统交互</div> <div class="option-analysis"><strong>D.</strong> 设置AWS DataSync来配置EFS文件系统和EKS节点之间的文件传输</div> <div class="option-analysis"><strong>E.</strong> 在EKS节点的子网中为EFS文件系统创建挂载目标 F. 禁用EFS文件系统的加密<div class="section-title"><strong>核心要求:</strong></div> 解决EKS集群中EC2实例无法挂载EFS文件系统的问题 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• EKS-容器编排服务，需要正确的网络和权限配置来访问EFS </div><div class="compact-content">• <span class="key-service">EFS</span>-网络文件系统，需要安全组规则和CSI驱动程序权限才能被挂载 <div class="section-title"><strong>正确答案BC:</strong></div> B选项配置安全组允许NFS流量(端口2049)从EKS节点访问EFS；C选项为EFS CSI驱动程序提供必要的IAM权限来管理文件系统挂载操作 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A-切换到Fargate不解决挂载问题，且题目明确要求使用EC2实例 </div><div class="compact-content">• 选项D-DataSync用于数据同步而非文件系统挂载，不解决根本问题 </div><div class="compact-content">• 选项E-挂载目标通常在EFS创建时自动配置，不是主要问题 </div><div class="compact-content">• 选项F-加密状态不影响文件系统挂载功能 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-正确的网络和权限配置确保EFS挂载性能 </div><div class="compact-content">• 成本-使用现有安全组和IAM角色配置，无额外成本 </div><div class="compact-content">• 可扩展性-安全组和IAM权限配置支持集群扩展需求</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: BC (B、C)</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-245">
            <div class="question-header">
                <div class="question-title">Question #245 ✅ 📝 <small style="float: right;">(245/353)</small></div>
            </div>
            <div class="question-content">A company deploys an application on on-premises devices in the company's on-premises data center. The company uses an AWS Direct Connect connection between the data center and the company's AWS account. During initial setup of the on-premises devices and during application updates, the application needs to retrieve configuration files from an Amazon Elastic File System (<span class="key-service">Amazon <span class="key-service">EFS</span></span>) file system. All traffic from the on-premises devices to <span class="key-service">Amazon <span class="key-service">EFS</span></span> must remain private and encrypted. The on-premises devices must follow the principle of least privilege for AWS access. The company's DevOps team needs the ability to revoke access from a single device without affecting the access of the other devices. Which combination of steps will meet these requirements? (Choose two.) BD (100%)</div>
            <div class="options-container">                <div class="option correct-answer"><strong>A.</strong> Create an IAM user that has an access key and a secret key for each device. Attach the AmazonElasticFileSystemFullAccess policy to all IAM users. Configure the AWS CLI on the on-premises devices to use the IAM user's access key and secret key.</div>                <div class="option"><strong>B.</strong> Generate certificates for each on-premises device in AWS Private Certificate Authority. Create a trust anchor in IAM Roles Anywhere that references an AWS Private C<div class="option-analysis"><strong>A.</strong> Create an IAM role that trusts IAM Roles Anywhere. Attach the AmazonElasticFileSystemClientReadWriteAccess to the role. Create an IAM Roles Anywhere profile for the IAM role. Configure the AWS CLI on the on-premises devices to use the aws_signing_helper command to obtain credentials. Most Voted</div></div>                <div class="option"><strong>C.</strong> Create an IAM user that has an access key and a secret key for all devices. Attach the AmazonElasticFileSystemClientReadWriteAccess policy to the IAM user. Configure the AWS CLI on the on-premises devices to use the IAM user's access key and secret key.</div>                <div class="option correct-answer"><strong>D.</strong> Use the amazon-<span class="key-service">efs</span>-utils package to mount the <span class="key-service">EFS</span> file system.</div>                <div class="option"><strong>E.</strong> Use the native Linux NFS client to mount the <span class="key-service">EFS</span> file system.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司在本地数据中心的设备上部署应用程序，使用AWS Direct Connect连接数据中心和AWS账户。在设备初始设置和应用更新期间，应用需要从Amazon EFS文件系统检索配置文件。所有从本地设备到Amazon EFS的流量必须保持私有和加密。本地设备必须遵循AWS访问的最小权限原则。DevOps团队需要能够撤销单个设备的访问权限而不影响其他设备。 <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 为每个设备创建具有访问密钥和秘密密钥的IAM用户，为所有IAM用户附加AmazonElasticFileSystemFullAccess策略，在本地设备上配置AWS CLI使用IAM用户的访问密钥和秘密密钥</div> <div class="option-analysis"><strong>B.</strong> 在AWS Private Certificate Authority中为每个本地设备生成证书，在IAM Roles Anywhere中创建引用AWS Private CA的信任锚点，创建信任IAM Roles Anywhere的IAM角色，为角色附加AmazonElasticFileSystemClientReadWriteAccess，为IAM角色创建IAM Roles Anywhere配置文件，在本地设备上配置AWS CLI使用aws_signing_helper命令获取凭证</div> <div class="option-analysis"><strong>C.</strong> 为所有设备创建具有访问密钥和秘密密钥的IAM用户，为IAM用户附加AmazonElasticFileSystemClientReadWriteAccess策略，在本地设备上配置AWS CLI使用IAM用户的访问密钥和秘密密钥</div> <div class="option-analysis"><strong>D.</strong> 使用amazon-<span class="key-service">efs</span>-utils包挂载EFS文件系统</div> <div class="option-analysis"><strong>E.</strong> 使用原生Linux NFS客户端挂载EFS文件系统<div class="section-title"><strong>核心要求:</strong></div> 本地设备通过Direct Connect私有加密访问EFS，支持单设备权限撤销和最小权限原则 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• <span class="key-service">Amazon <span class="key-service">EFS</span></span>-提供可扩展的网络文件系统存储 </div><div class="compact-content">• AWS Direct Connect-提供本地到AWS的专用网络连接 </div><div class="compact-content">• IAM-管理访问权限和身份验证 <div class="section-title"><strong>正确答案AD:</strong></div> A选项为每设备创建独立IAM用户实现单设备权限撤销，D选项使用amazon-<span class="key-service">efs</span>-utils提供加密传输和优化的EFS访问 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项B-IAM Roles Anywhere主要用于外部身份提供商集成，对于简单的设备访问过于复杂 </div><div class="compact-content">• 选项C-所有设备共享同一IAM用户无法实现单设备权限撤销要求 </div><div class="compact-content">• 选项E-原生NFS客户端缺乏加密传输和AWS集成优化功能 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 安全性-每设备独立凭证，加密传输，最小权限 </div><div class="compact-content">• 管理性-支持单设备权限撤销，简化运维 </div><div class="compact-content">• 兼容性-与Direct Connect和EFS的最佳集成</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: AD (A、D)</strong>
                </div>
            </div>
        </div>
        <div class="question-block failed" id="question-246">
            <div class="question-header">
                <div class="question-title">Question #246 ❌ ⚪ <small style="float: right;">(246/353)</small></div>
            </div>
            <div class="question-content">A DevOps engineer is setting up an Amazon Elastic Container Service (<span class="key-service">Amazon ECS</span>) blue/green deployment for an application by using <span class="key-service">AWS CodeDeploy</span> and <span class="key-service">AWS CloudFormation</span>. During the deployment window, the application must be highly available and CodeDeploy must shift 10% of traffic to a new version of the application every minute until all traffic is shifted. Which configuration should the DevOps engineer add in the CloudFormation template to meet these requirements? B (100%)</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Add an AppSpec file with the CodeDeployDefault.ECSLinear10PercentEvery1Minutes deployment configuration.</div>                <div class="option correct-answer"><strong>B.</strong> Add the AWS::CodeDeployBlueGreen transform and the AWS::CodeDeploy::BlueGreen hook parameter with the CodeDeployDefault.ECSLinear10PercentEvery1Minutes deployment configuration.</div>                <div class="option"><strong>C.</strong> Add an AppSpec file with the ECSCanary10Percent5Minutes deployment configuration.</div>                <div class="option"><strong>D.</strong> Add the AWS::CodeDeployBlueGreen transform and the AWS::CodeDeploy::BlueGreen hook parameter with the ECSCanary10Percent5Minutes deployment configuration.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="failure">Analysis failed - please retry</div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: B</strong>
                </div>
            </div>
        </div>
        <div class="question-block failed" id="question-247">
            <div class="question-header">
                <div class="question-title">Question #247 ❌ ⚪ <small style="float: right;">(247/353)</small></div>
            </div>
            <div class="question-content">A company uses an organization in <span class="key-service">AWS Organizations</span> to manage its AWS accounts. The company's DevOps team has developed an <span class="key-service">AWS Lambda</span> function that calls the Organizations API to create new AWS accounts. The Lambda function runs in the organization's management account. The DevOps team needs to move the Lambda function from the management account to a dedicated AWS account. The DevOps team must ensure that the Lambda function has the ability to create new AWS accounts only in Organizations before the team deploys the Lambda function to the new account. Which solution will meet these requirements? A (100%)</div>
            <div class="options-container">                <div class="option correct-answer"><strong>A.</strong> In the management account, create a new IAM role that has the necessary permission to create new accounts in Organizations. Allow the role to be assumed by the Lambda execution role in the new AWS account. Update the Lambda function code to assume the role when the Lambda function creates new AWS accounts. Update the Lambda execution role to ensure that it has permission to assume the new role.</div>                <div class="option"><strong>B.</strong> In the management account, turn on delegated administration for Organizations. Create a new delegation policy that grants the new AWS account permission to create new AWS accounts in Organizations. Ensure that the Lambda execution role has the organizations:CreateAccount permission.</div>                <div class="option"><strong>C.</strong> In the management account, create a new IAM role that has the necessary permission to create new accounts in Organizations. Allow the role to be assumed by the Lambda service principal. Update the Lambda function code to assume the role when the Lambda function creates new AWS accounts. Update the Lambda execution role to ensure that it has permission to assume the new role.</div>                <div class="option"><strong>D.</strong> In the management account, enable AWS Control Tower. Turn on delegated administration for AWS Control Tower. Create a resource policy that allows the new AWS account to create new AWS accounts in AWS Control Tower. Update the Lambda function code to use the AWS Control Tower API in the new AWS account. Ensure that the Lambda execution role has the controltower:CreateManagedAccount permission.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="failure">Analysis failed - please retry</div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: A</strong>
                </div>
            </div>
        </div>
        <div class="question-block failed" id="question-248">
            <div class="question-header">
                <div class="question-title">Question #248 ❌ ⚪ <small style="float: right;">(248/353)</small></div>
            </div>
            <div class="question-content">A company has deployed an application in a single AWS Region. The application backend uses <span class="key-service">Amazon DynamoDB</span> tables and <span class="key-service">Amazon S3</span> buckets. The company wants to deploy the application in a secondary Region. The company must ensure that the data in the DynamoDB tables and the S3 buckets persists across both Regions. The data must also immediately propagate across Regions. Which solution will meet these requirements with the MOST operational efficiency? A (100%)</div>
            <div class="options-container">                <div class="option correct-answer"><strong>A.</strong> Implement two-way S3 bucket replication between the primary Region's S3 buckets and the secondary Region's S3 buckets. Convert the DynamoDB tables into global tables. Set the secondary Region as the additional Region.</div>                <div class="option"><strong>B.</strong> Implement S3 Batch Operations copy jobs between the primary Region and the secondary Region for all S3 buckets. Convert the DynamoDB tables into global tables. Set the secondary Region as the additional Region.</div>                <div class="option"><strong>C.</strong> Implement two-way S3 bucket replication between the primary Region's S3 buckets and the secondary Region's S3 buckets. Enable DynamoDB streams on the DynamoDB tables in both Regions. In each Region, create an <span class="key-service">AWS Lambda</span> function that subscribes to the DynamoDB streams. Configure the Lambda function to copy new records to the DynamoDB tables in the other Region.</div>                <div class="option"><strong>D.</strong> Implement S3 Batch Operations copy jobs between the primary Region and the secondary Region for all S3 buckets. Enable DynamoDB streams on the DynamoDB tables in both Regions. In each Region, create an <span class="key-service">AWS Lambda</span> function that subscribes to the DynamoDB streams. Configure the Lambda function to copy new records to the DynamoDB tables in the other Region.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="failure">Analysis failed - please retry</div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: A</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-249">
            <div class="question-header">
                <div class="question-title">Question #249 ✅ ⚪ <small style="float: right;">(249/353)</small></div>
            </div>
            <div class="question-content">A company has configured <span class="key-service">Amazon RDS</span> storage autoscaling for its RDS DB instances. A DevOps team needs to visualize the autoscaling events on an <span class="key-service">Amazon CloudWatch</span> dashboard. Which solution will meet this requirement? A (100%)</div>
            <div class="options-container">                <div class="option correct-answer"><strong>A.</strong> Create an Amazon EventBridge rule that reacts to RDS storage autoscaling events from RDS events. Create an <span class="key-service">AWS Lambda</span> function that publishes a CloudWatch custom metric. Configure the EventBridge rule to invoke the Lambda function. Visualize the custom metric by using the CloudWatch dashboard.</div>                <div class="option"><strong>B.</strong> Create a trail by using <span class="key-service">AWS CloudTrail</span> with management events configured. Configure the trail to send the management events to <span class="key-service">Amazon CloudWatch</span> Logs. Create a metric filter in CloudWatch Logs to match the RDS storage autoscaling events. Visualize the metric filter by using the CloudWatch dashboard.</div>                <div class="option"><strong>C.</strong> Create an Amazon EventBridge rule that reacts to RDS storage autoscaling events from the RDS events. Create a CloudWatch alarm. Configure the EventBridge rule to change the status of the CloudWatch alarm. Visualize the alarm status by using the CloudWatch dashboard.</div>                <div class="option"><strong>D.</strong> Create a trail by using <span class="key-service">AWS CloudTrail</span> with data events configured. Configure the trail to send the data events to <span class="key-service">Amazon CloudWatch</span> Logs. Create a metric filter in CloudWatch Logs to match the RDS storage autoscaling events. Visualize the metric filter by using the CloudWatch dashboard.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司为其RDS DB实例配置了Amazon RDS存储自动扩展。DevOps团队需要在Amazon CloudWatch仪表板上可视化自动扩展事件。哪种解决方案能满足这个要求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 创建Amazon EventBridge规则来响应来自RDS事件的RDS存储自动扩展事件。创建AWS Lambda函数来发布CloudWatch自定义指标。配置EventBridge规则调用Lambda函数。使用CloudWatch仪表板可视化自定义指标。</div> <div class="option-analysis"><strong>B.</strong> 使用AWS CloudTrail创建配置了管理事件的跟踪。配置跟踪将管理事件发送到Amazon CloudWatch Logs。在CloudWatch Logs中创建指标过滤器来匹配RDS存储自动扩展事件。使用CloudWatch仪表板可视化指标过滤器。</div> <div class="option-analysis"><strong>C.</strong> 创建Amazon EventBridge规则来响应来自RDS事件的RDS存储自动扩展事件。创建CloudWatch告警。配置EventBridge规则来改变CloudWatch告警的状态。使用CloudWatch仪表板可视化告警状态。</div> <div class="option-analysis"><strong>D.</strong> 使用AWS CloudTrail创建配置了数据事件的跟踪。配置跟踪将数据事件发送到Amazon CloudWatch Logs。在CloudWatch Logs中创建指标过滤器来匹配RDS存储自动扩展事件。使用CloudWatch仪表板可视化指标过滤器。<div class="section-title"><strong>核心要求:</strong></div> 在CloudWatch仪表板上可视化RDS存储自动扩展事件 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• EventBridge-捕获RDS自动扩展事件 </div><div class="compact-content">• Lambda-处理事件并发布自定义指标 </div><div class="compact-content">• CloudWatch-提供指标可视化 <div class="section-title"><strong>正确答案A:</strong></div> 使用EventBridge捕获RDS存储自动扩展事件，通过Lambda函数将事件转换为CloudWatch自定义指标，实现最佳的事件驱动可视化 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项B-CloudTrail管理事件不包含RDS存储自动扩展事件 </div><div class="compact-content">• 选项C-告警状态变化不适合持续的事件可视化需求 </div><div class="compact-content">• 选项D-CloudTrail数据事件主要用于S3和Lambda，不涵盖RDS自动扩展 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-EventBridge实时事件处理，响应迅速 </div><div class="compact-content">• 成本-按事件付费，成本效益高 </div><div class="compact-content">• 可扩展性-事件驱动架构，自动处理所有扩展事件</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: A</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-250">
            <div class="question-header">
                <div class="question-title">Question #250 ✅ ⚪ <small style="float: right;">(250/353)</small></div>
            </div>
            <div class="question-content">A company uses containers for its applications. The company learns that some container images are missing required security configurations. A DevOps engineer needs to implement a solution to create a standard base image. The solution must publish the base image weekly to the us-west-2 Region, us-east-2 Region, and eu-central-1 Region. Which solution will meet these requirements? C (80%) A (20%)</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Create an EC2 Image Builder pipeline that uses a container recipe to build the image. Configure the pipeline to distribute the image to an Amazon Elastic Container Registry (<span class="key-service">Amazon ECR</span>) repository in us-west-2. Configure ECR replication from us-west-2 to us-east-2 and from us-east-2 to eu-central-1. Configure the pipeline to run weekly.</div>                <div class="option"><strong>B.</strong> Create an <span class="key-service">AWS CodePipeline</span> pipeline that uses an <span class="key-service">AWS CodeBuild</span> project to build the image. Use <span class="key-service">AWS CodeDeploy</span> to publish the image to an Amazon Elastic Container Registry (<span class="key-service">Amazon ECR</span>) repository in us-west-2. Configure ECR replication from us-west-2 to us-east-2 and from us-east-2 to eu-central-1. Configure the pipeline to run weekly.</div>                <div class="option correct-answer"><strong>C.</strong> Create an EC2 Image Builder pipeline that uses a container recipe to build the image. Configure the pipeline to distribute the image to Amazon Elastic Container Registry (<span class="key-service">Amazon ECR</span>) repositories in all three Regions. Configure the pipeline to run weekly.</div>                <div class="option"><strong>D.</strong> Create an <span class="key-service">AWS CodePipeline</span> pipeline that uses an <span class="key-service">AWS CodeBuild</span> project to build the image. Use <span class="key-service">AWS CodeDeploy</span> to publish the image to Amazon Elastic Container Registry (<span class="key-service">Amazon ECR</span>) repositories in all three Regions. Configure the pipeline to run weekly.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司使用容器运行应用程序。公司发现某些容器镜像缺少必需的安全配置。DevOps工程师需要实施解决方案来创建标准基础镜像。该解决方案必须每周将基础镜像发布到us-west-2、us-east-2和eu-central-1三个区域。 <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 创建使用容器配方构建镜像的EC2 Image Builder管道，配置管道将镜像分发到us-west-2的Amazon ECR存储库，配置ECR从us-west-2复制到us-east-2再到eu-central-1，设置管道每周运行。</div> <div class="option-analysis"><strong>B.</strong> 创建使用AWS CodeBuild项目构建镜像的AWS CodePipeline管道，使用AWS CodeDeploy将镜像发布到us-west-2的Amazon ECR存储库，配置ECR从us-west-2复制到us-east-2再到eu-central-1，设置管道每周运行。</div> <div class="option-analysis"><strong>C.</strong> 创建使用容器配方构建镜像的EC2 Image Builder管道，配置管道将镜像分发到所有三个区域的Amazon ECR存储库，设置管道每周运行。</div> <div class="option-analysis"><strong>D.</strong> 创建使用AWS CodeBuild项目构建镜像的AWS CodePipeline管道，使用AWS CodeDeploy将镜像发布到所有三个区域的Amazon ECR存储库，设置管道每周运行。<div class="section-title"><strong>核心要求:</strong></div> 创建标准容器基础镜像并每周自动发布到三个区域 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• EC2 Image Builder-专门用于构建和管理标准化镜像的托管服务 </div><div class="compact-content">• <span class="key-service">Amazon ECR</span>-容器镜像存储和管理服务 <div class="section-title"><strong>正确答案C:</strong></div> EC2 Image Builder原生支持容器镜像构建和多区域分发，可直接配置将镜像同时发布到多个区域的ECR存储库，无需额外的复制步骤 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A-使用链式ECR复制增加了复杂性和延迟，不如直接多区域分发高效 </div><div class="compact-content">• 选项B-CodeDeploy不适用于容器镜像发布，且ECR复制方案过于复杂 </div><div class="compact-content">• 选项D-CodeDeploy不支持ECR镜像发布功能，技术方案不可行 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-直接多区域分发比链式复制更快更可靠 </div><div class="compact-content">• 成本-EC2 Image Builder比CodePipeline+CodeBuild组合更经济 </div><div class="compact-content">• 可扩展性-Image Builder原生多区域支持便于后续扩展到更多区域</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: C</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-251">
            <div class="question-header">
                <div class="question-title">Question #251 ✅ ⚪ <small style="float: right;">(251/353)</small></div>
            </div>
            <div class="question-content">A DevOps engineer needs to implement a solution to install antivirus software on all the <span class="key-service">Amazon EC2</span> instances in an AWS account. The EC2 instances run the most recent version of Amazon Linux. The solution must detect all instances and must use an <span class="key-service">AWS Systems Manager</span> document to install the software if the software is not present. Which solution will meet these requirements? A (100%)</div>
            <div class="options-container">                <div class="option correct-answer"><strong>A.</strong> Create an association in Systems Manager State Manager. Target all the managed nodes. Include the software in the association. Configure the association to use the Systems Manager document.</div>                <div class="option"><strong>B.</strong> Set up <span class="key-service">AWS Config</span> to record all the resources in the account. Create an <span class="key-service">AWS Config</span> custom rule to determine if the software is installed on all the EC2 instances. Configure an automatic remediation action that uses the Systems Manager document for noncompliant EC2 instances.</div>                <div class="option"><strong>C.</strong> Activate <span class="key-service">Amazon EC2</span> scanning on Amazon Inspector to determine if the software is installed on all the EC2 instances. Associate the findings with the Systems Manager document.</div>                <div class="option"><strong>D.</strong> Create an Amazon EventBridge rule that uses <span class="key-service">AWS CloudTrail</span> to detect the RunInstances API call. Configure inventory collection in Systems Manager Inventory to determine if the software is installed on the EC2 instances. Associate the Systems Manager inventory with the Systems Manager document.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一名DevOps工程师需要实施一个解决方案，在AWS账户中的所有Amazon EC2实例上安装防病毒软件。EC2实例运行最新版本的Amazon Linux。解决方案必须检测所有实例，并且必须使用AWS Systems Manager文档在软件不存在时安装软件。 <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 在Systems Manager State Manager中创建关联，目标为所有托管节点，在关联中包含软件，配置关联使用Systems Manager文档</div> <div class="option-analysis"><strong>B.</strong> 设置AWS Config记录账户中的所有资源，创建AWS Config自定义规则确定软件是否安装在所有EC2实例上，为不合规的EC2实例配置使用Systems Manager文档的自动修复操作</div> <div class="option-analysis"><strong>C.</strong> 在Amazon Inspector上激活Amazon EC2扫描以确定软件是否安装在所有EC2实例上，将发现结果与Systems Manager文档关联</div> <div class="option-analysis"><strong>D.</strong> 创建使用AWS CloudTrail检测RunInstances API调用的Amazon EventBridge规则，在Systems Manager Inventory中配置清单收集以确定软件是否安装在EC2实例上，将Systems Manager清单与Systems Manager文档关联<div class="section-title"><strong>核心要求:</strong></div> 在所有EC2实例上自动检测并安装防病毒软件 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• Systems Manager State Manager-管理实例配置状态和自动化软件安装 </div><div class="compact-content">• Systems Manager Document-定义自动化任务和软件安装步骤 <div class="section-title"><strong>正确答案A:</strong></div> State Manager关联可以持续监控所有托管节点的状态，自动检测软件是否存在，并在需要时执行Systems Manager文档进行安装，完全满足自动化和持续合规要求 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项B-AWS Config主要用于合规性检查而非持续的软件管理，自动修复功能相对复杂且不是专门为软件安装设计 </div><div class="compact-content">• 选项C-Amazon Inspector主要用于安全漏洞扫描，不是软件安装管理工具，无法直接执行安装任务 </div><div class="compact-content">• 选项D-过于复杂，只能检测新实例创建但无法管理现有实例，且EventBridge+CloudTrail+Inventory的组合不如State Manager直接有效 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-State Manager提供原生的持续配置管理和自动化执行能力 </div><div class="compact-content">• 成本-使用专门的State Manager服务比组合多个服务更经济高效 </div><div class="compact-content">• 可扩展性-State Manager可自动管理所有当前和未来的托管节点</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: A</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-252">
            <div class="question-header">
                <div class="question-title">Question #252 ✅ 📝 <small style="float: right;">(252/353)</small></div>
            </div>
            <div class="question-content">A company needs to increase the security of the container images that run in its production environment. The company wants to integrate operating system scanning and programming language package vulnerability scanning for the containers in its CI/CD pipeline. The CI/CD pipeline is an <span class="key-service">AWS CodePipeline</span> pipeline that includes an <span class="key-service">AWS CodeBuild</span> build project, <span class="key-service">AWS CodeDeploy</span> actions, and an Amazon Elastic Container Registry (<span class="key-service">Amazon ECR</span>) repository. A DevOps engineer needs to add an image scan to the CI/CD pipeline. The CI/CD pipeline must deploy only images without CRITICAL and HIGH findings into production. Which combination of steps will meet these requirements? (Choose two.) BD (100%)</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Use <span class="key-service">Amazon ECR</span> basic scanning.</div>                <div class="option correct-answer"><strong>B.</strong> Use <span class="key-service">Amazon ECR</span> enhanced scanning.</div>                <div class="option"><strong>C.</strong> Configure <span class="key-service">Amazon ECR</span> to submit a Rejected status to the CI/CD pipeline when the image scan returns CRITICAL or HIGH findings.</div>                <div class="option correct-answer"><strong>D.</strong> Configure an Amazon EventBridge rule to invoke an <span class="key-service">AWS Lambda</span> function when the image scan is completed. Configure the Lambda function to consume the Amazon Inspector scan status and to submit an Approved or Rejected status to the CI/CD pipeline.</div>                <div class="option"><strong>E.</strong> Configure an Amazon EventBridge rule to invoke an <span class="key-service">AWS Lambda</span> function when the image scan is completed. Configure the Lambda function to consume the Clair scan status and to submit an Approved or Rejected status to the CI/CD pipeline.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司需要提高生产环境中运行的容器镜像的安全性。公司希望在CI/CD管道中集成操作系统扫描和编程语言包漏洞扫描。CI/CD管道是AWS CodePipeline管道，包括AWS CodeBuild构建项目、AWS CodeDeploy操作和Amazon ECR存储库。DevOps工程师需要向CI/CD管道添加镜像扫描。CI/CD管道必须仅将没有CRITICAL和HIGH发现的镜像部署到生产环境。 <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 使用Amazon ECR基础扫描</div> <div class="option-analysis"><strong>B.</strong> 使用Amazon ECR增强扫描</div> <div class="option-analysis"><strong>C.</strong> 配置Amazon ECR在镜像扫描返回CRITICAL或HIGH发现时向CI/CD管道提交拒绝状态</div> <div class="option-analysis"><strong>D.</strong> 配置Amazon EventBridge规则在镜像扫描完成时调用AWS Lambda函数，配置Lambda函数使用Amazon Inspector扫描状态并向CI/CD管道提交批准或拒绝状态</div> <div class="option-analysis"><strong>E.</strong> 配置Amazon EventBridge规则在镜像扫描完成时调用AWS Lambda函数，配置Lambda函数使用Clair扫描状态并向CI/CD管道提交批准或拒绝状态<div class="section-title"><strong>核心要求:</strong></div> 在CI/CD管道中集成容器镜像的操作系统和编程语言包漏洞扫描，阻止CRITICAL和HIGH漏洞镜像部署 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• <span class="key-service">Amazon ECR</span> Enhanced Scanning-提供操作系统和编程语言包漏洞扫描 </div><div class="compact-content">• Amazon Inspector-ECR增强扫描的底层扫描引擎 </div><div class="compact-content">• Amazon EventBridge-监听扫描完成事件并触发后续处理 <div class="section-title"><strong>正确答案BD:</strong></div> ECR增强扫描提供全面的漏洞检测能力，EventBridge+Lambda实现扫描结果的自动化处理和CI/CD管道状态控制 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A-基础扫描仅检测已知CVE，不支持编程语言包扫描 </div><div class="compact-content">• 选项C-ECR本身不能直接向CI/CD管道提交状态，需要额外的集成机制 </div><div class="compact-content">• 选项E-Clair不是ECR增强扫描使用的扫描引擎，应该是Amazon Inspector <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-增强扫描提供更全面的漏洞检测覆盖 </div><div class="compact-content">• 成本-EventBridge和Lambda按使用量计费，成本可控 </div><div class="compact-content">• 可扩展性-基于事件驱动架构，可自动处理任意数量的镜像扫描</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: BD (B、D)</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-253">
            <div class="question-header">
                <div class="question-title">Question #253 ✅ ⚪ <small style="float: right;">(253/353)</small></div>
            </div>
            <div class="question-content">A company's DevOps team manages a set of AWS accounts that are in an organization in <span class="key-service">AWS Organizations</span>. The company needs a solution that ensures that all <span class="key-service">Amazon EC2</span> instances use approved AMIs that the DevOps team manages. The solution also must remediate the usage of AMIs that are not approved. The individual account administrators must not be able to remove the restriction to use approved AMIs. Which solution will meet these requirements? D (100%)</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Use <span class="key-service">AWS CloudFormation</span> StackSets to deploy an Amazon EventBridge rule to each account. Configure the rule to react to <span class="key-service">AWS CloudTrail</span> events for <span class="key-service">Amazon EC2</span> and to send a notification to an Amazon Simple Notification Service (<span class="key-service">Amazon SNS</span>) topic. Subscribe the DevOps team to the SNS topic.</div>                <div class="option"><strong>B.</strong> Use <span class="key-service">AWS CloudFormation</span> StackSets to deploy the approved-amis-by-id <span class="key-service">AWS Config</span> managed rule to each account. Configure the rule with the list of approved AMIs. Configure the rule to run the AWS-StopEC2Instance <span class="key-service">AWS Systems Manager</span> Automation runbook for the noncompliant EC2 instances.</div>                <div class="option"><strong>C.</strong> Create an <span class="key-service">AWS Lambda</span> function that processes <span class="key-service">AWS CloudTrail</span> events for <span class="key-service">Amazon EC2</span>. Configure the Lambda function to send a notification to an Amazon Simple Notification Service (<span class="key-service">Amazon SNS</span>) topic. Subscribe the DevOps team to the SNS topic. Deploy the Lambda function in each account in the organization. Create an Amazon EventBridge rule in each account. Configure the EventBridge rules to react to <span class="key-service">AWS CloudTrail</span> events for <span class="key-service">Amazon EC2</span> and to invoke the Lambda function.</div>                <div class="option correct-answer"><strong>D.</strong> Enable <span class="key-service">AWS Config</span> across the organization. Create a conformance pack that uses the approved-amis-by-id <span class="key-service">AWS Config</span> managed rule with the list of approved AMIs. Deploy the conformance pack across the organization. Configure the rule to run the AWS-StopEC2Instance <span class="key-service">AWS Systems Manager</span> Automation runbook for the noncompliant EC2 instances.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司的DevOps团队管理AWS Organizations中的一组AWS账户。公司需要确保所有EC2实例使用DevOps团队管理的已批准AMI，并修复使用未批准AMI的情况。各账户管理员不能移除使用已批准AMI的限制。 <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 使用CloudFormation StackSets在每个账户部署EventBridge规则，配置规则响应EC2的CloudTrail事件并发送通知到SNS主题，DevOps团队订阅SNS主题。</div> <div class="option-analysis"><strong>B.</strong> 使用CloudFormation StackSets在每个账户部署approved-amis-by-id Config托管规则，配置已批准AMI列表，为不合规EC2实例运行AWS-StopEC2Instance Systems Manager自动化运行手册。</div> <div class="option-analysis"><strong>C.</strong> 创建处理EC2 CloudTrail事件的Lambda函数，配置函数发送通知到SNS主题，DevOps团队订阅主题，在组织每个账户部署Lambda函数，创建EventBridge规则响应EC2 CloudTrail事件并调用Lambda函数。</div> <div class="option-analysis"><strong>D.</strong> 在组织中启用Config，创建使用approved-amis-by-id Config托管规则和已批准AMI列表的合规包，在组织中部署合规包，配置规则为不合规EC2实例运行AWS-StopEC2Instance Systems Manager自动化运行手册。<div class="section-title"><strong>核心要求:</strong></div> 在组织级别强制使用已批准AMI并自动修复违规，防止账户管理员绕过限制 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• <span class="key-service">AWS Config</span> - 监控资源合规性和自动修复 </div><div class="compact-content">• <span class="key-service">AWS Organizations</span> - 组织级别统一管理 </div><div class="compact-content">• Systems Manager Automation - 自动化修复操作 <div class="section-title"><strong>正确答案D:</strong></div> 使用Config conformance pack在组织级别部署合规规则，通过approved-amis-by-id规则检测违规AMI，自动运行停止实例的修复操作，账户管理员无法移除组织级别的限制 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A - 仅提供通知功能，无自动修复能力，不满足修复要求 </div><div class="compact-content">• 选项B - 使用StackSets部署到各账户，账户管理员可能移除限制，不满足防篡改要求 </div><div class="compact-content">• 选项C - 仅提供通知功能，无合规检查和自动修复，架构复杂但功能不足 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能 - 组织级别统一管理，避免重复部署 </div><div class="compact-content">• 成本 - Config conformance pack成本效益高于多账户重复部署 </div><div class="compact-content">• 可扩展性 - 组织级别部署自动覆盖新账户，管理简化</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: D</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-254">
            <div class="question-header">
                <div class="question-title">Question #254 ✅ ⚪ <small style="float: right;">(254/353)</small></div>
            </div>
            <div class="question-content">A company gives its employees limited rights to AWS. DevOps engineers have the ability to assume an administrator role. For tracking purposes, the security team wants to receive a near-real-time notification when the administrator role is assumed. How should this be accomplished? D (100%)</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Configure <span class="key-service">AWS Config</span> to publish logs to an <span class="key-service">Amazon S3</span> bucket. Use Amazon Athena to query the logs and send a notification to the security team when the administrator role is assumed.</div>                <div class="option"><strong>B.</strong> Configure <span class="key-service">Amazon GuardDuty</span> to monitor when the administrator role is assumed and send a notification to the security team.</div>                <div class="option"><strong>C.</strong> Create an Amazon EventBridge event rule using an AWS Management Console sign-in events event pattern that publishes a message to an <span class="key-service">Amazon SNS</span> topic if the administrator role is assumed.</div>                <div class="option correct-answer"><strong>D.</strong> Create an Amazon EventBridge events rule using an AWS API call that uses an <span class="key-service">AWS CloudTrail</span> event pattern to invoke an <span class="key-service">AWS Lambda</span> function that publishes a message to an <span class="key-service">Amazon SNS</span> topic if the administrator role is assumed.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司给员工有限的AWS权限。DevOps工程师能够担任管理员角色。出于跟踪目的，安全团队希望在管理员角色被担任时收到近实时通知。应该如何实现？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 配置AWS Config将日志发布到Amazon S3存储桶。使用Amazon Athena查询日志，当管理员角色被担任时向安全团队发送通知。</div> <div class="option-analysis"><strong>B.</strong> 配置Amazon GuardDuty监控管理员角色被担任的情况，并向安全团队发送通知。</div> <div class="option-analysis"><strong>C.</strong> 创建Amazon EventBridge事件规则，使用AWS Management Console登录事件模式，如果管理员角色被担任则向Amazon SNS主题发布消息。</div> <div class="option-analysis"><strong>D.</strong> 创建Amazon EventBridge事件规则，使用AWS API调用和AWS CloudTrail事件模式来调用AWS Lambda函数，如果管理员角色被担任则向Amazon SNS主题发布消息。<div class="section-title"><strong>核心要求:</strong></div> 实现管理员角色担任的近实时通知监控 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• <span class="key-service">AWS CloudTrail</span>-记录API调用和角色担任活动 </div><div class="compact-content">• Amazon EventBridge-提供近实时事件处理和路由 </div><div class="compact-content">• <span class="key-service">AWS Lambda</span>-执行通知逻辑处理 <div class="section-title"><strong>正确答案D:</strong></div> CloudTrail捕获AssumeRole API调用，EventBridge基于CloudTrail事件模式触发Lambda函数，Lambda处理后通过SNS发送通知，实现完整的近实时监控链路 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A-AWS Config主要用于配置合规性监控，不是实时事件处理，Athena查询延迟高 </div><div class="compact-content">• 选项B-GuardDuty专注于安全威胁检测，不监控正常的角色担任活动 </div><div class="compact-content">• 选项C-Management Console登录事件无法捕获程序化的角色担任操作 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-EventBridge+Lambda提供毫秒级近实时响应 </div><div class="compact-content">• 成本-按事件付费模式，成本效益高 </div><div class="compact-content">• 可扩展性-无服务器架构自动扩展，支持高频角色切换</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: D</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-255">
            <div class="question-header">
                <div class="question-title">Question #255 ✅ 📝 <small style="float: right;">(255/353)</small></div>
            </div>
            <div class="question-content">A company needs a strategy for failover and disaster recovery of its data and application. The application uses a MySQL database and <span class="key-service">Amazon EC2</span> instances. The company requires a maximum RPO of 2 hours and a maximum RTO of 10 minutes for its data and application at all times. Which combination of deployment strategies will meet these requirements? (Choose two.) BD (100%)</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Create an Amazon Aurora Single-AZ cluster in multiple AWS Regions as the data store. Use Aurora's automatic recovery capabilities in the event of a disaster.</div>                <div class="option correct-answer"><strong>B.</strong> Create an Amazon Aurora global database in two AWS Regions as the data store. In the event of a failure, promote the secondary Region to the primary for the application. Update the application to use the Aurora cluster endpoint in the secondary Region.</div>                <div class="option"><strong>C.</strong> Create an Amazon Aurora cluster in multiple AWS Regions as the data store. Use a Network Load Balancer to balance the database traffic in different Regions.</div>                <div class="option correct-answer"><strong>D.</strong> Set up the application in two AWS Regions. Use <span class="key-service">Amazon Route 53</span> failover routing that points to Application Load Balancers in both Regions. Use health checks and Auto Scaling groups in each Region.</div>                <div class="option"><strong>E.</strong> Set up the application in two AWS Regions. Configure AWS Global Accelerator to point to Application Load Balancers (ALBs) in both Regions. Add both ALBs to a single endpoint group. Use health checks and Auto Scaling groups in each Region.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司需要制定数据和应用程序的故障转移和灾难恢复策略。应用程序使用MySQL数据库和Amazon EC2实例。公司要求数据和应用程序的最大RPO为2小时，最大RTO为10分钟。哪种部署策略组合能满足这些要求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 在多个AWS Region中创建Amazon Aurora Single-AZ集群作为数据存储，在灾难发生时使用Aurora的自动恢复功能</div> <div class="option-analysis"><strong>B.</strong> 在两个AWS Region中创建Amazon Aurora global database作为数据存储，故障时将辅助Region提升为主Region，更新应用程序使用辅助Region中的Aurora集群端点</div> <div class="option-analysis"><strong>C.</strong> 在多个AWS Region中创建Amazon Aurora集群作为数据存储，使用Network Load Balancer在不同Region之间平衡数据库流量</div> <div class="option-analysis"><strong>D.</strong> 在两个AWS Region中设置应用程序，使用Amazon Route 53故障转移路由指向两个Region的Application Load Balancer，在每个Region使用健康检查和Auto Scaling组</div> <div class="option-analysis"><strong>E.</strong> 在两个AWS Region中设置应用程序，配置AWS Global Accelerator指向两个Region的Application Load Balancer，将两个ALB添加到单个端点组，在每个Region使用健康检查和Auto Scaling组<div class="section-title"><strong>核心要求:</strong></div> 满足RPO 2小时和RTO 10分钟的灾难恢复要求 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• Amazon Aurora Global Database-提供跨Region数据复制和快速故障转移 </div><div class="compact-content">• Route 53故障转移路由-实现应用程序层的自动故障转移 <div class="section-title"><strong>正确答案BD:</strong></div> Aurora Global Database提供跨Region数据复制满足RPO要求，Route 53故障转移路由实现应用程序快速切换满足RTO要求 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A-Single-AZ部署无法提供跨Region灾难恢复能力 </div><div class="compact-content">• 选项C-Network Load Balancer不适用于数据库层的灾难恢复场景 </div><div class="compact-content">• 选项E-Global Accelerator主要用于性能优化而非灾难恢复故障转移 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-Aurora Global Database提供低延迟跨Region复制 </div><div class="compact-content">• 成本-使用托管服务降低运维成本 </div><div class="compact-content">• 可扩展性-Auto Scaling组确保应用程序弹性扩展能力</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: BD (B、D)</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-256">
            <div class="question-header">
                <div class="question-title">Question #256 ✅ 📝 <small style="float: right;">(256/353)</small></div>
            </div>
            <div class="question-content">A developer is using the AWS Serverless Application Model (AWS SAM) to create a prototype for an <span class="key-service">AWS Lambda</span> function. The AWS SAM template contains an AWS::Serverless::Function resource that has the CodeUri property that points to an <span class="key-service">Amazon S3</span> location. The developer wants to identify the correct commands for deployment before creating a CI/CD pipeline. The developer creates an archive of the Lambda function code named package.zip. The developer uploads the .zip file archive to the S3 location specified in the CodeUri property. The developer runs the sam deploy command and deploys the Lambda function. The developer updates the Lambda function code and uses the same steps to deploy the new version of the Lambda function. The sam deploy command fails and returns an error of no changes to deploy. Which solutions will deploy the new version? (Choose two.) CE (60%) AC (40%)</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Use the <span class="key-service">aws cloudformation</span> update-stack command instead of the sam deploy command.</div>                <div class="option"><strong>B.</strong> Use the <span class="key-service">aws cloudformation</span> update-stack-instances command instead of the sam deploy command.</div>                <div class="option correct-answer"><strong>C.</strong> Update the CodeUri property to reference the local application code folder. Use the sam deploy command.</div>                <div class="option"><strong>D.</strong> Update the CodeUri property to reference the local application code folder. Use the <span class="key-service">aws cloudformation</span> create-change-set command and the <span class="key-service">aws cloudformation</span> execute-change-set command.</div>                <div class="option correct-answer"><strong>E.</strong> Update the CodeUri property to reference the local application code folder. Use the <span class="key-service">aws cloudformation</span> package command and the <span class="key-service">aws cloudformation</span> deploy command. cloudformation deploy command.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 开发者使用AWS Serverless Application Model (AWS SAM)为AWS Lambda函数创建原型。AWS SAM模板包含AWS::Serverless::Function资源，其CodeUri属性指向Amazon S3位置。开发者想在创建CI/CD管道前确定正确的部署命令。开发者创建名为package.zip的Lambda函数代码归档文件，上传到CodeUri属性指定的S3位置，运行sam deploy命令部署Lambda函数。开发者更新Lambda函数代码并使用相同步骤部署新版本时，sam deploy命令失败并返回"no changes to deploy"<span class="wrong-reason">错误</span>。哪些解决方案能部署新版本？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 使用aws cloudformation update-stack命令替代sam deploy命令</div> <div class="option-analysis"><strong>B.</strong> 使用aws cloudformation update-stack-instances命令替代sam deploy命令</div> <div class="option-analysis"><strong>C.</strong> 更新CodeUri属性引用本地应用代码文件夹，使用sam deploy命令</div> <div class="option-analysis"><strong>D.</strong> 更新CodeUri属性引用本地应用代码文件夹，使用aws cloudformation create-change-set命令和aws cloudformation execute-change-set命令</div> <div class="option-analysis"><strong>E.</strong> 更新CodeUri属性引用本地应用代码文件夹，使用aws cloudformation package命令和aws cloudformation deploy命令<div class="section-title"><strong>核心要求:</strong></div> 解决SAM部署时"no changes to deploy"<span class="wrong-reason">错误</span>，实现Lambda函数代码更新部署 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• AWS SAM - 简化serverless应用开发和部署的框架 </div><div class="compact-content">• <span class="key-service">AWS Lambda</span> - 无服务器计算服务 </div><div class="compact-content">• <span class="key-service">Amazon S3</span> - 对象存储服务 <div class="section-title"><strong>正确答案CE:</strong></div> 问题根源是CodeUri指向固定S3位置，SAM无法检测到代码变更。解决方案是将CodeUri改为本地代码路径，让SAM自动处理打包和上传。选项C使用sam deploy，选项E使用等效的CloudFormation命令组合。 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A - 直接使用CloudFormation命令无法解决代码检测问题，仍会遇到相同错误 </div><div class="compact-content">• 选项B - update-stack-instances用于StackSets管理，不适用于单个stack部署场景 </div><div class="compact-content">• 选项D - create-change-set和execute-change-set组合不是标准的SAM部署流程 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能 - 本地代码路径方式支持增量更新和自动优化 </div><div class="compact-content">• 成本 - 减少手动S3上传操作，降低管理开销 </div><div class="compact-content">• 可扩展性 - 为后续CI/CD管道集成提供标准化部署流程</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: CE (C、E)</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-257">
            <div class="question-header">
                <div class="question-title">Question #257 ✅ ⚪ <small style="float: right;">(257/353)</small></div>
            </div>
            <div class="question-content">A company runs its container workloads in AWS App Runner. A DevOps engineer manages the company's container repository in Amazon Elastic Container Registry (<span class="key-service">Amazon ECR</span>). The DevOps engineer must implement a solution that continuously monitors the container repository. The solution must create a new container image when the solution detects an operating system vulnerability or language package vulnerability. Which solution will meet these requirements? A (100%)</div>
            <div class="options-container">                <div class="option correct-answer"><strong>A.</strong> Use EC2 Image Builder to create a container image pipeline. Use <span class="key-service">Amazon ECR</span> as the target repository. Turn on enhanced scanning on the ECR repository. Create an Amazon EventBridge rule to capture an Inspector finding event. Use the event to invoke the image pipeline. Re-upload the container to the repository. Most Voted</div>                <div class="option"><strong>B.</strong> Use EC2 Image Builder to create a container image pipeline. Use <span class="key-service">Amazon ECR</span> as the target repository. Enable <span class="key-service">Amazon GuardDuty</span> Malware Protection on the container workload. Create an Amazon EventBridge rule to capture a GuardDuty finding event. Use the event to invoke the image pipeline.</div>                <div class="option"><strong>C.</strong> Create an <span class="key-service">AWS CodeBuild</span> project to create a container image. Use <span class="key-service">Amazon ECR</span> as the target repository. Turn on basic scanning on the repository. Create an Amazon EventBridge rule to capture an ECR image action event. Use the event to invoke the CodeBuild project. Re- upload the container to the repository.</div>                <div class="option"><strong>D.</strong> Create an <span class="key-service">AWS CodeBuild</span> project to create a container image. Use <span class="key-service">Amazon ECR</span> as the target repository. Configure <span class="key-service">AWS Systems Manager</span> Compliance to scan all managed nodes. Create an Amazon EventBridge rule to capture a configuration compliance state change event. Use the event to invoke the CodeBuild project.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司在AWS App Runner中运行容器工作负载。DevOps工程师在Amazon Elastic Container Registry (<span class="key-service">Amazon ECR</span>)中管理公司的容器仓库。DevOps工程师必须实施一个持续监控容器仓库的解决方案。该解决方案必须在检测到操作系统漏洞或语言包漏洞时创建新的容器镜像。 <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 使用EC2 Image Builder创建容器镜像管道。使用Amazon ECR作为目标仓库。在ECR仓库上启用增强扫描。创建Amazon EventBridge规则捕获Inspector发现事件。使用事件调用镜像管道。重新上传容器到仓库。</div> <div class="option-analysis"><strong>B.</strong> 使用EC2 Image Builder创建容器镜像管道。使用Amazon ECR作为目标仓库。在容器工作负载上启用Amazon GuardDuty恶意软件保护。创建Amazon EventBridge规则捕获GuardDuty发现事件。使用事件调用镜像管道。</div> <div class="option-analysis"><strong>C.</strong> 创建AWS CodeBuild项目来创建容器镜像。使用Amazon ECR作为目标仓库。在仓库上启用基础扫描。创建Amazon EventBridge规则捕获ECR镜像操作事件。使用事件调用CodeBuild项目。重新上传容器到仓库。</div> <div class="option-analysis"><strong>D.</strong> 创建AWS CodeBuild项目来创建容器镜像。使用Amazon ECR作为目标仓库。配置AWS Systems Manager Compliance扫描所有托管节点。创建Amazon EventBridge规则捕获配置合规状态变更事件。使用事件调用CodeBuild项目。<div class="section-title"><strong>核心要求:</strong></div> 实现容器漏洞检测和自动镜像重建的持续监控解决方案 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• EC2 Image Builder-自动化容器镜像构建和管理 </div><div class="compact-content">• Amazon ECR增强扫描-基于Inspector的深度漏洞检测 </div><div class="compact-content">• Amazon EventBridge-事件驱动的自动化触发 <div class="section-title"><strong>正确答案A:</strong></div> ECR增强扫描集成Inspector进行深度漏洞检测，通过EventBridge捕获Inspector发现事件自动触发EC2 Image Builder重建镜像 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项B-GuardDuty主要检测恶意软件而非操作系统和语言包漏洞 </div><div class="compact-content">• 选项C-基础扫描功能有限，ECR镜像操作事件无法准确识别漏洞 </div><div class="compact-content">• 选项D-Systems Manager Compliance针对EC2实例而非容器镜像漏洞 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-增强扫描提供最全面的漏洞检测能力 </div><div class="compact-content">• 成本-EC2 Image Builder提供托管的镜像构建服务 </div><div class="compact-content">• 可扩展性-EventBridge实现完全自动化的事件驱动架构</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: A</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-258">
            <div class="question-header">
                <div class="question-title">Question #258 ✅ ⚪ <small style="float: right;">(258/353)</small></div>
            </div>
            <div class="question-content">A company wants to use <span class="key-service">AWS Systems Manager</span> documents to bootstrap physical laptops for developers. The bootstrap code is stored in GitHub. A DevOps engineer has already created a Systems Manager activation, installed the Systems Manager agent with the registration code, and installed an activation ID on all the laptops. Which set of steps should be taken next? C (100%)</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Configure the Systems Manager document to use the AWS-RunShellScript command to copy the files from GitHub to <span class="key-service">Amazon S3</span>, then use the aws-downloadContent plugin with a sourceType of S3.</div>                <div class="option"><strong>B.</strong> Configure the Systems Manager document to use the aws-configurePackage plugin with an install action and point to the Git repository.</div>                <div class="option correct-answer"><strong>C.</strong> Configure the Systems Manager document to use the aws-downloadContent plugin with a sourceType of GitHub and sourceInfo with the repository details.</div>                <div class="option"><strong>D.</strong> Configure the Systems Manager document to use the aws:softwareInventory plugin and run the script from the Git repository.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司希望使用AWS Systems Manager文档来引导开发人员的物理笔记本电脑。引导代码存储在GitHub中。DevOps工程师已经创建了Systems Manager激活，使用注册代码安装了Systems Manager代理，并在所有笔记本电脑上安装了激活ID。接下来应该采取哪组步骤？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 配置Systems Manager文档使用AWS-RunShellScript命令将文件从GitHub复制到Amazon S3，然后使用aws-downloadContent插件，sourceType设为S3。</div> <div class="option-analysis"><strong>B.</strong> 配置Systems Manager文档使用aws-configurePackage插件，执行安装操作并指向Git仓库。</div> <div class="option-analysis"><strong>C.</strong> 配置Systems Manager文档使用aws-downloadContent插件，sourceType设为GitHub，sourceInfo包含仓库详细信息。</div> <div class="option-analysis"><strong>D.</strong> 配置Systems Manager文档使用aws:softwareInventory插件并从Git仓库运行脚本。<div class="section-title"><strong>核心要求:</strong></div> 直接从GitHub下载引导代码到物理笔记本电脑 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• <span class="key-service">AWS Systems Manager</span> - 管理混合环境中的实例和设备 </div><div class="compact-content">• aws-downloadContent插件 - 从多种源下载内容的原生插件 <div class="section-title"><strong>正确答案C:</strong></div> aws-downloadContent插件原生支持GitHub作为源类型，可直接指定仓库信息下载代码，这是最直接高效的方案 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A - 增加不必要的S3中转步骤，复杂化流程且增加成本 </div><div class="compact-content">• 选项B - aws-configurePackage用于软件包管理，不适用于直接从Git仓库下载代码 </div><div class="compact-content">• 选项D - aws:softwareInventory用于收集软件清单信息，不能执行下载和运行操作 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能 - 直接从GitHub下载避免中转延迟 </div><div class="compact-content">• 成本 - 无需额外S3存储成本 </div><div class="compact-content">• 可扩展性 - 原生插件支持，维护简单</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: C</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-259">
            <div class="question-header">
                <div class="question-title">Question #259 ✅ 📝 <small style="float: right;">(259/353)</small></div>
            </div>
            <div class="question-content">A company's development team uses <span class="key-service">AWS CloudFormation</span> to deploy its application resources. The team must use CloudFormation for all changes to the environment. The team cannot use the AWS Management Console or the AWS CLI to make manual changes directly. The team uses a developer IAM role to access the environment. The role is configured with the AdministratorAccess managed IAM policy. The company has created a new CloudFormationDeployment IAM role that has the following policy attached: The company wants to ensure that only CloudFormation can use the new role. The development team cannot make any manual changes to the deployed resources. Which combination of steps will meet these requirements? (Choose three.) ADF (100%)</div>
            <div class="options-container">                <div class="option correct-answer"><strong>A.</strong> Remove the AdministratorAccess policy. Assign the ReadOnlyAccess managed IAM policy to the developer role. Instruct the developers to use the CloudFormationDeployment role as a CloudFormation service role when the developers deploy new stacks.</div>                <div class="option"><strong>B.</strong> Update the trust policy of the CloudFormationDeployment role to allow the developer IAM role to assume the CloudFormationDeployment role.</div>                <div class="option"><strong>C.</strong> Configure the developer IAM role to be able to get and pass the CloudFormationDeployment role if iam:PassedToService equals cloudformation.amazonaws.com. Configure the CloudFormationDeployment role to allow all cloudformation actions for all resources.</div>                <div class="option correct-answer"><strong>D.</strong> Update the trust policy of the CloudFormationDeployment role to allow the cloudformation.amazonaws.com AWS principal to perform the assume role action. the iam:AssumeRole action.</div>                <div class="option"><strong>E.</strong> Remove the AdministratorAccess policy. Assign the ReadOnlyAccess managed IAM policy to the developer role. Instruct the developers to assume the CloudFormationDeployment role when the developers deploy new stacks. F. Add an IAM policy to the CloudFormationDeployment role to allow cloudformation:* on all resources. Add a policy that allows the iam:PassRole action for the ARN of the CloudFormationDeployment role if iam:PassedToService equals cloudformation.amazonaws.com.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 公司开发团队使用AWS CloudFormation部署应用资源，必须通过CloudFormation进行所有环境变更，不能使用AWS Management Console或AWS CLI手动更改。团队使用具有AdministratorAccess策略的开发者IAM角色访问环境。公司创建了新的CloudFormationDeployment IAM角色并附加了相应策略。公司希望确保只有CloudFormation能使用新角色，开发团队不能手动更改已部署资源。哪些步骤组合能满足要求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 移除AdministratorAccess策略，为开发者角色分配ReadOnlyAccess托管IAM策略，指导开发者在部署新堆栈时使用CloudFormationDeployment角色作为CloudFormation服务角色</div> <div class="option-analysis"><strong>B.</strong> 更新CloudFormationDeployment角色的信任策略以允许开发者IAM角色代入CloudFormationDeployment角色</div> <div class="option-analysis"><strong>C.</strong> 配置开发者IAM角色能够获取和传递CloudFormationDeployment角色（当iam:PassedToService等于cloudformation.amazonaws.com时），配置CloudFormationDeployment角色允许所有资源的所有cloudformation操作</div> <div class="option-analysis"><strong>D.</strong> 更新CloudFormationDeployment角色的信任策略以允许cloudformation.amazonaws.com AWS主体执行代入角色操作</div> <div class="option-analysis"><strong>E.</strong> 移除AdministratorAccess策略，为开发者角色分配ReadOnlyAccess托管IAM策略，指导开发者在部署新堆栈时代入CloudFormationDeployment角色 F. 为CloudFormationDeployment角色添加IAM策略以允许所有资源的cloudformation:*操作，添加策略允许CloudFormationDeployment角色ARN的iam:PassRole操作（当iam:PassedToService等于cloudformation.amazonaws.com时）<div class="section-title"><strong>核心要求:</strong></div> 确保只有CloudFormation服务能使用部署角色，防止开发者手动更改资源 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• IAM角色信任策略-控制谁能代入角色 </div><div class="compact-content">• CloudFormation服务角色-允许CloudFormation代表用户执行操作 </div><div class="compact-content">• IAM权限边界-限制用户直接操作资源的能力 <div class="section-title"><strong>正确答案AD:</strong></div> A选项限制开发者只有只读权限并使用CloudFormation服务角色模式，D选项配置信任策略只允许CloudFormation服务代入部署角色，确保角色只能被CloudFormation使用 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项B-允许开发者直接代入部署角色，违反了只有CloudFormation能使用角色的要求 </div><div class="compact-content">• 选项C-配置开发者能直接代入角色，同样违反安全要求 </div><div class="compact-content">• 选项E-让开发者直接代入角色而非通过CloudFormation服务角色 </div><div class="compact-content">• 选项F-描述的是角色权限配置而非信任关系，且未解决谁能使用角色的问题 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 安全性-严格控制角色使用权限，只允许CloudFormation服务访问 </div><div class="compact-content">• <span class="key-point">合规性</span>-满足所有变更必须通过CloudFormation的治理要求 </div><div class="compact-content">• 可操作性-开发者保持部署能力但无法绕过CloudFormation进行手动更改</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: AD (A、D)</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-260">
            <div class="question-header">
                <div class="question-title">Question #260 ✅ ⚪ <small style="float: right;">(260/353)</small></div>
            </div>
            <div class="question-content">A company is developing a web application's infrastructure using <span class="key-service">AWS CloudFormation</span>. The database engineering team maintains the database resources in a CloudFormation template, and the software development team maintains the web application resources in a separate CloudFormation template. As the scope of the application grows, the software development team needs to use resources maintained by the database engineering team. However, both teams have their own review and lifecycle management processes that they want to keep. Both teams also require resource-level change-set reviews. The software development team would like to deploy changes to this template using their CI/CD pipeline. Which solution will meet these requirements? A (100%)</div>
            <div class="options-container">                <div class="option correct-answer"><strong>A.</strong> Create a stack export from the database CloudFormation template and import those references into the web application CloudFormation template.</div>                <div class="option"><strong>B.</strong> Create a CloudFormation nested stack to make cross-stack resource references and parameters available in both stacks.</div>                <div class="option"><strong>C.</strong> Create a CloudFormation stack set to make cross-stack resource references and parameters available in both stacks.</div>                <div class="option"><strong>D.</strong> Create input parameters in the web application CloudFormation template and pass resource names and IDs from the database stack.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司正在使用AWS CloudFormation开发Web应用程序的基础设施。数据库工程团队在CloudFormation模板中维护数据库资源，软件开发团队在单独的CloudFormation模板中维护Web应用程序资源。随着应用程序范围的扩大，软件开发团队需要使用数据库工程团队维护的资源。但是，两个团队都有自己的审查和生命周期管理流程，他们希望保持这些流程。两个团队还需要资源级别的变更集审查。软件开发团队希望使用他们的CI/CD管道部署对此模板的更改。哪种解决方案将满足这些要求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 从数据库CloudFormation模板创建stack导出，并将这些引用导入到Web应用程序CloudFormation模板中。</div> <div class="option-analysis"><strong>B.</strong> 创建CloudFormation嵌套stack，使跨stack资源引用和参数在两个stack中都可用。</div> <div class="option-analysis"><strong>C.</strong> 创建CloudFormation stack set，使跨stack资源引用和参数在两个stack中都可用。</div> <div class="option-analysis"><strong>D.</strong> 在Web应用程序CloudFormation模板中创建输入参数，并从数据库stack传递资源名称和ID。<div class="section-title"><strong>核心要求:</strong></div> 两个独立团队需要保持各自的审查和生命周期管理流程，同时实现跨stack资源共享 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• CloudFormation Stack Exports - 允许一个stack导出资源供其他stack引用 </div><div class="compact-content">• CloudFormation Cross-Stack References - 实现独立stack间的资源共享 <div class="section-title"><strong>正确答案A:</strong></div> 使用stack导出和导入机制，数据库团队导出资源，开发团队导入引用，保持两个团队的独立性和各自的生命周期管理 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项B - 嵌套stack会创建父子依赖关系，违背了团队独立管理的要求 </div><div class="compact-content">• 选项C - Stack set用于跨账户/区域部署相同模板，不适用于跨stack资源引用 </div><div class="compact-content">• 选项D - 手动传递参数增加复杂性，缺乏自动化且容易出错 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能 - 导出/导入提供直接的资源引用，无额外开销 </div><div class="compact-content">• 成本 - 无额外成本，使用原生CloudFormation功能 </div><div class="compact-content">• 可扩展性 - 支持团队独立扩展，保持各自的CI/CD流程</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: A</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-261">
            <div class="question-header">
                <div class="question-title">Question #261 ✅ ⚪ <small style="float: right;">(261/353)</small></div>
            </div>
            <div class="question-content">A company has an organization in <span class="key-service">AWS Organizations</span>. A DevOps engineer needs to maintain multiple AWS accounts that belong to different OUs in the organization. All resources, including IAM policies and <span class="key-service">Amazon S3</span> policies within an account, are deployed through <span class="key-service">AWS CloudFormation</span>. All templates and code are maintained in an <span class="key-service">AWS CodeCommit</span> repository. Recently, some developers have not been able to access an S3 bucket from some accounts in the organization. The following policy is attached to the S3 bucket: What should the DevOps engineer do to resolve this access issue? D (100%)</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Modify the S3 bucket policy. Turn off the S3 Block Public Access setting on the S3 bucket. In the S3 policy, add the aws:SourceAccount condition. Add the AWS account IDs of all developers who are experiencing the issue.</div>                <div class="option"><strong>B.</strong> Verify that no IAM permissions boundaries are denying developers access to the S3 bucket. Make the necessary changes to IAM permissions boundaries. Use an <span class="key-service">AWS Config</span> recorder in the individual developer accounts that are experiencing the issue to revert any changes that are blocking access. Commit the fix back into the CodeCommit repository. Invoke deployment through CloudFormation to apply the changes.</div>                <div class="option"><strong>C.</strong> Configure an <span class="key-service">SCP</span> that stops anyone from modifying IAM resources in developer OUs. In the S3 policy, add the aws:SourceAccount condition. Add the AWS account IDs of all developers who are experiencing the issue. Commit the fix back into the CodeCommit repository. Invoke deployment through CloudFormation to apply the changes.</div>                <div class="option correct-answer"><strong>D.</strong> Ensure that no <span class="key-service">SCP</span> is blocking access for developers to the S3 bucket. Ensure that no IAM policy permissions boundaries are denying access to developer IAM users. Make the necessary changes to the <span class="key-service">SCP</span> and IAM policy permissions boundaries in the CodeCommit repository. Invoke deployment through CloudFormation to apply the changes.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司在AWS Organizations中有一个组织。DevOps工程师需要维护属于组织中不同OU的多个AWS账户。所有资源包括IAM策略和Amazon S3策略都通过AWS CloudFormation部署。所有模板和代码都维护在AWS CodeCommit存储库中。最近，一些开发人员无法从组织中的某些账户访问S3存储桶。以下策略附加到S3存储桶上：DevOps工程师应该如何解决此访问问题？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 修改S3存储桶策略。关闭S3存储桶上的S3 Block Public Access设置。在S3策略中添加aws:SourceAccount条件。添加所有遇到问题的开发人员的AWS账户ID。</div> <div class="option-analysis"><strong>B.</strong> 验证没有IAM权限边界拒绝开发人员访问S3存储桶。对IAM权限边界进行必要更改。在遇到问题的各个开发人员账户中使用AWS Config记录器来恢复任何阻止访问的更改。将修复提交回CodeCommit存储库。通过CloudFormation调用部署以应用更改。</div> <div class="option-analysis"><strong>C.</strong> 配置SCP阻止任何人修改开发人员OU中的IAM资源。在S3策略中添加aws:SourceAccount条件。添加所有遇到问题的开发人员的AWS账户ID。将修复提交回CodeCommit存储库。通过CloudFormation调用部署以应用更改。</div> <div class="option-analysis"><strong>D.</strong> 确保没有SCP阻止开发人员访问S3存储桶。确保没有IAM策略权限边界拒绝开发人员IAM用户的访问。在CodeCommit存储库中对SCP和IAM策略权限边界进行必要更改。通过CloudFormation调用部署以应用更改。<div class="section-title"><strong>核心要求:</strong></div> 解决AWS Organizations环境中开发人员无法访问S3存储桶的权限问题 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• <span class="key-service">AWS Organizations</span> - 提供SCP服务控制策略管理多账户权限 </div><div class="compact-content">• IAM权限边界 - 定义用户或角色的最大权限范围 </div><div class="compact-content">• CloudFormation - 基础设施即代码部署和管理 <div class="section-title"><strong>正确答案D:</strong></div> 系统性检查并修复可能阻止访问的两个主要权限控制机制：<span class="key-service">SCP</span>（组织级别控制）和IAM权限边界（账户级别控制），通过代码库管理确保变更可追踪 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A - 关闭Block Public Access和使用SourceAccount条件不能解决组织内部权限问题 </div><div class="compact-content">• 选项B - AWS Config用于合规监控而非权限修复，且未考虑SCP影响 </div><div class="compact-content">• 选项C - 配置限制性SCP会进一步阻止访问而非解决问题 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能 - 全面排查SCP和权限边界确保快速定位问题根因 </div><div class="compact-content">• 成本 - 利用现有CloudFormation和CodeCommit避免额外工具成本 </div><div class="compact-content">• 可扩展性 - 通过代码库管理权限变更支持多账户环境的统一管理</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: D</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-262">
            <div class="question-header">
                <div class="question-title">Question #262 ✅ 📝 <small style="float: right;">(262/353)</small></div>
            </div>
            <div class="question-content">A company has an organization in <span class="key-service">AWS Organizations</span> for its multi-account environment. A DevOps engineer is developing an AWS CodeArtifact based strategy for application package management across the organization. Each application team at the company has its own account in the organization. Each application team also has limited access to a centralized shared services account. Each application team needs full access to download, publish, and grant access to its own packages. Some common library packages that the application teams use must also be shared with the entire organization. Which combination of steps will meet these requirements with the LEAST administrative overhead? (Choose three.) BCD (75%) BDE (25%)</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Create a domain in each application team's account. Grant each application team's account full read access and write access to the application team's domain.</div>                <div class="option correct-answer"><strong>B.</strong> Create a domain in the shared services account. Grant the organization read access and CreateRepository access.</div>                <div class="option"><strong>C.</strong> Create a repository in each application team's account. Grant each application team's account full read access and write access to its own repository.</div>                <div class="option correct-answer"><strong>D.</strong> Create a repository in the shared services account. Grant the organization read access to the repository in the shared services account. Set the repository as the upstream repository in each application team's repository.</div>                <div class="option correct-answer"><strong>E.</strong> For teams that require shared packages, create resource-based policies that allow read access to the repository from other application teams' accounts. F. Set the other application teams' repositories as upstream repositories.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司在AWS Organizations中有一个多账户环境的组织。DevOps工程师正在开发基于AWS CodeArtifact的应用程序包管理策略。公司的每个应用团队在组织中都有自己的账户，并且对集中式共享服务账户有有限访问权限。每个应用团队需要完全访问权限来下载、发布和授权访问自己的包。一些应用团队使用的通用库包也必须与整个组织共享。哪种步骤组合能以最少的管理开销满足这些要求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 在每个应用团队的账户中创建一个domain，授予每个应用团队的账户对其domain的完全读写访问权限</div> <div class="option-analysis"><strong>B.</strong> 在共享服务账户中创建一个domain，授予组织读取访问权限和CreateRepository访问权限</div> <div class="option-analysis"><strong>C.</strong> 在每个应用团队的账户中创建一个repository，授予每个应用团队的账户对其自己repository的完全读写访问权限</div> <div class="option-analysis"><strong>D.</strong> 在共享服务账户中创建一个repository，授予组织对共享服务账户中repository的读取访问权限，将该repository设置为每个应用团队repository的上游repository</div> <div class="option-analysis"><strong>E.</strong> 对于需要共享包的团队，创建基于资源的策略，允许其他应用团队账户对repository的读取访问权限 F. 将其他应用团队的repository设置为上游repository<div class="section-title"><strong>核心要求:</strong></div> 建立跨组织的CodeArtifact包管理策略，支持团队独立管理和组织级共享 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• AWS CodeArtifact - 软件包管理服务，支持domain和repository层级结构 </div><div class="compact-content">• <span class="key-service">AWS Organizations</span> - 多账户管理，提供组织级权限控制 <div class="section-title"><strong>正确答案BDE:</strong></div> 在共享服务账户创建统一domain(B)，建立共享repository作为上游源(D)，通过资源策略实现精细化访问控制(E)，形成层级化包管理架构 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A - 多domain架构增加管理复杂性，无法有效支持跨账户包共享 </div><div class="compact-content">• 选项C - 在应用账户创建repository需要先有domain，且与统一管理策略冲突 </div><div class="compact-content">• 选项F - 设置应用团队repository为上游违反了集中式共享包管理原则 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能 - 上游repository机制提供高效的包分发和缓存 </div><div class="compact-content">• 成本 - 单一domain减少重复资源，降低管理成本 </div><div class="compact-content">• 可扩展性 - 基于资源策略的权限模型支持灵活的团队扩展</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: BDE (B、D、E)</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-263">
            <div class="question-header">
                <div class="question-title">Question #263 ✅ ⚪ <small style="float: right;">(263/353)</small></div>
            </div>
            <div class="question-content">A company deploys an application to <span class="key-service">Amazon EC2</span> instances. The application runs Amazon Linux 2 and uses <span class="key-service">AWS CodeDeploy</span>. The application has the following file structure for its code repository: The appspec.yml file has the following contents in the files section: What will the result be for the deployment of the config.txt file? B (100%)</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> The config.txt file will be deployed to only /var/www/html/config/config.txt.</div>                <div class="option"><strong>B.</strong> The config.txt file will be deployed to /usr/local/src/config.txt and to /var/www/html/config/config.txt.</div>                <div class="option correct-answer"><strong>C.</strong> The config.txt file will be deployed to only /usr/local/src/config.txt.</div>                <div class="option"><strong>D.</strong> The config.txt file will be deployed to /usr/local/src/config.txt and to /var/www/html/application/web/config.txt.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司将应用程序部署到Amazon EC2实例。应用程序运行Amazon Linux 2并使用AWS CodeDeploy。应用程序的代码仓库具有以下文件结构，appspec.yml文件在files部分有以下内容，config.txt文件的部署结果是什么？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> config.txt文件将仅部署到/var/www/html/config/config.txt</div> <div class="option-analysis"><strong>B.</strong> config.txt文件将部署到/usr/local/src/config.txt和/var/www/html/config/config.txt</div> <div class="option-analysis"><strong>C.</strong> config.txt文件将仅部署到/usr/local/src/config.txt</div> <div class="option-analysis"><strong>D.</strong> config.txt文件将部署到/usr/local/src/config.txt和/var/www/html/application/web/config.txt<div class="section-title"><strong>核心要求:</strong></div> 理解AWS CodeDeploy中appspec.yml文件的files部分配置规则 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• <span class="key-service">AWS CodeDeploy</span> - 自动化应用程序部署服务，通过appspec.yml定义部署规则 </div><div class="compact-content">• <span class="key-service">Amazon EC2</span> - 运行应用程序的虚拟服务器实例 <div class="section-title"><strong>正确答案C:</strong></div> CodeDeploy的appspec.yml中files部分按照source到destination的映射规则，config.txt根据配置只会部署到指定的单一目标路径/usr/local/src/config.txt <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A - 目标路径错误，不是/var/www/html/config/目录 </div><div class="compact-content">• 选项B - 包含了错误的目标路径/var/www/html/config/config.txt </div><div class="compact-content">• 选项D - 包含了错误的目标路径/var/www/html/application/web/config.txt <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能 - CodeDeploy按配置精确部署，避免不必要的文件复制 </div><div class="compact-content">• 成本 - 单一路径部署减少存储空间占用和网络传输 </div><div class="compact-content">• 可扩展性 - appspec.yml配置文件提供灵活的部署路径管理</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: C</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-264">
            <div class="question-header">
                <div class="question-title">Question #264 ✅ 📝 <small style="float: right;">(264/353)</small></div>
            </div>
            <div class="question-content">A company has set up AWS CodeArtifact repositories with public upstream repositories. The company's development team consumes open source dependencies from the repositories in the company's internal network. The company's security team recently discovered a critical vulnerability in the most recent version of a package that the development team consumes. The security team has produced a patched version to fix the vulnerability. The company needs to prevent the vulnerable version from being downloaded. The company also needs to allow the security team to publish the patched version. Which combination of steps will meet these requirements? (Choose two.) CD (60%) BD (40%)</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Update the status of the affected CodeArtifact package version to unlisted.</div>                <div class="option correct-answer"><strong>B.</strong> Update the status of the affected CodeArtifact package version to deleted.</div>                <div class="option"><strong>C.</strong> Update the status of the affected CodeArtifact package version to archived.</div>                <div class="option correct-answer"><strong>D.</strong> Update the CodeArtifact package origin control settings to allow direct publishing and to block upstream operations.</div>                <div class="option"><strong>E.</strong> Update the CodeArtifact package origin control settings to block direct publishing and to allow upstream operations.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司设置了带有公共上游仓库的AWS CodeArtifact仓库。公司开发团队在内部网络中从这些仓库消费开源依赖项。安全团队最近发现开发团队使用的某个包的最新版本存在严重漏洞。安全团队已制作了修补版本来修复漏洞。公司需要阻止下载有漏洞的版本，同时允许安全团队发布修补版本。哪种步骤组合能满足这些要求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 将受影响的CodeArtifact包版本状态更新为unlisted（未列出）</div> <div class="option-analysis"><strong>B.</strong> 将受影响的CodeArtifact包版本状态更新为deleted（已删除）</div> <div class="option-analysis"><strong>C.</strong> 将受影响的CodeArtifact包版本状态更新为archived（已归档）</div> <div class="option-analysis"><strong>D.</strong> 更新CodeArtifact包源控制设置以允许直接发布并阻止上游操作</div> <div class="option-analysis"><strong>E.</strong> 更新CodeArtifact包源控制设置以阻止直接发布并允许上游操作<div class="section-title"><strong>核心要求:</strong></div> 阻止有漏洞包版本下载并允许发布修补版本 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• AWS CodeArtifact - 企业级包管理服务，支持包版本状态管理和源控制 </div><div class="compact-content">• Package Origin Control - 控制包的发布来源和上游同步行为 <div class="section-title"><strong>正确答案BD:</strong></div> 删除有漏洞版本完全阻止下载，配置源控制允许直接发布修补版本同时阻止从上游拉取有漏洞版本 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A - unlisted状态仍可通过直接引用下载，无法完全阻止访问 </div><div class="compact-content">• 选项C - archived状态包仍可被下载使用，不能阻止漏洞传播 </div><div class="compact-content">• 选项E - 阻止直接发布会导致无法发布修补版本，不满足需求 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 安全性 - 必须完全阻止有漏洞版本的下载访问 </div><div class="compact-content">• 可用性 - 确保修补版本能够正常发布和分发 </div><div class="compact-content">• 控制性 - 精确控制包来源避免上游污染</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: BD (B、D)</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-265">
            <div class="question-header">
                <div class="question-title">Question #265 ✅ ⚪ <small style="float: right;">(265/353)</small></div>
            </div>
            <div class="question-content">A company is running a custom-built application that processes records. All the components run on <span class="key-service">Amazon EC2</span> instances that run in an Auto Scaling group. Each record's processing is a multistep sequential action that is compute-intensive. Each step is always completed in 5 minutes or less. A limitation of the current system is that if any steps fail, the application has to reprocess the record from the beginning. The company wants to update the architecture so that the application must reprocess only the failed steps. What is the MOST operationally efficient solution that meets these requirements? D (100%)</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Create a web application to write records to <span class="key-service">Amazon S3</span>. Use S3 Event Notifications to publish to an Amazon Simple Notification Service (<span class="key-service">Amazon SNS</span>) topic. Use an EC2 instance to poll <span class="key-service">Amazon SNS</span> and start processing. Save intermediate results to <span class="key-service">Amazon S3</span> to pass on to the next step.</div>                <div class="option"><strong>B.</strong> Perform the processing steps by using logic in the application. Convert the application code to run in a container. Use <span class="key-service">AWS Fargate</span> to manage the container instances. Configure the container to invoke itself to pass the state from one step to the next.</div>                <div class="option"><strong>C.</strong> Create a web application to pass records to an Amazon Kinesis data stream. Decouple the processing by using the Kinesis data stream and <span class="key-service">AWS Lambda</span> functions.</div>                <div class="option correct-answer"><strong>D.</strong> Create a web application to pass records to <span class="key-service">AWS Step Functions</span>. Decouple the processing into Step Functions tasks and <span class="key-service">AWS Lambda</span> functions.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司运行自定义应用程序处理记录，所有组件在Auto Scaling组的EC2实例上运行。每个记录的处理是多步骤顺序操作且计算密集，每步在5分钟内完成。当前系统限制是任何步骤失败都需要从头重新处理记录。公司希望更新架构使应用程序只需重新处理失败的步骤。 <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 创建web应用程序将记录写入S3，使用S3事件通知发布到SNS主题，使用EC2实例轮询SNS并开始处理，将中间结果保存到S3传递给下一步。</div> <div class="option-analysis"><strong>B.</strong> 使用应用程序逻辑执行处理步骤，将应用程序代码转换为容器运行，使用Fargate管理容器实例，配置容器调用自身将状态从一步传递到下一步。</div> <div class="option-analysis"><strong>C.</strong> 创建web应用程序将记录传递给Kinesis数据流，使用Kinesis数据流和Lambda函数解耦处理。</div> <div class="option-analysis"><strong>D.</strong> 创建web应用程序将记录传递给Step Functions，将处理解耦为Step Functions任务和Lambda函数。<div class="section-title"><strong>核心要求:</strong></div> 实现多步骤处理的故障恢复机制，只重新处理失败步骤而非整个流程 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• Step Functions-提供状态机管理和错误处理，支持步骤级重试 </div><div class="compact-content">• Lambda-无服务器计算，适合短时间处理任务 <div class="section-title"><strong>正确答案D:</strong></div> Step Functions天然支持工作流状态管理和步骤级错误处理，可以精确控制失败步骤的重试，Lambda处理5分钟内的计算任务完全匹配 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A-S3+SNS+EC2架构复杂，需要自行实现状态管理和错误处理逻辑 </div><div class="compact-content">• 选项B-容器自调用方案复杂，状态传递和错误处理需要大量自定义代码 </div><div class="compact-content">• 选项C-Kinesis适合流式数据处理，但缺乏工作流状态管理和步骤级重试能力 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-Step Functions+Lambda提供最佳的步骤级控制和重试机制 </div><div class="compact-content">• 成本-无服务器架构按需付费，避免EC2持续运行成本 </div><div class="compact-content">• 可扩展性-托管服务自动扩展，运维复杂度最低</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: D</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-266">
            <div class="question-header">
                <div class="question-title">Question #266 ✅ ⚪ <small style="float: right;">(266/353)</small></div>
            </div>
            <div class="question-content">A company is migrating its on-premises Windows applications and Linux applications to AWS. The company will use automation to launch <span class="key-service">Amazon EC2</span> instances to mirror the on-premises configurations. The migrated applications require access to shared storage that uses SMB for Windows and NFS for Linux. The company is also creating a pilot light disaster recovery (DR) environment in another AWS Region. The company will use automation to launch and configure the EC2 instances in the DR Region. The company needs to replicate the storage to the DR Region. Which storage solution will meet these requirements? D (100%)</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Use <span class="key-service">Amazon S3</span> for the application storage. Create an S3 bucket in the primary Region and an S3 bucket in the DR Region. Configure S3 Cross-Region Replication (CRR) from the primary Region to the DR Region.</div>                <div class="option"><strong>B.</strong> Use Amazon Elastic Block Store (Amazon EBS) for the application storage. Create a backup plan in AWS Backup that creates snapshots of the EBS volumes that are in the primary Region and replicates the snapshots to the DR Region.</div>                <div class="option"><strong>C.</strong> Use a Volume Gateway in AWS Storage Gateway for the application storage. Configure Cross-Region Replication (CRR) of the Volume Gateway from the primary Region to the DR Region.</div>                <div class="option correct-answer"><strong>D.</strong> Use Amazon FSx for NetApp ONTAP for the application storage. Create an FSx for ONTAP instance in the DR Region. Configure NetApp SnapMirror replication from the primary Region to the DR Region.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司正在将其本地Windows应用程序和Linux应用程序迁移到AWS。公司将使用自动化启动Amazon EC2实例来镜像本地配置。迁移的应用程序需要访问共享存储，Windows使用SMB，Linux使用NFS。公司还在另一个AWS Region创建pilot light灾难恢复环境。公司将使用自动化在DR Region启动和配置EC2实例。公司需要将存储复制到DR Region。哪种存储解决方案能满足这些要求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 使用Amazon S3作为应用程序存储。在主Region创建S3存储桶，在DR Region创建S3存储桶。配置从主Region到DR Region的S3 Cross-Region Replication (CRR)。</div> <div class="option-analysis"><strong>B.</strong> 使用Amazon Elastic Block Store (Amazon EBS)作为应用程序存储。在AWS Backup中创建备份计划，对主Region的EBS卷创建快照并将快照复制到DR Region。</div> <div class="option-analysis"><strong>C.</strong> 使用AWS Storage Gateway中的Volume Gateway作为应用程序存储。配置Volume Gateway从主Region到DR Region的Cross-Region Replication (CRR)。</div> <div class="option-analysis"><strong>D.</strong> 使用Amazon FSx for NetApp ONTAP作为应用程序存储。在DR Region创建FSx for ONTAP实例。配置从主Region到DR Region的NetApp SnapMirror复制。<div class="section-title"><strong>核心要求:</strong></div> 需要支持SMB和NFS协议的共享存储，并能跨Region复制用于灾难恢复 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• Amazon FSx for NetApp ONTAP-提供企业级文件系统，原生支持SMB和NFS协议 </div><div class="compact-content">• NetApp SnapMirror-提供高效的跨Region数据复制功能 <div class="section-title"><strong>正确答案D:</strong></div> FSx for NetApp ONTAP原生支持SMB和NFS协议，满足Windows和Linux应用需求，SnapMirror提供企业级跨Region复制能力 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A-S3不支持SMB/NFS协议，无法作为文件系统挂载点 </div><div class="compact-content">• 选项B-EBS是块存储，不支持SMB/NFS文件共享协议 </div><div class="compact-content">• 选项C-Volume Gateway主要用于块存储，不直接支持文件协议且无原生CRR功能 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-FSx提供高性能文件系统，支持多协议访问 </div><div class="compact-content">• 成本-按需付费，SnapMirror提供增量复制降低传输成本 </div><div class="compact-content">• 可扩展性-支持多AZ部署，自动扩展存储容量</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: D</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-267">
            <div class="question-header">
                <div class="question-title">Question #267 ✅ 📝 <small style="float: right;">(267/353)</small></div>
            </div>
            <div class="question-content">A company's application uses a fleet of <span class="key-service">Amazon EC2</span> On-Demand Instances to analyze and process data. The EC2 instances are in an Auto Scaling group. The Auto Scaling group is a target group for an Application Load Balancer (ALB). The application analyzes critical data that cannot tolerate interruption. The application also analyzes noncritical data that can withstand interruption. The critical data analysis requires quick scalability in response to real-time application demand. The noncritical data analysis involves memory consumption. A DevOps engineer must implement a solution that reduces scale-out latency for the critical data. The solution also must process the noncritical data. Which combination of steps will meet these requirements? (Choose two.) BD (80%) BE (20%)</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> For the critical data, modify the existing Auto Scaling group. Create a warm pool instance in the stopped state. Define the warm pool size. Create a new version of the launch template that has detailed monitoring enabled. Use Spot Instances.</div>                <div class="option correct-answer"><strong>B.</strong> For the critical data, modify the existing Auto Scaling group. Create a warm pool instance in the stopped state. Define the warm pool size. Create a new version of the launch template that has detailed monitoring enabled. Use On-Demand Instances.</div>                <div class="option"><strong>C.</strong> For the critical data, modify the existing Auto Scaling group. Create a lifecycle hook to ensure that bootstrap scripts are completed successfully. Ensure that the application on the instances is ready to accept traffic before the instances are registered. Create a new version of the launch template that has detailed monitoring enabled.</div>                <div class="option"><strong>D.</strong> For the noncritical data, create a second Auto Scaling group that uses a launch template. Configure the launch template to install the unified <span class="key-service">Amazon CloudWatch</span> agent and to configure the CloudWatch agent with a custom memory utilization metric. Use Spot Instances. Add the new Auto Scaling group as the target group for the AL<div class="option-analysis"><strong>B.</strong> Modify the application to use two target groups for critical data and noncritical data.</div></div>                <div class="option correct-answer"><strong>E.</strong> For the noncritical data, create a second Auto Scaling group. Choose the predefined memory utilization metric type for the target tracking scaling policy. Use Spot Instances. Add the new Auto Scaling group as the target group for the AL<div class="option-analysis"><strong>B.</strong> Modify the application to use two target groups for critical data and noncritical data.</div></div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司的应用程序使用Amazon EC2 On-Demand实例队列来分析和处理数据。EC2实例在Auto Scaling组中，该组是Application Load Balancer (ALB)的目标组。应用程序分析不能容忍中断的关键数据和可以承受中断的非关键数据。关键数据分析需要快速扩展以响应实时应用需求。非关键数据分析涉及内存消耗。DevOps工程师必须实施一个解决方案，减少关键数据的横向扩展延迟，同时处理非关键数据。 <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 对于关键数据，修改现有Auto Scaling组，创建处于停止状态的warm pool实例，定义warm pool大小，创建启用详细监控的launch template新版本，使用Spot实例。</div> <div class="option-analysis"><strong>B.</strong> 对于关键数据，修改现有Auto Scaling组，创建处于停止状态的warm pool实例，定义warm pool大小，创建启用详细监控的launch template新版本，使用On-Demand实例。</div> <div class="option-analysis"><strong>C.</strong> 对于关键数据，修改现有Auto Scaling组，创建lifecycle hook确保bootstrap脚本成功完成，确保实例上的应用程序在注册前准备好接受流量，创建启用详细监控的launch template新版本。</div> <div class="option-analysis"><strong>D.</strong> 对于非关键数据，创建使用launch template的第二个Auto Scaling组，配置launch template安装统一Amazon CloudWatch代理并配置自定义内存利用率指标，使用Spot实例，将新Auto Scaling组添加为ALB的目标组，修改应用程序为关键和非关键数据使用两个目标组。</div> <div class="option-analysis"><strong>E.</strong> 对于非关键数据，创建第二个Auto Scaling组，为目标跟踪扩展策略选择预定义的内存利用率指标类型，使用Spot实例，将新Auto Scaling组添加为ALB的目标组，修改应用程序为关键和非关键数据使用两个目标组。<div class="section-title"><strong>核心要求:</strong></div> 减少关键数据扩展延迟并处理基于内存的非关键数据工作负载 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• Auto Scaling Warm Pool-预热实例减少启动时间 </div><div class="compact-content">• Target Tracking Scaling-基于内存指标自动扩展 </div><div class="compact-content">• Spot实例-成本优化的可中断计算 <div class="section-title"><strong>正确答案BE:</strong></div> B选项使用warm pool和On-Demand实例确保关键数据快速扩展和高可用性；E选项使用预定义内存指标和Spot实例为非关键数据提供成本效益的基于内存的扩展 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A-关键数据使用Spot实例可能导致中断，违反不容忍中断的要求 </div><div class="compact-content">• 选项C-lifecycle hook增加启动时间，不能减少扩展延迟 </div><div class="compact-content">• 选项D-自定义CloudWatch代理配置复杂，而预定义指标更简单有效 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-warm pool减少冷启动时间，预定义指标简化配置 </div><div class="compact-content">• 成本-非关键工作负载使用Spot实例，关键工作负载使用On-Demand </div><div class="compact-content">• 可扩展性-分离关键和非关键工作负载，各自优化扩展策略</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: BE (B、E)</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-268">
            <div class="question-header">
                <div class="question-title">Question #268 ✅ 📝 <small style="float: right;">(268/353)</small></div>
            </div>
            <div class="question-content">A company recently migrated its application to an Amazon Elastic Kubernetes Service (<span class="key-service">Amazon EKS</span>) cluster that uses <span class="key-service">Amazon EC2</span> instances. The company configured the application to automatically scale based on CPU utilization. The application produces memory errors when it experiences heavy loads. The application also does not scale out enough to handle the increased load. The company needs to collect and analyze memory metrics for the application over time. Which combination of steps will meet these requirements? (Choose three.) ACE (63%) BCE (25%) 13%</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Attach the CloudWatchAgentServerPolicy managed IAM policy to the IAM instance profile that the cluster uses.</div>                <div class="option"><strong>B.</strong> Attach the CloudWatchAgentServerPolicy managed IAM policy to a service account role for the cluster.</div>                <div class="option correct-answer"><strong>C.</strong> Collect performance metrics by deploying the unified <span class="key-service">Amazon CloudWatch</span> agent to the existing EC2 instances in the cluster. Add the agent to the AMI for any new EC2 instances that are added to the cluster. Most Voted</div>                <div class="option"><strong>D.</strong> Collect performance logs by deploying the AWS Distro for OpenTelemetry collector as a DaemonSet.</div>                <div class="option correct-answer"><strong>E.</strong> Analyze the pod_memory_utilization <span class="key-service">Amazon CloudWatch</span> metric in the ContainerInsights namespace by using the Service dimension. F. Analyze the node_memory_utilization <span class="key-service">Amazon CloudWatch</span> metric in the ContainerInsights namespace by using the ClusterName dimension.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司最近将其应用程序迁移到使用Amazon EC2实例的Amazon EKS集群。公司配置应用程序基于CPU利用率自动扩展。应用程序在高负载时产生内存错误，且扩展不足以处理增加的负载。公司需要收集和分析应用程序的内存指标。哪些步骤组合能满足要求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 将CloudWatchAgentServerPolicy托管IAM策略附加到集群使用的IAM实例配置文件</div> <div class="option-analysis"><strong>B.</strong> 将CloudWatchAgentServerPolicy托管IAM策略附加到集群的服务账户角色</div> <div class="option-analysis"><strong>C.</strong> 通过将统一的Amazon CloudWatch代理部署到集群中现有的EC2实例来收集性能指标，并将代理添加到添加到集群的任何新EC2实例的AMI中</div> <div class="option-analysis"><strong>D.</strong> 通过将AWS Distro for OpenTelemetry收集器部署为DaemonSet来收集性能日志</div> <div class="option-analysis"><strong>E.</strong> 通过使用Service维度分析ContainerInsights命名空间中的pod_memory_utilization Amazon CloudWatch指标 F. 通过使用ClusterName维度分析ContainerInsights命名空间中的node_memory_utilization Amazon CloudWatch指标<div class="section-title"><strong>核心要求:</strong></div> 为EKS集群收集和分析内存指标以解决内存错误和扩展问题 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• <span class="key-service">Amazon CloudWatch</span> - 提供指标收集和监控功能 </div><div class="compact-content">• Container Insights - 专门为容器化应用提供详细的性能指标 <div class="section-title"><strong>正确答案CE:</strong></div> C部署CloudWatch代理收集详细内存指标，E使用Container Insights的pod级内存利用率指标进行应用层面分析 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A - 实例配置文件方式不适用于EKS容器化环境的指标收集 </div><div class="compact-content">• 选项B - 虽然是正确的权限方式但题目重点是指标收集和分析方法 </div><div class="compact-content">• 选项D - OpenTelemetry收集器主要用于日志而非内存指标收集 </div><div class="compact-content">• 选项F - node级指标过于粗粒度，无法精确分析应用内存问题 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能 - 需要pod级别的精确内存指标而非节点级粗粒度指标 </div><div class="compact-content">• 成本 - CloudWatch代理是标准的AWS原生监控解决方案 </div><div class="compact-content">• 可扩展性 - Container Insights提供容器化应用的专业监控能力</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: CE (C、E)</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-269">
            <div class="question-header">
                <div class="question-title">Question #269 ✅ ⚪ <small style="float: right;">(269/353)</small></div>
            </div>
            <div class="question-content">A company's video streaming platform usage has increased from 10,000 users each day to 50,000 users each day in multiple countries. The company deploys the streaming platform on Amazon Elastic Kubernetes Service (<span class="key-service">Amazon EKS</span>). The EKS workload scales up to thousands of nodes during peak viewing time. The company's users report occurrences of unauthorized logins. Users also report sudden interruptions and logouts from the platform. The company wants additional security measures for the entire platform. The company also needs a summarized view of the resource behaviors and interactions across the company's entire AWS environment. The summarized view must show login attempts, API calls, and network traffic. The solution must permit network traffic analysis while minimizing the overhead of managing logs. The solution must also quickly investigate any potential malicious behavior that is associated with the EKS workload. Which solution will meet these requirements? B (100%)</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Enable <span class="key-service">Amazon GuardDuty</span> for EKS Audit Log Monitoring. Enable <span class="key-service">AWS CloudTrail</span> logs. Store the EKS audit logs and CloudTrail log files in an <span class="key-service">Amazon S3</span> bucket. Use Amazon Athena to create an external table. Use Amazon QuickSight to create a dashboard.</div>                <div class="option"><strong>B.</strong> Enable <span class="key-service">Amazon GuardDuty</span> for EKS Audit Log Monitoring. Enable Amazon Detective in the company's AWS account. Enable EKS audit logs from optional source packages in Detective.</div>                <div class="option"><strong>C.</strong> Enable <span class="key-service">Amazon CloudWatch</span> Container Insights. Enable <span class="key-service">AWS CloudTrail</span> logs. Store the EKS audit logs and CloudTrail log files in an <span class="key-service">Amazon S3</span> bucket. Use Amazon Athena to create an external table. Use Amazon QuickSight to create a dashboard.</div>                <div class="option correct-answer"><strong>D.</strong> Enable <span class="key-service">Amazon GuardDuty</span> for EKS Audit Log Monitoring. Enable <span class="key-service">Amazon CloudWatch</span> Container Insights and <span class="key-service">VPC</span> Flow Logs. Enable <span class="key-service">AWS CloudTrail</span> logs.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司的视频流媒体平台使用量从每天10,000用户增长到多个国家的50,000用户。公司在Amazon EKS上部署流媒体平台，EKS工作负载在高峰观看时间扩展到数千个节点。用户报告未授权登录和平台突然中断登出问题。公司需要整个平台的额外安全措施，以及整个AWS环境中资源行为和交互的汇总视图，显示登录尝试、API调用和网络流量。解决方案必须允许网络流量分析同时最小化日志管理开销，并快速调查与EKS工作负载相关的潜在恶意行为。 <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 启用Amazon GuardDuty的EKS审计日志监控，启用AWS CloudTrail日志，将EKS审计日志和CloudTrail日志文件存储在Amazon S3存储桶中，使用Amazon Athena创建外部表，使用Amazon QuickSight创建仪表板。</div> <div class="option-analysis"><strong>B.</strong> 启用Amazon GuardDuty的EKS审计日志监控，在公司AWS账户中启用Amazon Detective，在Detective中启用可选源包中的EKS审计日志。</div> <div class="option-analysis"><strong>C.</strong> 启用Amazon CloudWatch Container Insights，启用AWS CloudTrail日志，将EKS审计日志和CloudTrail日志文件存储在Amazon S3存储桶中，使用Amazon Athena创建外部表，使用Amazon QuickSight创建仪表板。</div> <div class="option-analysis"><strong>D.</strong> 启用Amazon GuardDuty的EKS审计日志监控，启用Amazon CloudWatch Container Insights和VPC Flow Logs，启用AWS CloudTrail日志。<div class="section-title"><strong>核心要求:</strong></div> 为大规模EKS平台提供全面安全监控和统一视图，包含威胁检测、网络流量分析和恶意行为调查能力 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• <span class="key-service">Amazon GuardDuty</span>-提供威胁检测和EKS审计日志监控 </div><div class="compact-content">• CloudWatch Container Insights-提供容器性能监控和资源行为分析 </div><div class="compact-content">• <span class="key-service">VPC</span> Flow Logs-提供网络流量分析 </div><div class="compact-content">• CloudTrail-记录API调用和登录活动 <div class="section-title"><strong>正确答案D:</strong></div> 组合GuardDuty威胁检测、Container Insights容器监控、<span class="key-service">VPC</span> Flow Logs网络分析和CloudTrail API审计，提供完整的安全监控覆盖，满足所有要求且无需额外日志管理开销 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A-需要手动构建分析平台，增加管理开销，缺乏自动威胁检测能力 </div><div class="compact-content">• 选项B-Detective主要用于事后调查，缺乏实时网络流量监控和容器性能分析 </div><div class="compact-content">• 选项C-缺乏GuardDuty威胁检测功能，且需要手动构建分析平台增加开销 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-原生AWS服务集成提供实时监控和快速威胁响应 </div><div class="compact-content">• 成本-使用托管服务避免自建分析平台的开发和维护成本 </div><div class="compact-content">• 可扩展性-所有服务都能自动扩展以支持数千节点的EKS集群</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: D</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-270">
            <div class="question-header">
                <div class="question-title">Question #270 ✅ 📝 <small style="float: right;">(270/353)</small></div>
            </div>
            <div class="question-content">A company uses <span class="key-service">AWS Organizations</span> to manage hundreds of AWS accounts. The company has a team that is responsible for AWS Identity and Access Management (IAM). The IAM team wants to implement <span class="key-service">AWS IAM</span> Identity Center (AWS Single Sign-On). The IAM team must have only the minimum needed permissions to manage IAM Identity Center. The IAM team must not be able to gain unneeded access to the Organizations management account. The IAM team must be able to provision new IAM Identity Center permission sets and assignments for existing and new member accounts. Which combination of steps will meet these requirements? (Choose three.) ADF (67%) BCF (33%)</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Create a new AWS account for the IAM team. In the new account, enable IAM Identity Center. In the Organizations management account, register the new account as a delegated administrator for IAM Identity Center.</div>                <div class="option"><strong>B.</strong> Create a new AWS account for the IAM team. In the Organizations management account, enable IAM Identity Center. In the Organizations management account, register the new account as a delegated administrator for IAM Identity Center.</div>                <div class="option correct-answer"><strong>C.</strong> In IAM Identity Center, create users and a group for the IAM team. Add the users to the group. Create a new permission set. Attach the AWSSSODirectoryAdministrator managed IAM policy to the group.</div>                <div class="option correct-answer"><strong>D.</strong> In IAM Identity Center, create users and a group for the IAM team. Add the users to the group. Create a new permission set. Attach the AWSSSOMemberAccountAdministrator managed IAM policy to the group.</div>                <div class="option correct-answer"><strong>E.</strong> Assign the permission set to the Organizations management account. Allow the IAM team group to use the permission set. F. Assign the permission set to the new AWS account. Allow the IAM team group to use the permission set. Most Voted</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司使用AWS Organizations管理数百个AWS账户。公司有一个负责AWS Identity and Access Management (IAM)的团队。IAM团队想要实施AWS IAM Identity Center (AWS Single Sign-On)。IAM团队必须只拥有管理IAM Identity Center所需的最小权限。IAM团队不能获得对Organizations管理账户的不必要访问权限。IAM团队必须能够为现有和新的成员账户配置新的IAM Identity Center权限集和分配。哪些步骤组合将满足这些要求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 为IAM团队创建新的AWS账户。在新账户中启用IAM Identity Center。在Organizations管理账户中，将新账户注册为IAM Identity Center的委托管理员。</div> <div class="option-analysis"><strong>B.</strong> 为IAM团队创建新的AWS账户。在Organizations管理账户中启用IAM Identity Center。在Organizations管理账户中，将新账户注册为IAM Identity Center的委托管理员。</div> <div class="option-analysis"><strong>C.</strong> 在IAM Identity Center中，为IAM团队创建用户和组。将用户添加到组中。创建新的权限集。将AWSSSODirectoryAdministrator托管IAM策略附加到组。</div> <div class="option-analysis"><strong>D.</strong> 在IAM Identity Center中，为IAM团队创建用户和组。将用户添加到组中。创建新的权限集。将AWSSSOMemberAccountAdministrator托管IAM策略附加到组。</div> <div class="option-analysis"><strong>E.</strong> 将权限集分配给Organizations管理账户。允许IAM团队组使用该权限集。 F. 将权限集分配给新的AWS账户。允许IAM团队组使用该权限集。<div class="section-title"><strong>核心要求:</strong></div> 为IAM团队提供管理IAM Identity Center的最小权限，同时避免对管理账户的不必要访问 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• <span class="key-service">AWS Organizations</span> - 集中管理多个AWS账户的服务 </div><div class="compact-content">• <span class="key-service">AWS IAM</span> Identity Center - 集中管理用户访问和单点登录的服务 </div><div class="compact-content">• 委托管理员 - 允许成员账户管理特定服务而不访问管理账户 <div class="section-title"><strong>正确答案CDE:</strong></div> 在管理账户启用IAM Identity Center，创建IAM团队用户组并分配目录管理员和成员账户管理员权限，通过管理账户权限集实现集中管理 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A - 在成员账户启用IAM Identity Center违反了集中管理原则 </div><div class="compact-content">• 选项B - 正确的架构但与F组合会导致权限分散 </div><div class="compact-content">• 选项F - 将权限集分配给成员账户而非管理账户，无法实现集中管理 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 安全性 - 最小权限原则，避免管理账户直接访问 </div><div class="compact-content">• 管理效率 - 集中在管理账户启用和管理IAM Identity Center </div><div class="compact-content">• 权限控制 - 通过委托管理员模式实现职责分离</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: CDE (C、D、E)</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-271">
            <div class="question-header">
                <div class="question-title">Question #271 ✅ 📝 <small style="float: right;">(271/353)</small></div>
            </div>
            <div class="question-content">A company uses an organization in <span class="key-service">AWS Organizations</span> that has all features enabled. The company uses AWS Backup in a primary account and uses an AWS Key Management Service (AWS KMS) key to encrypt the backups. The company needs to automate a cross-account backup of the resources that AWS Backup backs up in the primary account. The company configures cross-account backup in the Organizations management account. The company creates a new AWS account in the organization and configures an AWS Backup backup vault in the new account. The company creates a KMS key in the new account to encrypt the backups. Finally, the company configures a new backup plan in the primary account. The destination for the new backup plan is the backup vault in the new account. When the AWS Backup job in the primary account is invoked, the job creates backups in the primary account. However, the backups are not copied to the new account's backup vault. Which combination of steps must the company take so that backups can be copied to the new account's backup vault? (Choose two.) AE (54%) AD (46%)</div>
            <div class="options-container">                <div class="option correct-answer"><strong>A.</strong> Edit the backup vault access policy in the new account to allow access to the primary account.</div>                <div class="option"><strong>B.</strong> Edit the backup vault access policy in the primary account to allow access to the new account.</div>                <div class="option"><strong>C.</strong> Edit the backup vault access policy in the primary account to allow access to the KMS key in the new account.</div>                <div class="option"><strong>D.</strong> Edit the key policy of the KMS key in the primary account to share the key with the new account.</div>                <div class="option correct-answer"><strong>E.</strong> Edit the key policy of the KMS key in the new account to share the key with the primary account.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司在AWS Organizations中使用启用了所有功能的组织，在主账户中使用AWS Backup并用AWS KMS密钥加密备份。公司需要自动化跨账户备份主账户中AWS Backup备份的资源。公司在Organizations管理账户中配置跨账户备份，在组织中创建新AWS账户并配置AWS Backup备份保管库，在新账户中创建KMS密钥加密备份，最后在主账户中配置新备份计划，目标是新账户的备份保管库。当主账户中的AWS Backup作业被调用时，作业在主账户中创建备份，但备份未复制到新账户的备份保管库。公司必须采取哪些步骤组合才能将备份复制到新账户的备份保管库？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 编辑新账户中的备份保管库访问策略以允许主账户访问</div> <div class="option-analysis"><strong>B.</strong> 编辑主账户中的备份保管库访问策略以允许新账户访问</div> <div class="option-analysis"><strong>C.</strong> 编辑主账户中的备份保管库访问策略以允许访问新账户中的KMS密钥</div> <div class="option-analysis"><strong>D.</strong> 编辑主账户中KMS密钥的密钥策略以与新账户共享密钥</div> <div class="option-analysis"><strong>E.</strong> 编辑新账户中KMS密钥的密钥策略以与主账户共享密钥<div class="section-title"><strong>核心要求:</strong></div> 配置跨账户AWS Backup备份复制的访问权限和加密权限 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• AWS Backup-跨账户备份服务，需要目标账户备份保管库访问权限 </div><div class="compact-content">• AWS KMS-加密服务，目标账户的KMS密钥需要授权源账户使用 <div class="section-title"><strong>正确答案AE:</strong></div> 跨账户备份需要目标账户的备份保管库允许源账户访问(A)，同时目标账户的KMS密钥必须授权源账户使用以完成加密备份复制(E) <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项B-源账户备份保管库不需要授权目标账户访问，数据流向是从源到目标 </div><div class="compact-content">• 选项C-备份保管库访问策略不用于配置KMS密钥访问权限，这是KMS密钥策略的职责 </div><div class="compact-content">• 选项D-源账户的KMS密钥不参与目标账户的备份加密过程，目标使用自己的KMS密钥 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-正确的权限配置确保备份复制顺利执行 </div><div class="compact-content">• 成本-避免不必要的权限配置减少管理开销 </div><div class="compact-content">• 可扩展性-标准的跨账户权限模式便于扩展到更多账户</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: AE (A、E)</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-272">
            <div class="question-header">
                <div class="question-title">Question #272 ✅ 📝 <small style="float: right;">(272/353)</small></div>
            </div>
            <div class="question-content">A company runs an application that uses an <span class="key-service">Amazon S3</span> bucket to store images. A DevOps engineer needs to implement a multi-Region strategy for the objects that are stored in the S3 bucket. The company needs to be able to fail over to an S3 bucket in another AWS Region. When an image is added to either S3 bucket, the image must be replicated to the other S3 bucket within 15 minutes. The DevOps engineer enables two-way replication between the S3 buckets. Which combination of steps should the DevOps engineer take next to meet the requirements? (Choose three.) ABC (100%)</div>
            <div class="options-container">                <div class="option correct-answer"><strong>A.</strong> Enable S3 Replication Time Control (S3 RTC) on each replication rule.</div>                <div class="option"><strong>B.</strong> Create an S3 Multi-Region Access Point in an active-passive configuration.</div>                <div class="option"><strong>C.</strong> Call the SubmitMultiRegionAccessPointRoutes operation in the AWS API when the company needs to fail over to the S3 bucket in the other Region.</div>                <div class="option correct-answer"><strong>D.</strong> Enable S3 Transfer Acceleration on both S3 buckets.</div>                <div class="option"><strong>E.</strong> Configure a routing control in <span class="key-service">Amazon Route 53</span> Recovery Controller. Add the S3 buckets in an active-passive configuration. F. Call the UpdateRoutingControlStates operation in the AWS API when the company needs to fail over to the S3 bucket in the other Region.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司运行一个使用Amazon S3存储桶存储图像的应用程序。DevOps工程师需要为S3存储桶中存储的对象实施多区域策略。公司需要能够故障转移到另一个AWS区域的S3存储桶。当图像添加到任一S3存储桶时，必须在15分钟内复制到另一个S3存储桶。DevOps工程师启用了S3存储桶之间的双向复制。工程师接下来应该采取哪些步骤组合来满足要求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 在每个复制规则上启用S3 Replication Time Control (S3 RTC)</div> <div class="option-analysis"><strong>B.</strong> 创建一个主动-被动配置的S3 Multi-Region Access Point</div> <div class="option-analysis"><strong>C.</strong> 当公司需要故障转移到另一个区域的S3存储桶时，在AWS API中调用SubmitMultiRegionAccessPointRoutes操作</div> <div class="option-analysis"><strong>D.</strong> 在两个S3存储桶上启用S3 Transfer Acceleration</div> <div class="option-analysis"><strong>E.</strong> 在Amazon Route 53 Recovery Controller中配置路由控制，以主动-被动配置添加S3存储桶 F. 当公司需要故障转移到另一个区域的S3存储桶时，在AWS API中调用UpdateRoutingControlStates操作<div class="section-title"><strong>核心要求:</strong></div> 实现S3多区域复制，确保15分钟内完成对象复制并支持区域故障转移 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• S3 RTC - 保证复制时间控制，确保在指定时间内完成跨区域复制 </div><div class="compact-content">• S3 Transfer Acceleration - 加速全球数据传输，提高跨区域复制性能 <div class="section-title"><strong>正确答案AD:</strong></div> S3 RTC确保15分钟复制SLA，Transfer Acceleration优化跨区域传输速度，满足性能要求 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项B - Multi-Region Access Point主要用于访问路由，不是复制性能优化方案 </div><div class="compact-content">• 选项C - SubmitMultiRegionAccessPointRoutes用于访问点路由，非复制时间控制 </div><div class="compact-content">• 选项E - Route 53 Recovery Controller用于应用层故障转移，非S3复制层面控制 </div><div class="compact-content">• 选项F - UpdateRoutingControlStates操作与S3复制时间要求无关 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-S3 RTC保证复制SLA，Transfer Acceleration提升传输速度 </div><div class="compact-content">• 成本-使用原生S3功能，避免额外的控制服务开销 </div><div class="compact-content">• 可扩展性-基于S3原生复制机制，支持大规模对象复制需求</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: AD (A、D)</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-273">
            <div class="question-header">
                <div class="question-title">Question #273 ✅ 📝 <small style="float: right;">(273/353)</small></div>
            </div>
            <div class="question-content">A company uses the AWS Cloud Development Kit (AWS CDK) to define its application. The company uses a pipeline that consists of <span class="key-service">AWS CodePipeline</span> and <span class="key-service">AWS CodeBuild</span> to deploy the CDK application. The company wants to introduce unit tests to the pipeline to test various infrastructure components. The company wants to ensure that a deployment proceeds if no unit tests result in a failure. Which combination of steps will enforce the testing requirement in the pipeline? (Choose two.) AD (100%)</div>
            <div class="options-container">                <div class="option correct-answer"><strong>A.</strong> Update the CodeBuild build phase commands to run the tests then to deploy the application. Set the OnFailure phase property to ABORT.</div>                <div class="option"><strong>B.</strong> Update the CodeBuild build phase commands to run the tests then to deploy the application. Add the --rollback true flag to the cdk deploy command.</div>                <div class="option"><strong>C.</strong> Update the CodeBuild build phase commands to run the tests then to deploy the application. Add the --require-approval any-change flag to the cdk deploy command.</div>                <div class="option correct-answer"><strong>D.</strong> Create a test that uses the AWS CDK assertions module. Use the template.hasResourceProperties assertion to test that resources have the expected properties.</div>                <div class="option"><strong>E.</strong> Create a test that uses the cdk diff command. Configure the test to fail if any resources have changed.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司使用AWS CDK定义其应用程序。公司使用由AWS CodePipeline和AWS CodeBuild组成的流水线来部署CDK应用程序。公司希望在流水线中引入单元测试来测试各种基础设施组件。公司希望确保如果没有单元测试失败，部署就会继续进行。哪些步骤组合将在流水线中强制执行测试要求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 更新CodeBuild构建阶段命令以运行测试然后部署应用程序。将OnFailure阶段属性设置为ABORT。</div> <div class="option-analysis"><strong>B.</strong> 更新CodeBuild构建阶段命令以运行测试然后部署应用程序。在cdk deploy命令中添加--rollback true标志。</div> <div class="option-analysis"><strong>C.</strong> 更新CodeBuild构建阶段命令以运行测试然后部署应用程序。在cdk deploy命令中添加--require-approval any-change标志。</div> <div class="option-analysis"><strong>D.</strong> 创建使用AWS CDK assertions模块的测试。使用template.hasResourceProperties断言来测试资源是否具有预期属性。</div> <div class="option-analysis"><strong>E.</strong> 创建使用cdk diff命令的测试。配置测试在任何资源发生更改时失败。<div class="section-title"><strong>核心要求:</strong></div> 在CDK部署流水线中实现单元测试，确保测试失败时阻止部署继续 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• AWS CDK - 基础设施即代码框架，支持单元测试和assertions模块 </div><div class="compact-content">• <span class="key-service">AWS CodeBuild</span> - CI/CD构建服务，可配置构建阶段和失败处理策略 <div class="section-title"><strong>正确答案AD:</strong></div> A选项通过设置OnFailure为ABORT确保测试失败时中止部署；D选项使用CDK assertions模块创建真正的单元测试来验证基础设施组件属性 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项B - rollback标志用于部署回滚，不能阻止测试失败时的部署继续 </div><div class="compact-content">• 选项C - require-approval标志用于手动批准，与自动化测试要求无关 </div><div class="compact-content">• 选项E - cdk diff只是比较差异，不是真正的单元测试且逻辑错误 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能 - 在构建阶段集成测试，快速反馈 </div><div class="compact-content">• 成本 - 利用现有CodeBuild服务，无额外成本 </div><div class="compact-content">• 可扩展性 - CDK assertions模块支持全面的基础设施测试</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: AD (A、D)</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-274">
            <div class="question-header">
                <div class="question-title">Question #274 ✅ ⚪ <small style="float: right;">(274/353)</small></div>
            </div>
            <div class="question-content">A company has an application that runs on <span class="key-service">Amazon EC2</span> instances behind an Application Load Balancer (ALB). The EC2 instances are in multiple Availability Zones. The application was misconfigured in a single Availability Zone, which caused a partial outage of the application. A DevOps engineer made changes to ensure that the unhealthy EC2 instances in one Availability Zone do not affect the healthy EC2 instances in the other Availability Zones. The DevOps engineer needs to test the application's failover and shift where the ALB sends traffic. During failover, the ALB must avoid sending traffic to the Availability Zone where the failure has occurred. Which solution will meet these requirements? A (75%) C (25%)</div>
            <div class="options-container">                <div class="option correct-answer"><strong>A.</strong> Turn off cross-zone load balancing on the AL<div class="option-analysis"><strong>B.</strong> Use <span class="key-service">Amazon Route 53</span> Application Recovery Controller to start a zonal shift away from the Availability Zone.</div></div>                <div class="option"><strong>B.</strong> Turn off cross-zone load balancing on the ALB's target group. Use <span class="key-service">Amazon Route 53</span> Application Recovery Controller to start a zonal shift away from the Availability Zone.</div>                <div class="option"><strong>C.</strong> Create an <span class="key-service">Amazon Route 53</span> Application Recovery Controller resource set that uses the DNS hostname of the AL<div class="option-analysis"><strong>B.</strong> Start a zonal shift for the resource set away from the Availability Zone.</div></div>                <div class="option"><strong>D.</strong> Create an <span class="key-service">Amazon Route 53</span> Application Recovery Controller resource set that uses the ARN of the ALB's target group. Create a readiness check that uses the ElbV2TargetGroupsCanServeTraffic rule.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司的应用程序运行在Application Load Balancer (ALB)后面的Amazon EC2实例上，EC2实例分布在多个Availability Zone中。应用程序在单个Availability Zone中配置错误，导致应用程序部分中断。DevOps工程师进行了更改以确保一个Availability Zone中的不健康EC2实例不会影响其他Availability Zone中的健康EC2实例。DevOps工程师需要测试应用程序的故障转移并改变ALB发送流量的位置。在故障转移期间，ALB必须避免向发生故障的Availability Zone发送流量。 <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 在ALB上关闭跨区域负载均衡，使用Amazon Route 53 Application Recovery Controller启动从该Availability Zone的区域转移</div> <div class="option-analysis"><strong>B.</strong> 在ALB的目标组上关闭跨区域负载均衡，使用Amazon Route 53 Application Recovery Controller启动从该Availability Zone的区域转移</div> <div class="option-analysis"><strong>C.</strong> 创建使用ALB的DNS主机名的Amazon Route 53 Application Recovery Controller资源集，为资源集启动从该Availability Zone的区域转移</div> <div class="option-analysis"><strong>D.</strong> 创建使用ALB目标组ARN的Amazon Route 53 Application Recovery Controller资源集，创建使用ElbV2TargetGroupsCanServeTraffic规则的就绪检查<div class="section-title"><strong>核心要求:</strong></div> 实现ALB在故障转移时避免向故障Availability Zone发送流量的能力 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• Application Load Balancer - 提供跨区域负载分发和流量控制 </div><div class="compact-content">• Route 53 Application Recovery Controller - 提供区域转移功能控制流量分布 <div class="section-title"><strong>正确答案A:</strong></div> 关闭ALB的跨区域负载均衡确保流量按区域分布，结合Route 53 ARC的zonal shift功能可以直接控制ALB避免向特定AZ发送流量 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项B - 跨区域负载均衡是在ALB级别配置的，不是在目标组级别 </div><div class="compact-content">• 选项C - 使用DNS主机名无法直接控制ALB的区域流量分布 </div><div class="compact-content">• 选项D - 创建就绪检查不能实现主动的流量转移控制 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能 - 确保故障AZ不接收流量，维持应用可用性 </div><div class="compact-content">• 成本 - 利用现有ALB和ARC服务，无需额外资源 </div><div class="compact-content">• 可扩展性 - 支持多AZ架构的灵活流量控制</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: A</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-275">
            <div class="question-header">
                <div class="question-title">Question #275 ✅ ⚪ <small style="float: right;">(275/353)</small></div>
            </div>
            <div class="question-content">A company sends its AWS Network Firewall flow logs to an <span class="key-service">Amazon S3</span> bucket. The company then analyzes the flow logs by using Amazon Athena. The company needs to transform the flow logs and add additional data before the flow logs are delivered to the existing S3 bucket. Which solution will meet these requirements? D (100%)</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Create an <span class="key-service">AWS Lambda</span> function to transform the data and to write a new object to the existing S3 bucket. Configure the Lambda function with an S3 trigger for the existing S3 bucket. Specify all object create events for the event type. Acknowledge the recursive invocation.</div>                <div class="option"><strong>B.</strong> Enable Amazon EventBridge notifications on the existing S3 bucket. Create a custom EventBridge event bus. Create an EventBridge rule that is associated with the custom event bus. Configure the rule to react to all object create events for the existing S3 bucket and to invoke an <span class="key-service">AWS Step Functions</span> workflow. Configure a Step Functions task to transform the data and to write the data into a new S3 bucket.</div>                <div class="option correct-answer"><strong>C.</strong> Create an Amazon EventBridge rule that is associated with the default EventBridge event bus. Configure the rule to react to all object create events for the existing S3 bucket. Define a new S3 bucket as the target for the rule. Create an EventBridge input transformation to customize the event before passing the event to the rule target.</div>                <div class="option"><strong>D.</strong> Create an Amazon Kinesis Data Firehose delivery stream that is configured with an <span class="key-service">AWS Lambda</span> transformer. Specify the existing S3 bucket as the destination. Change the Network Firewall logging destination from <span class="key-service">Amazon S3</span> to Kinesis Data Firehose.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司将其AWS Network Firewall流日志发送到Amazon S3存储桶，然后使用Amazon Athena分析流日志。公司需要在流日志传送到现有S3存储桶之前转换流日志并添加额外数据。 <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 创建AWS Lambda函数来转换数据并将新对象写入现有S3存储桶，为现有S3存储桶配置Lambda函数的S3触发器，为事件类型指定所有对象创建事件，确认递归调用。</div> <div class="option-analysis"><strong>B.</strong> 在现有S3存储桶上启用Amazon EventBridge通知，创建自定义EventBridge事件总线，创建与自定义事件总线关联的EventBridge规则，配置规则响应现有S3存储桶的所有对象创建事件并调用AWS Step Functions工作流，配置Step Functions任务转换数据并将数据写入新S3存储桶。</div> <div class="option-analysis"><strong>C.</strong> 创建与默认EventBridge事件总线关联的Amazon EventBridge规则，配置规则响应现有S3存储桶的所有对象创建事件，定义新S3存储桶作为规则目标，创建EventBridge输入转换以在将事件传递给规则目标之前自定义事件。</div> <div class="option-analysis"><strong>D.</strong> 创建配置了AWS Lambda转换器的Amazon Kinesis Data Firehose传输流，指定现有S3存储桶为目标，将Network Firewall日志记录目标从Amazon S3更改为Kinesis Data Firehose。<div class="section-title"><strong>核心要求:</strong></div> 在流日志到达S3存储桶前进行数据转换和增强处理 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• Kinesis Data Firehose - 实时数据传输和转换服务 </div><div class="compact-content">• Lambda - 无服务器计算进行数据转换 </div><div class="compact-content">• EventBridge - 事件驱动架构服务 <div class="section-title"><strong>正确答案D:</strong></div> 通过修改Network Firewall日志输出到Kinesis Data Firehose，利用内置Lambda转换器在数据流中实时转换数据后再传送到S3，实现了在数据到达目标前的转换需求 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A - 存在递归调用风险，且是在数据已到达S3后进行处理，不符合"传送前转换"要求 </div><div class="compact-content">• 选项B - 架构过于复杂，使用Step Functions增加不必要的复杂性和延迟 </div><div class="compact-content">• 选项C - EventBridge输入转换只能转换事件元数据，无法转换实际的日志内容数据 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能 - Firehose提供实时流处理，无延迟 </div><div class="compact-content">• 成本 - 直接集成方案，避免多服务调用成本 </div><div class="compact-content">• 可扩展性 - Firehose自动扩展，处理大量日志数据</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: C</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-276">
            <div class="question-header">
                <div class="question-title">Question #276 ✅ 📝 <small style="float: right;">(276/353)</small></div>
            </div>
            <div class="question-content">A DevOps engineer needs to implement integration tests into an existing <span class="key-service">AWS CodePipeline</span> CI/CD workflow for an Amazon Elastic Container Service (<span class="key-service">Amazon ECS</span>) service. The CI/CD workflow retrieves new application code from an <span class="key-service">AWS CodeCommit</span> repository and builds a container image. The CI/CD workflow then uploads the container image to Amazon Elastic Container Registry (<span class="key-service">Amazon ECR</span>) with a new image tag version. The integration tests must ensure that new versions of the service endpoint are reachable and that various API methods return successful response data. The DevOps engineer has already created an ECS cluster to test the service. Which combination of steps will meet these requirements with the LEAST management overhead? (Choose three.) ADE (100%)</div>
            <div class="options-container">                <div class="option correct-answer"><strong>A.</strong> Add a deploy stage to the pipeline. Configure <span class="key-service">Amazon ECS</span> as the action provider.</div>                <div class="option"><strong>B.</strong> Add a deploy stage to the pipeline. Configure <span class="key-service">AWS CodeDeploy</span> as the action provider.</div>                <div class="option"><strong>C.</strong> Add an appspec.yml file to the CodeCommit repository.</div>                <div class="option correct-answer"><strong>D.</strong> Update the image build pipeline stage to output an imagedefinitions.json file that references the new image tag.</div>                <div class="option correct-answer"><strong>E.</strong> Create an <span class="key-service">AWS Lambda</span> function that runs connectivity checks and API calls against the service. Integrate the Lambda function with CodePipeline by using a Lambda action stage. F. Write a script that runs integration tests against the service. Upload the script to an <span class="key-service">Amazon S3</span> bucket. Integrate the script in the S3 bucket with CodePipeline by using an S3 action stage.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一名DevOps工程师需要将集成测试实施到现有的AWS CodePipeline CI/CD工作流中，用于Amazon ECS服务。CI/CD工作流从AWS CodeCommit存储库检索新应用程序代码并构建容器镜像，然后将容器镜像上传到Amazon ECR并使用新的镜像标签版本。集成测试必须确保服务端点的新版本可达，并且各种API方法返回成功的响应数据。DevOps工程师已经创建了一个ECS集群来测试服务。哪种步骤组合能以最少的管理开销满足这些要求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 向管道添加部署阶段，配置Amazon ECS作为操作提供者</div> <div class="option-analysis"><strong>B.</strong> 向管道添加部署阶段，配置AWS CodeDeploy作为操作提供者</div> <div class="option-analysis"><strong>C.</strong> 向CodeCommit存储库添加appspec.yml文件</div> <div class="option-analysis"><strong>D.</strong> 更新镜像构建管道阶段以输出引用新镜像标签的imagedefinitions.json文件</div> <div class="option-analysis"><strong>E.</strong> 创建一个AWS Lambda函数来运行连接检查和对服务的API调用，通过使用Lambda操作阶段将Lambda函数与CodePipeline集成 F. 编写一个对服务运行集成测试的脚本，将脚本上传到Amazon S3存储桶，通过使用S3操作阶段将S3存储桶中的脚本与CodePipeline集成<div class="section-title"><strong>核心要求:</strong></div> 在ECS服务的CI/CD管道中实现集成测试，确保服务端点可达性和API响应验证 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• <span class="key-service">Amazon ECS</span> - 容器服务部署和运行平台 </div><div class="compact-content">• <span class="key-service">AWS CodePipeline</span> - CI/CD管道编排服务 </div><div class="compact-content">• <span class="key-service">AWS Lambda</span> - 无服务器计算执行集成测试 <div class="section-title"><strong>正确答案ADE:</strong></div> 使用ECS直接部署(A)配合imagedefinitions.json文件(D)实现容器部署，通过Lambda函数(E)执行自动化集成测试，提供最低管理开销的完整解决方案 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项B - CodeDeploy增加不必要的复杂性，ECS直接部署更简单 </div><div class="compact-content">• 选项C - appspec.yml用于CodeDeploy，与ECS直接部署不匹配 </div><div class="compact-content">• 选项F - S3脚本方案需要额外的执行环境配置，管理开销更大 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能 - Lambda函数提供快速的集成测试执行 </div><div class="compact-content">• 成本 - ECS直接部署避免额外的CodeDeploy费用 </div><div class="compact-content">• 可扩展性 - 原生ECS集成支持更好的扩展性和维护性</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: ADE (A、D、E)</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-277">
            <div class="question-header">
                <div class="question-title">Question #277 ✅ 📝 <small style="float: right;">(277/353)</small></div>
            </div>
            <div class="question-content">A company runs applications on Windows and Linux <span class="key-service">Amazon EC2</span> instances. The instances run across multiple Availability Zones in an AWS Region. The company uses Auto Scaling groups for each application. The company needs a durable storage solution for the instances. The solution must use SMB for Windows and must use NFS for Linux. The solution must also have sub-millisecond latencies. All instances will read and write the data. Which combination of steps will meet these requirements? (Choose three.) BDE (67%) BDF (33%)</div>
            <div class="options-container">                <div class="option correct-answer"><strong>A.</strong> Create an Amazon Elastic File System (<span class="key-service">Amazon <span class="key-service">EFS</span></span>) file system that has targets in multiple Availability Zones.</div>                <div class="option correct-answer"><strong>B.</strong> Create an Amazon FSx for NetApp ONTAP Multi-AZ file system.</div>                <div class="option"><strong>C.</strong> Create a General Purpose SSD (gp3) Amazon Elastic Block Store (Amazon EBS) volume to use for shared storage.</div>                <div class="option"><strong>D.</strong> Update the user data for each application's launch template to mount the file system.</div>                <div class="option"><strong>E.</strong> Perform an instance refresh on each Auto Scaling group. F. Update the EC2 instances for each application to mount the file system when new instances are launched.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司在Windows和Linux Amazon EC2实例上运行应用程序。实例跨AWS区域内的多个可用区运行。公司为每个应用程序使用Auto Scaling组。公司需要为实例提供持久存储解决方案。解决方案必须为Windows使用SMB，为Linux使用NFS。解决方案还必须具有亚毫秒级延迟。所有实例都将读写数据。哪种步骤组合将满足这些要求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 创建一个在多个可用区中具有目标的Amazon Elastic File System (<span class="key-service">Amazon <span class="key-service">EFS</span></span>)文件系统。</div> <div class="option-analysis"><strong>B.</strong> 创建一个Amazon FSx for NetApp ONTAP Multi-AZ文件系统。</div> <div class="option-analysis"><strong>C.</strong> 创建一个通用SSD (gp3) Amazon Elastic Block Store (Amazon EBS)卷用于共享存储。</div> <div class="option-analysis"><strong>D.</strong> 更新每个应用程序启动模板的用户数据以挂载文件系统。</div> <div class="option-analysis"><strong>E.</strong> 对每个Auto Scaling组执行实例刷新。 F. 更新每个应用程序的EC2实例，在启动新实例时挂载文件系统。<div class="section-title"><strong>核心要求:</strong></div> 需要同时支持SMB和NFS协议、具备亚毫秒级延迟的跨可用区共享存储解决方案 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• <span class="key-service">Amazon <span class="key-service">EFS</span></span> - 提供NFS协议支持的托管文件系统服务 </div><div class="compact-content">• Amazon FSx for NetApp ONTAP - 同时支持SMB和NFS协议的高性能文件系统 <div class="section-title"><strong>正确答案AB:</strong></div> EFS提供Linux所需的NFS协议支持，FSx for NetApp ONTAP同时支持Windows的SMB和Linux的NFS协议，两者结合可满足混合环境的协议需求和性能要求 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项C - EBS卷无法在多个实例间共享，不支持SMB/NFS协议 </div><div class="compact-content">• 选项D - 仅配置挂载不足以完成完整解决方案 </div><div class="compact-content">• 选项E - 实例刷新与存储挂载配置无关 </div><div class="compact-content">• 选项F - 描述过于宽泛，缺乏具体实现细节 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能 - 需要亚毫秒级延迟和高IOPS支持 </div><div class="compact-content">• 协议兼容 - 必须同时支持SMB和NFS协议 </div><div class="compact-content">• 可扩展性 - 支持Auto Scaling环境下的动态挂载</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: AB (A、B)</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-278">
            <div class="question-header">
                <div class="question-title">Question #278 ✅ ⚪ <small style="float: right;">(278/353)</small></div>
            </div>
            <div class="question-content">A company uses an organization in <span class="key-service">AWS Organizations</span> that a security team and a DevOps team manage. Both teams access the accounts by using <span class="key-service">AWS IAM</span> Identity Center. A dedicated group has been created for each team. The DevOps team's group has been assigned a permission set named DevOps. The permission set has the AdministratorAccess managed IAM policy attached. The permission set has been applied to all accounts in the organization. The security team wants to ensure that the DevOps team does not have access to IAM Identity Center in the organization's management account. The security team has attached the following <span class="key-service">SCP</span> to the organization root: After implementing the policy, the security team discovers that the DevOps team can still access IAM Identity Center. Which solution will fix the problem? B (40%) D (40%) A (20%)</div>
            <div class="options-container">                <div class="option correct-answer"><strong>A.</strong> In the organization's management account, create a new OU. Move the organization's management account to the new OU. Detach the <span class="key-service">SCP</span> from the organization root. Attach the <span class="key-service">SCP</span> to the new OU.</div>                <div class="option"><strong>B.</strong> In the organization's management account, update the <span class="key-service">SCP</span> condition reference to the ARN of the DevOps team's group role to include the AWS account ID of the organization's management account.</div>                <div class="option"><strong>C.</strong> In IAM Identity Center, create a new permission set. Ensure that the assigned policy has full access but explicitly denies permission for the sso:* action and the sso-directory:* action. Update the assigned permission set for the DevOps team's group role in the organization's management account. Delete the <span class="key-service">SCP</span>.</div>                <div class="option"><strong>D.</strong> In IAM Identity Center, update the DevOps permission set. Ensure that the assigned policy has full access but explicitly denies permission for the sso:* action and the sso-directory:* action. In the Deny statement, add a StringEquals condition that compares the aws:SourceAccount global condition context key with the organization's management account I<div class="option-analysis"><strong>D.</strong> Delete the <span class="key-service">SCP</span>.</div></div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司使用AWS Organizations中的组织，由安全团队和DevOps团队管理。两个团队都通过AWS IAM Identity Center访问账户。为每个团队创建了专用组。DevOps团队的组被分配了名为DevOps的权限集，该权限集附加了AdministratorAccess托管IAM策略，并应用于组织中的所有账户。安全团队希望确保DevOps团队无法访问组织管理账户中的IAM Identity Center。安全团队已将SCP附加到组织根部，但实施后发现DevOps团队仍可访问IAM Identity Center。哪个解决方案能解决这个问题？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 在组织的管理账户中，创建一个新的OU。将组织的管理账户移动到新的OU。从组织根部分离SCP。将SCP附加到新的OU。</div> <div class="option-analysis"><strong>B.</strong> 在组织的管理账户中，更新SCP条件引用到DevOps团队组角色的ARN，包含组织管理账户的AWS账户ID。</div> <div class="option-analysis"><strong>C.</strong> 在IAM Identity Center中，创建一个新的权限集。确保分配的策略具有完全访问权限但明确拒绝sso:*操作和sso-directory:*操作。更新组织管理账户中DevOps团队组角色的分配权限集。删除SCP。</div> <div class="option-analysis"><strong>D.</strong> 在IAM Identity Center中，更新DevOps权限集。确保分配的策略具有完全访问权限但明确拒绝sso:*操作和sso-directory:*操作。在Deny语句中，添加StringEquals条件，将aws:SourceAccount全局条件上下文键与组织管理账户ID进行比较。删除SCP。<div class="section-title"><strong>核心要求:</strong></div> 限制DevOps团队在组织管理账户中访问IAM Identity Center服务 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• <span class="key-service">AWS Organizations</span> - 提供SCP策略控制和OU组织结构管理 </div><div class="compact-content">• IAM Identity Center - 提供集中身份管理和权限集配置 <div class="section-title"><strong>正确答案A:</strong></div> 管理账户无法被SCP直接限制，需要创建新OU并将管理账户移入其中，然后将SCP附加到OU上才能生效 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项B - 仅更新SCP条件无法解决管理账户不受SCP限制的根本问题 </div><div class="compact-content">• 选项C - 创建新权限集增加了复杂性，且删除SCP会影响其他账户的控制 </div><div class="compact-content">• 选项D - 修改权限集并删除SCP无法保持对其他账户的统一控制 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能 - 通过OU结构实现精确的策略应用范围 </div><div class="compact-content">• 成本 - 利用现有SCP策略，无需重新设计权限架构 </div><div class="compact-content">• 可扩展性 - 保持组织层面的统一安全控制框架</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: A</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-279">
            <div class="question-header">
                <div class="question-title">Question #279 ✅ ⚪ <small style="float: right;">(279/353)</small></div>
            </div>
            <div class="question-content">An <span class="key-service">Amazon EC2</span> Auto Scaling group manages EC2 instances that were created from an AMI. The AMI has the <span class="key-service">AWS Systems Manager</span> Agent installed. When an EC2 instance is launched into the Auto Scaling group, tags are applied to the EC2 instance. EC2 instances that are launched by the Auto Scaling group must have the correct operating system configuration. Which solution will meet these requirements? B (100%)</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Create a Systems Manager Run Command document that configures the desired instance configuration. Set up Systems Manager Compliance to invoke the Run Command document when the EC2 instances are not in compliance with the most recent patches.</div>                <div class="option correct-answer"><strong>B.</strong> Create a Systems Manager State Manager association that links to the Systems Manager command document. Create a tag query that runs immediately.</div>                <div class="option"><strong>C.</strong> Create a Systems Manager Run Command task that specifies the desired instance configuration. Create a maintenance window in Systems Manager Maintenance Windows that runs daily. Register the Run Command task against the maintenance window. Designate the targets.</div>                <div class="option"><strong>D.</strong> Create a Systems Manager Patch Manager patch baseline and a patch group that use the same tags that the Auto Scaling group applies. Register the patch group with the patch baseline. Define a Systems Manager command document to patch the instances. Invoke the document by using Systems Manager Run Command.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一个Amazon EC2 Auto Scaling组管理从AMI创建的EC2实例。AMI已安装AWS Systems Manager Agent。当EC2实例启动到Auto Scaling组时，会对EC2实例应用标签。由Auto Scaling组启动的EC2实例必须具有正确的操作系统配置。哪种解决方案能满足这些要求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 创建一个配置所需实例配置的Systems Manager Run Command文档。设置Systems Manager Compliance在EC2实例不符合最新补丁时调用Run Command文档。</div> <div class="option-analysis"><strong>B.</strong> 创建一个链接到Systems Manager命令文档的Systems Manager State Manager关联。创建一个立即运行的标签查询。</div> <div class="option-analysis"><strong>C.</strong> 创建一个指定所需实例配置的Systems Manager Run Command任务。在Systems Manager Maintenance Windows中创建每日运行的维护窗口。将Run Command任务注册到维护窗口并指定目标。</div> <div class="option-analysis"><strong>D.</strong> 创建一个Systems Manager Patch Manager补丁基线和使用Auto Scaling组相同标签的补丁组。将补丁组注册到补丁基线。定义Systems Manager命令文档来修补实例。使用Systems Manager Run Command调用文档。<div class="section-title"><strong>核心要求:</strong></div> Auto Scaling组中新启动的EC2实例需要立即自动配置正确的操作系统设置 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• Systems Manager State Manager-自动维护实例配置状态的持续管理服务 </div><div class="compact-content">• Auto Scaling-根据需求自动启动和终止EC2实例的服务 <div class="section-title"><strong>正确答案B:</strong></div> State Manager关联可以基于标签自动识别新启动的实例并立即应用配置，确保Auto Scaling组中的实例始终保持正确的操作系统配置状态 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A-Compliance是被动检查合规性，无法在实例启动时主动配置 </div><div class="compact-content">• 选项C-维护窗口是定时执行，无法满足新实例立即配置的需求 </div><div class="compact-content">• 选项D-Patch Manager主要用于补丁管理，不是完整的操作系统配置解决方案 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-State Manager提供实时自动配置，响应速度最快 </div><div class="compact-content">• 成本-利用现有标签机制，无需额外的调度和监控成本 </div><div class="compact-content">• 可扩展性-自动适应Auto Scaling组的动态扩缩容需求</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: B</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-280">
            <div class="question-header">
                <div class="question-title">Question #280 ✅ ⚪ <small style="float: right;">(280/353)</small></div>
            </div>
            <div class="question-content">A company uses <span class="key-service">AWS Organizations</span> to manage its AWS accounts. The organization root has a child OU that is named Department. The Department OU has a child OU that is named Engineering. The default FullAWSAccess policy is attached to the root, the Department OU, and the Engineering OU. The company has many AWS accounts in the Engineering OU. Each account has an administrative IAM role with the AdministratorAccess IAM policy attached. The default FullAWSAccess policy is also attached to each account. A DevOps engineer plans to remove the FullAWSAccess policy from the Department OU. The DevOps engineer will replace the policy with a policy that contains an Allow statement for all <span class="key-service">Amazon EC2</span> API operations. What will happen to the permissions of the administrative IAM roles as a result of this change? B (67%) A (33%)</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> All API actions on all resources will be allowed.</div>                <div class="option correct-answer"><strong>B.</strong> All API actions on EC2 resources will be allowed. All other API actions will be denied.</div>                <div class="option"><strong>C.</strong> All API actions on all resources will be denied.</div>                <div class="option"><strong>D.</strong> All API actions on EC2 resources will be denied. All other API actions will be allowed.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司使用AWS Organizations管理其AWS账户。组织根有一个名为Department的子OU。Department OU有一个名为Engineering的子OU。默认的FullAWSAccess策略附加到根、Department OU和Engineering OU。公司在Engineering OU中有许多AWS账户。每个账户都有一个附加了AdministratorAccess IAM策略的管理IAM角色。默认的FullAWSAccess策略也附加到每个账户。DevOps工程师计划从Department OU中移除FullAWSAccess策略，并用包含所有Amazon EC2 API操作Allow语句的策略替换。此更改对管理IAM角色权限会产生什么影响？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 所有资源上的所有API操作都将被允许。</div> <div class="option-analysis"><strong>B.</strong> EC2资源上的所有API操作都将被允许。所有其他API操作都将被拒绝。</div> <div class="option-analysis"><strong>C.</strong> 所有资源上的所有API操作都将被拒绝。</div> <div class="option-analysis"><strong>D.</strong> EC2资源上的所有API操作都将被拒绝。所有其他API操作都将被允许。<div class="section-title"><strong>核心要求:</strong></div> 理解AWS Organizations中SCP策略继承和权限交集的影响机制 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• <span class="key-service">AWS Organizations</span> - 提供SCP策略的层级继承和权限边界控制 </div><div class="compact-content">• IAM - 提供角色权限，但受到SCP策略的限制和过滤 <div class="section-title"><strong>正确答案B:</strong></div> SCP策略采用交集模式，当Department OU的FullAWSAccess被替换为仅允许EC2操作的策略后，Engineering OU中的账户权限将被限制为EC2操作与原有权限的交集，即只能执行EC2相关操作 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A - 忽略了SCP策略的限制作用，Department OU的策略变更会直接影响子OU的权限边界 </div><div class="compact-content">• 选项C - 过度限制，Engineering OU仍有FullAWSAccess且新策略允许EC2操作 </div><div class="compact-content">• 选项D - 逻辑颠倒，EC2操作是被明确允许的，其他操作才会被拒绝 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 权限继承 - SCP策略从父OU向子OU传递并形成权限边界 </div><div class="compact-content">• 交集原则 - 最终权限是所有层级SCP策略的交集 </div><div class="compact-content">• 策略优先级 - SCP作为权限边界优先于IAM策略生效</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: B</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-281">
            <div class="question-header">
                <div class="question-title">Question #281 ✅ ⚪ <small style="float: right;">(281/353)</small></div>
            </div>
            <div class="question-content">A company manages AWS accounts in <span class="key-service">AWS Organizations</span>. The company needs a solution to send <span class="key-service">Amazon CloudWatch</span> Logs data to an <span class="key-service">Amazon S3</span> bucket in a dedicated AWS account. The solution must support all existing and future CloudWatch Logs log groups. Which solution will meet these requirements? D (100%)</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Enable Organizations backup policies to back up all log groups to a dedicated S3 bucket. Add an S3 bucket policy that allows access from all accounts that belong to the company.</div>                <div class="option"><strong>B.</strong> Create a backup plan in AWS Backup. Specify a dedicated S3 bucket as a backup vault. Assign all CloudWatch Logs log group resources to the backup plan. Create resource assignments in the backup plan for all accounts that belong to the company.</div>                <div class="option"><strong>C.</strong> Create a backup plan in AWS Backup. Specify a dedicated S3 bucket as a backup vault. Assign all existing log groups to the backup plan. Create resource assignments in the backup plan for all accounts that belong to the company. Create an <span class="key-service">AWS Systems Manager</span> Automation runbook to assign log groups to a backup plan. Create an <span class="key-service">AWS Config</span> rule that has an automatic remediation action for all noncompliant log groups. Specify the runbook as the rule's target.</div>                <div class="option correct-answer"><strong>D.</strong> Create a CloudWatch Logs destination and an Amazon Kinesis Data Firehose delivery stream in the dedicated AWS account. Specify the S3 bucket as the destination of the delivery stream. Create subscription filters for all existing log groups in all accounts. Create an <span class="key-service">AWS Lambda</span> function to call the CloudWatch Logs PutSubscriptionFilter API operation. Create an Amazon EventBridge rule to invoke the Lambda function when a CreateLogGroup event occurs.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司在AWS Organizations中管理AWS账户。公司需要一个解决方案将Amazon CloudWatch Logs数据发送到专用AWS账户中的Amazon S3存储桶。解决方案必须支持所有现有和未来的CloudWatch Logs日志组。 <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 启用Organizations备份策略将所有日志组备份到专用S3存储桶。添加S3存储桶策略允许公司所有账户访问。</div> <div class="option-analysis"><strong>B.</strong> 在AWS Backup中创建备份计划。指定专用S3存储桶作为备份保管库。将所有CloudWatch Logs日志组资源分配给备份计划。为公司所有账户创建备份计划中的资源分配。</div> <div class="option-analysis"><strong>C.</strong> 在AWS Backup中创建备份计划。指定专用S3存储桶作为备份保管库。将所有现有日志组分配给备份计划。为公司所有账户创建备份计划中的资源分配。创建AWS Systems Manager自动化运行手册将日志组分配给备份计划。创建带有自动修复操作的AWS Config规则处理所有不合规日志组。指定运行手册作为规则目标。</div> <div class="option-analysis"><strong>D.</strong> 在专用AWS账户中创建CloudWatch Logs目标和Amazon Kinesis Data Firehose传输流。指定S3存储桶作为传输流目标。为所有账户中的所有现有日志组创建订阅筛选器。创建AWS Lambda函数调用CloudWatch Logs PutSubscriptionFilter API操作。创建Amazon EventBridge规则在CreateLogGroup事件发生时调用Lambda函数。<div class="section-title"><strong>核心要求:</strong></div> 实现跨账户CloudWatch Logs数据实时传输到专用S3存储桶并自动支持新日志组 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• CloudWatch Logs - 日志数据源和订阅筛选器管理 </div><div class="compact-content">• Kinesis Data Firehose - 实时数据传输到S3存储桶 </div><div class="compact-content">• EventBridge - 监听新日志组创建事件触发自动化 <div class="section-title"><strong>正确答案D:</strong></div> 使用CloudWatch Logs订阅筛选器将日志流式传输到Kinesis Data Firehose，再传输到S3，通过EventBridge和Lambda实现新日志组的自动配置 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A - Organizations备份策略不支持CloudWatch Logs备份 </div><div class="compact-content">• 选项B - AWS Backup不支持CloudWatch Logs作为备份资源类型 </div><div class="compact-content">• 选项C - 同样基于不支持的AWS Backup服务，且方案过于复杂 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能 - 实时流式传输vs批量备份传输 </div><div class="compact-content">• 成本 - 原生日志传输服务vs复杂自动化方案 </div><div class="compact-content">• 可扩展性 - 事件驱动自动配置新日志组vs手动管理</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: D</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-282">
            <div class="question-header">
                <div class="question-title">Question #282 ✅ 📝 <small style="float: right;">(282/353)</small></div>
            </div>
            <div class="question-content">A DevOps engineer manages a Java-based application that runs in an Amazon Elastic Container Service (<span class="key-service">Amazon ECS</span>) cluster on <span class="key-service">AWS Fargate</span>. Auto scaling has not been configured for the application. The DevOps engineer has determined that the Java Virtual Machine (JVM) thread count is a good indicator of when to scale the application. The application serves customer traffic on port 8080 and makes JVM metrics available on port 9404. Application use has recently increased. The DevOps engineer needs to configure auto scaling for the application. Which solution will meet these requirements with the LEAST operational overhead? (Choose two.)</div>
            <div class="options-container">                <div class="option correct-answer"><strong>A.</strong> Deploy the <span class="key-service">Amazon CloudWatch</span> agent as a container sidecar. Configure the CloudWatch agent to retrieve JVM metrics from port 9404. Create CloudWatch alarms on the JVM thread count metric to scale the application. Add a step scaling policy in Fargate to scale up and scale down based on the CloudWatch alarms.</div>                <div class="option"><strong>B.</strong> Deploy the <span class="key-service">Amazon CloudWatch</span> agent as a container sidecar. Configure a metric filter for the JVM thread count metric on the CloudWatch log group for the CloudWatch agent. Add a target tracking policy in Fargate. Select the metric from the metric filter as a scale target.</div>                <div class="option"><strong>C.</strong> Create an Amazon Managed Service for Prometheus workspace. Deploy AWS Distro for OpenTelemetry as a container sidecar to publish the JVM metrics from port 9404 to the Prometheus workspace. Configure rules for the workspace to use the JVM thread count metric to scale the application. Add a step scaling policy in Fargate. Select the Prometheus rules to scale up and scaling down.</div>                <div class="option correct-answer"><strong>D.</strong> Create an Amazon Managed Service for Prometheus workspace. Deploy AWS Distro for OpenTelemetry as a container sidecar to retrieve JVM metrics from port 9404 to publish the JVM metrics from port 9404 to the Prometheus workspace. Add a target tracking policy in Fargate. Select the Prometheus metric as a scale target.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一名DevOps工程师管理运行在AWS Fargate上Amazon ECS集群中的Java应用程序。应用程序未配置自动扩展。工程师确定JVM线程数是扩展应用程序的良好指标。应用程序在8080端口提供客户流量，在9404端口提供JVM指标。应用使用量最近增加。工程师需要为应用程序配置自动扩展。哪个解决方案能以最少的运营开销满足这些要求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 将Amazon CloudWatch代理部署为容器sidecar。配置CloudWatch代理从9404端口检索JVM指标。在JVM线程数指标上创建CloudWatch告警来扩展应用程序。在Fargate中添加步进扩展策略，基于CloudWatch告警进行扩展和缩减。</div> <div class="option-analysis"><strong>B.</strong> 将Amazon CloudWatch代理部署为容器sidecar。在CloudWatch代理的CloudWatch日志组上为JVM线程数指标配置指标过滤器。在Fargate中添加目标跟踪策略。选择指标过滤器中的指标作为扩展目标。</div> <div class="option-analysis"><strong>C.</strong> 创建Amazon Managed Service for Prometheus工作空间。部署AWS Distro for OpenTelemetry作为容器sidecar，将9404端口的JVM指标发布到Prometheus工作空间。为工作空间配置规则，使用JVM线程数指标扩展应用程序。在Fargate中添加步进扩展策略。选择Prometheus规则进行扩展和缩减。</div> <div class="option-analysis"><strong>D.</strong> 创建Amazon Managed Service for Prometheus工作空间。部署AWS Distro for OpenTelemetry作为容器sidecar，从9404端口检索JVM指标并发布到Prometheus工作空间。在Fargate中添加目标跟踪策略。选择Prometheus指标作为扩展目标。<div class="section-title"><strong>核心要求:</strong></div> 为Fargate上的ECS应用配置基于JVM线程数的自动扩展，最小化运营开销 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• <span class="key-service">Amazon ECS</span> Fargate-无服务器容器运行平台，支持自动扩展策略 </div><div class="compact-content">• CloudWatch-AWS原生监控服务，提供指标收集和告警功能 </div><div class="compact-content">• Amazon Managed Service for Prometheus-托管的Prometheus服务，支持容器指标监控 <div class="section-title"><strong>正确答案AD:</strong></div> 两种方案都提供完整的指标收集到自动扩展的端到端解决方案：A使用CloudWatch原生集成，D使用Prometheus现代化监控栈，都能直接与Fargate扩展策略集成 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项B-指标过滤器用于日志分析而非直接指标收集，无法有效处理JVM性能指标 </div><div class="compact-content">• 选项C-Prometheus规则不能直接触发Fargate扩展策略，缺少与AWS Auto Scaling的集成机制 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-直接从应用指标端点收集JVM线程数，实现精确的扩展触发 </div><div class="compact-content">• 成本-使用托管服务减少基础设施管理成本，避免自建监控系统 </div><div class="compact-content">• 可扩展性-支持目标跟踪和步进扩展策略，适应不同的流量模式和扩展需求</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: AD (A、D)</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-283">
            <div class="question-header">
                <div class="question-title">Question #283 ✅ ⚪ <small style="float: right;">(283/353)</small></div>
            </div>
            <div class="question-content">A company has an application that runs in a single AWS Region. The application runs on an Amazon Elastic Kubernetes Service (<span class="key-service">Amazon EKS</span>) cluster and connects to an Amazon Aurora MySQL cluster. The application is built in an <span class="key-service">AWS CodeBuild</span> project. The container images are published to Amazon Elastic Container Registry (<span class="key-service">Amazon ECR</span>). The company needs to replicate the state of the application for the container images and the database to a second Region. Which solution will meet these requirements in the MOST operationally efficient way?</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Turn on <span class="key-service">Amazon S3</span> Cross-Region Replication (CRR) on the bucket that holds the ECR container images. Deploy the application to an EKS cluster in the second Region by referencing the new S3 bucket object URL for the container image in a Kubernetes deployment file. Configure a cross-Region Aurora Replica in the second Region. Configure the new application deployment to use the endpoints for the cross-Region Aurora Replica.</div>                <div class="option"><strong>B.</strong> Create an Amazon EventBridge rule that reacts to image pushes to the ECR repository. Configure the EventBridge rule to invoke an <span class="key-service">AWS Lambda</span> function to replicate the image to a new ECR repository in the second Region. Deploy the application to an EKS cluster in the second Region by referencing the new ECR repository in a Kubernetes deployment file. Configure a cross-Region Aurora Replica in the second Region. Configure the new application deployment to use the endpoints for the cross-Region Aurora Replica.</div>                <div class="option correct-answer"><strong>C.</strong> Turn on Cross-Region Replication to replicate the ECR repository to the second Region. Deploy the application to an EKS cluster in the second Region by referencing the new ECR repository in a Kubernetes deployment file. Configure an Aurora global database with clusters in the initial Region and the second Region. Configure the new application deployment to use the endpoints for the second Region's cluster in the Aurora global database.</div>                <div class="option"><strong>D.</strong> Configure the CodeBuild project to also push the container image to an ECR repository in the second Region. Deploy the application to an EKS cluster in the second Region by referencing the new ECR repository in a Kubernetes deployment file. Configure an Aurora MySQL cluster in the second Region as the target for binary log replication from the Aurora MySQL cluster in the initial Region. Configure the new application deployment to use the endpoints for the second Region's cluster.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司有一个在单个AWS区域运行的应用程序。该应用程序运行在Amazon EKS集群上并连接到Amazon Aurora MySQL集群。应用程序在AWS CodeBuild项目中构建。容器镜像发布到Amazon ECR。公司需要将应用程序的容器镜像和数据库状态复制到第二个区域。哪种解决方案能以最具运营效率的方式满足这些要求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 在存储ECR容器镜像的存储桶上启用Amazon S3跨区域复制(CRR)。通过在Kubernetes部署文件中引用新S3存储桶对象URL作为容器镜像，将应用程序部署到第二个区域的EKS集群。在第二个区域配置跨区域Aurora副本。配置新的应用程序部署使用跨区域Aurora副本的端点。</div> <div class="option-analysis"><strong>B.</strong> 创建Amazon EventBridge规则响应ECR存储库的镜像推送。配置EventBridge规则调用AWS Lambda函数将镜像复制到第二个区域的新ECR存储库。通过在Kubernetes部署文件中引用新ECR存储库，将应用程序部署到第二个区域的EKS集群。在第二个区域配置跨区域Aurora副本。配置新的应用程序部署使用跨区域Aurora副本的端点。</div> <div class="option-analysis"><strong>C.</strong> 启用跨区域复制将ECR存储库复制到第二个区域。通过在Kubernetes部署文件中引用新ECR存储库，将应用程序部署到第二个区域的EKS集群。配置Aurora全球数据库，在初始区域和第二个区域都有集群。配置新的应用程序部署使用Aurora全球数据库中第二个区域集群的端点。</div> <div class="option-analysis"><strong>D.</strong> 配置CodeBuild项目同时将容器镜像推送到第二个区域的ECR存储库。通过在Kubernetes部署文件中引用新ECR存储库，将应用程序部署到第二个区域的EKS集群。在第二个区域配置Aurora MySQL集群作为来自初始区域Aurora MySQL集群二进制日志复制的目标。配置新的应用程序部署使用第二个区域集群的端点。<div class="section-title"><strong>核心要求:</strong></div> 以最具运营效率的方式将EKS应用程序和Aurora数据库复制到第二个区域 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• <span class="key-service">Amazon ECR</span>-容器镜像存储和跨区域复制 </div><div class="compact-content">• Aurora Global Database-提供跨区域数据库复制和故障转移能力 <div class="section-title"><strong>正确答案C:</strong></div> 使用ECR原生跨区域复制功能和Aurora Global Database提供自动化的镜像和数据库复制，运营开销最小 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A-ECR镜像不存储在S3中，无法使用S3 CRR复制ECR镜像 </div><div class="compact-content">• 选项B-使用EventBridge和Lambda增加了不必要的复杂性和运营开销 </div><div class="compact-content">• 选项D-需要修改CodeBuild项目并手动配置二进制日志复制，运营效率较低 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-Aurora Global Database提供更好的跨区域性能和一致性 </div><div class="compact-content">• 成本-避免额外的Lambda函数和EventBridge规则成本 </div><div class="compact-content">• 可扩展性-ECR原生复制和Aurora Global Database提供更好的自动化扩展能力</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: C</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-284">
            <div class="question-header">
                <div class="question-title">Question #284 ✅ ⚪ <small style="float: right;">(284/353)</small></div>
            </div>
            <div class="question-content">A company is building a serverless application that uses <span class="key-service">AWS Lambda</span> functions to process data. A BeginResponse Lambda function initializes data in response to specific application events. The company needs to ensure that a large number of Lambda functions are invoked after the BeginResponse Lambda function runs. Each Lambda function must be invoked in parallel and depends on only the outputs of the BeginResponse Lambda function. Each Lambda function has retry logic for invocation and must be able to fine-tune concurrency without losing data. Which solution will meet these requirements with the MOST operational efficiency?</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Create an Amazon Simple Notification Service (<span class="key-service">Amazon SNS</span>) topic. Modify the BeginResponse Lambda function to publish to the SNS topic before the BeginResponse Lambda function finishes running. Subscribe all Lambda functions that need to invoke after the BeginResponse Lambda function runs to the SNS topic. Subscribe any new Lambda functions to the SNS topic.</div>                <div class="option correct-answer"><strong>B.</strong> Create an Amazon Simple Queue Service (<span class="key-service">Amazon SQS</span>) queue for each Lambda function that needs to run after the BeginResponse Lambda function runs. Subscribe each Lambda function to its own SQS queue. Create an Amazon Simple Notification Service (<span class="key-service">Amazon SNS</span>) topic. Subscribe each SQS queue to the SNS topic. Modify the BeginResponse function to publish to the SNS topic when it finishes running.</div>                <div class="option"><strong>C.</strong> Create an Amazon Simple Queue Service (<span class="key-service">Amazon SQS</span>) queue for each Lambda function that needs to run after the BeginResponse Lambda function runs. Subscribe the Lambda function to the SQS queue. Create an Amazon Simple Notification Service (<span class="key-service">Amazon SNS</span>) topic for each SQS queue. Subscribe the SQS queues to the SNS topics. Modify the BeginResponse function to publish to the SNS topics when the function finishes running.</div>                <div class="option"><strong>D.</strong> Create an <span class="key-service">AWS Step Functions</span> Standard Workflow. Configure states in the workflow to invoke the Lambda functions sequentially. Create an Amazon Simple Notification Service (<span class="key-service">Amazon SNS</span>) topic. Modify the BeginResponse Lambda function to publish to the SNS topic before the Lambda function finishes running. Create a new Lambda function that is subscribed to the SNS topic and that invokes the Step Functions workflow.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司正在构建使用AWS Lambda函数处理数据的无服务器应用程序。BeginResponse Lambda函数响应特定应用程序事件初始化数据。公司需要确保在BeginResponse Lambda函数运行后调用大量Lambda函数。每个Lambda函数必须并行调用且仅依赖BeginResponse Lambda函数的输出。每个Lambda函数具有调用重试逻辑，必须能够在不丢失数据的情况下微调并发性。哪种解决方案能以最高的运营效率满足这些要求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 创建Amazon SNS主题。修改BeginResponse Lambda函数在完成运行前发布到SNS主题。将所有需要在BeginResponse Lambda函数运行后调用的Lambda函数订阅到SNS主题。将任何新的Lambda函数订阅到SNS主题。</div> <div class="option-analysis"><strong>B.</strong> 为每个需要在BeginResponse Lambda函数运行后运行的Lambda函数创建Amazon SQS队列。将每个Lambda函数订阅到其自己的SQS队列。创建Amazon SNS主题。将每个SQS队列订阅到SNS主题。修改BeginResponse函数在完成运行时发布到SNS主题。</div> <div class="option-analysis"><strong>C.</strong> 为每个需要在BeginResponse Lambda函数运行后运行的Lambda函数创建Amazon SQS队列。将Lambda函数订阅到SQS队列。为每个SQS队列创建Amazon SNS主题。将SQS队列订阅到SNS主题。修改BeginResponse函数在函数完成运行时发布到SNS主题。</div> <div class="option-analysis"><strong>D.</strong> 创建AWS Step Functions标准工作流。配置工作流中的状态以顺序调用Lambda函数。创建Amazon SNS主题。修改BeginResponse Lambda函数在完成运行前发布到SNS主题。创建订阅SNS主题并调用Step Functions工作流的新Lambda函数。<div class="section-title"><strong>核心要求:</strong></div> 实现大量Lambda函数并行调用，支持重试逻辑和并发控制，确保数据不丢失 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• <span class="key-service">Amazon SNS</span>-实现扇出消息分发到多个目标 </div><div class="compact-content">• <span class="key-service">Amazon SQS</span>-提供消息队列、重试机制和并发控制 </div><div class="compact-content">• <span class="key-service">AWS Lambda</span>-无服务器计算服务 <div class="section-title"><strong>正确答案B:</strong></div> 使用SNS扇出到多个SQS队列，每个Lambda函数对应一个SQS队列，实现并行处理、重试机制和独立的并发控制 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A-直接SNS订阅Lambda缺乏重试机制和并发控制能力 </div><div class="compact-content">• 选项C-为每个SQS队列创建独立SNS主题增加不必要的复杂性和运营开销 </div><div class="compact-content">• 选项D-Step Functions顺序执行违背并行处理要求 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-SNS+SQS架构支持高并发和并行处理 </div><div class="compact-content">• 成本-单个SNS主题配合多个SQS队列成本效益最优 </div><div class="compact-content">• 可扩展性-易于添加新Lambda函数和队列，运营效率最高</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: B</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-285">
            <div class="question-header">
                <div class="question-title">Question #285 ✅ ⚪ <small style="float: right;">(285/353)</small></div>
            </div>
            <div class="question-content">A company operates a globally deployed product out of multiple AWS Regions. The company's DevOps team needs to use <span class="key-service">Amazon API Gateway</span> to deploy an API to support the product. The API must be deployed redundantly. The deployment must provide independent availability from each company location. The deployment also must respond to a custom domain URL and must optimize performance for the API user requests. Which solution will meet these requirements?</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Deploy an API Gateway edge-optimized API endpoint in the us-east-1 Region. Create an API Gateway custom domain for the API. Create an <span class="key-service">Amazon Route 53</span> record set with a geoproximity routing policy for the API's custom domain. Increase the geographic bias to the maximum allowed value.</div>                <div class="option"><strong>B.</strong> Deploy an API Gateway regional API endpoint in the us-east-1 Region. Integrate the API Gateway API with a public Application Load Balancer (ALB). Create an AWS Global Accelerator standard accelerator. Associate the endpoint with the AL<div class="option-analysis"><strong>B.</strong> Create an <span class="key-service">Amazon Route 53</span> alias record set that points the custom domain name to the DNS name that is assigned to the accelerator.</div></div>                <div class="option correct-answer"><strong>C.</strong> Deploy an API Gateway regional API endpoint in every AWS Region where the company's product is deployed. Create an API Gateway custom domain in each Region for the deployed API Gateway API. Create an <span class="key-service">Amazon Route 53</span> record set that has a latency routing policy for every deployed API Gateway custom domain.</div>                <div class="option"><strong>D.</strong> Deploy an API Gateway edge-optimized API endpoint in the us-east-1 Region. Create an Amazon CloudFront distribution. Configure the CloudFront distribution with an alternate domain name. Specify the API Gateway Invoke URL as the origin domain. Create an <span class="key-service">Amazon Route 53</span> alias record set with a simple routing policy. Point the routing policy to the CloudFront distribution domain name.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司在多个AWS Region全球部署产品。DevOps团队需要使用Amazon API Gateway部署API来支持产品。API必须冗余部署，从每个公司位置提供独立可用性，还必须响应自定义域名URL并为API用户请求优化性能。 <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 在us-east-1 Region部署API Gateway边缘优化API端点，为API创建API Gateway自定义域名，创建Amazon Route 53记录集使用地理邻近路由策略，将地理偏差增加到最大允许值。</div> <div class="option-analysis"><strong>B.</strong> 在us-east-1 Region部署API Gateway区域API端点，将API Gateway API与公共Application Load Balancer集成，创建AWS Global Accelerator标准加速器，将端点与ALB关联，创建Amazon Route 53别名记录集将自定义域名指向加速器的DNS名称。</div> <div class="option-analysis"><strong>C.</strong> 在公司产品部署的每个AWS Region部署API Gateway区域API端点，在每个Region为部署的API Gateway API创建API Gateway自定义域名，创建Amazon Route 53记录集对每个部署的API Gateway自定义域名使用延迟路由策略。</div> <div class="option-analysis"><strong>D.</strong> 在us-east-1 Region部署API Gateway边缘优化API端点，创建Amazon CloudFront分发，配置CloudFront分发使用备用域名，指定API Gateway调用URL作为源域名，创建Amazon Route 53别名记录集使用简单路由策略指向CloudFront分发域名。<div class="section-title"><strong>核心要求:</strong></div> 全球多Region冗余部署API Gateway，提供独立可用性和性能优化 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• API Gateway-提供API管理和部署能力 </div><div class="compact-content">• Route 53-提供DNS路由和流量分发 </div><div class="compact-content">• 多Region部署-确保冗余和独立可用性 <div class="section-title"><strong>正确答案C:</strong></div> 在每个Region部署区域API端点提供真正的冗余和独立可用性，延迟路由策略确保用户被路由到最近的端点获得最佳性能 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A-仅在单个Region部署，不满足冗余和独立可用性要求 </div><div class="compact-content">• 选项B-仅在单个Region部署，ALB和Global Accelerator无法提供真正的区域独立性 </div><div class="compact-content">• 选项D-仅在单个Region部署，CloudFront虽然提供全球分发但不提供区域独立性 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-多Region部署配合延迟路由提供最佳用户体验 </div><div class="compact-content">• 成本-区域API端点比边缘优化更经济且满足需求 </div><div class="compact-content">• 可扩展性-每个Region独立部署提供最高的可用性和扩展性</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: C</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-286">
            <div class="question-header">
                <div class="question-title">Question #286 ✅ ⚪ <small style="float: right;">(286/353)</small></div>
            </div>
            <div class="question-content">A DevOps engineer uses <span class="key-service">AWS CodeBuild</span> to frequently produce software packages. The CodeBuild project builds large Docker images that the DevOps engineer can use across multiple builds. The DevOps engineer wants to improve build performance and minimize costs. Which solution will meet these requirements?</div>
            <div class="options-container">                <div class="option correct-answer"><strong>A.</strong> Store the Docker images in an Amazon Elastic Container Registry (<span class="key-service">Amazon ECR</span>) repository. Implement a local Docker layer cache for CodeBuild.</div>                <div class="option"><strong>B.</strong> Cache the Docker images in an <span class="key-service">Amazon S3</span> bucket that is available across multiple build hosts. Expire the cache by using an S3 Lifecycle policy.</div>                <div class="option"><strong>C.</strong> Store the Docker images in an Amazon Elastic Container Registry (<span class="key-service">Amazon ECR</span>) repository. Modify the CodeBuild project runtime configuration to always use the most recent image version.</div>                <div class="option"><strong>D.</strong> Create custom AMIs that contain the cached Docker images. In the CodeBuild build, launch <span class="key-service">Amazon EC2</span> instances from the custom AMIs.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一名DevOps工程师使用AWS CodeBuild频繁生成软件包。CodeBuild项目构建大型Docker镜像，工程师可以在多个构建中使用这些镜像。DevOps工程师希望提高构建性能并最小化成本。哪个解决方案能满足这些要求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 将Docker镜像存储在Amazon Elastic Container Registry (<span class="key-service">Amazon ECR</span>)仓库中。为CodeBuild实施本地Docker层缓存。</div> <div class="option-analysis"><strong>B.</strong> 将Docker镜像缓存在可跨多个构建主机使用的Amazon S3存储桶中。使用S3生命周期策略使缓存过期。</div> <div class="option-analysis"><strong>C.</strong> 将Docker镜像存储在Amazon Elastic Container Registry (<span class="key-service">Amazon ECR</span>)仓库中。修改CodeBuild项目运行时配置以始终使用最新的镜像版本。</div> <div class="option-analysis"><strong>D.</strong> 创建包含缓存Docker镜像的自定义AMI。在CodeBuild构建中，从自定义AMI启动Amazon EC2实例。<div class="section-title"><strong>核心要求:</strong></div> 优化CodeBuild构建大型Docker镜像的性能并降低成本 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• <span class="key-service">Amazon ECR</span> - 托管的Docker容器注册表服务 </div><div class="compact-content">• CodeBuild - 完全托管的持续集成服务，支持本地缓存 <div class="section-title"><strong>正确答案A:</strong></div> ECR提供高效的镜像存储和拉取，本地Docker层缓存避免重复下载相同的镜像层，显著提升构建速度并减少网络传输成本 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项B - S3不是为Docker镜像优化的存储方案，缺乏镜像层去重和高效拉取机制 </div><div class="compact-content">• 选项C - 始终使用最新版本无法利用缓存优势，每次都需要重新拉取完整镜像 </div><div class="compact-content">• 选项D - 自定义AMI和EC2实例增加管理复杂性和成本，违背CodeBuild托管服务的优势 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能 - Docker层缓存避免重复传输，ECR提供优化的镜像分发 </div><div class="compact-content">• 成本 - 减少网络传输和存储成本，无需额外EC2实例 </div><div class="compact-content">• 可扩展性 - 利用CodeBuild和ECR的原生集成和自动扩展能力</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: A</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-287">
            <div class="question-header">
                <div class="question-title">Question #287 ✅ ⚪ <small style="float: right;">(287/353)</small></div>
            </div>
            <div class="question-content">A large company recently acquired a small company. The large company invited the small company to join the large company's existing organization in <span class="key-service">AWS Organizations</span> as a new OU. A DevOps engineer determines that the small company needs to launch t3.small <span class="key-service">Amazon EC2</span> instance types for the company's application workloads. The small company needs to deploy the instances only within US-based AWS Regions. The DevOps engineer needs to use an <span class="key-service">SCP</span> in the small company's new OU to ensure that the small company can launch only the required instance types. Which solution will meet these requirements?</div>
            <div class="options-container">                <div class="option correct-answer"><strong>A.</strong> Configure a statement to deny the ec2:RunInstances action for all EC2 instance resources when the ec2:InstanceType condition is not equal to t3.small. Configure another statement to deny the ec2:RunInstances action for all EC2 instance resources when the aws:RequestedRegion condition is not equal to us-*.</div>                <div class="option"><strong>B.</strong> Configure a statement to allow the ec2:RunInstances action for all EC2 instance resources when the ec2:InstanceType condition is not equal to t3.small. Configure another statement to allow the ec2:RunInstances action for all EC2 instance resources when the aws:RequestedRegion condition is not equal to us-*.</div>                <div class="option"><strong>C.</strong> Configure a statement to deny the ec2:RunInstances action for all EC2 instance resources when the ec2:InstanceType condition is equal to t3.small. Configure another statement to deny the ec2:RunInstances action for all EC2 instance resources when the aws:RequestedRegion condition is equal to us-*.</div>                <div class="option"><strong>D.</strong> Configure a statement to allow the ec2:RunInstances action for all EC2 instance resources when the ec2:InstanceType condition is equal to t3.small. Configure another statement to allow the ec2:RunInstances action for all EC2 instance resources when the aws:RequestedRegion condition is equal to us-*.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家大公司最近收购了一家小公司。大公司邀请小公司作为新的OU加入大公司在AWS Organizations中的现有组织。DevOps工程师确定小公司需要为其应用工作负载启动t3.small Amazon EC2实例类型。小公司需要仅在美国的AWS区域内部署实例。DevOps工程师需要在小公司的新OU中使用SCP来确保小公司只能启动所需的实例类型。 <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 配置一个语句，当ec2:InstanceType条件不等于t3.small时，拒绝对所有EC2实例资源执行ec2:RunInstances操作。配置另一个语句，当aws:RequestedRegion条件不等于us-*时，拒绝对所有EC2实例资源执行ec2:RunInstances操作。</div> <div class="option-analysis"><strong>B.</strong> 配置一个语句，当ec2:InstanceType条件不等于t3.small时，允许对所有EC2实例资源执行ec2:RunInstances操作。配置另一个语句，当aws:RequestedRegion条件不等于us-*时，允许对所有EC2实例资源执行ec2:RunInstances操作。</div> <div class="option-analysis"><strong>C.</strong> 配置一个语句，当ec2:InstanceType条件等于t3.small时，拒绝对所有EC2实例资源执行ec2:RunInstances操作。配置另一个语句，当aws:RequestedRegion条件等于us-*时，拒绝对所有EC2实例资源执行ec2:RunInstances操作。</div> <div class="option-analysis"><strong>D.</strong> 配置一个语句，当ec2:InstanceType条件等于t3.small时，允许对所有EC2实例资源执行ec2:RunInstances操作。配置另一个语句，当aws:RequestedRegion条件等于us-*时，允许对所有EC2实例资源执行ec2:RunInstances操作。<div class="section-title"><strong>核心要求:</strong></div> 使用SCP限制小公司只能在美国区域启动t3.small实例类型 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• <span class="key-service">AWS Organizations</span>-提供集中管理多个AWS账户的服务 </div><div class="compact-content">• <span class="key-service">SCP</span>-服务控制策略，用于限制组织单位中账户的权限 <div class="section-title"><strong>正确答案A:</strong></div> 使用Deny语句配合条件键，当实例类型不是t3.small或区域不是us-*时拒绝启动实例，实现白名单效果 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项B-使用Allow语句配合错误条件，会允许启动非t3.small实例和非美国区域 </div><div class="compact-content">• 选项C-拒绝启动t3.small实例和美国区域，与需求完全相反 </div><div class="compact-content">• 选项D-SCP中Allow语句不起限制作用，无法实现权限控制 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-SCP策略评估不影响实例性能 </div><div class="compact-content">• 成本-通过限制实例类型控制成本 </div><div class="compact-content">• 可扩展性-SCP可应用于整个OU，便于管理扩展</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: A</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-288">
            <div class="question-header">
                <div class="question-title">Question #288 ✅ ⚪ <small style="float: right;">(288/353)</small></div>
            </div>
            <div class="question-content">A DevOps team manages infrastructure for an application. The application uses long-running processes to process items from an Amazon Simple Queue Service (<span class="key-service">Amazon SQS</span>) queue. The application is deployed to an Auto Scaling group. The application recently experienced an issue where items were taking significantly longer to process. The queue exceeded the expected size, which prevented various business processes from functioning properly. The application records all logs to a third-party tool. The team is currently subscribed to an Amazon Simple Notification Service (<span class="key-service">Amazon SNS</span>) topic that the team uses for alerts. The team needs to be alerted if the queue exceeds the expected size. Which solution will meet these requirements with the MOST operational efficiency?</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Create an <span class="key-service">Amazon CloudWatch</span> metric alarm with a period of 1 hour and a static threshold to alarm if the average of the ApproximateNumberOfMessagesDelayed metric is greater than the expected value. Configure the alarm to notify the SNS topic.</div>                <div class="option correct-answer"><strong>B.</strong> Create an <span class="key-service">Amazon CloudWatch</span> metric alarm with a period of 1 hour and a static threshold to alarm if the sum of the ApproximateNumberOfMessagesVisible metric is greater than the expected value. Configure the alarm to notify the SNS topic.</div>                <div class="option"><strong>C.</strong> Create an <span class="key-service">AWS Lambda</span> function that retrieves the ApproximateNumberOfMessages SQS queue attribute value and publishes the value as a new CloudWatch custom metric. Create an Amazon EventBridge rule that is scheduled to run every 5 minutes and that invokes the Lambda function. Configure a CloudWatch metrics alarm with a period of 1 hour and a static threshold to alarm if the sum of the new custom metric is greater than the expected value.</div>                <div class="option"><strong>D.</strong> Create an <span class="key-service">AWS Lambda</span> function that checks the ApproximateNumberOfMessagesDelayed SQS queue attribute and compares the value to a defined expected size in the function. Create an Amazon EventBridge rule that is scheduled to run every 5 minutes and that invokes the Lambda function. When the ApproximateNumberOfMessagesDelayed SQS queue attribute exceeds the expected size, send a notification to the SNS topic.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一个DevOps团队管理应用程序基础设施。应用程序使用长时间运行的进程来处理Amazon SQS队列中的项目。应用程序部署到Auto Scaling组。应用程序最近遇到项目处理时间显著延长的问题。队列超过了预期大小，阻止了各种业务流程正常运行。应用程序将所有日志记录到第三方工具。团队目前订阅了用于告警的Amazon SNS主题。团队需要在队列超过预期大小时收到告警。哪个解决方案能以最高的运营效率满足要求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 创建一个Amazon CloudWatch指标告警，周期为1小时，静态阈值，当ApproximateNumberOfMessagesDelayed指标的平均值大于预期值时告警。配置告警通知SNS主题。</div> <div class="option-analysis"><strong>B.</strong> 创建一个Amazon CloudWatch指标告警，周期为1小时，静态阈值，当ApproximateNumberOfMessagesVisible指标的总和大于预期值时告警。配置告警通知SNS主题。</div> <div class="option-analysis"><strong>C.</strong> 创建一个AWS Lambda函数检索ApproximateNumberOfMessages SQS队列属性值并将其发布为新的CloudWatch自定义指标。创建每5分钟运行一次的Amazon EventBridge规则调用Lambda函数。配置CloudWatch指标告警，周期1小时，静态阈值，当新自定义指标总和大于预期值时告警。</div> <div class="option-analysis"><strong>D.</strong> 创建一个AWS Lambda函数检查ApproximateNumberOfMessagesDelayed SQS队列属性并将值与函数中定义的预期大小进行比较。创建每5分钟运行一次的Amazon EventBridge规则调用Lambda函数。当ApproximateNumberOfMessagesDelayed SQS队列属性超过预期大小时，向SNS主题发送通知。<div class="section-title"><strong>核心要求:</strong></div> 监控SQS队列大小并在超过预期时通过SNS发送告警，要求最高运营效率 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• CloudWatch - 提供SQS原生指标监控和告警功能 </div><div class="compact-content">• SQS - 提供ApproximateNumberOfMessagesVisible等内置指标 </div><div class="compact-content">• SNS - 发送告警通知 <div class="section-title"><strong>正确答案B:</strong></div> 直接使用CloudWatch原生SQS指标ApproximateNumberOfMessagesVisible监控队列中可见消息总数，无需额外代码或自定义资源，运营效率最高 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A - ApproximateNumberOfMessagesDelayed指标监控延迟消息而非队列总大小，不符合需求 </div><div class="compact-content">• 选项C - 创建Lambda函数和自定义指标增加复杂性和成本，ApproximateNumberOfMessages与ApproximateNumberOfMessagesVisible功能重复 </div><div class="compact-content">• 选项D - 使用Lambda和EventBridge增加运营复杂性，且ApproximateNumberOfMessagesDelayed不是队列大小的正确指标 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能 - CloudWatch原生指标响应及时，无额外延迟 </div><div class="compact-content">• 成本 - 使用原生服务最经济，避免Lambda和EventBridge费用 </div><div class="compact-content">• 可扩展性 - CloudWatch告警自动扩展，无需管理额外基础设施</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: B</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-289">
            <div class="question-header">
                <div class="question-title">Question #289 ✅ ⚪ <small style="float: right;">(289/353)</small></div>
            </div>
            <div class="question-content">A large company runs critical workloads in multiple AWS accounts. The AWS accounts are managed under <span class="key-service">AWS Organizations</span> with all features enabled. The company stores confidential customer data in an <span class="key-service">Amazon S3</span> bucket. Access to the S3 bucket requires multiple levels of approval. The company wants to monitor when the S3 bucket is accessed by using the AWS CLI. The company also wants insights into the various activities performed by other users on all other S3 buckets in the AWS accounts to detect any issues. Which solution will meet these requirements?</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Create an <span class="key-service">AWS CloudTrail</span> trail that is delivered to <span class="key-service">Amazon CloudWatch</span> in each AWS account. Enable data events logs for all S3 buckets. Use <span class="key-service">Amazon GuardDuty</span> for anomaly detection in all the AWS accounts. Use Amazon Athena to perform SQL queries on the custom metrics created from the CloudTrail logs.</div>                <div class="option correct-answer"><strong>B.</strong> Create an <span class="key-service">AWS CloudTrail</span> organization trail that is delivered to <span class="key-service">Amazon CloudWatch</span> in the Organizations management account. Enable data events logs for all S3 buckets. Use <span class="key-service">Amazon CloudWatch</span> anomaly detection in all the AWS accounts. Use Amazon Athena to perform SQL queries on the custom metrics created from the CloudTrail logs.</div>                <div class="option"><strong>C.</strong> Create an <span class="key-service">AWS CloudTrail</span> organization trail that is delivered to <span class="key-service">Amazon CloudWatch</span> in the Organizations management account. Enable data events logs for all S3 buckets. Use <span class="key-service">Amazon CloudWatch</span> anomaly detection in all the AWS accounts. Use <span class="key-service">Amazon CloudWatch</span> Metrics Insights to perform SQL queries on the custom metrics created from the CloudTrail logs.</div>                <div class="option"><strong>D.</strong> Create an <span class="key-service">AWS CloudTrail</span> trail that is delivered to <span class="key-service">Amazon CloudWatch</span> in each AWS account. Enable data events logs for all S3 buckets. Use a custom solution for anomaly detection in all the AWS accounts. Use <span class="key-service">Amazon CloudWatch</span> Metrics Insights to perform SQL queries on the custom metrics created from the CloudTrail logs.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家大公司在多个AWS账户中运行关键工作负载。这些AWS账户通过启用所有功能的AWS Organizations进行管理。公司在Amazon S3存储桶中存储机密客户数据。访问该S3存储桶需要多级审批。公司希望监控使用AWS CLI访问S3存储桶的情况。公司还希望深入了解其他用户在所有AWS账户中其他S3存储桶上执行的各种活动以检测任何问题。哪种解决方案能满足这些要求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 在每个AWS账户中创建一个交付到Amazon CloudWatch的AWS CloudTrail跟踪。为所有S3存储桶启用数据事件日志。在所有AWS账户中使用Amazon GuardDuty进行异常检测。使用Amazon Athena对从CloudTrail日志创建的自定义指标执行SQL查询。</div> <div class="option-analysis"><strong>B.</strong> 在Organizations管理账户中创建一个交付到Amazon CloudWatch的AWS CloudTrail组织跟踪。为所有S3存储桶启用数据事件日志。在所有AWS账户中使用Amazon CloudWatch异常检测。使用Amazon Athena对从CloudTrail日志创建的自定义指标执行SQL查询。</div> <div class="option-analysis"><strong>C.</strong> 在Organizations管理账户中创建一个交付到Amazon CloudWatch的AWS CloudTrail组织跟踪。为所有S3存储桶启用数据事件日志。在所有AWS账户中使用Amazon CloudWatch异常检测。使用Amazon CloudWatch Metrics Insights对从CloudTrail日志创建的自定义指标执行SQL查询。</div> <div class="option-analysis"><strong>D.</strong> 在每个AWS账户中创建一个交付到Amazon CloudWatch的AWS CloudTrail跟踪。为所有S3存储桶启用数据事件日志。在所有AWS账户中使用自定义解决方案进行异常检测。使用Amazon CloudWatch Metrics Insights对从CloudTrail日志创建的自定义指标执行SQL查询。<div class="section-title"><strong>核心要求:</strong></div> 监控多账户环境中S3存储桶的CLI访问和用户活动，并进行异常检测分析 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• <span class="key-service">AWS CloudTrail</span>-记录API调用和数据事件，支持组织级跟踪 </div><div class="compact-content">• <span class="key-service">Amazon CloudWatch</span>-提供异常检测和日志存储功能 </div><div class="compact-content">• Amazon Athena-对结构化日志数据执行SQL查询分析 <div class="section-title"><strong>正确答案B:</strong></div> 使用CloudTrail组织跟踪实现跨账户统一监控，CloudWatch异常检测提供托管服务，Athena适合查询CloudTrail日志数据 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A-使用GuardDuty而非CloudWatch异常检测，且每账户单独跟踪增加管理复杂性 </div><div class="compact-content">• 选项C-使用CloudWatch Metrics Insights查询日志数据不如Athena适合 </div><div class="compact-content">• 选项D-自定义异常检测方案增加开发维护成本，且每账户单独跟踪效率低 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-组织跟踪提供统一视图，CloudWatch异常检测响应及时 </div><div class="compact-content">• 成本-单一组织跟踪比多个独立跟踪成本更低，托管服务减少运维成本 </div><div class="compact-content">• 可扩展性-组织跟踪自动覆盖新账户，托管异常检测服务可自动扩展</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: B</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-290">
            <div class="question-header">
                <div class="question-title">Question #290 ✅ ⚪ <small style="float: right;">(290/353)</small></div>
            </div>
            <div class="question-content">A DevOps team is deploying microservices for an application on an Amazon Elastic Kubernetes Service (<span class="key-service">Amazon EKS</span>) cluster. The cluster uses managed node groups. The DevOps team wants to enable auto scaling for the microservice Pods based on a specific CPU utilization percentage. The DevOps team has already installed the Kubernetes Metrics Server on the cluster. Which solution will meet these requirements in the MOST operationally efficient way?</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Edit the Auto Scaling group that is associated with the worker nodes of the EKS cluster. Configure the Auto Scaling group to use a target tracking scaling policy to scale when the average CPU utilization of the Auto Scaling group reaches a specific percentage.</div>                <div class="option"><strong>B.</strong> Deploy the Kubernetes Horizontal Pod Autoscaler (HPA) and the Kubernetes Vertical Pod Autoscaler (VPA) in the cluster. Configure the HPA to scale based on the target CPU utilization percentage. Configure the VPA to use the recommender mode setting.</div>                <div class="option"><strong>C.</strong> Run the <span class="key-service">AWS Systems Manager</span> AWS-UpdateEKSManagedNodeGroup Automation document. Modify the values for NodeGroupDesiredSize, NodeGroupMaxSize, and NodeGroupMinSize to be based on an estimate for the required node size.</div>                <div class="option correct-answer"><strong>D.</strong> Deploy the Kubernetes Horizontal Pod Autoscaler (HPA) and the Kubernetes Cluster Autoscaler in the cluster. Configure the HPA to scale based on the target CPU utilization percentage. Configure the Cluster Autoscaler to use the auto-discovery setting.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一个DevOps团队正在Amazon EKS集群上为应用程序部署微服务，集群使用托管节点组。团队希望基于特定CPU利用率百分比为微服务Pod启用自动扩展，已在集群上安装了Kubernetes Metrics Server。哪种解决方案能以最具运营效率的方式满足这些要求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 编辑与EKS集群工作节点关联的Auto Scaling组，配置Auto Scaling组使用目标跟踪扩展策略，当Auto Scaling组的平均CPU利用率达到特定百分比时进行扩展</div> <div class="option-analysis"><strong>B.</strong> 在集群中部署Kubernetes Horizontal Pod Autoscaler (HPA)和Kubernetes Vertical Pod Autoscaler (VPA)，配置HPA基于目标CPU利用率百分比进行扩展，配置VPA使用推荐器模式设置</div> <div class="option-analysis"><strong>C.</strong> 运行AWS Systems Manager的AWS-UpdateEKSManagedNodeGroup自动化文档，基于所需节点大小的估算修改NodeGroupDesiredSize、NodeGroupMaxSize和NodeGroupMinSize的值</div> <div class="option-analysis"><strong>D.</strong> 在集群中部署Kubernetes Horizontal Pod Autoscaler (HPA)和Kubernetes Cluster Autoscaler，配置HPA基于目标CPU利用率百分比进行扩展，配置Cluster Autoscaler使用自动发现设置<div class="section-title"><strong>核心要求:</strong></div> 基于CPU利用率为微服务Pod实现自动扩展 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• <span class="key-service">Amazon EKS</span> - 托管Kubernetes服务，支持Pod和节点自动扩展 </div><div class="compact-content">• Kubernetes HPA - 基于CPU/内存等指标水平扩展Pod </div><div class="compact-content">• Kubernetes Cluster Autoscaler - 根据Pod需求自动调整节点数量 <div class="section-title"><strong>正确答案D:</strong></div> HPA负责Pod级别的水平扩展，Cluster Autoscaler负责节点级别的扩展，两者配合实现完整的自动扩展解决方案 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A - 仅扩展节点而不扩展Pod，无法满足微服务Pod扩展需求 </div><div class="compact-content">• 选项B - VPA用于垂直扩展资源配置而非水平扩展Pod数量，不符合要求 </div><div class="compact-content">• 选项C - 手动修改节点组大小，缺乏自动化且运营效率低 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能 - HPA+Cluster Autoscaler提供Pod和节点双层自动扩展 </div><div class="compact-content">• 成本 - 根据实际需求动态调整资源，避免过度配置 </div><div class="compact-content">• 可扩展性 - 自动发现模式支持多节点组的灵活扩展管理</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: D</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-291">
            <div class="question-header">
                <div class="question-title">Question #291 ✅ ⚪ <small style="float: right;">(291/353)</small></div>
            </div>
            <div class="question-content">A company has multiple AWS accounts. The company uses <span class="key-service">AWS IAM</span> Identity Center that is integrated with a third-party SAML 2.0 identity provider (IdP). The attributes for access control feature is enabled in IAM Identity Center. The attribute mapping list maps the department key from the IdP to the ${path:enterprise.department} attribute. All existing <span class="key-service">Amazon EC2</span> instances have a d1, d2, d3 department tag that corresponds to three company's departments. A DevOps engineer must create policies based on the matching attributes. The policies must grant each user access to only the EC2 instances that are tagged with the user's respective department name. Which condition key should the DevOps engineer include in the custom permissions policies to meet these requirements?</div>
            <div class="options-container">            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司有多个AWS账户，使用与第三方SAML 2.0身份提供商(IdP)集成的AWS IAM Identity Center，启用了访问控制属性功能，属性映射将IdP的department键映射到${path:enterprise.department}属性。所有现有EC2实例都有d1、d2、d3部门标签对应公司三个部门。DevOps工程师必须基于匹配属性创建策略，策略必须授予每个用户仅访问标记有用户各自部门名称的EC2实例。工程师应在自定义权限策略中包含哪个条件键来满足这些要求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> [选项A内容未提供]</div> <div class="option-analysis"><strong>B.</strong> [选项B内容未提供]</div> <div class="option-analysis"><strong>C.</strong> [选项C内容未提供]</div> <div class="option-analysis"><strong>D.</strong> [选项D内容未提供]<div class="section-title"><strong>核心要求:</strong></div> 基于用户部门属性限制EC2实例访问权限 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• <span class="key-service">AWS IAM</span> Identity Center - 提供SAML联合身份验证和属性映射 </div><div class="compact-content">• EC2资源标签 - 用于标识实例所属部门 <div class="section-title"><strong>正确答案B:</strong></div> 应使用aws:PrincipalTag条件键配合StringEquals操作符，通过${path:enterprise.department}属性值与EC2实例的department标签进行匹配，实现基于用户部门属性的访问控制 <div class="section-title"><strong>错误选项:</strong></div> 其他选项可能使用了错误的条件键如aws:RequestedRegion、ec2:ResourceTag或aws:userid等，无法正确匹配用户的部门属性与资源标签 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 安全性-必须使用正确的条件键匹配用户属性和资源标签 </div><div class="compact-content">• 可管理性-利用现有的属性映射和标签体系 </div><div class="compact-content">• 精确性-确保用户只能访问对应部门的EC2实例</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: B</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-292">
            <div class="question-header">
                <div class="question-title">Question #292 ✅ ⚪ <small style="float: right;">(292/353)</small></div>
            </div>
            <div class="question-content">A security team wants to use <span class="key-service">AWS CloudTrail</span> to monitor all actions and API calls in multiple accounts that are in the same organization in <span class="key-service">AWS Organizations</span>. The security team needs to ensure that account users cannot turn off CloudTrail in the accounts. Which solution will meet this requirement?</div>
            <div class="options-container">                <div class="option correct-answer"><strong>A.</strong> Apply an <span class="key-service">SCP</span> to all OUs to deny the cloudtrail:StopLogging action and the cloudtrail:DeleteTrail action.</div>                <div class="option"><strong>B.</strong> Create IAM policies in each account to deny the cloudtrail:StopLogging action and the cloudtrail:DeleteTrail action.</div>                <div class="option"><strong>C.</strong> Set up <span class="key-service">Amazon CloudWatch</span> alarms to notify the security team when a user disables CloudTrail in an account.</div>                <div class="option"><strong>D.</strong> Use <span class="key-service">AWS Config</span> to automatically re-enable CloudTrail if a user disables CloudTrail in an account.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 安全团队希望使用AWS CloudTrail监控AWS Organizations同一组织内多个账户中的所有操作和API调用。安全团队需要确保账户用户无法在账户中关闭CloudTrail。哪个解决方案能满足这个要求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 对所有OU应用SCP来拒绝cloudtrail:StopLogging操作和cloudtrail:DeleteTrail操作。</div> <div class="option-analysis"><strong>B.</strong> 在每个账户中创建IAM策略来拒绝cloudtrail:StopLogging操作和cloudtrail:DeleteTrail操作。</div> <div class="option-analysis"><strong>C.</strong> 设置Amazon CloudWatch告警，当用户在账户中禁用CloudTrail时通知安全团队。</div> <div class="option-analysis"><strong>D.</strong> 使用AWS Config在用户禁用账户中的CloudTrail时自动重新启用CloudTrail。<div class="section-title"><strong>核心要求:</strong></div> 在AWS Organizations多账户环境中防止用户关闭CloudTrail监控 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• <span class="key-service">AWS Organizations</span> <span class="key-service">SCP</span>-组织级别的权限边界控制，可跨账户强制执行安全策略 </div><div class="compact-content">• CloudTrail-API调用审计服务，需要防止被用户关闭 <div class="section-title"><strong>正确答案A:</strong></div> SCP在组织级别强制执行权限边界，即使账户管理员也无法绕过，能从根本上阻止关闭CloudTrail的操作 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项B-IAM策略可被账户管理员修改或删除，无法提供可靠保护 </div><div class="compact-content">• 选项C-仅提供事后通知，无法阻止CloudTrail被关闭的行为 </div><div class="compact-content">• 选项D-存在时间窗口风险，且无法阻止用户反复关闭CloudTrail <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-SCP提供实时权限控制，无延迟阻止违规操作 </div><div class="compact-content">• 成本-SCP无额外费用，比多账户IAM管理更经济 </div><div class="compact-content">• 可扩展性-组织级别统一管理，新账户自动继承保护策略</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: A</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-293">
            <div class="question-header">
                <div class="question-title">Question #293 ✅ ⚪ <small style="float: right;">(293/353)</small></div>
            </div>
            <div class="question-content">A DevOps engineer needs to configure a blue/green deployment for an existing three-tier application. The application runs on <span class="key-service">Amazon EC2</span> instances and uses an <span class="key-service">Amazon RDS</span> database. The EC2 instances run behind an Application Load Balancer (ALB) and are in an Auto Scaling group. The DevOps engineer has created launch templates, Auto Scaling groups, and ALB target groups for the blue environment and the green environment. Each target group specifies which application version, blue or green, will be loaded on the EC2 instances. An <span class="key-service">Amazon Route 53</span> record for www.example.com points to the AL<div class="option-analysis"><strong>B.</strong> The deployment must shift traffic all at once from the blue environment to the green environment. Which solution will meet these requirements?</div></div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Start a rolling restart of the Auto Scaling group for the green environment to deploy the new application version to the green environment's EC2 instances. When the rolling restart is complete, use an AWS CLI command to update the ALB to send traffic to the green environment's target group.</div>                <div class="option correct-answer"><strong>B.</strong> Use an AWS CLI command to update the ALB to send traffic to the green environment's target group. Start a rolling restart of the Auto Scaling group for the green environment to deploy the new application version to the green environment's EC2 instances.</div>                <div class="option"><strong>C.</strong> Update the launch template to deploy the green environment's application version to the blue environment's EC2 instances. Do not change the target groups or the Auto Scaling groups in either environment. Perform a rolling restart of the blue environment's EC2 instances.</div>                <div class="option"><strong>D.</strong> Start a rolling restart of the Auto Scaling group for the green environment to deploy the new application version to the green environment's EC2 instances. When the rolling restart is complete, update Route 53 to point to the green environment's endpoint on the ALB.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一名DevOps工程师需要为现有的三层应用程序配置蓝/绿部署。应用程序运行在Amazon EC2实例上并使用Amazon RDS数据库。EC2实例运行在Application Load Balancer (ALB)后面并位于Auto Scaling组中。DevOps工程师已为蓝环境和绿环境创建了启动模板、Auto Scaling组和ALB目标组。每个目标组指定将在EC2实例上加载哪个应用程序版本（蓝或绿）。Amazon Route 53记录www.example.com指向ALB。部署必须一次性将流量从蓝环境切换到绿环境。 <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 启动绿环境Auto Scaling组的滚动重启以将新应用程序版本部署到绿环境的EC2实例。当滚动重启完成后，使用AWS CLI命令更新ALB将流量发送到绿环境的目标组。</div> <div class="option-analysis"><strong>B.</strong> 使用AWS CLI命令更新ALB将流量发送到绿环境的目标组。启动绿环境Auto Scaling组的滚动重启以将新应用程序版本部署到绿环境的EC2实例。</div> <div class="option-analysis"><strong>C.</strong> 更新启动模板以将绿环境的应用程序版本部署到蓝环境的EC2实例。不更改任一环境中的目标组或Auto Scaling组。对蓝环境的EC2实例执行滚动重启。</div> <div class="option-analysis"><strong>D.</strong> 启动绿环境Auto Scaling组的滚动重启以将新应用程序版本部署到绿环境的EC2实例。当滚动重启完成后，更新Route 53指向ALB上绿环境的端点。<div class="section-title"><strong>核心要求:</strong></div> 实现蓝/绿部署的一次性流量切换 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• Application Load Balancer - 负载均衡和流量路由 </div><div class="compact-content">• Auto Scaling Group - 管理EC2实例的自动扩缩容 </div><div class="compact-content">• Target Group - 定义负载均衡器的目标实例组 <div class="section-title"><strong>正确答案B:</strong></div> 先切换ALB流量路由到绿环境目标组实现即时切换，然后通过滚动重启部署新版本，确保流量切换的原子性操作 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A - 先部署后切换流量，违反了蓝/绿部署的即时切换原则 </div><div class="compact-content">• 选项C - 在蓝环境部署绿版本破坏了蓝/绿环境隔离，不是真正的蓝/绿部署 </div><div class="compact-content">• 选项D - 通过Route 53切换需要DNS传播时间，无法实现即时的一次性切换 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能 - ALB层面切换实现毫秒级流量转移 </div><div class="compact-content">• 成本 - 利用现有ALB和目标组架构无额外成本 </div><div class="compact-content">• 可扩展性 - 保持独立环境架构支持快速回滚和扩展</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: B</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-294">
            <div class="question-header">
                <div class="question-title">Question #294 ✅ ⚪ <small style="float: right;">(294/353)</small></div>
            </div>
            <div class="question-content">A company has an application that runs on <span class="key-service">Amazon EC2</span> instances in an Auto Scaling group. The application processes a high volume of messages from an Amazon Simple Queue Service (<span class="key-service">Amazon SQS</span>) queue. A DevOps engineer noticed that the application took several hours to process a group of messages from the SQS queue. The average CPU utilization of the Auto Scaling group did not cross the threshold of a target tracking scaling policy when processing the messages. The application that processes the SQS queue publishes logs to <span class="key-service">Amazon CloudWatch</span> Logs. The DevOps engineer needs to ensure that the queue is processed quickly. Which solution meets these requirements with the LEAST operational overhead?</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Create an <span class="key-service">AWS Lambda</span> function. Configure the Lambda function to publish a custom metric by using the ApproximateNumberOfMessagesVisible SQS queue attribute and the GroupInServiceInstances Auto Scaling group attribute to publish the queue messages for each instance. Schedule an Amazon EventBridge rule to run the Lambda function every hour. Create a target tracking scaling policy for the Auto Scaling group that uses the custom metric to scale in and out.</div>                <div class="option"><strong>B.</strong> Create an <span class="key-service">AWS Lambda</span> function. Configure the Lambda function to publish a custom metric by using the ApproximateNumberOfMessagesVisible SQS queue attribute and the GroupInServiceInstances Auto Scaling group attribute to publish the queue messages for each instance. Create a CloudWatch subscription filter for the application logs with the Lambda function as the target. Create a target tracking scaling policy for the Auto Scaling group that uses the custom metric to scale in and out.</div>                <div class="option correct-answer"><strong>C.</strong> Create a target tracking scaling policy for the Auto Scaling group. In the target tracking policy, use the ApproximateNumberOfMessagesVisible SQS queue attribute and the GroupInServiceInstances Auto Scaling group attribute to calculate how many messages are in the queue for each number of instances by using metric math. Use the calculated attribute to scale in and out.</div>                <div class="option"><strong>D.</strong> Create an <span class="key-service">AWS Lambda</span> function that logs the ApproximateNumberOfMessagesVisible attribute of the SQS queue to a CloudWatch Logs log group. Schedule an Amazon EventBridge rule to run the Lambda function every 5 minutes. Create a metric filter to count the number of log events from a CloudWatch logs group. Create a target tracking scaling policy for the Auto Scaling group that uses the custom metric to scale in and out.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司有一个运行在Auto Scaling组中Amazon EC2实例上的应用程序。该应用程序处理来自Amazon SQS队列的大量消息。DevOps工程师注意到应用程序需要几个小时来处理SQS队列中的一组消息。在处理消息时，Auto Scaling组的平均CPU利用率没有超过目标跟踪扩展策略的阈值。处理SQS队列的应用程序将日志发布到Amazon CloudWatch Logs。DevOps工程师需要确保队列被快速处理。哪个解决方案以最少的运营开销满足这些要求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 创建AWS Lambda函数，配置Lambda函数使用ApproximateNumberOfMessagesVisible SQS队列属性和GroupInServiceInstances Auto Scaling组属性发布自定义指标来发布每个实例的队列消息，安排Amazon EventBridge规则每小时运行Lambda函数，为Auto Scaling组创建使用自定义指标进行扩缩的目标跟踪扩展策略。</div> <div class="option-analysis"><strong>B.</strong> 创建AWS Lambda函数，配置Lambda函数使用ApproximateNumberOfMessagesVisible SQS队列属性和GroupInServiceInstances Auto Scaling组属性发布自定义指标来发布每个实例的队列消息，为应用程序日志创建以Lambda函数为目标的CloudWatch订阅过滤器，为Auto Scaling组创建使用自定义指标进行扩缩的目标跟踪扩展策略。</div> <div class="option-analysis"><strong>C.</strong> 为Auto Scaling组创建目标跟踪扩展策略，在目标跟踪策略中使用ApproximateNumberOfMessagesVisible SQS队列属性和GroupInServiceInstances Auto Scaling组属性通过指标数学计算每个实例数对应队列中有多少消息，使用计算属性进行扩缩。</div> <div class="option-analysis"><strong>D.</strong> 创建AWS Lambda函数将SQS队列的ApproximateNumberOfMessagesVisible属性记录到CloudWatch Logs日志组，安排Amazon EventBridge规则每5分钟运行Lambda函数，创建指标过滤器计算CloudWatch日志组的日志事件数量，为Auto Scaling组创建使用自定义指标进行扩缩的目标跟踪扩展策略。<div class="section-title"><strong>核心要求:</strong></div> 基于SQS队列消息数量而非CPU利用率实现Auto Scaling组的快速扩展，最小化运营开销 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• Auto Scaling - 基于队列长度而非CPU进行扩展 </div><div class="compact-content">• SQS - 提供ApproximateNumberOfMessagesVisible指标 </div><div class="compact-content">• CloudWatch - 提供指标数学功能进行实时计算 <div class="section-title"><strong>正确答案C:</strong></div> 直接使用CloudWatch指标数学功能结合SQS队列消息数和实例数计算每实例消息比率，无需额外Lambda函数或复杂架构 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A-需要Lambda函数和EventBridge定时触发，增加运营复杂度和延迟 </div><div class="compact-content">• 选项B-通过日志订阅过滤器触发Lambda，架构复杂且响应延迟 </div><div class="compact-content">• 选项D-将指标记录到日志再提取，架构冗余且增加不必要的延迟 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-直接基于队列长度扩展，响应最快 </div><div class="compact-content">• 成本-无需额外Lambda函数运行成本 </div><div class="compact-content">• 可扩展性-使用原生CloudWatch指标数学，运营开销最小</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: C</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-295">
            <div class="question-header">
                <div class="question-title">Question #295 ✅ ⚪ <small style="float: right;">(295/353)</small></div>
            </div>
            <div class="question-content">A company has a single AWS account that runs hundreds of <span class="key-service">Amazon EC2</span> instances in a single AWS Region. The company launches and terminates new EC2 instances every hour. The account includes existing EC2 instances that have been running for longer than a week. The company's security policy requires all running EC2 instances to have an EC2 instance profile attached. The company has created a default EC2 instance profile. The default EC2 instance profile must be attached to any EC2 instances that do not have a profile attached. Which solution will meet these requirements?</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Configure an Amazon EventBridge rule that matches the <span class="key-service">Amazon EC2</span> RunInstances API calls. Configure the rule to invoke an <span class="key-service">AWS Lambda</span> function to attach the default instance profile to the EC2 instances.</div>                <div class="option correct-answer"><strong>B.</strong> Configure <span class="key-service">AWS Config</span>. Deploy an <span class="key-service">AWS Config</span> ec2-instance-profile-attached managed rule. Configure an automatic remediation action that invokes an <span class="key-service">AWS Systems Manager</span> Automation runbook to attach the default instance profile to the EC2 instances.</div>                <div class="option"><strong>C.</strong> Configure an Amazon EventBridge rule that matches the <span class="key-service">Amazon EC2</span> StartInstances API calls. Configure the rule to invoke an <span class="key-service">AWS Systems Manager</span> Automation runbook to attach the default instance profile to the EC2 instances.</div>                <div class="option"><strong>D.</strong> Configure <span class="key-service">AWS Config</span>. Deploy an <span class="key-service">AWS Config</span> iam-role-managed-policy-check managed rule. Configure an automatic remediation action that invokes an <span class="key-service">AWS Lambda</span> function to attach the default instance profile to the EC2 instances.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司在单个AWS账户的单个AWS Region中运行数百个Amazon EC2实例。公司每小时启动和终止新的EC2实例。账户包括已运行超过一周的现有EC2实例。公司安全策略要求所有运行的EC2实例都必须附加EC2 instance profile。公司已创建默认EC2 instance profile，必须将其附加到任何未附加profile的EC2实例上。 <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 配置Amazon EventBridge规则匹配Amazon EC2 RunInstances API调用，配置规则调用AWS Lambda函数将默认instance profile附加到EC2实例</div> <div class="option-analysis"><strong>B.</strong> 配置AWS Config，部署AWS Config ec2-instance-profile-attached托管规则，配置自动修复操作调用AWS Systems Manager Automation runbook将默认instance profile附加到EC2实例</div> <div class="option-analysis"><strong>C.</strong> 配置Amazon EventBridge规则匹配Amazon EC2 StartInstances API调用，配置规则调用AWS Systems Manager Automation runbook将默认instance profile附加到EC2实例</div> <div class="option-analysis"><strong>D.</strong> 配置AWS Config，部署AWS Config iam-role-managed-policy-check托管规则，配置自动修复操作调用AWS Lambda函数将默认instance profile附加到EC2实例<div class="section-title"><strong>核心要求:</strong></div> 确保所有EC2实例都附加instance profile，包括现有和新启动的实例 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• <span class="key-service">AWS Config</span> - 持续监控资源配置合规性并支持自动修复 </div><div class="compact-content">• EventBridge - 基于API调用事件触发操作 <div class="section-title"><strong>正确答案B:</strong></div> AWS Config的ec2-instance-profile-attached规则可持续监控所有EC2实例的profile附加状态，自动修复功能可处理现有未合规实例和新启动实例 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A - RunInstances API仅在实例启动时触发，无法处理现有未合规实例 </div><div class="compact-content">• 选项C - StartInstances API仅在停止实例重启时触发，不覆盖新启动实例 </div><div class="compact-content">• 选项D - iam-role-managed-policy-check规则检查IAM角色策略而非EC2 instance profile附加状态 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能 - Config持续监控比事件驱动更全面 </div><div class="compact-content">• 成本 - 自动修复减少人工干预成本 </div><div class="compact-content">• 可扩展性 - Config规则可扩展到所有实例类型和状态</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: B</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-296">
            <div class="question-header">
                <div class="question-title">Question #296 ✅ 📝 <small style="float: right;">(296/353)</small></div>
            </div>
            <div class="question-content">A company uses <span class="key-service">AWS Organizations</span> to manage hundreds of AWS accounts. The company has a team that is responsible for AWS Identity and Access Management (IAM). The IAM team wants to implement <span class="key-service">AWS IAM</span> Identity Center. The IAM team must have only the minimum required permissions to manage IAM Identity Center. The IAM team must not be able to gain unnecessary access to the Organizations management account. The IAM team must be able to provision new IAM Identity Center permission sets and assignments for new and existing member accounts. Which combination of steps will meet these requirements? (Choose three.)</div>
            <div class="options-container">                <div class="option correct-answer"><strong>A.</strong> Create a new AWS account for the IAM team. Enable IAM Identity Center in the new account. In the Organizations management account, register the new account as a delegated administrator for IAM Identity Center.</div>                <div class="option"><strong>B.</strong> Create a new AWS account for the IAM team. Enable IAM Identity Center in the Organizations management account. In the Organizations management account, register the new account as a delegated administrator for IAM Identity Center.</div>                <div class="option"><strong>C.</strong> Create an <span class="key-service">SCP</span> in Organizations. Create a new OU for the Organizations management account, and link the new <span class="key-service">SCP</span> to the OU. Configure the <span class="key-service">SCP</span> to deny all access to IAM Identity Center.</div>                <div class="option correct-answer"><strong>D.</strong> Create IAM users and an IAM group for the IAM team in IAM Identity Center. Add the users to the group. Create a new permission set. Attach the AWSSSOMemberAccountAdministrator managed IAM policy to the group.</div>                <div class="option"><strong>E.</strong> Assign the new permission set to the Organizations management account. Allow the IAM team's group to use the permission set. F. Assign the new permission set to the new AWS account. Allow the IAM team's group to use the permission set.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司使用AWS Organizations管理数百个AWS账户。公司有一个负责AWS Identity and Access Management (IAM)的团队。IAM团队想要实施AWS IAM Identity Center。IAM团队必须只拥有管理IAM Identity Center所需的最小权限。IAM团队不能获得对Organizations管理账户的不必要访问权限。IAM团队必须能够为新的和现有的成员账户配置新的IAM Identity Center权限集和分配。哪些步骤组合将满足这些要求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 为IAM团队创建一个新的AWS账户。在新账户中启用IAM Identity Center。在Organizations管理账户中，将新账户注册为IAM Identity Center的委托管理员。</div> <div class="option-analysis"><strong>B.</strong> 为IAM团队创建一个新的AWS账户。在Organizations管理账户中启用IAM Identity Center。在Organizations管理账户中，将新账户注册为IAM Identity Center的委托管理员。</div> <div class="option-analysis"><strong>C.</strong> 在Organizations中创建SCP。为Organizations管理账户创建新的OU，并将新的SCP链接到OU。配置SCP拒绝对IAM Identity Center的所有访问。</div> <div class="option-analysis"><strong>D.</strong> 在IAM Identity Center中为IAM团队创建IAM用户和IAM组。将用户添加到组中。创建新的权限集。将AWSSSOMemberAccountAdministrator托管IAM策略附加到组。</div> <div class="option-analysis"><strong>E.</strong> 将新权限集分配给Organizations管理账户。允许IAM团队的组使用该权限集。 F. 将新权限集分配给新的AWS账户。允许IAM团队的组使用该权限集。<div class="section-title"><strong>核心要求:</strong></div> 为IAM团队实施IAM Identity Center的最小权限管理，避免对管理账户的不必要访问 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• <span class="key-service">AWS Organizations</span> - 多账户管理和委托管理员功能 </div><div class="compact-content">• IAM Identity Center - 集中身份管理和权限集配置 <div class="section-title"><strong>正确答案AD:</strong></div> 选项A通过委托管理员模式实现权限隔离，选项D配置适当的权限集和用户组管理 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项B - IAM Identity Center应在委托账户而非管理账户中启用 </div><div class="compact-content">• 选项C - SCP会阻止必要的IAM Identity Center管理功能 </div><div class="compact-content">• 选项E - 不应将权限分配给管理账户，违反最小权限原则 </div><div class="compact-content">• 选项F - 权限集应分配给需要管理的成员账户而非委托账户 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 安全性 - 通过委托管理员和最小权限原则避免管理账户访问 </div><div class="compact-content">• 管理效率 - 集中的权限集管理和用户组配置 </div><div class="compact-content">• <span class="key-point">合规性</span> - 满足最小权限要求和职责分离原则</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: AD (A、D)</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-297">
            <div class="question-header">
                <div class="question-title">Question #297 ✅ ⚪ <small style="float: right;">(297/353)</small></div>
            </div>
            <div class="question-content">A company uses an Amazon Aurora PostgreSQL global database that has two secondary AWS Regions. A DevOps engineer has configured the database parameter group to guarantee an RPO of 60 seconds. Write operations on the primary cluster are occasionally blocked because of the RPO setting. The DevOps engineer needs to reduce the frequency of blocked write operations. Which solution will meet these requirements?</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Add an additional secondary cluster to the global database.</div>                <div class="option"><strong>B.</strong> Enable write forwarding for the global database.</div>                <div class="option correct-answer"><strong>C.</strong> Remove one of the secondary clusters from the global database.</div>                <div class="option"><strong>D.</strong> Configure synchronous replication for the global database.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司使用Amazon Aurora PostgreSQL global database，有两个辅助AWS区域。DevOps工程师配置了数据库参数组以保证60秒的RPO。由于RPO设置，主集群上的写操作偶尔被阻塞。DevOps工程师需要减少写操作被阻塞的频率。 <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 向global database添加额外的辅助集群</div> <div class="option-analysis"><strong>B.</strong> 为global database启用写转发功能</div> <div class="option-analysis"><strong>C.</strong> 从global database中移除其中一个辅助集群</div> <div class="option-analysis"><strong>D.</strong> 为global database配置同步复制<div class="section-title"><strong>核心要求:</strong></div> 减少Aurora PostgreSQL global database中因RPO设置导致的写操作阻塞频率 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• Aurora Global Database-跨区域复制，需要等待所有辅助区域确认以满足RPO要求 </div><div class="compact-content">• RPO配置-恢复点目标，影响复制延迟和写操作性能 <div class="section-title"><strong>正确答案C:</strong></div> 减少辅助集群数量可以降低需要等待确认的区域数量，从而减少写操作阻塞，提高主集群写性能 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A-增加辅助集群会增加需要等待确认的区域，加剧写操作阻塞问题 </div><div class="compact-content">• 选项B-写转发用于从只读副本转发写请求，不解决RPO导致的阻塞问题 </div><div class="compact-content">• 选项D-同步复制会增加延迟，使写操作阻塞问题更严重 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-减少复制目标数量直接降低写操作延迟 </div><div class="compact-content">• 成本-移除集群降低运营成本 </div><div class="compact-content">• 可扩展性-在性能和灾难恢复能力间找到平衡点</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: C</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-298">
            <div class="question-header">
                <div class="question-title">Question #298 ✅ 📝 <small style="float: right;">(298/353)</small></div>
            </div>
            <div class="question-content">A company has a web application that is hosted on an Amazon Elastic Kubernetes Service (<span class="key-service">Amazon EKS</span>) cluster. The EKS cluster runs on <span class="key-service">AWS Fargate</span> that is available through an internet-facing Application Load Balancer. The application is experiencing stability issues that lead to longer response times. A DevOps engineer needs to configure observability in <span class="key-service">Amazon CloudWatch</span> to troubleshoot the issue. The solution must provide only the minimum necessary permissions. Which combination of steps will meet these requirements? (Choose three.)</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Deploy the CloudWatch agent as a Kubernetes StatefulSet to the EKS cluster.</div>                <div class="option correct-answer"><strong>B.</strong> Deploy the AWS Distro for OpenTelemetry Collector as a Kubernetes DaemonSet to the EKS cluster.</div>                <div class="option correct-answer"><strong>C.</strong> Associate a Kubernetes service account with an IAM role by using IAM roles for service accounts in <span class="key-service">Amazon EKS</span>. Use the CloudWatchAgentServerPolicy AWS managed policy.</div>                <div class="option"><strong>D.</strong> Associate a Kubernetes service account with an IAM role by using IAM roles for service accounts in <span class="key-service">Amazon EKS</span>. Use the CloudWatchAgentAdminPolicy AWS managed policy.</div>                <div class="option correct-answer"><strong>E.</strong> Configure an IAM OpenID Connect (OIDC) provider for the EKS cluster. F. Enable EKS control plane logging for the EKS cluster.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司有一个托管在Amazon EKS集群上的Web应用程序。EKS集群运行在AWS Fargate上，通过面向互联网的Application Load Balancer提供服务。应用程序遇到稳定性问题导致响应时间延长。DevOps工程师需要在Amazon CloudWatch中配置可观测性来排查问题。解决方案必须仅提供最小必要权限。 <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 将CloudWatch代理作为Kubernetes StatefulSet部署到EKS集群</div> <div class="option-analysis"><strong>B.</strong> 将AWS Distro for OpenTelemetry Collector作为Kubernetes DaemonSet部署到EKS集群</div> <div class="option-analysis"><strong>C.</strong> 使用EKS的IAM roles for service accounts将Kubernetes服务账户与IAM角色关联，使用CloudWatchAgentServerPolicy AWS托管策略</div> <div class="option-analysis"><strong>D.</strong> 使用EKS的IAM roles for service accounts将Kubernetes服务账户与IAM角色关联，使用CloudWatchAgentAdminPolicy AWS托管策略</div> <div class="option-analysis"><strong>E.</strong> 为EKS集群配置IAM OpenID Connect (OIDC)提供程序 F. 为EKS集群启用EKS控制平面日志记录<div class="section-title"><strong>核心要求:</strong></div> 在Fargate上的EKS集群配置CloudWatch可观测性，使用最小权限原则 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• <span class="key-service">Amazon EKS</span> - 托管Kubernetes服务，运行在Fargate上 </div><div class="compact-content">• AWS Distro for OpenTelemetry - 收集应用程序指标和追踪数据 </div><div class="compact-content">• IAM OIDC Provider - 实现EKS与IAM的身份联合 <div class="section-title"><strong>正确答案BCE:</strong></div> B选项使用OpenTelemetry Collector作为DaemonSet收集遥测数据，适合Fargate环境；C选项使用最小权限的ServerPolicy；E选项配置OIDC提供程序实现IAM角色与Kubernetes服务账户的安全绑定 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A - StatefulSet不适合监控代理部署，且CloudWatch Agent在Fargate上支持有限 </div><div class="compact-content">• 选项D - CloudWatchAgentAdminPolicy权限过大，违反最小权限原则 </div><div class="compact-content">• 选项F - 控制平面日志无法解决应用程序稳定性问题 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能 - OpenTelemetry提供全面的应用程序可观测性 </div><div class="compact-content">• 成本 - 使用托管策略降低管理开销 </div><div class="compact-content">• 可扩展性 - DaemonSet确保每个节点都有监控覆盖</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: BCE (B、C、E)</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-299">
            <div class="question-header">
                <div class="question-title">Question #299 ✅ ⚪ <small style="float: right;">(299/353)</small></div>
            </div>
            <div class="question-content">A company stores its Python-based application code in <span class="key-service">AWS CodeCommit</span>. The company uses <span class="key-service">AWS CodePipeline</span> to deploy the application. The CodeCommit repository and the CodePipeline pipeline are deployed to the same AWS account. The company's security team requires all code to be scanned for vulnerabilities before the code is deployed to production. If any vulnerabilities are found, the deployment must stop. Which solution will meet these requirements?</div>
            <div class="options-container">                <div class="option correct-answer"><strong>A.</strong> Create a new CodeBuild project. Configure the project to run a security scan on the code by using Amazon CodeGuru Security. Configure the CodeBuild project to raise an error if CodeGuru Security finds vulnerabilities. Create a new IAM role that has sufficient permissions to run CodeGuru Security scans. Assign the role to the CodeBuild project. In the CodePipeline pipeline, add a new stage before the deployment stage. Select <span class="key-service">AWS CodeBuild</span> as the action provider for the new stage. Use the source artifact from the CodeCommit repository. Configure the action to use the CodeBuild project.</div>                <div class="option"><strong>B.</strong> Create a new CodeBuild project. Configure the project to run a security scan on the code by using Amazon Inspector. Configure the CodeBuild project to raise an error if Amazon Inspector finds vulnerabilities. Create a new IAM role that has sufficient permissions to run Amazon Inspector scans. Assign the role to the CodeBuild project. In the CodePipeline pipeline, add a new stage before the deployment stage. Select <span class="key-service">AWS CodeBuild</span> as the action provider for the new stage. Use the source artifact from the CodeCommit repository. Configure the action to use the CodeBuild project.</div>                <div class="option"><strong>C.</strong> Update the IAM role that is attached to CodePipeline to include sufficient permissions to invoke Amazon DevOps Guru. In the CodePipeline pipeline, add a new stage before the deployment stage. Select DevOps Guru as the action provider for the new stage. Use the source artifact from the CodeCommit repository.</div>                <div class="option"><strong>D.</strong> Update the IAM role that is attached to CodePipeline to include sufficient permissions to invoke Amazon DevOps Guru. In the CodePipeline pipeline, add a new stage before the deployment stage. Select CodeGuru Security as the action provider for the new stage. Use the source artifact from the CodeCommit repository.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司将基于Python的应用程序代码存储在AWS CodeCommit中，使用AWS CodePipeline部署应用程序。CodeCommit存储库和CodePipeline管道部署在同一个AWS账户中。公司安全团队要求在代码部署到生产环境之前扫描所有代码的漏洞，如果发现任何漏洞，部署必须停止。哪个解决方案能满足这些要求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 创建新的CodeBuild项目，配置项目使用Amazon CodeGuru Security对代码运行安全扫描，配置CodeBuild项目在CodeGuru Security发现漏洞时引发错误，创建具有足够权限运行CodeGuru Security扫描的新IAM角色并分配给CodeBuild项目，在CodePipeline管道中在部署阶段之前添加新阶段，选择AWS CodeBuild作为新阶段的操作提供程序，使用来自CodeCommit存储库的源工件，配置操作使用CodeBuild项目。</div> <div class="option-analysis"><strong>B.</strong> 创建新的CodeBuild项目，配置项目使用Amazon Inspector对代码运行安全扫描，配置CodeBuild项目在Amazon Inspector发现漏洞时引发错误，创建具有足够权限运行Amazon Inspector扫描的新IAM角色并分配给CodeBuild项目，在CodePipeline管道中在部署阶段之前添加新阶段，选择AWS CodeBuild作为新阶段的操作提供程序，使用来自CodeCommit存储库的源工件，配置操作使用CodeBuild项目。</div> <div class="option-analysis"><strong>C.</strong> 更新附加到CodePipeline的IAM角色以包含调用Amazon DevOps Guru的足够权限，在CodePipeline管道中在部署阶段之前添加新阶段，选择DevOps Guru作为新阶段的操作提供程序，使用来自CodeCommit存储库的源工件。</div> <div class="option-analysis"><strong>D.</strong> 更新附加到CodePipeline的IAM角色以包含调用Amazon DevOps Guru的足够权限，在CodePipeline管道中在部署阶段之前添加新阶段，选择CodeGuru Security作为新阶段的操作提供程序，使用来自CodeCommit存储库的源工件。<div class="section-title"><strong>核心要求:</strong></div> 在代码部署前进行漏洞扫描，发现漏洞时停止部署 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• Amazon CodeGuru Security - 专门用于代码安全漏洞扫描的服务 </div><div class="compact-content">• <span class="key-service">AWS CodeBuild</span> - 构建服务，可集成安全扫描工具 <div class="section-title"><strong>正确答案A:</strong></div> 使用CodeBuild项目集成CodeGuru Security进行代码安全扫描，通过配置错误处理机制在发现漏洞时停止管道执行 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项B - Amazon Inspector主要用于EC2实例和容器镜像的安全评估，不适用于源代码扫描 </div><div class="compact-content">• 选项C - DevOps Guru用于运营洞察和异常检测，不是代码漏洞扫描工具，且不能直接作为CodePipeline操作提供程序 </div><div class="compact-content">• 选项D - CodeGuru Security不能直接作为CodePipeline的操作提供程序，需要通过CodeBuild集成 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能 - CodeGuru Security专为代码扫描优化，扫描效率高 </div><div class="compact-content">• 成本 - 按扫描次数付费，成本可控 </div><div class="compact-content">• 可扩展性 - 通过CodeBuild集成，支持大规模代码库扫描</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: A</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-300">
            <div class="question-header">
                <div class="question-title">Question #300 ✅ ⚪ <small style="float: right;">(300/353)</small></div>
            </div>
            <div class="question-content">A DevOps engineer deploys an application to a fleet of Amazon Linux EC2 instances. The DevOps engineer needs to monitor system metrics across the fleet. The DevOps engineer wants to monitor the relationship between network traffic and memory utilization for the application code. The DevOps engineer wants to track the data on a 60 second interval. Which solution will meet these requirements?</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Use <span class="key-service">Amazon CloudWatch</span> basic monitoring to collect the NetworkIn metric and the MemoryBytesUsed metric. Graph the metrics in CloudWatch.</div>                <div class="option"><strong>B.</strong> Use <span class="key-service">Amazon CloudWatch</span> detailed monitoring to collect the NetworkIn metric and the MemoryBytesUsed metric. Graph the metrics in CloudWatch.</div>                <div class="option correct-answer"><strong>C.</strong> Use <span class="key-service">Amazon CloudWatch</span> detailed monitoring to collect the NetworkIn metric. Install the CloudWatch agent on the EC2 instances to collect the mem_used metric. Graph the metrics in CloudWatch.</div>                <div class="option"><strong>D.</strong> Use <span class="key-service">Amazon CloudWatch</span> basic monitoring to collect the built-in NetworkIn metric. Install the CloudWatch agent on the EC2 instances to collect the mem_used metric. Graph the metrics in CloudWatch.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一名DevOps工程师将应用程序部署到Amazon Linux EC2实例集群。该工程师需要监控整个集群的系统指标，希望监控应用程序代码的网络流量与内存利用率之间的关系，并以60秒间隔跟踪数据。 <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 使用Amazon CloudWatch基础监控收集NetworkIn指标和MemoryBytesUsed指标，在CloudWatch中绘制指标图表。</div> <div class="option-analysis"><strong>B.</strong> 使用Amazon CloudWatch详细监控收集NetworkIn指标和MemoryBytesUsed指标，在CloudWatch中绘制指标图表。</div> <div class="option-analysis"><strong>C.</strong> 使用Amazon CloudWatch详细监控收集NetworkIn指标，在EC2实例上安装CloudWatch代理收集mem_used指标，在CloudWatch中绘制指标图表。</div> <div class="option-analysis"><strong>D.</strong> 使用Amazon CloudWatch基础监控收集内置NetworkIn指标，在EC2实例上安装CloudWatch代理收集mem_used指标，在CloudWatch中绘制指标图表。<div class="section-title"><strong>核心要求:</strong></div> 监控EC2集群的网络流量和内存利用率关系，60秒间隔数据收集 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• CloudWatch详细监控-提供1分钟粒度的网络指标收集 </div><div class="compact-content">• CloudWatch Agent-收集操作系统级别的内存使用指标 <div class="section-title"><strong>正确答案C:</strong></div> 详细监控提供60秒间隔的NetworkIn指标，CloudWatch Agent收集系统级mem_used内存指标，满足监控要求 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A-基础监控仅5分钟间隔且MemoryBytesUsed不是EC2默认指标 </div><div class="compact-content">• 选项B-MemoryBytesUsed不是EC2的默认可用指标 </div><div class="compact-content">• 选项D-基础监控仅提供5分钟间隔，不满足60秒要求 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-详细监控提供1分钟粒度数据收集 </div><div class="compact-content">• 成本-Agent部署成本合理，满足监控需求 </div><div class="compact-content">• 可扩展性-CloudWatch Agent可批量部署到EC2集群</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: C</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-301">
            <div class="question-header">
                <div class="question-title">Question #301 ✅ ⚪ <small style="float: right;">(301/353)</small></div>
            </div>
            <div class="question-content">A company uses <span class="key-service">AWS Systems Manager</span> to manage a fleet of Amazon Linux EC2 instances that have SSM Agent installed. All EC2 instances are configured to use Instance Metadata Service Version 2 (IMDSv2) and are running in the same AWS account and AWS Region. Company policy requires developers to use only Amazon Linux. The company wants to ensure that all new EC2 instances are automatically managed by Systems Manager after creation. Which solution will meet these requirements with the MOST operational efficiency?</div>
            <div class="options-container">                <div class="option correct-answer"><strong>A.</strong> Create an IAM role that has a trust policy that allows Systems Manager to assume the role. Attach the AmazonSSMManagedEC2InstanceDefaultPolicy policy to the role. Configure the default-ec2-instance-management-role SSM service setting to use the role.</div>                <div class="option"><strong>B.</strong> Ensure that <span class="key-service">AWS Config</span> is set up. Create an <span class="key-service">AWS Config</span> rule that validates if an EC2 instance has SSM Agent installed. Configure the rule to run on EC2 configuration changes. Configure automatic remediation for the rule to run the AWS-InstallSSMAgent SSM document to install SSM Agent.</div>                <div class="option"><strong>C.</strong> Configure Systems Manager Patch Manager. Create a patch baseline that automatically installs SSM Agent on all new EC2 instances. Create a patch group for all EC2 instances. Attach the patch baseline to the patch group. Create a maintenance window and maintenance window task to start installing SSM Agent daily.</div>                <div class="option"><strong>D.</strong> Create an EC2 instance role that has a trust policy that allows <span class="key-service">Amazon EC2</span> to assume the role. Attach the AmazonSSMManagedInstanceCore policy to the role. Ensure that <span class="key-service">AWS Config</span> is set up. Use the ec2-instance-profile-attached managed <span class="key-service">AWS Config</span> rule to validate if an EC2 instance has the role attached. Configure the rule to run on EC2 configuration changes. Configure automatic remediation for the rule to run the AWS-SetupManagedRoleOnEc2Instance SSM document to attach the role to the EC2 instance.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司使用AWS Systems Manager管理已安装SSM Agent的Amazon Linux EC2实例集群。所有EC2实例都配置使用Instance Metadata Service Version 2 (IMDSv2)，运行在同一AWS账户和Region中。公司政策要求开发者只使用Amazon Linux。公司希望确保所有新EC2实例在创建后自动被Systems Manager管理。哪个解决方案能以最高运营效率满足要求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 创建一个IAM角色，具有允许Systems Manager代入该角色的信任策略。将AmazonSSMManagedEC2InstanceDefaultPolicy策略附加到该角色。配置default-ec2-instance-management-role SSM服务设置使用该角色。</div> <div class="option-analysis"><strong>B.</strong> 确保设置AWS Config。创建AWS Config规则验证EC2实例是否安装了SSM Agent。配置规则在EC2配置更改时运行。为规则配置自动修复，运行AWS-InstallSSMAgent SSM文档来安装SSM Agent。</div> <div class="option-analysis"><strong>C.</strong> 配置Systems Manager Patch Manager。创建补丁基线，自动在所有新EC2实例上安装SSM Agent。为所有EC2实例创建补丁组。将补丁基线附加到补丁组。创建维护窗口和维护窗口任务，每日开始安装SSM Agent。</div> <div class="option-analysis"><strong>D.</strong> 创建EC2实例角色，具有允许Amazon EC2代入该角色的信任策略。将AmazonSSMManagedInstanceCore策略附加到该角色。确保设置AWS Config。使用ec2-instance-profile-attached托管AWS Config规则验证EC2实例是否附加了该角色。配置规则在EC2配置更改时运行。为规则配置自动修复，运行AWS-SetupManagedRoleOnEc2Instance SSM文档将角色附加到EC2实例。<div class="section-title"><strong>核心要求:</strong></div> 确保新EC2实例自动被Systems Manager管理，实现最高运营效率 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• <span class="key-service">AWS Systems Manager</span> - 提供EC2实例的集中管理和自动化 </div><div class="compact-content">• IAM角色和策略 - 提供必要的权限和信任关系 <div class="section-title"><strong>正确答案A:</strong></div> 通过配置default-ec2-instance-management-role服务设置，Systems Manager可以自动为新创建的EC2实例分配管理权限，无需手动干预 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项B - 需要事后检测和修复，不是预防性的自动化解决方案 </div><div class="compact-content">• 选项C - Patch Manager不是用于安装SSM Agent的正确服务，且题目已说明实例已安装SSM Agent </div><div class="compact-content">• 选项D - 过于复杂，需要Config规则检测和修复，运营效率低 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能 - 自动化程度最高，无需事后检测 </div><div class="compact-content">• 成本 - 使用原生SSM功能，无需额外Config服务 </div><div class="compact-content">• 可扩展性 - 一次配置后自动应用于所有新实例</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: A</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-302">
            <div class="question-header">
                <div class="question-title">Question #302 ✅ ⚪ <small style="float: right;">(302/353)</small></div>
            </div>
            <div class="question-content">A company configured an <span class="key-service">Amazon S3</span> event source for an <span class="key-service">AWS Lambda</span> function. The company needs the Lambda function to run when a new object is created or an existing object is modified in a specific S3 bucket. The Lambda function will use the S3 bucket name and the S3 object key of the incoming event to read the contents of the new or modified S3 object. The Lambda function will parse the contents and save the parsed contents to an <span class="key-service">Amazon DynamoDB</span> table. The Lambda function's execution role has permissions to read from the S3 bucket and to write to the DynamoDB table. During testing, a DevOps engineer discovers that the Lambda function does not run when objects are added to the S3 bucket or when existing objects are modified. Which solution will resolve these problems?</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Create an S3 bucket policy for the S3 bucket that grants the S3 bucket permission to invoke the Lambda function.</div>                <div class="option correct-answer"><strong>B.</strong> Create a resource policy for the Lambda function to grant <span class="key-service">Amazon S3</span> permission to invoke the Lambda function on the S3 bucket.</div>                <div class="option"><strong>C.</strong> Configure an Amazon Simple Queue Service (<span class="key-service">Amazon SQS</span>) queue as an OnFailure destination for the Lambda function. Update the Lambda function to process messages from the SQS queue and the S3 event notifications.</div>                <div class="option"><strong>D.</strong> Configure an Amazon Simple Queue Service (<span class="key-service">Amazon SQS</span>) queue as the destination for the S3 bucket event notifications. Update the Lambda function's execution role to have permission to read from the SQS queue. Update the Lambda function to consume messages from the SQS queue.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司为AWS Lambda函数配置了Amazon S3事件源。公司需要Lambda函数在特定S3存储桶中创建新对象或修改现有对象时运行。Lambda函数将使用传入事件的S3存储桶名称和S3对象键来读取新建或修改的S3对象内容。Lambda函数将解析内容并将解析结果保存到Amazon DynamoDB表中。Lambda函数的执行角色具有从S3存储桶读取和向DynamoDB表写入的权限。在测试期间，DevOps工程师发现当对象添加到S3存储桶或修改现有对象时Lambda函数不会运行。哪个解决方案能解决这些问题？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 为S3存储桶创建S3存储桶策略，授予S3存储桶调用Lambda函数的权限。</div> <div class="option-analysis"><strong>B.</strong> 为Lambda函数创建资源策略，授予Amazon S3在S3存储桶上调用Lambda函数的权限。</div> <div class="option-analysis"><strong>C.</strong> 配置Amazon Simple Queue Service (<span class="key-service">Amazon SQS</span>)队列作为Lambda函数的OnFailure目标。更新Lambda函数以处理来自SQS队列和S3事件通知的消息。</div> <div class="option-analysis"><strong>D.</strong> 配置Amazon Simple Queue Service (<span class="key-service">Amazon SQS</span>)队列作为S3存储桶事件通知的目标。更新Lambda函数的执行角色以具有从SQS队列读取的权限。更新Lambda函数以消费来自SQS队列的消息。<div class="section-title"><strong>核心要求:</strong></div> 解决S3事件触发Lambda函数失败的权限问题 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• S3 Event Notifications-触发Lambda函数执行的事件源 </div><div class="compact-content">• Lambda Resource Policy-控制哪些服务可以调用Lambda函数的权限策略 <div class="section-title"><strong>正确答案B:</strong></div> Lambda函数需要资源策略明确授权S3服务调用权限，这是S3事件触发Lambda的必要权限配置 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A-S3存储桶策略无法授予调用Lambda的权限，权限方向错误 </div><div class="compact-content">• 选项C-OnFailure目标用于处理执行失败，不解决触发权限问题 </div><div class="compact-content">• 选项D-引入SQS增加架构复杂性，且未解决根本的权限问题 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-直接S3触发Lambda响应最快，无中间队列延迟 </div><div class="compact-content">• 成本-资源策略配置无额外费用，SQS方案增加队列成本 </div><div class="compact-content">• 可扩展性-Lambda资源策略是标准S3事件集成模式，架构简洁</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: B</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-303">
            <div class="question-header">
                <div class="question-title">Question #303 ✅ 📝 <small style="float: right;">(303/353)</small></div>
            </div>
            <div class="question-content">A company recently configured AWS Control Tower in its organization in <span class="key-service">AWS Organizations</span>. The company enrolled all existing AWS accounts in AWS Control Tower. The company wants to ensure that all new AWS accounts are automatically enrolled in AWS Control Tower. The company has an existing <span class="key-service">AWS Step Functions</span> workflow that creates new AWS accounts and performs any actions required as part of account creation. The Step Functions workflow is defined in the same AWS account as AWS Control Tower. Which combination of steps should the company add to the Step Functions workflow to meet these requirements? (Choose two.)</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Create an Amazon EventBridge event that has an aws.controltower source and a CreateManagedAccount detail-type. Add the details of the new AWS account to the detail field of the event.</div>                <div class="option"><strong>B.</strong> Create an Amazon EventBridge event that has an aws.controltower source and a SetupLandingZone detail-type. Add the details of the new AWS account to the detail field of the event.</div>                <div class="option"><strong>C.</strong> Create an AWSControlTowerExecution role in the new AWS account. Configure the role to allow the AWS Control Tower administrator account to assume the role.</div>                <div class="option correct-answer"><strong>D.</strong> Call the AWS Service Catalog ProvisionProduct API operation with the details of the new AWS account.</div>                <div class="option correct-answer"><strong>E.</strong> Call the Organizations EnableAWSServiceAccess API operation with the controltower.amazonaws.com service name and the details of the new AWS account.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司最近在AWS Organizations中配置了AWS Control Tower，并将所有现有AWS账户注册到AWS Control Tower中。公司希望确保所有新的AWS账户都自动注册到AWS Control Tower中。公司有一个现有的AWS Step Functions工作流程来创建新的AWS账户并执行账户创建所需的任何操作。Step Functions工作流程定义在与AWS Control Tower相同的AWS账户中。公司应该在Step Functions工作流程中添加哪些步骤组合来满足这些要求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 创建一个Amazon EventBridge事件，具有aws.controltower源和CreateManagedAccount详细类型，将新AWS账户的详细信息添加到事件的detail字段中</div> <div class="option-analysis"><strong>B.</strong> 创建一个Amazon EventBridge事件，具有aws.controltower源和SetupLandingZone详细类型，将新AWS账户的详细信息添加到事件的detail字段中</div> <div class="option-analysis"><strong>C.</strong> 在新AWS账户中创建AWSControlTowerExecution角色，配置该角色允许AWS Control Tower管理员账户承担该角色</div> <div class="option-analysis"><strong>D.</strong> 使用新AWS账户的详细信息调用AWS Service Catalog ProvisionProduct API操作</div> <div class="option-analysis"><strong>E.</strong> 使用controltower.amazonaws.com服务名称和新AWS账户的详细信息调用Organizations EnableAWSServiceAccess API操作<div class="section-title"><strong>核心要求:</strong></div> 在Step Functions工作流程中自动将新创建的AWS账户注册到AWS Control Tower <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• AWS Control Tower - 通过Account Factory产品实现账户自动注册和治理 </div><div class="compact-content">• AWS Service Catalog - 提供Account Factory产品用于创建受管账户 </div><div class="compact-content">• <span class="key-service">AWS Organizations</span> - 需要启用Control Tower服务访问权限 <div class="section-title"><strong>正确答案DE:</strong></div> D选项通过Service Catalog的ProvisionProduct API调用Account Factory产品来创建受Control Tower管理的账户；E选项通过EnableAWSServiceAccess API为Organizations启用Control Tower服务访问，这是Control Tower管理账户的前提条件 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A - CreateManagedAccount不是有效的EventBridge事件类型，且EventBridge用于接收而非发送Control Tower事件 </div><div class="compact-content">• 选项B - SetupLandingZone用于初始化Landing Zone而非注册单个账户 </div><div class="compact-content">• 选项C - AWSControlTowerExecution角色由Control Tower自动创建，无需手动创建 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能 - Service Catalog API调用直接高效，Organizations服务访问一次性配置 </div><div class="compact-content">• 成本 - 利用现有Control Tower和Service Catalog服务，无额外成本 </div><div class="compact-content">• 可扩展性 - 通过API调用支持批量账户创建和自动化管理</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: DE (D、E)</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-304">
            <div class="question-header">
                <div class="question-title">Question #304 ✅ ⚪ <small style="float: right;">(304/353)</small></div>
            </div>
            <div class="question-content">A company's web application uses an Application Load Balancer (ALB) to direct traffic to <span class="key-service">Amazon EC2</span> instances across three Availability Zones. The company has deployed a newer version of the application to one Availability Zone for testing. If a problem is detected with the application, the company wants to direct traffic away from the affected Availability Zone until the deployment has been rolled back. The application must remain available and maintain static stability during the rollback. Which solution will meet these requirements with the MOST operational efficiency?</div>
            <div class="options-container">                <div class="option correct-answer"><strong>A.</strong> Disable cross-zone load balancing on the ALB's target group. Initiate a zonal shift on the ALB to direct traffic away from the affected Availability Zone.</div>                <div class="option"><strong>B.</strong> Disable cross-zone load balancing on the ALB's target group. Manually remove instances in the target group that belong to the affected Availability Zone.</div>                <div class="option"><strong>C.</strong> Configure cross-zone load balancing on the ALB's target group to inherit settings from the AL<div class="option-analysis"><strong>B.</strong> Initiate a zonal shift on the ALB to direct traffic away from the affected Availability Zone.</div></div>                <div class="option"><strong>D.</strong> Configure cross-zone load balancing on the ALB's target group to inherit settings from the AL<div class="option-analysis"><strong>B.</strong> Remove the subnet that is associated with the affected Availability Zone.</div></div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司的Web应用使用Application Load Balancer (ALB)将流量分发到三个Availability Zone的Amazon EC2实例。公司在一个Availability Zone部署了新版本应用进行测试。如果检测到应用问题，公司希望将流量从受影响的Availability Zone转移，直到部署回滚完成。应用必须保持可用并在回滚期间维持静态稳定性。哪个解决方案能以最高运营效率满足这些要求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 在ALB的target group上禁用跨区域负载均衡，在ALB上启动zonal shift将流量从受影响的Availability Zone转移</div> <div class="option-analysis"><strong>B.</strong> 在ALB的target group上禁用跨区域负载均衡，手动移除target group中属于受影响Availability Zone的实例</div> <div class="option-analysis"><strong>C.</strong> 配置ALB的target group跨区域负载均衡从ALB继承设置，在ALB上启动zonal shift将流量从受影响的Availability Zone转移</div> <div class="option-analysis"><strong>D.</strong> 配置ALB的target group跨区域负载均衡从ALB继承设置，移除与受影响Availability Zone关联的subnet<div class="section-title"><strong>核心要求:</strong></div> 快速将流量从问题Availability Zone转移并保持应用可用性和静态稳定性 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• ALB Zonal Shift-临时将流量从指定AZ转移的自动化功能 </div><div class="compact-content">• Cross-zone Load Balancing-控制负载均衡器跨AZ分发流量的行为 <div class="section-title"><strong>正确答案A:</strong></div> 禁用跨区域负载均衡确保流量按AZ隔离分发，zonal shift提供自动化的AZ级流量转移，操作简单且可快速恢复 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项B-手动移除实例操作复杂，恢复时需重新注册，运营效率低 </div><div class="compact-content">• 选项C-启用跨区域负载均衡会导致流量仍可能路由到问题AZ，与zonal shift目标冲突 </div><div class="compact-content">• 选项D-移除subnet是永久性架构变更，操作复杂且恢复困难，不适合临时故障处理 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-zonal shift提供即时流量转移，最小化故障影响 </div><div class="compact-content">• 成本-无额外资源成本，仅配置变更 </div><div class="compact-content">• 可扩展性-自动化操作支持快速扩展到多AZ场景</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: A</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-305">
            <div class="question-header">
                <div class="question-title">Question #305 ✅ ⚪ <small style="float: right;">(305/353)</small></div>
            </div>
            <div class="question-content">A company has several AWS accounts. An Amazon Connect instance runs in each account. The company uses an Amazon EventBridge default event bus in each account for event handling. A DevOps team needs to receive all the Amazon Connect events in a single DevOps account. Which solution meets these requirements?</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Update the resource-based policy of the default event bus in each account to allow the DevOps account to replay events. Configure an EventBridge rule in the DevOps account that matches Amazon Connect events and has a target of the default event bus in the other accounts.</div>                <div class="option"><strong>B.</strong> Update the resource-based policy of the default event bus in each account to allow the DevOps account to receive events. Configure an EventBridge rule in the DevOps account that matches Amazon Connect events and has a target of the default event bus in the other accounts.</div>                <div class="option correct-answer"><strong>C.</strong> Update the resource-based policy of the default event bus in the DevOps account. Update the policy to allow events to be received from the accounts. Configure an EventBridge rule in each account that matches Amazon Connect events and has a target of the DevOps account's default event bus.</div>                <div class="option"><strong>D.</strong> Update the resource-based policy of the default event bus in the DevOps account. Update the policy to allow events to be replayed by the accounts. Configure an EventBridge rule in each account that matches Amazon Connect events and has a target of the DevOps account's default event bus.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司有多个AWS账户。每个账户中运行一个Amazon Connect实例。公司在每个账户中使用Amazon EventBridge默认事件总线进行事件处理。DevOps团队需要在单个DevOps账户中接收所有Amazon Connect事件。哪个解决方案满足这些要求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 更新每个账户中默认事件总线的基于资源的策略，允许DevOps账户重放事件。在DevOps账户中配置EventBridge规则，匹配Amazon Connect事件并以其他账户的默认事件总线为目标。</div> <div class="option-analysis"><strong>B.</strong> 更新每个账户中默认事件总线的基于资源的策略，允许DevOps账户接收事件。在DevOps账户中配置EventBridge规则，匹配Amazon Connect事件并以其他账户的默认事件总线为目标。</div> <div class="option-analysis"><strong>C.</strong> 更新DevOps账户中默认事件总线的基于资源的策略，允许从其他账户接收事件。在每个账户中配置EventBridge规则，匹配Amazon Connect事件并以DevOps账户的默认事件总线为目标。</div> <div class="option-analysis"><strong>D.</strong> 更新DevOps账户中默认事件总线的基于资源的策略，允许其他账户重放事件。在每个账户中配置EventBridge规则，匹配Amazon Connect事件并以DevOps账户的默认事件总线为目标。<div class="section-title"><strong>核心要求:</strong></div> 实现跨账户EventBridge事件聚合到单一DevOps账户 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• Amazon Connect-生成需要聚合的事件 </div><div class="compact-content">• Amazon EventBridge-跨账户事件路由和处理服务 <div class="section-title"><strong>正确答案C:</strong></div> 在目标DevOps账户配置接收策略，在源账户配置转发规则，实现事件从多个源账户流向单一目标账户的正确架构 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A-事件流向错误，不应该从DevOps账户向其他账户发送规则，且replay概念不适用 </div><div class="compact-content">• 选项B-事件流向完全错误，DevOps账户不应该主动去其他账户拉取事件 </div><div class="compact-content">• 选项D-使用了不相关的replay概念，EventBridge跨账户场景不需要replay功能 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-源账户直接推送事件到目标账户，减少延迟 </div><div class="compact-content">• 成本-避免不必要的跨账户数据传输和复杂路由 </div><div class="compact-content">• 可扩展性-新增源账户只需配置转发规则，架构简单清晰</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: C</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-306">
            <div class="question-header">
                <div class="question-title">Question #306 ✅ 📝 <small style="float: right;">(306/353)</small></div>
            </div>
            <div class="question-content">A company has deployed an Amazon Elastic Kubernetes Service (<span class="key-service">Amazon EKS</span>) cluster with <span class="key-service">Amazon EC2</span> node groups. The company's DevOps team uses the Kubernetes Horizontal Pod Autoscaler and recently installed a supported EKS cluster Autoscaler. The DevOps team needs to implement a solution to collect metrics and logs of the EKS cluster to establish a baseline for performance. The DevOps team will create an initial set of thresholds for specific metrics and will update the thresholds over time as the cluster is used. The DevOps team must receive an Amazon Simple Notification Service (<span class="key-service">Amazon SNS</span>) email notification if the initial set of thresholds is exceeded or if the EKS cluster Autoscaler is not functioning properly. The solution must collect cluster, node, and pod metrics. The solution also must capture logs in <span class="key-service">Amazon CloudWatch</span>. Which combination of steps should the DevOps team take to meet these requirements? (Choose three.)</div>
            <div class="options-container">                <div class="option correct-answer"><strong>A.</strong> Deploy the CloudWatch agent and Fluent Bit to the cluster. Ensure that the EKS cluster has appropriate permissions to send metrics and logs to CloudWatch.</div>                <div class="option"><strong>B.</strong> Deploy AWS Distro for OpenTelemetry to the cluster. Ensure that the EKS cluster has appropriate permissions to send metrics and logs to CloudWatch.</div>                <div class="option correct-answer"><strong>C.</strong> Create CloudWatch alarms to monitor the CPU, memory, and node failure metrics of the cluster. Configure the alarms to send an SNS email notification to the DevOps team if thresholds are exceeded.</div>                <div class="option"><strong>D.</strong> Create a CloudWatch composite alarm to monitor a metric log filter of the CPU, memory, and node metrics of the cluster. Configure the alarm to send an SNS email notification to the DevOps team when anomalies are detected.</div>                <div class="option"><strong>E.</strong> Create a CloudWatch alarm to monitor the logs of the Autoscaler deployments for errors. Configure the alarm to send an SNS email notification to the DevOps team if thresholds are exceeded. F. Create a CloudWatch alarm to monitor a metric log filter of the Autoscaler deployments for errors. Configure the alarm to send an SNS email notification to the DevOps team if thresholds are exceeded.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司部署了带有EC2节点组的Amazon EKS集群。DevOps团队使用Kubernetes Horizontal Pod Autoscaler并安装了EKS cluster Autoscaler。需要实现收集EKS集群指标和日志的解决方案来建立性能基线，创建初始阈值集合并随时间更新。如果超过阈值或cluster Autoscaler功能异常，必须通过SNS发送邮件通知。解决方案必须收集集群、节点和pod指标，并在CloudWatch中捕获日志。 <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 将CloudWatch agent和Fluent Bit部署到集群，确保EKS集群具有向CloudWatch发送指标和日志的适当权限</div> <div class="option-analysis"><strong>B.</strong> 将AWS Distro for OpenTelemetry部署到集群，确保EKS集群具有向CloudWatch发送指标和日志的适当权限</div> <div class="option-analysis"><strong>C.</strong> 创建CloudWatch alarms监控集群的CPU、内存和节点故障指标，配置alarms在超过阈值时向DevOps团队发送SNS邮件通知</div> <div class="option-analysis"><strong>D.</strong> 创建CloudWatch composite alarm监控集群CPU、内存和节点指标的metric log filter，配置alarm在检测到异常时发送SNS邮件通知</div> <div class="option-analysis"><strong>E.</strong> 创建CloudWatch alarm监控Autoscaler部署的错误日志，配置alarm在超过阈值时向DevOps团队发送SNS邮件通知 F. 创建CloudWatch alarm监控Autoscaler部署错误的metric log filter，配置alarm在超过阈值时向DevOps团队发送SNS邮件通知<div class="section-title"><strong>核心要求:</strong></div> 为EKS集群建立完整的监控和告警系统，收集多层级指标并实现阈值告警 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• CloudWatch - 统一监控平台，收集指标和日志 </div><div class="compact-content">• CloudWatch agent/Fluent Bit - 标准的指标和日志收集组合 </div><div class="compact-content">• SNS - 告警通知服务 <div class="section-title"><strong>正确答案AC:</strong></div> A提供了EKS监控的标准解决方案，CloudWatch agent收集节点和集群指标，Fluent Bit收集容器日志；C创建基于具体指标的CloudWatch alarms实现阈值监控和SNS通知 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项B - AWS Distro for OpenTelemetry主要用于分布式追踪，不是EKS基础监控的首选方案 </div><div class="compact-content">• 选项D - composite alarm用于复杂条件组合，题目要求的是简单阈值告警，且metric log filter概念混淆 </div><div class="compact-content">• 选项E - 直接监控日志而非指标，不符合监控最佳实践 </div><div class="compact-content">• 选项F - metric log filter概念错误，应该是基于日志创建指标后再告警 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能 - CloudWatch agent+Fluent Bit提供全面的EKS监控覆盖 </div><div class="compact-content">• 成本 - 使用AWS原生监控服务，避免第三方工具成本 </div><div class="compact-content">• 可扩展性 - CloudWatch alarms支持动态阈值调整和扩展监控范围</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: AC (A、C)</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-307">
            <div class="question-header">
                <div class="question-title">Question #307 ✅ ⚪ <small style="float: right;">(307/353)</small></div>
            </div>
            <div class="question-content">A company discovers that its production environment and disaster recovery (DR) environment are deployed to the same AWS Region. All the production applications run on <span class="key-service">Amazon EC2</span> instances and are deployed by <span class="key-service">AWS CloudFormation</span>. The applications use an Amazon FSx for NetApp ONTAP volume for application storage. No application data resides on the EC2 instances. A DevOps engineer copies the required AMIs to a new DR Region. The DevOps engineer also updates the CloudFormation code to accept a Region as a parameter. The storage needs to have an RPO of 10 minutes in the DR Region. Which solution will meet these requirements?</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Create an <span class="key-service">Amazon S3</span> bucket in both Regions. Configure S3 Cross-Region Replication (CRR) for the S3 buckets. Create a scheduled <span class="key-service">AWS Lambda</span> function to copy any new content from the FSx for ONTAP volume to the S3 bucket in the production Region.</div>                <div class="option"><strong>B.</strong> Use AWS Backup to create a backup vault and a custom backup plan that has a 10-minute frequency. Specify the DR Region as the target Region. Assign the EC2 instances in the production Region to the backup plan.</div>                <div class="option"><strong>C.</strong> Create an <span class="key-service">AWS Lambda</span> function to create snapshots of the instance store volumes that are attached to the EC2 instances. Configure the Lambda function to copy the snapshots to the DR Region and to remove the previous copies. Create an Amazon EventBridge scheduled rule that invokes the Lambda function every 10 minutes.</div>                <div class="option correct-answer"><strong>D.</strong> Create an FSx for ONTAP instance in the DR Region. Configure a 5-minute schedule for a volume-level NetApp SnapMirror to replicate the volume from the production Region to the DR Region.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司发现其生产环境和灾难恢复(DR)环境部署在同一个AWS Region中。所有生产应用运行在Amazon EC2实例上并通过AWS CloudFormation部署。应用使用Amazon FSx for NetApp ONTAP卷作为应用存储。EC2实例上没有应用数据。DevOps工程师将所需AMI复制到新的DR Region，并更新CloudFormation代码以接受Region参数。存储在DR Region中需要10分钟的RPO。 <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 在两个Region中创建Amazon S3存储桶，为S3存储桶配置S3跨Region复制(CRR)，创建定时AWS Lambda函数将FSx for ONTAP卷中的新内容复制到生产Region的S3存储桶中。</div> <div class="option-analysis"><strong>B.</strong> 使用AWS Backup创建备份保险库和10分钟频率的自定义备份计划，指定DR Region作为目标Region，将生产Region中的EC2实例分配给备份计划。</div> <div class="option-analysis"><strong>C.</strong> 创建AWS Lambda函数为附加到EC2实例的实例存储卷创建快照，配置Lambda函数将快照复制到DR Region并删除之前的副本，创建Amazon EventBridge定时规则每10分钟调用Lambda函数。</div> <div class="option-analysis"><strong>D.</strong> 在DR Region中创建FSx for ONTAP实例，配置5分钟的卷级NetApp SnapMirror计划将卷从生产Region复制到DR Region。<div class="section-title"><strong>核心要求:</strong></div> 为FSx for NetApp ONTAP存储实现跨Region灾难恢复，满足10分钟RPO要求 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• FSx for NetApp ONTAP-提供高性能NAS存储，支持NetApp原生复制功能 </div><div class="compact-content">• NetApp SnapMirror-NetApp原生卷级复制技术，支持高频率数据同步 <div class="section-title"><strong>正确答案D:</strong></div> 使用NetApp SnapMirror原生复制功能，5分钟复制频率可满足10分钟RPO要求，是FSx for ONTAP的最佳跨Region复制方案 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A-需要额外的Lambda函数和S3存储，增加复杂性且无法保证10分钟RPO </div><div class="compact-content">• 选项B-AWS Backup不支持10分钟的高频备份，且备份EC2实例而非FSx存储 </div><div class="compact-content">• 选项C-题目明确说明应用数据不在EC2实例上，备份实例存储卷无意义 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-NetApp SnapMirror提供原生高效复制，延迟最低 </div><div class="compact-content">• 成本-使用FSx原生功能，无需额外服务和数据传输成本 </div><div class="compact-content">• 可扩展性-SnapMirror支持大规模数据复制，管理简单</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: D</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-308">
            <div class="question-header">
                <div class="question-title">Question #308 ✅ ⚪ <small style="float: right;">(308/353)</small></div>
            </div>
            <div class="question-content">During a security audit, a company discovered that some security groups allow SSH traffic from 0.0.0.0/0. A security team must implement a solution to detect and remediate this issue as soon as possible. The company uses one organization in <span class="key-service">AWS Organizations</span> to manage all the company's AWS accounts. Which solution will meet these requirements?</div>
            <div class="options-container">                <div class="option correct-answer"><strong>A.</strong> Enable <span class="key-service">AWS Config</span> for all AWS accounts. Use a periodic trigger to activate the <span class="key-service">vpc</span>-sg-port-restriction-check <span class="key-service">AWS Config</span> rule. Create an <span class="key-service">AWS Lambda</span> function to remediate any noncompliant rules.</div>                <div class="option"><strong>B.</strong> Create an <span class="key-service">AWS Lambda</span> function in each AWS account to delete all the security group rules. Create an Amazon EventBridge rule to match security group update events or creation events. Set the Lambda function in each account as a target for the rule.</div>                <div class="option"><strong>C.</strong> Enable <span class="key-service">AWS Config</span> for all AWS accounts. Create a custom <span class="key-service">AWS Config</span> rule to run on the restricted-ssh configuration change trigger. Configure the rule to invoke an <span class="key-service">AWS Lambda</span> function to remediate any noncompliant resources.</div>                <div class="option"><strong>D.</strong> Create an <span class="key-service">AWS Systems Manager</span> Automation document in each account to inspect all security groups and to delete noncompliant rules. Use an Amazon EventBridge rule to run the Automation document every hour.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 在安全审计期间，一家公司发现某些安全组允许来自0.0.0.0/0的SSH流量。安全团队必须尽快实施解决方案来检测和修复此问题。该公司使用AWS Organizations中的一个组织来管理所有公司的AWS账户。哪种解决方案能满足这些要求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 为所有AWS账户启用AWS Config。使用周期性触发器激活vpc-sg-port-restriction-check AWS Config规则。创建AWS Lambda函数来修复任何不合规的规则。</div> <div class="option-analysis"><strong>B.</strong> 在每个AWS账户中创建AWS Lambda函数来删除所有安全组规则。创建Amazon EventBridge规则来匹配安全组更新事件或创建事件。将每个账户中的Lambda函数设置为规则的目标。</div> <div class="option-analysis"><strong>C.</strong> 为所有AWS账户启用AWS Config。创建自定义AWS Config规则在restricted-ssh配置更改触发器上运行。配置规则调用AWS Lambda函数来修复任何不合规的资源。</div> <div class="option-analysis"><strong>D.</strong> 在每个账户中创建AWS Systems Manager自动化文档来检查所有安全组并删除不合规规则。使用Amazon EventBridge规则每小时运行自动化文档。<div class="section-title"><strong>核心要求:</strong></div> 检测和自动修复允许SSH从0.0.0.0/0访问的安全组规则 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• <span class="key-service">AWS Config</span> - 持续监控和评估AWS资源配置合规性 </div><div class="compact-content">• Lambda - 执行自动化修复操作 <div class="section-title"><strong>正确答案A:</strong></div> 使用AWS Config的内置规则vpc-sg-port-restriction-check专门检测不安全的端口访问，结合Lambda实现自动修复，是最直接有效的解决方案 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项B - Lambda删除所有安全组规则过于激进，会影响正常业务 </div><div class="compact-content">• 选项C - restricted-ssh不是有效的AWS Config触发器类型 </div><div class="compact-content">• 选项D - 每小时检查频率不够及时，且缺乏持续合规监控 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能 - 使用专门的Config规则提供精准检测 </div><div class="compact-content">• 成本 - 利用托管服务减少运维开销 </div><div class="compact-content">• 可扩展性 - Config和Lambda可跨多账户统一管理</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: A</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-309">
            <div class="question-header">
                <div class="question-title">Question #309 ✅ ⚪ <small style="float: right;">(309/353)</small></div>
            </div>
            <div class="question-content">A company's DevOps engineer must install a software package on 30 on-premises VMs and 15 <span class="key-service">Amazon EC2</span> instances. The DevOps engineer needs to ensure that all VMs receive the package in a process that is auditable and that any configuration drift on the VMs is automatically identified and alerted on. The company uses AWS Direct Connect to connect its on-premises data center to AWS. Which solution will meet these requirements with the MOST operational efficiency?</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Write a script that iterates through the list of VMs once a week. Configure the script to check for the package and install the package if the package is not found. Configure the script to send an email message notification to the system administrator if the package is not found.</div>                <div class="option correct-answer"><strong>B.</strong> Install the <span class="key-service">AWS Systems Manager</span> Agent (SSM Agent) on all VMs. Use the SSM Agent to install the package. Use <span class="key-service">AWS Config</span> to monitor for configuration drift. Use Amazon Simple Notification Service (<span class="key-service">Amazon SNS</span>) to notify the system administrator if any drift is found.</div>                <div class="option"><strong>C.</strong> Write a script that checks if the package is installed across the environment. Configure the script to create a list of all VMs that are noncompliant. Configure the script to send the list to the system administrator, who will install the package on the noncompliant VMs.</div>                <div class="option"><strong>D.</strong> Log in to each VM. Use a local package manager to install the package. Use <span class="key-service">AWS Config</span> to monitor the AWS resources for configuration changes. Write a script to monitor the on-premises resources.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 公司的DevOps工程师必须在30台本地VM和15个Amazon EC2实例上安装软件包。DevOps工程师需要确保所有VM都能通过可审计的流程接收软件包，并且VM上的任何配置漂移都能被自动识别和告警。公司使用AWS Direct Connect连接本地数据中心到AWS。哪个解决方案能以最高的运营效率满足这些要求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 编写脚本每周遍历VM列表一次，配置脚本检查软件包并在未找到时安装，如果未找到软件包则向系统管理员发送邮件通知。</div> <div class="option-analysis"><strong>B.</strong> 在所有VM上安装AWS Systems Manager Agent (SSM Agent)，使用SSM Agent安装软件包，使用AWS Config监控配置漂移，使用Amazon Simple Notification Service (<span class="key-service">Amazon SNS</span>)在发现漂移时通知系统管理员。</div> <div class="option-analysis"><strong>C.</strong> 编写脚本检查环境中是否安装了软件包，配置脚本创建所有不合规VM的列表，配置脚本将列表发送给系统管理员，由管理员在不合规VM上安装软件包。</div> <div class="option-analysis"><strong>D.</strong> 登录每个VM，使用本地包管理器安装软件包，使用AWS Config监控AWS资源的配置变更，编写脚本监控本地资源。<div class="section-title"><strong>核心要求:</strong></div> 在混合环境中统一管理软件包安装，实现可审计性和配置漂移检测 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• <span class="key-service">AWS Systems Manager</span> - 提供混合环境统一管理和自动化运维 </div><div class="compact-content">• <span class="key-service">AWS Config</span> - 监控资源配置变更和合规性检查 </div><div class="compact-content">• <span class="key-service">Amazon SNS</span> - 提供自动化告警通知机制 <div class="section-title"><strong>正确答案B:</strong></div> 使用SSM Agent实现跨混合环境的统一软件包管理，结合AWS Config进行配置漂移监控和SNS自动告警，提供完整的可审计性和自动化运维能力 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A - 缺乏实时监控能力，仅每周检查一次无法及时发现配置漂移 </div><div class="compact-content">• 选项C - 需要手动干预安装，不符合自动化和运营效率要求 </div><div class="compact-content">• 选项D - 完全手动操作，无法实现统一管理和自动化监控 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能 - SSM提供统一管理平台，支持批量操作和实时监控 </div><div class="compact-content">• 成本 - 利用AWS托管服务减少运维开销，避免自定义脚本维护成本 </div><div class="compact-content">• 可扩展性 - SSM Agent支持大规模混合环境管理，易于扩展到更多实例</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: B</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-310">
            <div class="question-header">
                <div class="question-title">Question #310 ✅ 📝 <small style="float: right;">(310/353)</small></div>
            </div>
            <div class="question-content">A company has an <span class="key-service">AWS CodePipeline</span> pipeline in the eu-west-1 Region. The pipeline stores the build artifacts in an <span class="key-service">Amazon S3</span> bucket. The pipeline builds and deploys an <span class="key-service">AWS Lambda</span> function by using an <span class="key-service">AWS CloudFormation</span> deploy action. A DevOps engineer needs to update the existing pipeline to also deploy the Lambda function to the us-east-1 Region. The pipeline has already been updated to create an additional artifact to deploy to us-east-1. Which combination of steps should the DevOps engineer take to meet these requirements? (Choose two.)</div>
            <div class="options-container">                <div class="option correct-answer"><strong>A.</strong> Modify the CloudFormation template to include a parameter for the Lambda function code's .zip file location. Create a new CloudFormation deploy action for us-east-1 in the pipeline. Configure the new deploy action to pass in the us-east-1 artifact location as a parameter override.</div>                <div class="option"><strong>B.</strong> Create a new CloudFormation deploy action for us-east-1 in the pipeline. Configure the new deploy action to use the CloudFormation template from the additional artifact that was created for us-east-1.</div>                <div class="option"><strong>C.</strong> Create an S3 bucket in us-east-1. Configure the S3 bucket policy to allow CodePipeline to have read and write access.</div>                <div class="option"><strong>D.</strong> Create an S3 bucket in us-east-1. Configure S3 Cross-Region Replication (CRR) from the S3 bucket in eu-west-1 to the S3 bucket in us-east-1.</div>                <div class="option correct-answer"><strong>E.</strong> Modify the pipeline to include the S3 bucket for us-east-1 as an artifact store. Create a new CloudFormation deploy action for us-east-1 in the pipeline. Configure the new deploy action to use the CloudFormation template from the us-east-1 artifact.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司在eu-west-1区域有一个AWS CodePipeline管道，管道将构建产物存储在Amazon S3存储桶中。管道使用AWS CloudFormation部署操作构建和部署AWS Lambda函数。DevOps工程师需要更新现有管道以同时将Lambda函数部署到us-east-1区域。管道已更新为创建额外的产物以部署到us-east-1。DevOps工程师应采取哪些步骤组合来满足这些要求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 修改CloudFormation模板以包含Lambda函数代码.zip文件位置的参数。在管道中为us-east-1创建新的CloudFormation部署操作。配置新部署操作将us-east-1产物位置作为参数覆盖传入。</div> <div class="option-analysis"><strong>B.</strong> 在管道中为us-east-1创建新的CloudFormation部署操作。配置新部署操作使用为us-east-1创建的额外产物中的CloudFormation模板。</div> <div class="option-analysis"><strong>C.</strong> 在us-east-1创建S3存储桶。配置S3存储桶策略以允许CodePipeline具有读写访问权限。</div> <div class="option-analysis"><strong>D.</strong> 在us-east-1创建S3存储桶。配置从eu-west-1的S3存储桶到us-east-1的S3存储桶的S3跨区域复制。</div> <div class="option-analysis"><strong>E.</strong> 修改管道以包含us-east-1的S3存储桶作为产物存储。在管道中为us-east-1创建新的CloudFormation部署操作。配置新部署操作使用来自us-east-1产物的CloudFormation模板。<div class="section-title"><strong>核心要求:</strong></div> 扩展现有CodePipeline以支持多区域Lambda函数部署 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• <span class="key-service">AWS CodePipeline</span>-跨区域部署需要每个区域的产物存储 </div><div class="compact-content">• <span class="key-service">Amazon S3</span>-作为产物存储，支持跨区域访问 </div><div class="compact-content">• <span class="key-service">AWS CloudFormation</span>-部署Lambda函数，需要参数化配置 <div class="section-title"><strong>正确答案AE:</strong></div> A选项通过参数化CloudFormation模板实现灵活的产物位置配置，E选项建立us-east-1区域的产物存储基础设施，两者结合实现完整的跨区域部署能力 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项B-缺少us-east-1区域的产物存储配置，无法支持跨区域部署 </div><div class="compact-content">• 选项C-仅创建存储桶但未集成到管道的产物存储中 </div><div class="compact-content">• 选项D-跨区域复制增加延迟和复杂性，不是最佳实践 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-每个区域独立的产物存储避免跨区域传输延迟 </div><div class="compact-content">• 成本-避免不必要的跨区域复制费用 </div><div class="compact-content">• 可扩展性-参数化模板支持未来更多区域扩展</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: AE (A、E)</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-311">
            <div class="question-header">
                <div class="question-title">Question #311 ✅ ⚪ <small style="float: right;">(311/353)</small></div>
            </div>
            <div class="question-content">A company uses an AWS Cloud Development Kit (AWS CDK) application for its infrastructure. The AWS CDK application creates <span class="key-service">AWS Lambda</span> functions and the IAM roles that are attached to the functions. The company also uses <span class="key-service">AWS Organizations</span>. The company's developers can assume the AWS CDK application deployment role. The company's security team discovered that the developers and the role used to deploy the AWS CDK application have more permissions than necessary. The security team also discovered that the roles attached to the Lambda functions that the CDK application creates have more permissions than necessary. The developers must not have the ability to grant additional permissions. Which solution will meet these requirements with the LEAST operational overhead?</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Create an <span class="key-service">SCP</span> that denies the iam:CreateRole action and the iam:UpdateRole action for the developer role and the AWS CDK application deployment role. Centrally create new IAM roles to attach to the Lambda functions for the developers to use to provision Lambda functions.</div>                <div class="option correct-answer"><strong>B.</strong> Create an IAM permission boundary policy. Define the maximum actions that the AWS CDK application requires in the policy. Update the account's AWS CDK bootstrapping to use the permission boundary. Update the configuration in the AWS CDK application for the default permissions boundary to use the policy.</div>                <div class="option"><strong>C.</strong> Create an IAM permission boundary policy. Define the maximum actions that the AWS CDK application requires in the policy. Instruct the developers to use the permission boundary policy name when they create a role in the AWS CDK application code.</div>                <div class="option"><strong>D.</strong> Create an <span class="key-service">SCP</span> that denies the iam:CreateRole action and the iam:UpdateRole action for the developer role. Give the AWS CDK deployment role access to create roles associated with Lambda functions. Run AWS Identity and Access Management Access Analyzer to verify that the Lambda function's role does not have permissions.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司使用AWS CDK应用程序管理基础设施，该应用创建Lambda函数和附加的IAM角色。公司使用AWS Organizations，开发人员可以承担CDK部署角色。安全团队发现开发人员和CDK部署角色权限过大，Lambda函数角色权限也过大。开发人员不能授予额外权限。哪个解决方案以最少运营开销满足要求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 创建SCP拒绝开发人员角色和CDK部署角色的iam:CreateRole和iam:UpdateRole操作，集中创建新IAM角色供开发人员用于配置Lambda函数。</div> <div class="option-analysis"><strong>B.</strong> 创建IAM权限边界策略，定义CDK应用所需的最大操作，更新账户的CDK引导程序使用权限边界，更新CDK应用配置使用默认权限边界策略。</div> <div class="option-analysis"><strong>C.</strong> 创建IAM权限边界策略，定义CDK应用所需的最大操作，指导开发人员在CDK应用代码中创建角色时使用权限边界策略名称。</div> <div class="option-analysis"><strong>D.</strong> 创建SCP拒绝开发人员角色的iam:CreateRole和iam:UpdateRole操作，给CDK部署角色创建Lambda函数关联角色的权限，运行IAM Access Analyzer验证Lambda函数角色权限。<div class="section-title"><strong>核心要求:</strong></div> 限制开发人员和CDK部署角色权限，防止授予过多权限，运营开销最小 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• IAM权限边界-限制角色或用户的最大权限范围 </div><div class="compact-content">• AWS CDK-基础设施即代码工具，支持权限边界配置 </div><div class="compact-content">• <span class="key-service">SCP</span>-组织级别的权限控制策略 <div class="section-title"><strong>正确答案B:</strong></div> 通过IAM权限边界在CDK引导和应用配置中自动限制所有创建角色的最大权限，无需手动干预，运营开销最小 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A-完全禁止角色创建需要集中管理所有角色，运营开销大且影响开发灵活性 </div><div class="compact-content">• 选项C-依赖开发人员手动使用权限边界，无法强制执行且容易遗漏 </div><div class="compact-content">• 选项D-仍允许CDK角色创建权限，未完全解决权限过大问题 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-自动化权限控制，无需人工干预 </div><div class="compact-content">• 成本-利用现有CDK权限边界功能，无额外基础设施成本 </div><div class="compact-content">• 可扩展性-在CDK级别统一配置，适用于所有未来资源创建</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: B</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-312">
            <div class="question-header">
                <div class="question-title">Question #312 ✅ ⚪ <small style="float: right;">(312/353)</small></div>
            </div>
            <div class="question-content">A company uses Amazon Elastic Container Registry (<span class="key-service">Amazon ECR</span>) private registries to store container images. A DevOps team needs to ensure that the container images are regularly scanned for software package vulnerabilities. Which solution will meet this requirement?</div>
            <div class="options-container">                <div class="option correct-answer"><strong>A.</strong> Enable enhanced scanning for private registries in <span class="key-service">Amazon ECR</span>.</div>                <div class="option"><strong>B.</strong> Enable basic continuous scanning for private registries in <span class="key-service">Amazon ECR</span>.</div>                <div class="option"><strong>C.</strong> Create an <span class="key-service">AWS Systems Manager</span> Automation document to scan images by using the AWS SDK. Configure the Automation document to run when a new image is pushed to an ECR registry.</div>                <div class="option"><strong>D.</strong> Create an <span class="key-service">AWS Lambda</span> function that scans all images in <span class="key-service">Amazon ECR</span> by using the AWS SDK. Create an Amazon EventBridge rule to invoke the Lambda function each day.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司使用Amazon Elastic Container Registry (<span class="key-service">Amazon ECR</span>)私有注册表存储容器镜像。DevOps团队需要确保容器镜像定期扫描软件包漏洞。哪个解决方案能满足这个要求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 为Amazon ECR中的私有注册表启用增强扫描功能</div> <div class="option-analysis"><strong>B.</strong> 为Amazon ECR中的私有注册表启用基础持续扫描功能</div> <div class="option-analysis"><strong>C.</strong> 创建AWS Systems Manager自动化文档使用AWS SDK扫描镜像，配置自动化文档在新镜像推送到ECR注册表时运行</div> <div class="option-analysis"><strong>D.</strong> 创建AWS Lambda函数使用AWS SDK扫描Amazon ECR中的所有镜像，创建Amazon EventBridge规则每天调用Lambda函数<div class="section-title"><strong>核心要求:</strong></div> 为ECR私有注册表中的容器镜像提供定期漏洞扫描 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• <span class="key-service">Amazon ECR</span>-提供容器镜像存储和内置扫描功能 </div><div class="compact-content">• Enhanced Scanning-基于Inspector的高级漏洞扫描服务 <div class="section-title"><strong>正确答案A:</strong></div> Enhanced scanning提供基于AWS Inspector的高级漏洞扫描，支持操作系统和编程语言包漏洞检测，自动化程度高且功能全面 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项B-基础扫描功能有限，仅检测CVE漏洞，不如增强扫描全面 </div><div class="compact-content">• 选项C-需要自定义开发和维护，复杂度高且可能遗漏扫描功能 </div><div class="compact-content">• 选项D-自建解决方案维护成本高，无法利用ECR原生扫描能力 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-Enhanced scanning提供实时自动扫描和详细报告 </div><div class="compact-content">• 成本-使用原生服务避免自建方案的开发维护成本 </div><div class="compact-content">• 可扩展性-ECR原生功能自动适配镜像数量变化无需手动配置</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: A</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-313">
            <div class="question-header">
                <div class="question-title">Question #313 ✅ 📝 <small style="float: right;">(313/353)</small></div>
            </div>
            <div class="question-content">A security team sets up a workflow that invokes an <span class="key-service">AWS Step Functions</span> workflow when Amazon EventBridge matches specific events. The events can be generated by several AWS services. <span class="key-service">AWS CloudTrail</span> records user activities. The security team notices that some important events do not invoke the workflow as expected. The CloudTrail logs do not indicate any direct errors related to the missing events. Which combination of steps will identify the root cause of the missing event invocations? (Choose three.)</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Enable EventBridge schema discovery on the event bus to determine whether the event patterns match the expected schema.</div>                <div class="option correct-answer"><strong>B.</strong> Configure <span class="key-service">Amazon CloudWatch</span> to monitor EventBridge metrics and Step Functions metrics. Set up alerts for anomalies in event patterns and workflow invocations.</div>                <div class="option"><strong>C.</strong> Configure an <span class="key-service">AWS Lambda</span> logging function to monitor and log events from EventBridge to provide more details about the processed events.</div>                <div class="option correct-answer"><strong>D.</strong> Review the Step Functions execution history for patterns of failures or timeouts that could correlate to the missing event invocations.</div>                <div class="option correct-answer"><strong>E.</strong> Review metrics for the EventBridge failed invocations to ensure that the IAM execution role that is attached to the rule has sufficient permissions. F. Verify that the Step Functions workflow has the correct permissions to be invoked by EventBridge.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 安全团队设置了一个工作流，当Amazon EventBridge匹配特定事件时调用AWS Step Functions工作流。事件可由多个AWS服务生成。AWS CloudTrail记录用户活动。安全团队注意到一些重要事件未按预期调用工作流。CloudTrail日志未显示与缺失事件相关的直接错误。哪些步骤组合将识别缺失事件调用的根本原因？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 在事件总线上启用EventBridge架构发现以确定事件模式是否匹配预期架构</div> <div class="option-analysis"><strong>B.</strong> 配置Amazon CloudWatch监控EventBridge指标和Step Functions指标，为事件模式和工作流调用异常设置警报</div> <div class="option-analysis"><strong>C.</strong> 配置AWS Lambda日志记录函数来监控和记录来自EventBridge的事件，以提供有关已处理事件的更多详细信息</div> <div class="option-analysis"><strong>D.</strong> 查看Step Functions执行历史记录中的失败或超时模式，这些模式可能与缺失的事件调用相关</div> <div class="option-analysis"><strong>E.</strong> 查看EventBridge失败调用的指标，确保附加到规则的IAM执行角色具有足够权限 F. 验证Step Functions工作流具有被EventBridge调用的正确权限<div class="section-title"><strong>核心要求:</strong></div> 诊断EventBridge事件未能触发Step Functions工作流的根本原因 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• EventBridge - 事件路由和规则匹配服务 </div><div class="compact-content">• Step Functions - 工作流编排服务 </div><div class="compact-content">• CloudWatch - 监控和指标收集服务 <div class="section-title"><strong>正确答案BDE:</strong></div> 通过CloudWatch监控指标发现异常(B)，检查Step Functions执行历史找到失败模式(D)，验证EventBridge规则的IAM权限配置(E)，形成完整的故障排查链路 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A - 架构发现主要用于事件结构理解，不能直接解决调用失败问题 </div><div class="compact-content">• 选项C - Lambda日志记录增加复杂性，CloudWatch原生监控更直接有效 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能 - 使用原生监控工具快速定位问题 </div><div class="compact-content">• 成本 - 避免额外Lambda函数的运行成本 </div><div class="compact-content">• 可扩展性 - 基于权限和执行历史的系统性排查方法</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: BDE (B、D、E)</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-314">
            <div class="question-header">
                <div class="question-title">Question #314 ✅ ⚪ <small style="float: right;">(314/353)</small></div>
            </div>
            <div class="question-content">A company's DevOps engineer uses <span class="key-service">AWS Systems Manager</span> to perform maintenance tasks. The company has a few <span class="key-service">Amazon EC2</span> instances that require a restart after notifications from AWS Health. The DevOps engineer must implement an automated solution that uses Amazon EventBridge to remediate the notifications during the company's scheduled maintenance windows. How should the DevOps engineer configure an EventBridge rule to meet these requirements?</div>
            <div class="options-container">                <div class="option correct-answer"><strong>A.</strong> Configure an event source of AWS Health. Configure event types that indicate scheduled instance termination and retirement. Target the AWS-RestartEC2Instance Systems Manager Automation runbook to restart the EC2 instances.</div>                <div class="option"><strong>B.</strong> Configure an event source of Systems Manager. Configure an event type that indicates a maintenance window. Target the AWS-RestartEC2Instance Systems Manager Automation runbook to restart the EC2 instances.</div>                <div class="option"><strong>C.</strong> Configure an event source of AWS Health. Configure event types that indicate scheduled instance termination and retirement. Target a newly created <span class="key-service">AWS Lambda</span> function that registers a Systems Manager maintenance window task to restart the EC2 instances.</div>                <div class="option"><strong>D.</strong> Configure an event source of EC2. Configure an event type that indicates instance state notification. Target a newly created <span class="key-service">AWS Lambda</span> function that registers a Systems Manager maintenance window task to restart the EC2 instances.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 公司的DevOps工程师使用AWS Systems Manager执行维护任务。公司有一些Amazon EC2实例在收到AWS Health通知后需要重启。DevOps工程师必须实现一个自动化解决方案，使用Amazon EventBridge在公司计划的维护窗口期间修复这些通知。DevOps工程师应该如何配置EventBridge规则来满足这些要求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 配置AWS Health作为事件源。配置表示计划实例终止和退役的事件类型。目标为AWS-RestartEC2Instance Systems Manager自动化运行手册来重启EC2实例。</div> <div class="option-analysis"><strong>B.</strong> 配置Systems Manager作为事件源。配置表示维护窗口的事件类型。目标为AWS-RestartEC2Instance Systems Manager自动化运行手册来重启EC2实例。</div> <div class="option-analysis"><strong>C.</strong> 配置AWS Health作为事件源。配置表示计划实例终止和退役的事件类型。目标为新创建的AWS Lambda函数，该函数注册Systems Manager维护窗口任务来重启EC2实例。</div> <div class="option-analysis"><strong>D.</strong> 配置EC2作为事件源。配置表示实例状态通知的事件类型。目标为新创建的AWS Lambda函数，该函数注册Systems Manager维护窗口任务来重启EC2实例。<div class="section-title"><strong>核心要求:</strong></div> 基于AWS Health通知自动化重启EC2实例的EventBridge规则配置 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• AWS Health - 提供AWS资源健康状态和计划维护事件通知 </div><div class="compact-content">• EventBridge - 事件驱动架构服务，连接事件源和目标 </div><div class="compact-content">• Systems Manager Automation - 提供预定义的自动化运行手册 <div class="section-title"><strong>正确答案A:</strong></div> 直接使用AWS Health作为事件源捕获计划维护通知，通过EventBridge触发Systems Manager预定义的重启自动化运行手册，实现最简洁高效的自动化流程 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项B - 事件源错误，应该监听AWS Health而不是Systems Manager的事件 </div><div class="compact-content">• 选项C - 架构过度复杂，不需要Lambda函数和维护窗口任务的额外层次 </div><div class="compact-content">• 选项D - 事件源错误，EC2状态通知无法提供AWS Health的计划维护信息 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能 - 直接事件触发比多层架构响应更快 </div><div class="compact-content">• 成本 - 使用预定义运行手册比自定义Lambda函数成本更低 </div><div class="compact-content">• 可扩展性 - Systems Manager Automation原生支持多实例批量操作</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: A</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-315">
            <div class="question-header">
                <div class="question-title">Question #315 ✅ ⚪ <small style="float: right;">(315/353)</small></div>
            </div>
            <div class="question-content">A DevOps engineer manages an <span class="key-service">AWS CodePipeline</span> pipeline that builds and deploys a web application on AWS. The pipeline has a source stage, a build stage, and a deploy stage. When deployed properly, the web application responds with a 200 OK HTTP response code when the URL of the home page is requested. The home page recently returned a 503 HTTP response code after CodePipeline deployed the application. The DevOps engineer needs to add an automated test into the pipeline. The automated test must ensure that the application returns a 200 OK HTTP response code after the application is deployed. The pipeline must fail if the response code is not present during the test. The DevOps engineer has added a CheckURL stage after the deploy stage in the pipeline. What should the DevOps engineer do next to implement the automated test?</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Configure the CheckURL stage to use an <span class="key-service">Amazon CloudWatch</span> action. Configure the action to use a canary synthetic monitoring check on the application URL and to report a success or failure to CodePipeline.</div>                <div class="option correct-answer"><strong>B.</strong> Create an <span class="key-service">AWS Lambda</span> function to check the response code status of the URL and to report a success or failure to CodePipeline. Configure an action in the CheckURL stage to invoke the Lambda function.</div>                <div class="option"><strong>C.</strong> Configure the CheckURL stage to use an <span class="key-service">AWS CodeDeploy</span> action. Configure the action with an input artifact that is the URL of the application and to report a success or failure to CodePipeline.</div>                <div class="option"><strong>D.</strong> Deploy an <span class="key-service">Amazon API Gateway</span> HTTP API that checks the response code status of the URL and that reports success or failure to CodePipeline. Configure the CheckURL stage to use the AWS Device Farm test action and to provide the API Gateway HTTP API as an input artifact.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一名DevOps工程师管理一个在AWS上构建和部署Web应用程序的CodePipeline流水线。该流水线有源代码阶段、构建阶段和部署阶段。正常部署时，Web应用程序在请求主页URL时返回200 OK HTTP响应代码。最近CodePipeline部署应用程序后主页返回503 HTTP响应代码。DevOps工程师需要在流水线中添加自动化测试，确保应用程序部署后返回200 OK HTTP响应代码。如果测试期间响应代码不正确，流水线必须失败。DevOps工程师已在部署阶段后添加了CheckURL阶段。接下来应该如何实现自动化测试？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 配置CheckURL阶段使用CloudWatch操作，配置该操作在应用程序URL上使用canary综合监控检查并向CodePipeline报告成功或失败</div> <div class="option-analysis"><strong>B.</strong> 创建Lambda函数检查URL的响应代码状态并向CodePipeline报告成功或失败，在CheckURL阶段配置操作来调用Lambda函数</div> <div class="option-analysis"><strong>C.</strong> 配置CheckURL阶段使用CodeDeploy操作，配置该操作以应用程序URL作为输入工件并向CodePipeline报告成功或失败</div> <div class="option-analysis"><strong>D.</strong> 部署API Gateway HTTP API检查URL的响应代码状态并向CodePipeline报告成功或失败，配置CheckURL阶段使用Device Farm测试操作并提供API Gateway HTTP API作为输入工件<div class="section-title"><strong>核心要求:</strong></div> 在CodePipeline中实现URL健康检查的自动化测试阶段 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• CodePipeline-CI/CD流水线编排服务 </div><div class="compact-content">• Lambda-无服务器计算服务，可直接集成到CodePipeline作为操作 <div class="section-title"><strong>正确答案B:</strong></div> Lambda函数可以直接作为CodePipeline的操作执行HTTP请求检查，通过返回值控制流水线成功或失败状态 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A-CloudWatch canary是独立的监控服务，无法直接作为CodePipeline阶段操作集成 </div><div class="compact-content">• 选项C-CodeDeploy是部署服务，不是用于URL健康检查的工具 </div><div class="compact-content">• 选项D-Device Farm是移动应用测试服务，不适用于Web应用URL检查场景 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-Lambda冷启动延迟低，检查响应快速 </div><div class="compact-content">• 成本-按请求付费，测试频率低成本最优 </div><div class="compact-content">• 可扩展性-原生CodePipeline集成，易于维护和扩展</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: B</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-316">
            <div class="question-header">
                <div class="question-title">Question #316 ✅ ⚪ <small style="float: right;">(316/353)</small></div>
            </div>
            <div class="question-content">A company has an application that uploads access logs to an <span class="key-service">Amazon CloudWatch</span> Logs log group. The fields in the log lines include the response code and the application name. The company wants to create a CloudWatch metric to track the number of requests by response code in a specific range and with a specific application name. Which solution will meet these requirements?</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Create a CloudWatch Logs log event filter on the CloudWatch Logs log stream to match the response code range. Configure the log event filter to increment a metric. Set the response code and application name as dimensions.</div>                <div class="option correct-answer"><strong>B.</strong> Create a CloudWatch Logs metric filter on the CloudWatch Logs log group to match the response code range. Configure the metric filter to increment a metric. Set the response code and application name as dimensions.</div>                <div class="option"><strong>C.</strong> Create a CloudWatch Contributor Insights rule on the CloudWatch Logs log stream with a filter to match the response code range. Configure the Contributor Insights rule to increment a CloudWatch metric with the response code and application name as dimensions.</div>                <div class="option"><strong>D.</strong> Create a CloudWatch Logs Insights query on the CloudWatch Logs log group to match the response code range. Configure the Logs Insights query to increment a CloudWatch metric with the response code and application name as dimensions.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司有一个应用程序将访问日志上传到Amazon CloudWatch Logs日志组。日志行中的字段包括响应代码和应用程序名称。公司希望创建一个CloudWatch指标来跟踪特定范围内响应代码和特定应用程序名称的请求数量。哪种解决方案能满足这些要求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 在CloudWatch Logs日志流上创建CloudWatch Logs日志事件过滤器来匹配响应代码范围。配置日志事件过滤器来递增指标。将响应代码和应用程序名称设置为维度。</div> <div class="option-analysis"><strong>B.</strong> 在CloudWatch Logs日志组上创建CloudWatch Logs指标过滤器来匹配响应代码范围。配置指标过滤器来递增指标。将响应代码和应用程序名称设置为维度。</div> <div class="option-analysis"><strong>C.</strong> 在CloudWatch Logs日志流上创建CloudWatch Contributor Insights规则，使用过滤器匹配响应代码范围。配置Contributor Insights规则来递增CloudWatch指标，将响应代码和应用程序名称作为维度。</div> <div class="option-analysis"><strong>D.</strong> 在CloudWatch Logs日志组上创建CloudWatch Logs Insights查询来匹配响应代码范围。配置Logs Insights查询来递增CloudWatch指标，将响应代码和应用程序名称作为维度。<div class="section-title"><strong>核心要求:</strong></div> 从日志中提取特定字段创建自定义CloudWatch指标进行监控 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• CloudWatch Logs - 日志存储和处理服务 </div><div class="compact-content">• CloudWatch Metrics - 指标监控和告警服务 <div class="section-title"><strong>正确答案B:</strong></div> CloudWatch Logs指标过滤器是从日志组中提取模式并创建自定义指标的标准方法，支持维度设置和自动指标递增 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A - 日志事件过滤器用于过滤日志事件，不能直接创建CloudWatch指标 </div><div class="compact-content">• 选项C - Contributor Insights用于分析日志中的贡献者模式，不是创建自定义指标的标准方法 </div><div class="compact-content">• 选项D - Logs Insights是交互式查询工具，不能自动递增指标或持续监控 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能 - 指标过滤器实时处理日志并自动更新指标 </div><div class="compact-content">• 成本 - 指标过滤器是最经济的日志到指标转换方案 </div><div class="compact-content">• 可扩展性 - 支持多维度指标和复杂的模式匹配规则</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: B</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-317">
            <div class="question-header">
                <div class="question-title">Question #317 ✅ ⚪ <small style="float: right;">(317/353)</small></div>
            </div>
            <div class="question-content">A DevOps engineer provisioned an Amazon Elastic Kubernetes Service (<span class="key-service">Amazon EKS</span>) cluster with managed node groups. The DevOps engineer associated an OpenID Connect (OIDC) issuer with the cluster. The DevOps engineer is configuring Amazon Elastic Block Store (Amazon EBS) General Purpose SSD (gp3) volumes for the cluster. The DevOps engineer attempts to initiate a PersistentVolumeClaim (PVC) request but is unable to provision a volume. To troubleshoot the issue, the DevOps engineer runs the kubectl describe pvc command. The DevOps engineer receives a failed to provision volume with StorageClass error and a could not create volume in EC2:UnauthorizedOperation error. Which solution will resolve these errors?</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Create a Kubernetes cluster role that allows the persistent volumes to perform get, list, watch, create, and delete operations. Configure the cluster role to allow get, list, and watch operations for storage in the cluster.</div>                <div class="option correct-answer"><strong>B.</strong> Create an Amazon EBS Container Storage Interface (CSI) driver IAM role that has the required permissions and trust relationships. Attach the IAM role to the Amazon EBS CSI driver add-on in the cluster.</div>                <div class="option"><strong>C.</strong> Add the ebs.csi.aws.com/volumeType:gp3 annotation to the PersistentVolumeClaim object in the cluster.</div>                <div class="option"><strong>D.</strong> Create a Kubernetes storage class object. Set the provisioner value to ebs.csi.aws.com. Set the volumeBindingMode value to WaitForFirstConsumer in the cluster.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一名DevOps工程师配置了Amazon EKS集群和托管节点组，并关联了OIDC发行者。在配置Amazon EBS gp3卷时，PersistentVolumeClaim请求失败，kubectl describe pvc命令显示StorageClass配置失败和EC2:UnauthorizedOperation错误。 <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 创建Kubernetes集群角色，允许持久卷执行get、list、watch、create和delete操作，并配置集群角色允许对存储执行get、list和watch操作</div> <div class="option-analysis"><strong>B.</strong> 创建具有所需权限和信任关系的Amazon EBS Container Storage Interface (CSI) driver IAM角色，并将IAM角色附加到集群中的Amazon EBS CSI driver插件</div> <div class="option-analysis"><strong>C.</strong> 在集群的PersistentVolumeClaim对象中添加ebs.csi.aws.com/volumeType:gp3注释</div> <div class="option-analysis"><strong>D.</strong> 创建Kubernetes存储类对象，将provisioner值设置为ebs.csi.aws.com，在集群中将volumeBindingMode值设置为WaitForFirstConsumer<div class="section-title"><strong>核心要求:</strong></div> 解决EKS集群中EBS CSI driver权限不足导致的PVC配置失败问题 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• <span class="key-service">Amazon EKS</span>-托管Kubernetes服务，需要正确的IAM权限配置 </div><div class="compact-content">• Amazon EBS CSI driver-负责在EKS中管理EBS卷的存储接口驱动 <div class="section-title"><strong>正确答案B:</strong></div> EC2:UnauthorizedOperation错误表明EBS CSI driver缺少必要的IAM权限来创建和管理EBS卷，需要创建具有适当权限的IAM角色并附加到CSI driver插件 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A-Kubernetes RBAC权限不能解决AWS API调用的IAM权限问题 </div><div class="compact-content">• 选项C-注释只是元数据标记，不能解决权限问题 </div><div class="compact-content">• 选项D-StorageClass配置不能解决底层IAM权限不足的问题 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-IAM权限配置不影响存储性能，但是配置正确性的前提 </div><div class="compact-content">• 成本-IAM角色配置无额外成本，避免因权限问题导致的资源浪费 </div><div class="compact-content">• 可扩展性-正确的IAM权限配置支持后续EBS卷的自动化管理和扩展</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: B</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-318">
            <div class="question-header">
                <div class="question-title">Question #318 ✅ 📝 <small style="float: right;">(318/353)</small></div>
            </div>
            <div class="question-content">A company runs a fleet of <span class="key-service">Amazon EC2</span> instances in a <span class="key-service">VPC</span>. The company's employees remotely access the EC2 instances by using the Remote Desktop Protocol (RDP). The company wants to collect metrics about how many RDP sessions the employees initiate every day. Which combination of steps will meet this requirement? (Choose three.)</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Create an Amazon EventBridge rule that reacts to EC2 Instance State-change Notification events.</div>                <div class="option"><strong>B.</strong> Create an <span class="key-service">Amazon CloudWatch</span> Logs log group. Specify the log group as a target for the EventBridge rule.</div>                <div class="option correct-answer"><strong>C.</strong> Create a flow log in <span class="key-service">VPC</span> Flow Logs.</div>                <div class="option correct-answer"><strong>D.</strong> Create an <span class="key-service">Amazon CloudWatch</span> Logs log group. Specify the log group as a destination for the flow log.</div>                <div class="option correct-answer"><strong>E.</strong> Create a log group metric filter. F. Create a log group subscription filter. Use EventBridge as the destination.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司在VPC中运行Amazon EC2实例集群。公司员工使用Remote Desktop Protocol (RDP)远程访问EC2实例。公司希望收集员工每天发起多少个RDP会话的指标。哪些步骤组合能满足这个要求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 创建Amazon EventBridge规则，响应EC2实例状态变更通知事件</div> <div class="option-analysis"><strong>B.</strong> 创建Amazon CloudWatch Logs日志组，将日志组指定为EventBridge规则的目标</div> <div class="option-analysis"><strong>C.</strong> 在VPC Flow Logs中创建流日志</div> <div class="option-analysis"><strong>D.</strong> 创建Amazon CloudWatch Logs日志组，将日志组指定为流日志的目标</div> <div class="option-analysis"><strong>E.</strong> 创建日志组指标过滤器 F. 创建日志组订阅过滤器，使用EventBridge作为目标<div class="section-title"><strong>核心要求:</strong></div> 收集和统计RDP会话连接指标 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• <span class="key-service">VPC</span> Flow Logs - 捕获网络流量数据包括RDP连接 </div><div class="compact-content">• CloudWatch Logs - 存储和处理流日志数据 </div><div class="compact-content">• CloudWatch Metrics - 通过指标过滤器生成自定义指标 <div class="section-title"><strong>正确答案CDE:</strong></div> <span class="key-service">VPC</span> Flow Logs捕获RDP流量(端口3389)→CloudWatch Logs存储流日志→指标过滤器解析RDP连接并生成指标 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A - EC2状态变更事件无法捕获RDP会话连接信息 </div><div class="compact-content">• 选项B - EventBridge无法直接获取RDP会话数据 </div><div class="compact-content">• 选项F - 订阅过滤器用于数据转发而非指标生成 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能 - <span class="key-service">VPC</span> Flow Logs实时捕获网络流量，指标过滤器自动处理 </div><div class="compact-content">• 成本 - 仅为必要的网络监控付费，无需额外基础设施 </div><div class="compact-content">• 可扩展性 - 自动适应EC2实例规模变化，支持大量并发RDP会话监控</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: CDE (C、D、E)</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-319">
            <div class="question-header">
                <div class="question-title">Question #319 ✅ ⚪ <small style="float: right;">(319/353)</small></div>
            </div>
            <div class="question-content">A company is using Amazon Elastic Kubernetes Service (<span class="key-service">Amazon EKS</span>) to run its applications. The EKS cluster is successfully running multiple pods. The company stores the pod images in Amazon Elastic Container Registry (<span class="key-service">Amazon ECR</span>). The company needs to configure Pod Identity access for the EKS cluster. The company has already updated the node IAM role by using the permissions for Pod Identity access. Which solution will meet these requirements?</div>
            <div class="options-container">                <div class="option correct-answer"><strong>A.</strong> Create an IAM OpenID Connect (OIDC) provider for the EKS cluster.</div>                <div class="option"><strong>B.</strong> Ensure that the nodes can reach the EKS Auth API. Add and configure the EKS Pod Identity Agent add-on for the EKS cluster.</div>                <div class="option"><strong>C.</strong> Create an EKS access entry that uses the API_AND_CONFIG_MAP cluster authentication mode.</div>                <div class="option"><strong>D.</strong> Configure the AWS Security Token Service (AWS STS) endpoint for the Kubernetes service account that the pods in the EKS cluster use.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司正在使用Amazon EKS运行应用程序。EKS集群成功运行多个pod。公司将pod镜像存储在Amazon ECR中。公司需要为EKS集群配置Pod Identity访问。公司已经使用Pod Identity访问权限更新了节点IAM角色。哪个解决方案能满足这些要求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 为EKS集群创建一个IAM OpenID Connect (OIDC)提供商。</div> <div class="option-analysis"><strong>B.</strong> 确保节点可以访问EKS Auth API。为EKS集群添加并配置EKS Pod Identity Agent附加组件。</div> <div class="option-analysis"><strong>C.</strong> 创建一个使用API_AND_CONFIG_MAP集群认证模式的EKS访问条目。</div> <div class="option-analysis"><strong>D.</strong> 为EKS集群中pod使用的Kubernetes服务账户配置AWS Security Token Service (AWS STS)端点。<div class="section-title"><strong>核心要求:</strong></div> 为EKS集群配置Pod Identity访问权限 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• <span class="key-service">Amazon EKS</span> - Kubernetes托管服务，需要配置pod身份认证 </div><div class="compact-content">• IAM OIDC Provider - 实现EKS与AWS IAM之间的身份联合认证 <div class="section-title"><strong>正确答案A:</strong></div> 创建IAM OIDC提供商是配置EKS Pod Identity的基础步骤，建立EKS集群与AWS IAM之间的信任关系，使pod能够通过服务账户获得AWS权限 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项B - Pod Identity Agent是较新的功能，但传统的OIDC方式仍是主要配置方法 </div><div class="compact-content">• 选项C - 访问条目主要用于集群访问控制，不是Pod Identity配置的核心 </div><div class="compact-content">• 选项D - STS端点配置是自动处理的，不需要手动配置 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能 - OIDC提供商提供高效的身份认证机制 </div><div class="compact-content">• 成本 - 无额外费用的标准AWS服务集成 </div><div class="compact-content">• 可扩展性 - 支持大规模pod的身份管理需求</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: A</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-320">
            <div class="question-header">
                <div class="question-title">Question #320 ✅ ⚪ <small style="float: right;">(320/353)</small></div>
            </div>
            <div class="question-content">A company has multiple AWS accounts in an organization in <span class="key-service">AWS Organizations</span> that has all features enabled. The company's DevOps administrator needs to improve security across all the company's AWS accounts. The administrator needs to identify the top users and roles in use across all accounts. Which solution will meet these requirements with the MOST operational efficiency?</div>
            <div class="options-container">                <div class="option correct-answer"><strong>A.</strong> Create a new organization trail in <span class="key-service">AWS CloudTrail</span>. Configure the trail to send log events to <span class="key-service">Amazon CloudWatch</span> Logs. Create a CloudWatch Contributor Insights rule for the userIdentity.arn log field. View the results in CloudWatch Contributor Insights.</div>                <div class="option"><strong>B.</strong> Create an unused access analysis for the organization by using AWS Identity and Access Management Access Analyzer. Review the analyzer results and determine if each finding has the intended level of permissions required for the workload.</div>                <div class="option"><strong>C.</strong> Create a new organization trail in <span class="key-service">AWS CloudTrail</span>. Create a table in Amazon Athena that uses partition projection. Load the Athena table with CloudTrail data. Query the Athena table to find the top users and roles.</div>                <div class="option"><strong>D.</strong> Generate a Service access report for each account by using Organizations. From the results, pull the last accessed date and last accessed by account fields to find the top users and roles.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司在AWS Organizations中有多个AWS账户，该组织启用了所有功能。公司的DevOps管理员需要提高所有AWS账户的安全性，需要识别所有账户中使用最多的顶级用户和角色。哪种解决方案能以最高的运营效率满足这些要求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 在AWS CloudTrail中创建新的组织级跟踪，配置跟踪将日志事件发送到Amazon CloudWatch Logs，为userIdentity.arn日志字段创建CloudWatch Contributor Insights规则，在CloudWatch Contributor Insights中查看结果。</div> <div class="option-analysis"><strong>B.</strong> 使用AWS Identity and Access Management Access Analyzer为组织创建未使用访问分析，审查分析器结果并确定每个发现是否具有工作负载所需的预期权限级别。</div> <div class="option-analysis"><strong>C.</strong> 在AWS CloudTrail中创建新的组织级跟踪，在Amazon Athena中创建使用分区投影的表，用CloudTrail数据加载Athena表，查询Athena表以找到顶级用户和角色。</div> <div class="option-analysis"><strong>D.</strong> 使用Organizations为每个账户生成服务访问报告，从结果中提取最后访问日期和最后访问账户字段以找到顶级用户和角色。<div class="section-title"><strong>核心要求:</strong></div> 识别AWS Organizations中所有账户的顶级用户和角色使用情况 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• <span class="key-service">AWS CloudTrail</span>-记录API调用和用户活动 </div><div class="compact-content">• CloudWatch Contributor Insights-自动分析日志数据并识别顶级贡献者 <div class="section-title"><strong>正确答案A:</strong></div> 组织级CloudTrail跟踪所有账户活动，CloudWatch Contributor Insights自动分析userIdentity.arn字段，直接提供顶级用户和角色的排名统计，无需手动查询和分析 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项B-Access Analyzer主要用于识别未使用的权限，不是用于统计使用频率最高的用户和角色 </div><div class="compact-content">• 选项C-需要手动创建和维护Athena表及查询，运营效率较低 </div><div class="compact-content">• 选项D-服务访问报告不提供用户和角色的使用频率排名信息 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-Contributor Insights提供实时自动分析和可视化结果 </div><div class="compact-content">• 成本-无需额外的数据处理和存储服务 </div><div class="compact-content">• 可扩展性-自动处理组织级别的所有账户数据</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: A</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-321">
            <div class="question-header">
                <div class="question-title">Question #321 ✅ ⚪ <small style="float: right;">(321/353)</small></div>
            </div>
            <div class="question-content">A company has an organization in <span class="key-service">AWS Organizations</span> with many OUs that contain many AWS accounts. The organization has a dedicated delegated administrator AWS account. The company needs the accounts in one OU to have server-side encryption enforced for all Amazon Elastic Block Store (Amazon EBS) volumes and Amazon Simple Queue Service (<span class="key-service">Amazon SQS</span>) queues that are created or updated on an <span class="key-service">AWS CloudFormation</span> stack. Which solution will enforce this policy before a CloudFormation stack operation in the accounts of this OU?</div>
            <div class="options-container">                <div class="option correct-answer"><strong>A.</strong> Activate trusted access to CloudFormation StackSets. Create a CloudFormation Hook that enforces server-side encryption on EBS volumes and SQS queues. Deploy the Hook across the accounts in the OU by using StackSets.</div>                <div class="option"><strong>B.</strong> Set up <span class="key-service">AWS Config</span> in all the accounts in the OU. Use <span class="key-service">AWS Systems Manager</span> to deploy <span class="key-service">AWS Config</span> rules that enforce server-side encryption for EBS volumes and SQS queues across the accounts in the OU.</div>                <div class="option"><strong>C.</strong> Write an <span class="key-service">SCP</span> to deny the creation of EBS volumes and SQS queues unless the EBS volumes and SQS queues have server-side encryption. Attach the <span class="key-service">SCP</span> to the OU.</div>                <div class="option"><strong>D.</strong> Create an <span class="key-service">AWS Lambda</span> function in the delegated administrator account that checks whether server-side encryption is enforced for EBS volumes and SQS queues. Create an IAM role to provide the Lambda function access to the accounts in the OU.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司在AWS Organizations中有一个包含多个OU的组织，这些OU包含许多AWS账户。该组织有一个专用的委托管理员AWS账户。公司需要某个OU中的账户对所有在AWS CloudFormation堆栈中创建或更新的Amazon EBS卷和Amazon SQS队列强制执行服务器端加密。哪种解决方案将在此OU账户的CloudFormation堆栈操作之前强制执行此策略？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 激活CloudFormation StackSets的可信访问。创建一个CloudFormation Hook来强制EBS卷和SQS队列的服务器端加密。使用StackSets在OU的账户中部署Hook。</div> <div class="option-analysis"><strong>B.</strong> 在OU的所有账户中设置AWS Config。使用AWS Systems Manager部署AWS Config规则，在OU的账户中强制EBS卷和SQS队列的服务器端加密。</div> <div class="option-analysis"><strong>C.</strong> 编写SCP拒绝创建EBS卷和SQS队列，除非EBS卷和SQS队列具有服务器端加密。将SCP附加到OU。</div> <div class="option-analysis"><strong>D.</strong> 在委托管理员账户中创建AWS Lambda函数，检查EBS卷和SQS队列是否强制执行服务器端加密。创建IAM角色为Lambda函数提供访问OU中账户的权限。<div class="section-title"><strong>核心要求:</strong></div> 在CloudFormation堆栈操作前强制执行EBS和SQS的服务器端加密策略 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• CloudFormation Hook-在堆栈操作前进行预检查和策略强制执行 </div><div class="compact-content">• StackSets-跨多个账户和OU统一部署CloudFormation资源 <div class="section-title"><strong>正确答案A:</strong></div> CloudFormation Hook提供堆栈操作前的预检查机制，StackSets确保Hook在OU所有账户中统一部署和执行 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项B-AWS Config是事后检测合规性，无法在CloudFormation操作前阻止不合规资源创建 </div><div class="compact-content">• 选项C-SCP虽能阻止操作但过于粗暴，会完全阻止资源创建而非仅阻止未加密资源 </div><div class="compact-content">• 选项D-Lambda函数需要额外触发机制，无法自动在CloudFormation操作前执行检查 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-Hook在堆栈操作前即时检查，避免创建后再修正的性能损耗 </div><div class="compact-content">• 成本-预防式控制避免创建不合规资源后的删除重建成本 </div><div class="compact-content">• 可扩展性-StackSets确保策略在整个OU范围内统一应用和管理</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: A</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-322">
            <div class="question-header">
                <div class="question-title">Question #322 ✅ 📝 <small style="float: right;">(322/353)</small></div>
            </div>
            <div class="question-content">A company is running an internal application in an Amazon Elastic Container Service (<span class="key-service">Amazon ECS</span>) cluster on <span class="key-service">Amazon EC2</span>. The ECS cluster instances can connect to the public internet. The ECS tasks that run on the cluster instances are configured to use images from both private Amazon Elastic Container Registry (<span class="key-service">Amazon ECR</span>) repositories and a public ECR registry repository. A new security policy requires the company to remove the ECS cluster's direct access to the internet. The company must remove any NAT gateways and internet gateways from the <span class="key-service">VPC</span> that hosts the cluster. A DevOps engineer needs to ensure the ECS cluster can still download images from both the public ECR registry and the private ECR repositories. Images from the public ECR registry must remain up-to-date. New versions of the images must be available to the ECS cluster within 24 hours of publication. Which combination of steps will meet these requirements with the LEAST operational overhead? (Choose three.)</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Create an <span class="key-service">AWS CodeBuild</span> project and a new private ECR repository for each image that is downloaded from the public ECR registry. Configure each project to pull the image from the public ECR repository and push the image to the new private ECR repository. Create an Amazon EventBridge rule that invokes the CodeBuild project once every 24 hours. Update each task definition in the ECS cluster to refer to the new private ECR repository.</div>                <div class="option"><strong>B.</strong> Create a new <span class="key-service">Amazon ECR</span> pull through cache rule for each image that is downloaded from the public ECR registry. Create an <span class="key-service">AWS Lambda</span> function that invokes each pull through cache rule. Create an Amazon EventBridge rule that invokes the Lambda function once every 24 hours. Update each task definition in the ECS cluster to refer to the image from the pull through cache.</div>                <div class="option correct-answer"><strong>C.</strong> Create a new <span class="key-service">Amazon ECR</span> pull through cache rule for the public ECR registry. Update each task definition in the ECS cluster to refer to the image from the pull through cache. Ensure each public image has been downloaded through the pull through cache at least once before removing internet access from the <span class="key-service">VPC</span>.</div>                <div class="option correct-answer"><strong>D.</strong> Create an <span class="key-service">Amazon ECR</span> interface <span class="key-service">VPC</span> endpoint for the public ECR repositories that are in the <span class="key-service">VPC</span>.</div>                <div class="option correct-answer"><strong>E.</strong> Create an <span class="key-service">Amazon ECR</span> interface <span class="key-service">VPC</span> endpoint for the private ECR repositories that are in the <span class="key-service">VPC</span>. F. Create an <span class="key-service">Amazon S3</span> gateway endpoint in the <span class="key-service">VPC</span>.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司在Amazon EC2上的Amazon ECS集群中运行内部应用程序。ECS集群实例可以连接到公共互联网。集群上运行的ECS任务配置为使用来自私有Amazon ECR存储库和公共ECR注册表存储库的镜像。新的安全策略要求公司移除ECS集群对互联网的直接访问。公司必须从托管集群的VPC中移除所有NAT网关和互联网网关。DevOps工程师需要确保ECS集群仍能从公共ECR注册表和私有ECR存储库下载镜像。来自公共ECR注册表的镜像必须保持最新。新版本的镜像必须在发布后24小时内对ECS集群可用。哪种步骤组合能以最少的运营开销满足这些要求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 为从公共ECR注册表下载的每个镜像创建AWS CodeBuild项目和新的私有ECR存储库。配置每个项目从公共ECR存储库拉取镜像并推送到新的私有ECR存储库。创建Amazon EventBridge规则每24小时调用一次CodeBuild项目。更新ECS集群中的每个任务定义以引用新的私有ECR存储库。</div> <div class="option-analysis"><strong>B.</strong> 为从公共ECR注册表下载的每个镜像创建新的Amazon ECR拉取缓存规则。创建AWS Lambda函数调用每个拉取缓存规则。创建Amazon EventBridge规则每24小时调用一次Lambda函数。更新ECS集群中的每个任务定义以引用来自拉取缓存的镜像。</div> <div class="option-analysis"><strong>C.</strong> 为公共ECR注册表创建新的Amazon ECR拉取缓存规则。更新ECS集群中的每个任务定义以引用来自拉取缓存的镜像。确保在从VPC移除互联网访问之前，每个公共镜像至少通过拉取缓存下载一次。</div> <div class="option-analysis"><strong>D.</strong> 在VPC中为公共ECR存储库创建Amazon ECR接口VPC端点。</div> <div class="option-analysis"><strong>E.</strong> 在VPC中为私有ECR存储库创建Amazon ECR接口VPC端点。 F. 在VPC中创建Amazon S3网关端点。<div class="section-title"><strong>核心要求:</strong></div> 在移除互联网访问后确保ECS集群能访问公共和私有ECR存储库 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• <span class="key-service">Amazon ECR</span> Pull Through Cache - 缓存公共镜像到私有存储库 </div><div class="compact-content">• <span class="key-service">VPC</span> Endpoint - 提供私有网络访问AWS服务的能力 <div class="section-title"><strong>正确答案CDE:</strong></div> C选项使用ECR拉取缓存规则将公共镜像缓存到私有存储库，D选项创建VPC端点访问公共ECR，E选项创建VPC端点访问私有ECR，组合提供完整的无互联网访问解决方案 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A - CodeBuild方案增加了不必要的运营复杂性和成本开销 </div><div class="compact-content">• 选项B - Lambda定时调用增加了额外的运营开销，不如直接缓存方案简单 </div><div class="compact-content">• 选项F - S3网关端点在此场景中不是必需的 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能 - VPC端点提供高性能私有网络访问 </div><div class="compact-content">• 成本 - 拉取缓存避免重复传输，VPC端点按使用量计费 </div><div class="compact-content">• 可扩展性 - ECR拉取缓存自动处理镜像更新，无需手动管理</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: CDE (C、D、E)</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-323">
            <div class="question-header">
                <div class="question-title">Question #323 ✅ 📝 <small style="float: right;">(323/353)</small></div>
            </div>
            <div class="question-content">A company has a continuous integration pipeline where the company creates container images by using <span class="key-service">AWS CodeBuild</span>. The created images are stored in Amazon Elastic Container Registry (<span class="key-service">Amazon ECR</span>). Checking for and fixing the vulnerabilities in the images takes the company too much time. The company wants to identify the image vulnerabilities quickly and notify the security team of the vulnerabilities. Which combination of steps will meet these requirements with the LEAST operational overhead? (Choose two.)</div>
            <div class="options-container">                <div class="option correct-answer"><strong>A.</strong> Activate Amazon Inspector enhanced scanning for <span class="key-service">Amazon ECR</span>. Configure the enhanced scanning to use continuous scanning. Set up a topic in Amazon Simple Notification Service (<span class="key-service">Amazon SNS</span>).</div>                <div class="option correct-answer"><strong>B.</strong> Create an Amazon EventBridge rule for Amazon Inspector findings. Set an Amazon Simple Notification Service (<span class="key-service">Amazon SNS</span>) topic as the rule target.</div>                <div class="option"><strong>C.</strong> Activate <span class="key-service">AWS Lambda</span> enhanced scanning for <span class="key-service">Amazon ECR</span>. Configure the enhanced scanning to use continuous scanning. Set up a topic in Amazon Simple Email Service (Amazon SES).</div>                <div class="option"><strong>D.</strong> Create a new <span class="key-service">AWS Lambda</span> function. Invoke the new Lambda function when scan findings are detected.</div>                <div class="option"><strong>E.</strong> Activate default basic scanning for <span class="key-service">Amazon ECR</span> for all container images. Configure the default basic scanning to use continuous scanning. Set up a topic in Amazon Simple Notification Service (<span class="key-service">Amazon SNS</span>).</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司有一个持续集成管道，使用AWS CodeBuild创建容器镜像，镜像存储在Amazon ECR中。检查和修复镜像漏洞耗时过长，公司希望快速识别镜像漏洞并通知安全团队。哪种步骤组合能以最少运营开销满足要求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 为Amazon ECR激活Amazon Inspector增强扫描，配置增强扫描使用持续扫描，在Amazon SNS中设置主题</div> <div class="option-analysis"><strong>B.</strong> 为Amazon Inspector发现创建Amazon EventBridge规则，将Amazon SNS主题设置为规则目标</div> <div class="option-analysis"><strong>C.</strong> 为Amazon ECR激活AWS Lambda增强扫描，配置增强扫描使用持续扫描，在Amazon SES中设置主题</div> <div class="option-analysis"><strong>D.</strong> 创建新的AWS Lambda函数，在检测到扫描发现时调用新的Lambda函数</div> <div class="option-analysis"><strong>E.</strong> 为所有容器镜像激活Amazon ECR默认基础扫描，配置默认基础扫描使用持续扫描，在Amazon SNS中设置主题<div class="section-title"><strong>核心要求:</strong></div> 快速识别容器镜像漏洞并自动通知安全团队，最小化运营开销 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• Amazon Inspector - 提供容器镜像漏洞扫描和安全评估 </div><div class="compact-content">• Amazon EventBridge - 事件驱动架构，自动触发通知流程 <div class="section-title"><strong>正确答案AB:</strong></div> Inspector增强扫描提供全面漏洞检测，EventBridge规则自动捕获扫描结果并触发SNS通知，实现完全自动化的漏洞发现和通知流程 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项C-Lambda不提供ECR扫描功能，且SES用于邮件服务而非消息通知 </div><div class="compact-content">• 选项D-需要自定义Lambda函数增加开发和维护成本，不符合最少运营开销要求 </div><div class="compact-content">• 选项E-基础扫描功能有限，检测能力不如增强扫描全面 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-增强扫描提供更快更全面的漏洞检测 </div><div class="compact-content">• 成本-使用托管服务避免自定义开发成本 </div><div class="compact-content">• 可扩展性-EventBridge自动处理事件，无需手动干预</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: AB (A、B)</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-324">
            <div class="question-header">
                <div class="question-title">Question #324 ✅ ⚪ <small style="float: right;">(324/353)</small></div>
            </div>
            <div class="question-content">A DevOps administrator is configuring a repository to store a company's container images. The administrator needs to configure a lifecycle rule that automatically deletes container images that have a specific tag and that are older than 15 days. Which solution will meet these requirements with the MOST operational efficiency?</div>
            <div class="options-container">                <div class="option correct-answer"><strong>A.</strong> Create a repository in Amazon Elastic Container Registry (<span class="key-service">Amazon ECR</span>). Add a lifecycle policy to the repository to expire images that have the matching tag after 15 days.</div>                <div class="option"><strong>B.</strong> Create a repository in AWS CodeArtifact. Add a repository policy to the CodeArtifact repository to expire old assets that have the matching tag after 15 days.</div>                <div class="option"><strong>C.</strong> Create a bucket in <span class="key-service">Amazon S3</span>. Add a bucket lifecycle policy to expire old objects that have the matching tag after 15 days.</div>                <div class="option"><strong>D.</strong> Create an EC2 Image Builder container recipe. Add a build component to expire the container that has the matching tag after 15 days.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一位DevOps管理员正在配置存储库来存储公司的容器镜像。管理员需要配置生命周期规则，自动删除具有特定标签且超过15天的容器镜像。哪个解决方案能以最高运营效率满足这些要求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 在Amazon Elastic Container Registry (<span class="key-service">Amazon ECR</span>)中创建存储库。向存储库添加生命周期策略，使具有匹配标签的镜像在15天后过期。</div> <div class="option-analysis"><strong>B.</strong> 在AWS CodeArtifact中创建存储库。向CodeArtifact存储库添加存储库策略，使具有匹配标签的旧资产在15天后过期。</div> <div class="option-analysis"><strong>C.</strong> 在Amazon S3中创建存储桶。添加存储桶生命周期策略，使具有匹配标签的旧对象在15天后过期。</div> <div class="option-analysis"><strong>D.</strong> 创建EC2 Image Builder容器配方。添加构建组件，使具有匹配标签的容器在15天后过期。<div class="section-title"><strong>核心要求:</strong></div> 为容器镜像配置基于标签和时间的自动删除生命周期规则 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• <span class="key-service">Amazon ECR</span>-专门的容器镜像注册服务，提供原生生命周期管理 </div><div class="compact-content">• AWS CodeArtifact-软件包管理服务，主要用于应用程序依赖包 <div class="section-title"><strong>正确答案A:</strong></div> Amazon ECR是AWS原生容器镜像注册服务，内置生命周期策略功能，可直接基于标签和时间自动删除镜像，运营效率最高 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项B-CodeArtifact用于软件包管理而非容器镜像存储，不是最佳选择 </div><div class="compact-content">• 选项C-S3虽可存储容器镜像但缺乏容器特定的管理功能，运营复杂度高 </div><div class="compact-content">• 选项D-EC2 Image Builder用于构建镜像而非存储管理，不符合需求场景 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-ECR提供容器镜像专用的高性能存储和分发 </div><div class="compact-content">• 成本-原生生命周期管理减少存储成本和运维开销 </div><div class="compact-content">• 可扩展性-ECR与容器生态系统深度集成，支持大规模部署</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: A</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-325">
            <div class="question-header">
                <div class="question-title">Question #325 ✅ 📝 <small style="float: right;">(325/353)</small></div>
            </div>
            <div class="question-content">A company uses Amazon Redshift as its data warehouse solution. The company wants to create a dashboard to view changes to the Redshift users and the queries the users perform. Which combination of steps will meet this requirement? (Choose two.)</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Create an <span class="key-service">Amazon CloudWatch</span> log group. Create an <span class="key-service">AWS CloudTrail</span> trail that writes to the CloudWatch log group.</div>                <div class="option correct-answer"><strong>B.</strong> Create a new <span class="key-service">Amazon S3</span> bucket. Configure default audit logging on the Redshift cluster. Configure the S3 bucket as the target.</div>                <div class="option correct-answer"><strong>C.</strong> Configure the Redshift cluster database audit logging to include user activity logs. Configure <span class="key-service">Amazon CloudWatch</span> as the target.</div>                <div class="option"><strong>D.</strong> Create an <span class="key-service">Amazon CloudWatch</span> dashboard that has a log widget. Configure the widget to display user details from the Redshift logs.</div>                <div class="option"><strong>E.</strong> Create an <span class="key-service">AWS Lambda</span> function that uses Amazon Athena to query the Redshift logs. Create an <span class="key-service">Amazon CloudWatch</span> dashboard that has a custom widget type that uses the Lambda function.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司使用Amazon Redshift作为数据仓库解决方案。公司希望创建一个仪表板来查看Redshift用户的变更和用户执行的查询。哪种步骤组合能满足这个要求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 创建一个Amazon CloudWatch日志组。创建一个AWS CloudTrail跟踪，将其写入CloudWatch日志组。</div> <div class="option-analysis"><strong>B.</strong> 创建一个新的Amazon S3存储桶。在Redshift集群上配置默认审计日志记录。将S3存储桶配置为目标。</div> <div class="option-analysis"><strong>C.</strong> 配置Redshift集群数据库审计日志记录以包含用户活动日志。将Amazon CloudWatch配置为目标。</div> <div class="option-analysis"><strong>D.</strong> 创建一个包含日志小部件的Amazon CloudWatch仪表板。配置小部件以显示来自Redshift日志的用户详细信息。</div> <div class="option-analysis"><strong>E.</strong> 创建一个使用Amazon Athena查询Redshift日志的AWS Lambda函数。创建一个包含使用Lambda函数的自定义小部件类型的Amazon CloudWatch仪表板。<div class="section-title"><strong>核心要求:</strong></div> 监控Redshift用户变更和查询活动并创建可视化仪表板 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• Amazon Redshift-数据仓库服务，支持审计日志记录用户活动和查询 </div><div class="compact-content">• <span class="key-service">Amazon CloudWatch</span>-监控服务，提供日志存储和仪表板可视化功能 <div class="section-title"><strong>正确答案BC:</strong></div> B选项启用Redshift审计日志并存储到S3，C选项配置用户活动日志到CloudWatch，两者结合提供完整的日志收集和可视化解决方案 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A-CloudTrail主要记录API调用，无法捕获Redshift内部的用户查询活动 </div><div class="compact-content">• 选项D-仅创建仪表板而未配置日志数据源，缺少数据收集步骤 </div><div class="compact-content">• 选项E-过度复杂化，使用Athena和Lambda增加不必要的复杂性和成本 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-直接的日志记录和CloudWatch原生可视化提供最佳性能 </div><div class="compact-content">• 成本-使用原生AWS服务避免额外的Lambda和Athena查询费用 </div><div class="compact-content">• 可扩展性-CloudWatch和S3都具备自动扩展能力处理大量日志数据</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: BC (B、C)</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-326">
            <div class="question-header">
                <div class="question-title">Question #326 ✅ ⚪ <small style="float: right;">(326/353)</small></div>
            </div>
            <div class="question-content">A company uses an organization in <span class="key-service">AWS Organizations</span> to manage its 500 AWS accounts. The organization has all features enabled. The AWS accounts are in a single OU. The developers need to use the CostCenter tag key for all resources in the organization's member accounts. Some teams do not use the CostCenter tag key to tag their <span class="key-service">Amazon EC2</span> instances. The cloud team wrote a script that scans all EC2 instances in the organization's member accounts. If the EC2 instances do not have a CostCenter tag key, the script will notify AWS account administrators. To avoid this notification, some developers use the CostCenter tag key with an arbitrary string in the tag value. The cloud team needs to ensure that all EC2 instances in the organization use a CostCenter tag key with the appropriate cost center value. Which solution will meet these requirements?</div>
            <div class="options-container">                <div class="option correct-answer"><strong>A.</strong> Create an <span class="key-service">SCP</span> that prevents the creation of EC2 instances without the CostCenter tag key. Create a tag policy that requires the CostCenter tag to be values from a known list of cost centers for all EC2 instances. Attach the policy to the OU. Update the script to scan the tag keys and tag values. Modify the script to update noncompliant resources with a default approved tag value for the CostCenter tag key.</div>                <div class="option"><strong>B.</strong> Create an <span class="key-service">SCP</span> that prevents the creation of EC2 instances without the CostCenter tag key. Attach the policy to the OU. Update the script to scan the tag keys and tag values and notify the administrators when the tag values are not valid.</div>                <div class="option"><strong>C.</strong> Create an <span class="key-service">SCP</span> that prevents the creation of EC2 instances without the CostCenter tag key. Attach the policy to the OU. Create an IAM permission boundary in the organization's member accounts that restricts the CostCenter tag values to a list of valid cost centers.</div>                <div class="option"><strong>D.</strong> Create a tag policy that requires the CostCenter tag to be values from a known list of cost centers for all EC2 instances. Attach the policy to the OU. Configure an <span class="key-service">AWS Lambda</span> function that adds an empty CostCenter tag key to an EC2 instance. Create an Amazon EventBridge rule that matches events to the RunInstances API action with the Lambda function as the target.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司使用AWS Organizations中的组织来管理其500个AWS账户。组织启用了所有功能。AWS账户位于单个OU中。开发人员需要为组织成员账户中的所有资源使用CostCenter标签键。一些团队不使用CostCenter标签键来标记他们的Amazon EC2实例。云团队编写了一个脚本，扫描组织成员账户中的所有EC2实例。如果EC2实例没有CostCenter标签键，脚本将通知AWS账户管理员。为了避免此通知，一些开发人员使用CostCenter标签键但在标签值中使用任意字符串。云团队需要确保组织中的所有EC2实例都使用带有适当成本中心值的CostCenter标签键。 <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 创建一个SCP防止创建没有CostCenter标签键的EC2实例。创建一个标签策略，要求所有EC2实例的CostCenter标签值来自已知成本中心列表。将策略附加到OU。更新脚本扫描标签键和标签值。修改脚本为不合规资源更新CostCenter标签键的默认批准标签值。</div> <div class="option-analysis"><strong>B.</strong> 创建一个SCP防止创建没有CostCenter标签键的EC2实例。将策略附加到OU。更新脚本扫描标签键和标签值，当标签值无效时通知管理员。</div> <div class="option-analysis"><strong>C.</strong> 创建一个SCP防止创建没有CostCenter标签键的EC2实例。将策略附加到OU。在组织成员账户中创建IAM权限边界，将CostCenter标签值限制为有效成本中心列表。</div> <div class="option-analysis"><strong>D.</strong> 创建一个标签策略，要求所有EC2实例的CostCenter标签值来自已知成本中心列表。将策略附加到OU。配置AWS Lambda函数为EC2实例添加空的CostCenter标签键。创建Amazon EventBridge规则匹配RunInstances API操作事件，以Lambda函数为目标。<div class="section-title"><strong>核心要求:</strong></div> 确保组织中所有EC2实例都使用带有有效成本中心值的CostCenter标签 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• <span class="key-service">SCP</span>-防止创建不合规资源的权限控制 </div><div class="compact-content">• Tag Policy-强制标签值符合预定义列表 </div><div class="compact-content">• <span class="key-service">AWS Organizations</span>-集中管理多账户标签策略 <div class="section-title"><strong>正确答案A:</strong></div> 结合SCP防止创建无标签实例和Tag Policy验证标签值有效性，通过脚本自动修复不合规资源，提供完整的预防和修复机制 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项B-仅通知管理员但不自动修复不合规资源，无法确保合规性 </div><div class="compact-content">• 选项C-IAM权限边界无法有效控制标签值，且不提供修复机制 </div><div class="compact-content">• 选项D-缺少SCP防护，Lambda添加空标签值不符合要求 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-自动化修复减少人工干预 </div><div class="compact-content">• 成本-预防性控制避免后期大量修复工作 </div><div class="compact-content">• 可扩展性-组织级策略适用于所有500个账户</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: A</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-327">
            <div class="question-header">
                <div class="question-title">Question #327 ✅ 📝 <small style="float: right;">(327/353)</small></div>
            </div>
            <div class="question-content">A DevOps engineer uses a pipeline in <span class="key-service">AWS CodePipeline</span>. The pipeline has a build action and a deploy action for a single-page web application that is delivered to an <span class="key-service">Amazon S3</span> bucket. Amazon CloudFront serves the web application. The build action creates an artifact for the web application. The DevOps engineer has created an <span class="key-service">AWS CloudFormation</span> template that defines the S3 bucket and configures the S3 bucket to host the application. The DevOps engineer has configured a CloudFormation deploy action before the S3 action. The CloudFormation deploy action creates the S3 bucket. The DevOps engineer needs to configure the S3 deploy action to use the S3 bucket from the CloudFormation template. Which combination of steps will meet these requirements? (Choose two.)</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Add an output named BucketName to the CloudFormation template. Set the output's value to refer to the S3 bucket from the CloudFormation template. Configure the output value to export to an AWS::SSM::Parameter resource named StackVariables.</div>                <div class="option correct-answer"><strong>B.</strong> Add an output named BucketName to the CloudFormation template. Set the output's value to refer to the S3 bucket from the CloudFormation template. Set the CloudFormation action's namespace to StackVariables in the pipeline.</div>                <div class="option"><strong>C.</strong> Configure the output artifacts of the CloudFormation action in the pipeline to be an <span class="key-service">AWS Systems Manager</span> Parameter Store parameter named StackVariables. Name the artifact BucketName.</div>                <div class="option correct-answer"><strong>D.</strong> Configure the build artifact from the build action as the input to the CodePipeline S3 deploy action. Configure the deploy action to deploy to the S3 bucket by using the StackVariables.BucketName variable.</div>                <div class="option"><strong>E.</strong> Configure the build artifact from the build action and the <span class="key-service">AWS Systems Manager</span> parameter as the inputs to the deploy action. Configure the deploy action to deploy to the S3 bucket by using the StackVariables.BucketName variable.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一个DevOps工程师使用AWS CodePipeline中的管道。该管道有一个构建操作和一个部署操作，用于将单页Web应用程序交付到Amazon S3存储桶。Amazon CloudFront为Web应用程序提供服务。构建操作为Web应用程序创建工件。DevOps工程师创建了一个AWS CloudFormation模板，该模板定义S3存储桶并配置S3存储桶来托管应用程序。DevOps工程师在S3操作之前配置了CloudFormation部署操作。CloudFormation部署操作创建S3存储桶。DevOps工程师需要配置S3部署操作以使用CloudFormation模板中的S3存储桶。哪种步骤组合将满足这些要求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 向CloudFormation模板添加名为BucketName的输出。将输出值设置为引用CloudFormation模板中的S3存储桶。配置输出值导出到名为StackVariables的AWS::SSM::Parameter资源。</div> <div class="option-analysis"><strong>B.</strong> 向CloudFormation模板添加名为BucketName的输出。将输出值设置为引用CloudFormation模板中的S3存储桶。在管道中将CloudFormation操作的命名空间设置为StackVariables。</div> <div class="option-analysis"><strong>C.</strong> 在管道中将CloudFormation操作的输出工件配置为名为StackVariables的AWS Systems Manager Parameter Store参数。将工件命名为BucketName。</div> <div class="option-analysis"><strong>D.</strong> 将构建操作的构建工件配置为CodePipeline S3部署操作的输入。配置部署操作使用StackVariables.BucketName变量部署到S3存储桶。</div> <div class="option-analysis"><strong>E.</strong> 将构建操作的构建工件和AWS Systems Manager参数配置为部署操作的输入。配置部署操作使用StackVariables.BucketName变量部署到S3存储桶。<div class="section-title"><strong>核心要求:</strong></div> 在CodePipeline中实现CloudFormation创建的S3存储桶名称传递给后续S3部署操作 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• <span class="key-service">AWS CodePipeline</span> - 编排CI/CD流程，支持操作间变量传递 </div><div class="compact-content">• <span class="key-service">AWS CloudFormation</span> - 基础设施即代码，通过输出和命名空间传递资源信息 </div><div class="compact-content">• <span class="key-service">Amazon S3</span> - 静态网站托管，需要动态获取存储桶名称 <div class="section-title"><strong>正确答案BD:</strong></div> B选项通过CloudFormation输出和命名空间机制暴露存储桶名称，D选项在S3部署操作中使用命名空间变量引用存储桶，实现了标准的CodePipeline变量传递模式 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A - 不需要导出到SSM Parameter，CodePipeline有内置的变量传递机制 </div><div class="compact-content">• 选项C - 混淆了输出工件和变量概念，CloudFormation输出不是Parameter Store参数 </div><div class="compact-content">• 选项E - 不需要SSM参数作为输入，CloudFormation命名空间变量已足够 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能 - 使用CodePipeline内置变量传递，无额外API调用开销 </div><div class="compact-content">• 成本 - 避免不必要的SSM Parameter Store使用，降低运营成本 </div><div class="compact-content">• 可扩展性 - 标准化的CloudFormation输出模式，便于模板复用和维护</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: BD (B、D)</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-328">
            <div class="question-header">
                <div class="question-title">Question #328 ✅ ⚪ <small style="float: right;">(328/353)</small></div>
            </div>
            <div class="question-content">A company used a lift and shift strategy to migrate a workload to AWS. The company has an Auto Scaling group of <span class="key-service">Amazon EC2</span> instances. Each EC2 instance runs a web application, a database, and a Redis cache. Users are experiencing large variations in the web application's response times. Requests to the web application go to a single EC2 instance that is under significant load. The company wants to separate the application components to improve availability and performance. Which solution will meet these requirements?</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Create a Network Load Balancer and an Auto Scaling group for the web application. Migrate the database to an Amazon Aurora Serverless database. Create an Application Load Balancer and an Auto Scaling group for the Redis cache.</div>                <div class="option"><strong>B.</strong> Create an Application Load Balancer and an Auto Scaling group for the web application. Migrate the database to an Amazon Aurora database that has a Multi-AZ deployment. Create a Network Load Balancer and an Auto Scaling group in a single Availability Zone for the Redis cache.</div>                <div class="option"><strong>C.</strong> Create a Network Load Balancer and an Auto Scaling group for the web application. Migrate the database to an Amazon Aurora Serverless database. Create an Amazon ElastiCache (Redis OSS) cluster for the cache. Create a target group that has a DNS target type that contains the ElastiCache (Redis OSS) cluster hostname.</div>                <div class="option correct-answer"><strong>D.</strong> Create an Application Load Balancer and an Auto Scaling group for the web application. Migrate the database to an Amazon Aurora database that has a Multi-AZ deployment. Create an Amazon ElastiCache (Redis OSS) cluster for the cache.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司使用lift and shift策略将工作负载迁移到AWS。公司有一个Amazon EC2实例的Auto Scaling组。每个EC2实例运行Web应用程序、数据库和Redis缓存。用户在Web应用程序的响应时间上遇到很大变化。对Web应用程序的请求会发送到承受重大负载的单个EC2实例。公司希望分离应用程序组件以提高可用性和性能。 <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 为Web应用程序创建Network Load Balancer和Auto Scaling组。将数据库迁移到Amazon Aurora Serverless数据库。为Redis缓存创建Application Load Balancer和Auto Scaling组。</div> <div class="option-analysis"><strong>B.</strong> 为Web应用程序创建Application Load Balancer和Auto Scaling组。将数据库迁移到具有Multi-AZ部署的Amazon Aurora数据库。在单个Availability Zone中为Redis缓存创建Network Load Balancer和Auto Scaling组。</div> <div class="option-analysis"><strong>C.</strong> 为Web应用程序创建Network Load Balancer和Auto Scaling组。将数据库迁移到Amazon Aurora Serverless数据库。为缓存创建Amazon ElastiCache (Redis OSS)集群。创建包含ElastiCache (Redis OSS)集群主机名的DNS目标类型的目标组。</div> <div class="option-analysis"><strong>D.</strong> 为Web应用程序创建Application Load Balancer和Auto Scaling组。将数据库迁移到具有Multi-AZ部署的Amazon Aurora数据库。为缓存创建Amazon ElastiCache (Redis OSS)集群。<div class="section-title"><strong>核心要求:</strong></div> 分离单体应用架构，解决负载分布不均和性能问题 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• Application Load Balancer-七层负载均衡，支持HTTP/HTTPS流量分发 </div><div class="compact-content">• Aurora Multi-AZ-托管数据库服务，提供高可用性和自动故障转移 </div><div class="compact-content">• ElastiCache Redis-托管缓存服务，提供高性能内存数据存储 <div class="section-title"><strong>正确答案D:</strong></div> 使用ALB实现Web层负载均衡，Aurora Multi-AZ提供数据库高可用性，ElastiCache替代自建Redis缓存，完整分离三层架构 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A-为Redis缓存使用ALB和Auto Scaling组不合理，缓存应使用托管服务 </div><div class="compact-content">• 选项B-Redis缓存仍使用EC2实例部署，未实现组件分离 </div><div class="compact-content">• 选项C-Web应用使用NLB不适合HTTP流量，目标组配置过于复杂 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-ALB提供更好的HTTP流量分发，ElastiCache提供高性能缓存 </div><div class="compact-content">• 成本-托管服务减少运维成本，Multi-AZ提供成本效益的高可用性 </div><div class="compact-content">• 可扩展性-完全分离的三层架构支持独立扩展各组件</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: D</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-329">
            <div class="question-header">
                <div class="question-title">Question #329 ✅ ⚪ <small style="float: right;">(329/353)</small></div>
            </div>
            <div class="question-content">A company is using <span class="key-service">AWS Organizations</span> and wants to implement a governance strategy with the following requirements: <div class="compact-content">• AWS resource access is restricted to the same two Regions for all accounts. </div><div class="compact-content">• AWS services are limited to a specific group of authorized services for all accounts. </div><div class="compact-content">• Authentication is provided by Active Directory. </div><div class="compact-content">• Access permissions are organized by job function and are identical in each account. Which solution will meet these requirements?</div></div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Establish an organizational unit (OU) with group policies in the management account to restrict Regions and authorized services. Use <span class="key-service">AWS CloudFormation</span> StackSets to provision roles with permissions for each job function, including an IAM trust policy for IAM identity provider authentication in each account.</div>                <div class="option"><strong>B.</strong> Establish a permission boundary in the management account to restrict Regions and authorized services. Use <span class="key-service">AWS CloudFormation</span> StackSets to provision roles with permissions for each job function, including an IAM trust policy for IAM identity provider authentication in each account.</div>                <div class="option"><strong>C.</strong> Establish a service control policy in the management account to restrict Regions and authorized services. Use AWS Resource Access Manager (AWS RAM) to share management account roles with permissions for each job function, including <span class="key-service">AWS IAM</span> Identity Center for authentication in each account.</div>                <div class="option correct-answer"><strong>D.</strong> Establish a service control policy in the management account to restrict Regions and authorized services. Use <span class="key-service">AWS CloudFormation</span> StackSets to provision roles with permissions for each job function, including an IAM trust policy for IAM identity provider authentication in each account.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司正在使用AWS Organizations，希望实施治理策略，要求：所有账户的AWS资源访问限制在相同的两个Region；所有账户的AWS服务限制为特定的授权服务组；通过Active Directory提供身份验证；访问权限按工作职能组织且在每个账户中相同。 <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 在管理账户中建立带有组策略的organizational unit (OU)来限制Region和授权服务，使用AWS CloudFormation StackSets为每个工作职能配置角色权限，包括在每个账户中为IAM identity provider身份验证配置IAM信任策略。</div> <div class="option-analysis"><strong>B.</strong> 在管理账户中建立permission boundary来限制Region和授权服务，使用AWS CloudFormation StackSets为每个工作职能配置角色权限，包括在每个账户中为IAM identity provider身份验证配置IAM信任策略。</div> <div class="option-analysis"><strong>C.</strong> 在管理账户中建立service control policy来限制Region和授权服务，使用AWS Resource Access Manager (AWS RAM)共享管理账户角色的工作职能权限，包括在每个账户中使用AWS IAM Identity Center进行身份验证。</div> <div class="option-analysis"><strong>D.</strong> 在管理账户中建立service control policy来限制Region和授权服务，使用AWS CloudFormation StackSets为每个工作职能配置角色权限，包括在每个账户中为IAM identity provider身份验证配置IAM信任策略。<div class="section-title"><strong>核心要求:</strong></div> 跨多账户实施统一的Region限制、服务限制和基于Active Directory的身份验证治理策略 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• Service Control Policy (<span class="key-service">SCP</span>) - 在Organizations中限制Region和服务访问的标准机制 </div><div class="compact-content">• <span class="key-service">AWS CloudFormation</span> StackSets - 跨多账户部署相同IAM角色和权限的最佳实践 <div class="section-title"><strong>正确答案D:</strong></div> 使用SCP在组织级别限制Region和服务访问，通过StackSets在所有账户中统一部署基于Active Directory的IAM角色和信任策略 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A - 组策略不是AWS Organizations中限制资源访问的正确机制，应使用SCP </div><div class="compact-content">• 选项B - Permission boundary用于限制单个用户/角色权限，无法在组织级别限制Region和服务 </div><div class="compact-content">• 选项C - AWS RAM无法共享IAM角色，且IAM Identity Center不适用于现有Active Directory集成场景 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能 - SCP提供组织级别的即时访问控制 </div><div class="compact-content">• 成本 - StackSets避免手动配置多账户的运维成本 </div><div class="compact-content">• 可扩展性 - 解决方案支持新账户自动继承相同治理策略</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: D</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-330">
            <div class="question-header">
                <div class="question-title">Question #330 ✅ ⚪ <small style="float: right;">(330/353)</small></div>
            </div>
            <div class="question-content">A company detects unusual login attempts in many of its AWS accounts. A DevOps engineer must implement a solution that sends a notification to the company's security team when multiple failed login attempts occur. The DevOps engineer has already created an Amazon Simple Notification Service (<span class="key-service">Amazon SNS</span>) topic and has subscribed the security team to the SNS topic. Which solution will provide the notification with the LEAST operational effort?</div>
            <div class="options-container">                <div class="option correct-answer"><strong>A.</strong> Configure <span class="key-service">AWS CloudTrail</span> to send management events to an <span class="key-service">Amazon CloudWatch</span> Logs log group. Create a CloudWatch Logs metric filter to match failed ConsoleLogin events. Create a CloudWatch alarm that is based on the metric filter. Configure an alarm action to send messages to the SNS topic.</div>                <div class="option"><strong>B.</strong> Configure <span class="key-service">AWS CloudTrail</span> to send management events to an <span class="key-service">Amazon S3</span> bucket. Create an Amazon Athena query that returns a failure if the query finds failed logins in the logs in the S3 bucket. Create an Amazon EventBridge rule to periodically run the query. Create a second EventBridge rule to detect when the query fails and to send a message to the SNS topic.</div>                <div class="option"><strong>C.</strong> Configure <span class="key-service">AWS CloudTrail</span> to send data events to an <span class="key-service">Amazon CloudWatch</span> Logs log group. Create a CloudWatch logs metric filter to match failed ConsoleLogin events. Create a CloudWatch alarm that is based on the metric filter. Configure an alarm action to send messages to the SNS topic.</div>                <div class="option"><strong>D.</strong> Configure <span class="key-service">AWS CloudTrail</span> to send data events to an <span class="key-service">Amazon S3</span> bucket. Configure an <span class="key-service">Amazon S3</span> event notification for the s3:ObjectCreated event type. Filter the event type by ConsoleLogin failed events. Configure the event notification to forward to the SNS topic.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司在其多个AWS账户中检测到异常登录尝试。DevOps工程师必须实施一个解决方案，当发生多次登录失败尝试时向公司安全团队发送通知。DevOps工程师已经创建了Amazon SNS主题并让安全团队订阅了该SNS主题。哪个解决方案能以最少的运维工作量提供通知？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 配置AWS CloudTrail将管理事件发送到Amazon CloudWatch Logs日志组，创建CloudWatch Logs指标过滤器匹配失败的ConsoleLogin事件，创建基于指标过滤器的CloudWatch告警，配置告警操作向SNS主题发送消息</div> <div class="option-analysis"><strong>B.</strong> 配置AWS CloudTrail将管理事件发送到Amazon S3存储桶，创建Amazon Athena查询在S3存储桶日志中查找失败登录时返回失败，创建Amazon EventBridge规则定期运行查询，创建第二个EventBridge规则检测查询失败并向SNS主题发送消息</div> <div class="option-analysis"><strong>C.</strong> 配置AWS CloudTrail将数据事件发送到Amazon CloudWatch Logs日志组，创建CloudWatch Logs指标过滤器匹配失败的ConsoleLogin事件，创建基于指标过滤器的CloudWatch告警，配置告警操作向SNS主题发送消息</div> <div class="option-analysis"><strong>D.</strong> 配置AWS CloudTrail将数据事件发送到Amazon S3存储桶，为s3:ObjectCreated事件类型配置Amazon S3事件通知，通过ConsoleLogin失败事件过滤事件类型，配置事件通知转发到SNS主题<div class="section-title"><strong>核心要求:</strong></div> 检测多次登录失败并自动通知安全团队，要求最少运维工作量 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• <span class="key-service">AWS CloudTrail</span>-记录AWS账户活动和API调用 </div><div class="compact-content">• <span class="key-service">Amazon CloudWatch</span>-监控和告警服务 </div><div class="compact-content">• <span class="key-service">Amazon SNS</span>-消息通知服务 <div class="section-title"><strong>正确答案A:</strong></div> CloudTrail管理事件包含登录活动，通过CloudWatch Logs指标过滤器和告警实现自动化监控通知，架构简单运维工作量最少 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项B-使用Athena查询和多个EventBridge规则增加复杂性和运维开销 </div><div class="compact-content">• 选项C-登录事件属于管理事件而非数据事件，事件类型配置错误 </div><div class="compact-content">• 选项D-S3事件通知无法直接过滤CloudTrail日志中的特定登录失败事件 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-CloudWatch实时监控响应速度快 </div><div class="compact-content">• 成本-原生集成服务成本最低 </div><div class="compact-content">• 可扩展性-CloudWatch告警自动扩展无需额外配置</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: A</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-331">
            <div class="question-header">
                <div class="question-title">Question #331 ✅ ⚪ <small style="float: right;">(331/353)</small></div>
            </div>
            <div class="question-content">A company has deployed a new REST API by using <span class="key-service">Amazon API Gateway</span>. The company uses the API to access confidential data. The API must be accessed from only specific VPCs in the company. Which solution will meet these requirements?</div>
            <div class="options-container">                <div class="option correct-answer"><strong>A.</strong> Create and attach a resource policy to the API Gateway API. Configure the resource policy to allow only the specific <span class="key-service">VPC</span> IDs.</div>                <div class="option"><strong>B.</strong> Add a security group to the API Gateway API. Configure the inbound rules to allow only the specific <span class="key-service">VPC</span> IP address ranges.</div>                <div class="option"><strong>C.</strong> Create and attach an IAM role to the API Gateway API. Configure the IAM role to allow only the specific <span class="key-service">VPC</span> IDs.</div>                <div class="option"><strong>D.</strong> Add an ACL to the API Gateway API. Configure the outbound rules to allow only the specific <span class="key-service">VPC</span> IP address ranges.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司使用Amazon API Gateway部署了新的REST API。公司使用该API访问机密数据。API必须仅能从公司的特定VPC中访问。哪种解决方案能满足这些要求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 为API Gateway API创建并附加资源策略。配置资源策略仅允许特定的VPC ID。</div> <div class="option-analysis"><strong>B.</strong> 为API Gateway API添加安全组。配置入站规则仅允许特定的VPC IP地址范围。</div> <div class="option-analysis"><strong>C.</strong> 为API Gateway API创建并附加IAM角色。配置IAM角色仅允许特定的VPC ID。</div> <div class="option-analysis"><strong>D.</strong> 为API Gateway API添加ACL。配置出站规则仅允许特定的VPC IP地址范围。<div class="section-title"><strong>核心要求:</strong></div> 限制API Gateway仅能从特定VPC访问以保护机密数据 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• API Gateway - 托管REST API服务，支持资源策略进行访问控制 </div><div class="compact-content">• <span class="key-service">VPC</span> - 虚拟私有云，提供网络隔离 <div class="section-title"><strong>正确答案A:</strong></div> API Gateway资源策略可以基于VPC ID或VPC端点进行访问控制，通过aws:sourceVpc条件键限制特定VPC的访问权限 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项B - API Gateway不支持直接附加安全组，安全组用于EC2实例级别的网络控制 </div><div class="compact-content">• 选项C - IAM角色用于身份验证和授权，无法基于网络位置(<span class="key-service">VPC</span>)进行访问控制 </div><div class="compact-content">• 选项D - API Gateway不使用传统的网络ACL，且出站规则不适用于API访问控制场景 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能 - 资源策略在API Gateway层面直接过滤请求，响应快速 </div><div class="compact-content">• 成本 - 无额外费用，使用API Gateway内置功能 </div><div class="compact-content">• 可扩展性 - 支持多VPC配置，易于管理和扩展访问控制规则</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: A</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-332">
            <div class="question-header">
                <div class="question-title">Question #332 ✅ ⚪ <small style="float: right;">(332/353)</small></div>
            </div>
            <div class="question-content">A company runs a website by using an Amazon Elastic Container Service (<span class="key-service">Amazon ECS</span>) service that is connected to an Application Load Balancer (ALB). The service was in a steady state with tasks responding to requests successfully. A DevOps engineer updated the task definition with a new container image and deployed the new task definition to the service. The DevOps engineer noticed that the service is frequently stopping and starting new tasks because the ALB health checks are failing. What should the DevOps engineer do to troubleshoot the failed deployment? B (100%) Unlock free, top-quality video courses on ExamTopics with a simple registration. Elevate your learning journey with our expertly curated content. Register now to access a diverse range of educational resources designed for success with ExamTopics!</div>
            <div class="options-container">                <div class="option correct-answer"><strong>A.</strong> Ensure that a security group associated with the service allows traffic from the ALB.</div>                <div class="option"><strong>B.</strong> Increase the ALB health check grace period for the service.</div>                <div class="option"><strong>C.</strong> Increase the service minimum healthy percent setting.</div>                <div class="option"><strong>D.</strong> Decrease the ALB health check interval.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司使用连接到Application Load Balancer (ALB)的Amazon Elastic Container Service (<span class="key-service">Amazon ECS</span>)服务运行网站。服务处于稳定状态，任务成功响应请求。DevOps工程师用新容器镜像更新了任务定义并部署到服务。工程师注意到由于ALB健康检查失败，服务频繁停止和启动新任务。DevOps工程师应该如何排查失败的部署？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 确保与服务关联的安全组允许来自ALB的流量</div> <div class="option-analysis"><strong>B.</strong> 增加服务的ALB健康检查宽限期</div> <div class="option-analysis"><strong>C.</strong> 增加服务的最小健康百分比设置</div> <div class="option-analysis"><strong>D.</strong> 减少ALB健康检查间隔<div class="section-title"><strong>核心要求:</strong></div> 解决ECS服务部署后ALB健康检查失败导致任务频繁重启的问题 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• <span class="key-service">Amazon ECS</span> - 容器编排服务，运行应用任务 </div><div class="compact-content">• Application Load Balancer - 负载均衡器，执行健康检查 <div class="section-title"><strong>正确答案A:</strong></div> 新容器镜像可能改变了网络配置或端口设置，导致安全组规则不再允许ALB访问ECS任务，这是健康检查失败的最常见原因 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项B - 宽限期只是延迟检查时间，不解决根本的连通性问题 </div><div class="compact-content">• 选项C - 最小健康百分比影响部署策略，不解决健康检查失败问题 </div><div class="compact-content">• 选项D - 减少检查间隔会加剧问题，使任务重启更频繁 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能 - 确保ALB能正常访问后端任务进行健康检查 </div><div class="compact-content">• 成本 - 避免因连通性问题导致的资源浪费和频繁重启 </div><div class="compact-content">• 可扩展性 - 正确的安全组配置是服务稳定运行的基础</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: A</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-333">
            <div class="question-header">
                <div class="question-title">Question #333 ✅ ⚪ <small style="float: right;">(333/353)</small></div>
            </div>
            <div class="question-content">A company that uses electronic patient health records runs a fleet of <span class="key-service">Amazon EC2</span> instances with an Amazon Linux operating system. The company must continuously ensure that the EC2 instances are running operating system patches and application patches that are in compliance with current privacy regulations. The company uses a custom repository to store application patches. A DevOps engineer needs to automate the deployment of operating system patches and application patches. The DevOps engineer wants to use both the default operating system patch repository and the custom patch repository. Which solution will meet these requirements with the LEAST effort?</div>
            <div class="options-container">                <div class="option correct-answer"><strong>A.</strong> Use <span class="key-service">AWS Systems Manager</span> to create a new custom patch baseline that includes the default operating system repository and the custom repository. Run the AWS-RunPatchBaseline document by using the Run command to verify and install patches. Use the BaselineOverride API to configure the new custom patch baseline.</div>                <div class="option"><strong>B.</strong> Use AWS Direct Connect to integrate the custom repository with the EC2 instances. Use Amazon EventBridge events to deploy the patches.</div>                <div class="option"><strong>C.</strong> Use the yum-config-manager command to add the custom repository to the /etc/yum.repos.d configuration. Run the yum-config-manager-enable command to activate the new repository.</div>                <div class="option"><strong>D.</strong> Use <span class="key-service">AWS Systems Manager</span> to create a patch baseline for the default operating system repository and a second patch baseline for the custom repository. Run the AWS-RunPatchBaseline document by using the Run command to verify and install patches. Use the BaselineOverride API to configure the default patch baseline and the custom patch baseline.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家使用电子患者健康记录的公司运行着一组Amazon EC2实例，使用Amazon Linux操作系统。公司必须持续确保EC2实例运行的操作系统补丁和应用程序补丁符合当前隐私法规要求。公司使用自定义存储库来存储应用程序补丁。DevOps工程师需要自动化部署操作系统补丁和应用程序补丁，希望同时使用默认操作系统补丁存储库和自定义补丁存储库。 <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 使用AWS Systems Manager创建一个新的自定义patch baseline，包含默认操作系统存储库和自定义存储库，通过Run command运行AWS-RunPatchBaseline文档来验证和安装补丁，使用BaselineOverride API配置新的自定义patch baseline</div> <div class="option-analysis"><strong>B.</strong> 使用AWS Direct Connect将自定义存储库与EC2实例集成，使用Amazon EventBridge事件来部署补丁</div> <div class="option-analysis"><strong>C.</strong> 使用yum-config-manager命令将自定义存储库添加到/etc/yum.repos.d配置中，运行yum-config-manager-enable命令激活新存储库</div> <div class="option-analysis"><strong>D.</strong> 使用AWS Systems Manager为默认操作系统存储库创建一个patch baseline，为自定义存储库创建第二个patch baseline，通过Run command运行AWS-RunPatchBaseline文档来验证和安装补丁，使用BaselineOverride API配置默认和自定义patch baseline<div class="section-title"><strong>核心要求:</strong></div> 自动化部署操作系统和应用程序补丁，同时使用默认和自定义存储库 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• <span class="key-service">AWS Systems Manager</span> - 提供补丁管理和自动化运维能力 </div><div class="compact-content">• Patch Manager - 管理补丁基线和补丁部署流程 <div class="section-title"><strong>正确答案A:</strong></div> 创建单一自定义patch baseline整合两个存储库，通过Systems Manager统一管理补丁部署，实现最少工作量的自动化解决方案 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项B - Direct Connect用于网络连接而非补丁管理，EventBridge无法直接处理补丁部署 </div><div class="compact-content">• 选项C - 手动配置yum存储库无法实现自动化要求，缺乏集中管理能力 </div><div class="compact-content">• 选项D - 创建两个独立patch baseline增加管理复杂度，不符合最少工作量要求 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能 - 统一patch baseline减少管理开销 </div><div class="compact-content">• 成本 - 使用托管服务降低运维成本 </div><div class="compact-content">• 可扩展性 - Systems Manager支持大规模EC2实例补丁管理</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: A</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-334">
            <div class="question-header">
                <div class="question-title">Question #334 ✅ 📝 <small style="float: right;">(334/353)</small></div>
            </div>
            <div class="question-content">A company uses an organization in <span class="key-service">AWS Organizations</span> to manage multiple AWS accounts. The company has enabled all features for the organization. The company configured the organization as a hierarchy of OUs under the root OU. The company recently registered all its OUs and enrolled all its AWS accounts in AWS Control Tower. The company needs to customize the AWS Control Tower managed <span class="key-service">AWS Config</span> configuration recorder in each of the company's AWS accounts. The company needs to apply the customizations to both the existing AWS accounts and to any new AWS accounts that the company enrolls in AWS Control Tower in the future. Which combination of steps will meet these requirements? (Choose three.)</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Create a new AWS account. Create an <span class="key-service">AWS Lambda</span> function in the new account to apply the customizations to the <span class="key-service">AWS Config</span> configuration recorder in each AWS account in the organization.</div>                <div class="option"><strong>B.</strong> Create a new AWS account as an <span class="key-service">AWS Config</span> delegated administrator. Create an <span class="key-service">AWS Lambda</span> function in the delegated administrator account to apply the customizations to the <span class="key-service">AWS Config</span> configuration recorder in the delegated administrator account.</div>                <div class="option correct-answer"><strong>C.</strong> Configure an Amazon EventBridge rule in the AWS Control Tower management account to invoke an <span class="key-service">AWS Lambda</span> function when the Organizations OU is registered or reregistered. Re-register the root Organizations OU.</div>                <div class="option correct-answer"><strong>D.</strong> Configure the AWSControlTowerExecution IAM role in each AWS account in the organization to be assumable by an <span class="key-service">AWS Lambda</span> function. Configure the Lambda function to assume the AWSControlTowerExecution IAM role.</div>                <div class="option correct-answer"><strong>E.</strong> Create an IAM role in the AWS Control Tower management account that an <span class="key-service">AWS Lambda</span> function can assume. Grant the IAM role permission to assume the AWSControlTowerExecution IAM role in any account in the organization. Configure the Lambda function to use the new IAM role. F. Configure an Amazon EventBridge rule in the AWS Control Tower management account to invoke an <span class="key-service">AWS Lambda</span> function when an AWS account is updated or enrolled in AWS Control Tower or when the landing zone is updated. Re-register each Organizations OU in the organization.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司使用AWS Organizations中的组织来管理多个AWS账户。公司已为组织启用所有功能，并将组织配置为根OU下的OU层次结构。公司最近注册了所有OU并将所有AWS账户注册到AWS Control Tower中。公司需要自定义每个AWS账户中的AWS Control Tower托管的AWS Config配置记录器，并需要将自定义应用于现有AWS账户和未来注册到AWS Control Tower的新账户。 <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 创建新的AWS账户，在新账户中创建AWS Lambda函数，将自定义应用于组织中每个AWS账户的AWS Config配置记录器</div> <div class="option-analysis"><strong>B.</strong> 创建新的AWS账户作为AWS Config委托管理员，在委托管理员账户中创建AWS Lambda函数，将自定义应用于委托管理员账户的AWS Config配置记录器</div> <div class="option-analysis"><strong>C.</strong> 在AWS Control Tower管理账户中配置Amazon EventBridge规则，当Organizations OU注册或重新注册时调用AWS Lambda函数，重新注册根Organizations OU</div> <div class="option-analysis"><strong>D.</strong> 配置组织中每个AWS账户的AWSControlTowerExecution IAM角色可被AWS Lambda函数承担，配置Lambda函数承担AWSControlTowerExecution IAM角色</div> <div class="option-analysis"><strong>E.</strong> 在AWS Control Tower管理账户中创建AWS Lambda函数可承担的IAM角色，授予该IAM角色权限以承担组织中任何账户的AWSControlTowerExecution IAM角色，配置Lambda函数使用新IAM角色 F. 在AWS Control Tower管理账户中配置Amazon EventBridge规则，当AWS账户更新或注册到AWS Control Tower或landing zone更新时调用AWS Lambda函数，重新注册组织中的每个Organizations OU<div class="section-title"><strong>核心要求:</strong></div> 自定义AWS Control Tower托管的AWS Config配置记录器并应用于现有和未来账户 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• AWS Control Tower-提供多账户治理和自动化 </div><div class="compact-content">• <span class="key-service">AWS Config</span>-配置管理和合规监控 </div><div class="compact-content">• EventBridge-事件驱动的自动化触发 </div><div class="compact-content">• Lambda-执行自定义配置逻辑 <div class="section-title"><strong>正确答案CDE:</strong></div> 通过EventBridge监听OU注册事件触发Lambda函数，使用跨账户IAM角色链实现权限传递，Lambda承担管理账户角色再承担目标账户的AWSControlTowerExecution角色来修改Config配置 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A-创建独立账户增加复杂性且无法有效管理跨账户权限 </div><div class="compact-content">• 选项B-仅针对委托管理员账户而非所有组织账户 </div><div class="compact-content">• 选项F-事件触发范围过于宽泛且重新注册所有OU操作过重 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-EventBridge事件驱动确保及时响应账户变更 </div><div class="compact-content">• 成本-利用现有Control Tower管理账户避免额外账户成本 </div><div class="compact-content">• 可扩展性-IAM角色链和事件驱动架构自动处理新账户注册</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: CDE (C、D、E)</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-335">
            <div class="question-header">
                <div class="question-title">Question #335 ✅ ⚪ <small style="float: right;">(335/353)</small></div>
            </div>
            <div class="question-content">A company runs an application in an Auto Scaling group of <span class="key-service">Amazon EC2</span> instances behind an Application Load Balancer (ALB). The EC2 instances run Docker containers that make requests to a MySQL database that runs on separate EC2 instances. A DevOps engineer needs to update the application to use a serverless architecture. Which solution will meet this requirement with the FEWEST changes?</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Replace the containers that run on EC2 instances and the ALB with <span class="key-service">AWS Lambda</span> functions. Replace the MySQL database with an Amazon Aurora Serverless v2 database that is compatible with MySQL.</div>                <div class="option correct-answer"><strong>B.</strong> Replace the containers that run on EC2 instances with <span class="key-service">AWS Fargate</span>. Replace the MySQL database with an Amazon Aurora Serverless v2 database that is compatible with MySQL.</div>                <div class="option"><strong>C.</strong> Replace the containers that run on EC2 instances and the ALB with <span class="key-service">AWS Lambda</span> functions. Replace the MySQL database with <span class="key-service">Amazon DynamoDB</span> tables.</div>                <div class="option"><strong>D.</strong> Replace the containers that run on EC2 instances with <span class="key-service">AWS Fargate</span>. Replace the MySQL database with <span class="key-service">Amazon DynamoDB</span> tables.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司在Application Load Balancer (ALB)后面的Amazon EC2实例Auto Scaling组中运行应用程序。EC2实例运行Docker容器，这些容器向运行在独立EC2实例上的MySQL数据库发出请求。DevOps工程师需要更新应用程序以使用serverless架构。哪个解决方案能以最少的更改满足此要求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 将运行在EC2实例上的容器和ALB替换为AWS Lambda函数。将MySQL数据库替换为与MySQL兼容的Amazon Aurora Serverless v2数据库。</div> <div class="option-analysis"><strong>B.</strong> 将运行在EC2实例上的容器替换为AWS Fargate。将MySQL数据库替换为与MySQL兼容的Amazon Aurora Serverless v2数据库。</div> <div class="option-analysis"><strong>C.</strong> 将运行在EC2实例上的容器和ALB替换为AWS Lambda函数。将MySQL数据库替换为Amazon DynamoDB表。</div> <div class="option-analysis"><strong>D.</strong> 将运行在EC2实例上的容器替换为AWS Fargate。将MySQL数据库替换为Amazon DynamoDB表。<div class="section-title"><strong>核心要求:</strong></div> 以最少更改将现有容器化应用迁移到serverless架构 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• <span class="key-service">AWS Fargate</span>-容器的serverless计算服务，无需管理底层EC2实例 </div><div class="compact-content">• Amazon Aurora Serverless v2-MySQL兼容的serverless数据库，自动扩缩容 <div class="section-title"><strong>正确答案B:</strong></div> Fargate保持容器架构不变只需移除EC2管理，Aurora Serverless v2保持MySQL兼容性无需修改应用代码 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A-Lambda需要重写容器化应用为函数代码，改动较大 </div><div class="compact-content">• 选项C-Lambda和DynamoDB都需要重写应用逻辑和数据访问层 </div><div class="compact-content">• 选项D-DynamoDB需要修改SQL查询为NoSQL操作，改动较大 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-Fargate支持长时间运行容器，Aurora Serverless v2提供一致的MySQL性能 </div><div class="compact-content">• 成本-按实际使用付费，无需预置容量管理 </div><div class="compact-content">• 可扩展性-两服务都支持自动扩缩容，满足serverless要求</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: B</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-336">
            <div class="question-header">
                <div class="question-title">Question #336 ✅ ⚪ <small style="float: right;">(336/353)</small></div>
            </div>
            <div class="question-content">A company uses an organization in <span class="key-service">AWS Organizations</span> to manage 10 AWS accounts. All features are enabled, and trusted access for <span class="key-service">AWS CloudFormation</span> is enabled. A DevOps engineer needs to use CloudFormation to deploy an IAM role to the Organizations management account and all member accounts in the organization. Which solution will meet these requirements with the LEAST operational overhead?</div>
            <div class="options-container">                <div class="option correct-answer"><strong>A.</strong> Create a CloudFormation StackSet that has service-managed permissions. Set the root OU as a deployment target.</div>                <div class="option"><strong>B.</strong> Create a CloudFormation StackSet that has service-managed permissions. Set the root OU as a deployment target. Deploy a separate CloudFormation stack in the Organizations management account.</div>                <div class="option"><strong>C.</strong> Create a CloudFormation StackSet that has self-managed permissions. Set the root OU as a deployment target.</div>                <div class="option"><strong>D.</strong> Create a CloudFormation StackSet that has self-managed permissions. Set the root OU as a deployment target. Deploy a separate CloudFormation stack in the Organizations management account.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司使用AWS Organizations中的组织来管理10个AWS账户。所有功能都已启用，并且已启用AWS CloudFormation的可信访问。DevOps工程师需要使用CloudFormation将IAM角色部署到Organizations管理账户和组织中的所有成员账户。哪种解决方案能以最少的运营开销满足这些要求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 创建具有服务管理权限的CloudFormation StackSet，将根OU设置为部署目标。</div> <div class="option-analysis"><strong>B.</strong> 创建具有服务管理权限的CloudFormation StackSet，将根OU设置为部署目标，在Organizations管理账户中部署单独的CloudFormation堆栈。</div> <div class="option-analysis"><strong>C.</strong> 创建具有自管理权限的CloudFormation StackSet，将根OU设置为部署目标。</div> <div class="option-analysis"><strong>D.</strong> 创建具有自管理权限的CloudFormation StackSet，将根OU设置为部署目标，在Organizations管理账户中部署单独的CloudFormation堆栈。<div class="section-title"><strong>核心要求:</strong></div> 使用CloudFormation将IAM角色部署到管理账户和所有成员账户，运营开销最小 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• CloudFormation StackSet-跨多个账户和区域部署资源的服务 </div><div class="compact-content">• <span class="key-service">AWS Organizations</span>-集中管理多个AWS账户的服务 <div class="section-title"><strong>正确答案A:</strong></div> 服务管理权限的StackSet可以自动使用Organizations的可信关系，无需手动配置权限，且根OU包含管理账户和所有成员账户，一次部署即可覆盖所有目标 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项B-不需要单独的堆栈，StackSet部署到根OU已包含管理账户 </div><div class="compact-content">• 选项C-自管理权限需要手动配置跨账户角色，增加运营开销 </div><div class="compact-content">• 选项D-既有自管理权限的复杂性，又有不必要的单独堆栈部署 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-服务管理权限利用现有可信关系，部署更快 </div><div class="compact-content">• 成本-减少手动配置和维护工作 </div><div class="compact-content">• 可扩展性-根OU覆盖所有账户，自动包含未来新增账户</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: A</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-337">
            <div class="question-header">
                <div class="question-title">Question #337 ✅ 📝 <small style="float: right;">(337/353)</small></div>
            </div>
            <div class="question-content">A company runs an application that stores artifacts in an <span class="key-service">Amazon S3</span> bucket. The application has a large user base. The application writes a high volume of objects to the S3 bucket. The company has enabled event notifications for the S3 bucket. When the application writes an object to the S3 bucket, several processing tasks need to be performed simultaneously. The company's DevOps team needs to create an <span class="key-service">AWS Step Functions</span> workflow to orchestrate the processing tasks. Which combination of steps should the DevOps team take to meet these requirements with the LEAST operational overhead? (Choose two.)</div>
            <div class="options-container">                <div class="option correct-answer"><strong>A.</strong> Create a Standard workflow that contains a parallel state that defines the processing tasks. Create an Asynchronous Express workflow that contains a parallel state that defines the processing tasks.</div>                <div class="option"><strong>B.</strong> Create a Synchronous Express workflow that contains a map state that defines the processing tasks.</div>                <div class="option"><strong>C.</strong> Create an Amazon EventBridge rule to match when a new S3 object is created. Configure the EventBridge rule to invoke an <span class="key-service">AWS Lambda</span> function. Configure the Lambda function to start the processing workflow.</div>                <div class="option correct-answer"><strong>D.</strong> Create an Amazon EventBridge rule to match when a new S3 object is created. Configure the EventBridge rule to start the processing workflow.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司运行一个应用程序，将工件存储在Amazon S3存储桶中。该应用程序有大量用户基础，向S3存储桶写入大量对象。公司已为S3存储桶启用事件通知。当应用程序向S3存储桶写入对象时，需要同时执行多个处理任务。公司的DevOps团队需要创建AWS Step Functions工作流来编排处理任务。DevOps团队应采取哪种步骤组合以最少的运营开销满足这些要求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 创建包含定义处理任务的并行状态的Standard工作流。创建包含定义处理任务的并行状态的Asynchronous Express工作流。</div> <div class="option-analysis"><strong>B.</strong> 创建包含定义处理任务的映射状态的Synchronous Express工作流。</div> <div class="option-analysis"><strong>C.</strong> 创建Amazon EventBridge规则以匹配新S3对象创建时。配置EventBridge规则调用AWS Lambda函数。配置Lambda函数启动处理工作流。</div> <div class="option-analysis"><strong>D.</strong> 创建Amazon EventBridge规则以匹配新S3对象创建时。配置EventBridge规则启动处理工作流。<div class="section-title"><strong>核心要求:</strong></div> 为S3对象创建事件触发多个并行处理任务的Step Functions工作流，最小化运营开销 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• Step Functions - 工作流编排服务，支持Standard和Express工作流类型 </div><div class="compact-content">• EventBridge - 事件驱动架构服务，可直接集成Step Functions </div><div class="compact-content">• S3事件通知 - 对象操作触发事件到EventBridge <div class="section-title"><strong>正确答案AD:</strong></div> A提供Standard工作流的并行状态执行多个处理任务，D通过EventBridge直接触发Step Functions工作流，避免Lambda中间层，实现最少运营开销 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项B - Synchronous Express工作流不适合长时间运行的处理任务，且map状态用于迭代而非并行处理 </div><div class="compact-content">• 选项C - 增加Lambda函数作为中间层增加了复杂性和运营开销，不符合最少开销要求 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能 - Standard工作流支持长时间运行任务，并行状态提供真正的并发执行 </div><div class="compact-content">• 成本 - EventBridge直接集成避免额外Lambda调用成本 </div><div class="compact-content">• 可扩展性 - EventBridge原生支持高吞吐量S3事件处理</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: AD (A、D)</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-338">
            <div class="question-header">
                <div class="question-title">Question #338 ✅ 📝 <small style="float: right;">(338/353)</small></div>
            </div>
            <div class="question-content">A DevOps team supports an application that runs in an Amazon Elastic Container Service (<span class="key-service">Amazon ECS</span>) cluster behind an Application Load Balancer (ALB). Currently, the DevOps team uses <span class="key-service">AWS CodeDeploy</span> to deploy the application by using a blue/green all-at-once strategy. Recently, the DevOps team had to roll back a deployment when a new version of the application dramatically increased response times for requests. The DevOps team needs to use a deployment strategy that will allow the team to monitor a new version of the application before the team shifts all traffic to the new version. If a new version of the application increases response times, the deployment should be rolled back as quickly as possible. Which combination of steps will meet these requirements? (Choose two.)</div>
            <div class="options-container">                <div class="option correct-answer"><strong>A.</strong> Modify the CodeDeploy deployment to use the CodeDeployDefault.ECSCanary10Percent5Minutes configuration.</div>                <div class="option"><strong>B.</strong> Modify the CodeDeploy deployment to use the CodeDeployDefault.ECSLinear10PercentEvery3Minutes configuration.</div>                <div class="option"><strong>C.</strong> Create an <span class="key-service">Amazon CloudWatch</span> alarm to monitor the UnHealthyHostCount metric for the AL<div class="option-analysis"><strong>B.</strong> Set the alarm to activate if the metric is higher than the desired value. Associate the alarm with the CodeDeploy deployment group. Modify the deployment group to roll back when a deployment fails.</div></div>                <div class="option correct-answer"><strong>D.</strong> Create an <span class="key-service">Amazon CloudWatch</span> alarm to monitor the TargetResponseTime metric for the AL<div class="option-analysis"><strong>B.</strong> Set the alarm to activate if the metric is higher than the desired value. Associate the alarm with the CodeDeploy deployment group. Modify the deployment group to roll back when alarm thresholds are met.</div></div>                <div class="option"><strong>E.</strong> Create an <span class="key-service">Amazon CloudWatch</span> alarm to monitor the TargetConnectionErrorCount metric for the AL<div class="option-analysis"><strong>B.</strong> Set the alarm to activate if the metric is higher than the desired value. Associate the alarm with the CodeDeploy deployment group. Modify the deployment group to roll back when alarm thresholds are met.</div></div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一个DevOps团队支持运行在Amazon ECS集群中的应用程序，该集群位于Application Load Balancer (ALB)后面。目前，DevOps团队使用AWS CodeDeploy通过蓝/绿一次性策略部署应用程序。最近，当新版本应用程序显著增加请求响应时间时，DevOps团队不得不回滚部署。DevOps团队需要使用一种部署策略，允许团队在将所有流量切换到新版本之前监控新版本的应用程序。如果新版本应用程序增加响应时间，部署应该尽快回滚。哪种步骤组合将满足这些要求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 修改CodeDeploy部署以使用CodeDeployDefault.ECSCanary10Percent5Minutes配置。</div> <div class="option-analysis"><strong>B.</strong> 修改CodeDeploy部署以使用CodeDeployDefault.ECSLinear10PercentEvery3Minutes配置。</div> <div class="option-analysis"><strong>C.</strong> 创建Amazon CloudWatch告警监控ALB的UnHealthyHostCount指标。设置告警在指标高于期望值时激活。将告警与CodeDeploy部署组关联。修改部署组在部署失败时回滚。</div> <div class="option-analysis"><strong>D.</strong> 创建Amazon CloudWatch告警监控ALB的TargetResponseTime指标。设置告警在指标高于期望值时激活。将告警与CodeDeploy部署组关联。修改部署组在告警阈值满足时回滚。</div> <div class="option-analysis"><strong>E.</strong> 创建Amazon CloudWatch告警监控ALB的TargetConnectionErrorCount指标。设置告警在指标高于期望值时激活。将告警与CodeDeploy部署组关联。修改部署组在告警阈值满足时回滚。<div class="section-title"><strong>核心要求:</strong></div> 需要渐进式部署策略并监控响应时间以实现快速回滚 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• CodeDeploy - 提供ECS蓝/绿部署的Canary和Linear策略 </div><div class="compact-content">• CloudWatch - 监控ALB指标并触发自动回滚机制 <div class="section-title"><strong>正确答案AD:</strong></div> Canary策略允许先部署10%流量进行监控，TargetResponseTime指标直接对应题目中的响应时间问题，可实现基于性能的自动回滚 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项B - Linear策略虽然渐进但无法在监控阶段暂停，不如Canary策略适合监控需求 </div><div class="compact-content">• 选项C - UnHealthyHostCount监控健康检查失败，不能检测响应时间性能问题 </div><div class="compact-content">• 选项E - TargetConnectionErrorCount监控连接错误，与响应时间慢的问题不匹配 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能 - Canary策略提供监控窗口，TargetResponseTime直接监控性能指标 </div><div class="compact-content">• 成本 - 利用现有CodeDeploy和CloudWatch服务，无额外基础设施成本 </div><div class="compact-content">• 可扩展性 - 自动化监控和回滚机制可适用于不同规模的部署场景</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: AD (A、D)</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-339">
            <div class="question-header">
                <div class="question-title">Question #339 ✅ ⚪ <small style="float: right;">(339/353)</small></div>
            </div>
            <div class="question-content">A security team must record the configuration of AWS resources, detect issues, and send notifications for findings. The main workload in the AWS account consists of an <span class="key-service">Amazon EC2</span> Auto Scaling group that scales in and out several times during the day. The team wants to be notified within 2 days if any <span class="key-service">Amazon EC2</span> security group allows traffic on port 22 for 0.0.0.0/0. The team also needs a snapshot of the configuration of the AWS resources to be taken routinely. The security team has already created and subscribed to an Amazon Simple Notification Service (<span class="key-service">Amazon SNS</span>) topic. Which solution meets these requirements?</div>
            <div class="options-container">                <div class="option correct-answer"><strong>A.</strong> Configure <span class="key-service">AWS Config</span> to use periodic recording for the AWS account. Deploy the <span class="key-service">vpc</span>-sg-port-restriction-check <span class="key-service">AWS Config</span> managed rule. Configure <span class="key-service">AWS Config</span> to use the SNS topic as the target for notifications.</div>                <div class="option"><strong>B.</strong> Configure <span class="key-service">AWS Config</span> to use configuration change recording for the AWS account. Deploy the <span class="key-service">vpc</span>-sg-open-only-to-authorized-ports AWS Configure managed rule. Configure <span class="key-service">AWS Config</span> to use the SNS topic as the target for notifications.</div>                <div class="option"><strong>C.</strong> Configure <span class="key-service">AWS Config</span> to use configuration change recording for the AWS account. Deploy the ssh-restricted <span class="key-service">AWS Config</span> managed rule. Configure <span class="key-service">AWS Config</span> to use the SNS topic as the target for notifications.</div>                <div class="option"><strong>D.</strong> Create an <span class="key-service">AWS Lambda</span> function to evaluate security groups and publish a message to the SNS topic. Use an Amazon EventBridge rule to schedule the Lambda function to run once a day.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 安全团队必须记录AWS资源配置、检测问题并发送通知。账户中的主要工作负载包含一个Amazon EC2 Auto Scaling组，每天会多次扩缩容。团队希望在2天内收到通知，如果任何Amazon EC2安全组允许0.0.0.0/0在端口22上的流量。团队还需要定期获取AWS资源配置快照。安全团队已创建并订阅了Amazon SNS主题。 <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 为AWS账户配置AWS Config使用周期性记录，部署vpc-sg-port-restriction-check AWS Config托管规则，配置AWS Config使用SNS主题作为通知目标。</div> <div class="option-analysis"><strong>B.</strong> 为AWS账户配置AWS Config使用配置变更记录，部署vpc-sg-open-only-to-authorized-ports AWS Config托管规则，配置AWS Config使用SNS主题作为通知目标。</div> <div class="option-analysis"><strong>C.</strong> 为AWS账户配置AWS Config使用配置变更记录，部署ssh-restricted AWS Config托管规则，配置AWS Config使用SNS主题作为通知目标。</div> <div class="option-analysis"><strong>D.</strong> 创建AWS Lambda函数评估安全组并发布消息到SNS主题，使用Amazon EventBridge规则调度Lambda函数每天运行一次。<div class="section-title"><strong>核心要求:</strong></div> 需要记录资源配置、检测端口22开放给0.0.0.0/0的安全组并在2天内通知，同时定期获取配置快照。 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• <span class="key-service">AWS Config</span>-提供资源配置记录、合规性检查和通知功能 </div><div class="compact-content">• <span class="key-service">Amazon SNS</span>-发送通知消息 <div class="section-title"><strong>正确答案A:</strong></div> 使用周期性记录模式满足定期快照需求，<span class="key-service">vpc</span>-sg-port-restriction-check规则专门检测安全组端口限制，配合SNS实现及时通知。 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项B-<span class="key-service">vpc</span>-sg-open-only-to-authorized-ports规则不是专门检测端口22的标准托管规则 </div><div class="compact-content">• 选项C-ssh-restricted规则主要检测EC2实例SSH访问而非安全组端口配置 </div><div class="compact-content">• 选项D-自定义Lambda方案复杂度高，缺少配置快照功能且每天运行频率可能无法满足2天内通知要求 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-AWS Config托管规则提供自动化检测和快速响应 </div><div class="compact-content">• 成本-使用托管服务比自定义开发更经济 </div><div class="compact-content">• 可扩展性-Config自动适应Auto Scaling组的动态变化</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: A</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-340">
            <div class="question-header">
                <div class="question-title">Question #340 ✅ ⚪ <small style="float: right;">(340/353)</small></div>
            </div>
            <div class="question-content">A company has proprietary data available by using an Amazon CloudFront distribution. The company needs to ensure that the distribution is accessible by only users from the corporate office that have a known set of IP address ranges. An AWS WAF web ACL is associated with the distribution and has a default action set to Count. Which solution will meet these requirements with the LEAST operational overhead?</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Create a new regex pattern set. Add the regex pattern set to a new rule group. Create a new web ACL that has a default action set to Block. Associate the web ACL with the CloudFront distribution. Add a rule that allows traffic based on the new rule group.</div>                <div class="option"><strong>B.</strong> Create an AWS WAF IP address set that matches the corporate office IP address range. Create a new web ACL that has a default action set to Allow. Associate the web ACL with the CloudFront distribution. Add a rule that allows traffic from the IP address set.</div>                <div class="option"><strong>C.</strong> Create a new regex pattern set. Add the regex pattern set to a new rule group. Set the default action on the existing web ACL to Allow. Add a rule that has priority 0 that allows traffic based on the regex pattern set.</div>                <div class="option correct-answer"><strong>D.</strong> Create a WAF IP address set that matches the corporate office IP address range. Set the default action on the existing web ACL to Block. Add a rule that has priority 0 that allows traffic from the IP address set.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司通过Amazon CloudFront分发拥有专有数据。公司需要确保该分发仅可被来自企业办公室的已知IP地址范围的用户访问。AWS WAF web ACL已关联到该分发并设置默认操作为Count。哪个解决方案能以最少的运营开销满足这些要求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 创建新的正则表达式模式集，将其添加到新规则组，创建默认操作为Block的新web ACL，将web ACL关联到CloudFront分发，添加基于新规则组允许流量的规则</div> <div class="option-analysis"><strong>B.</strong> 创建匹配企业办公室IP地址范围的AWS WAF IP地址集，创建默认操作为Allow的新web ACL，将web ACL关联到CloudFront分发，添加允许来自IP地址集流量的规则</div> <div class="option-analysis"><strong>C.</strong> 创建新的正则表达式模式集，将其添加到新规则组，将现有web ACL的默认操作设置为Allow，添加优先级0的规则允许基于正则表达式模式集的流量</div> <div class="option-analysis"><strong>D.</strong> 创建匹配企业办公室IP地址范围的WAF IP地址集，将现有web ACL的默认操作设置为Block，添加优先级0的规则允许来自IP地址集的流量<div class="section-title"><strong>核心要求:</strong></div> 限制CloudFront分发仅允许特定IP范围访问，最小化运营开销 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• AWS WAF - 提供web应用防火墙功能，控制访问规则 </div><div class="compact-content">• CloudFront - 内容分发网络，需要访问控制保护 <div class="section-title"><strong>正确答案D:</strong></div> 利用现有web ACL，创建IP地址集匹配企业IP范围，设置默认拒绝，添加高优先级允许规则，运营开销最小 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A - 使用正则表达式处理IP地址过于复杂，且需创建新web ACL增加开销 </div><div class="compact-content">• 选项B - 默认Allow策略存在安全风险，且创建新web ACL增加运营复杂度 </div><div class="compact-content">• 选项C - 使用正则表达式处理IP地址不合适，默认Allow存在安全隐患 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能 - IP地址集匹配比正则表达式更高效 </div><div class="compact-content">• 成本 - 复用现有web ACL避免额外资源创建 </div><div class="compact-content">• 可扩展性 - IP地址集易于维护和更新企业IP范围</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: D</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-341">
            <div class="question-header">
                <div class="question-title">Question #341 ✅ ⚪ <small style="float: right;">(341/353)</small></div>
            </div>
            <div class="question-content">A company runs several applications in the same AWS account. The applications send logs to <span class="key-service">Amazon CloudWatch</span>. A data analytics team needs to collect performance metrics and custom metrics from the applications. The analytics team needs to transform the metrics data before storing the data in an <span class="key-service">Amazon S3</span> bucket. The analytics team must automatically collect any new metrics that are added to the CloudWatch namespace. Which solution will meet these requirements with the LEAST operational overhead?</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Configure a CloudWatch metric stream to include metrics from the application and the CloudWatch namespace. Configure the metric stream to deliver the metrics to an Amazon Data Firehose delivery stream. Configure the Firehose delivery stream to invoke an <span class="key-service">AWS Lambda</span> function to transform the data. Configure the delivery stream to send the transformed data to the S3 bucket.</div>                <div class="option correct-answer"><strong>B.</strong> Configure a CloudWatch metrics stream to include all the metrics and to deliver the metrics to an Amazon Data Firehose delivery stream. Configure the Firehose delivery stream to invoke an <span class="key-service">AWS Lambda</span> function to transform the data. Configure the delivery stream to send the transformed data to the S3 bucket.</div>                <div class="option"><strong>C.</strong> Configure metric filters for the CloudWatch logs to create custom metrics. Configure a CloudWatch metric stream to deliver the application metrics to the S3 bucket.</div>                <div class="option"><strong>D.</strong> Configure subscription filters on the application log groups to target an Amazon Data Firehose delivery stream. Configure the Firehose delivery stream to invoke an <span class="key-service">AWS Lambda</span> function to transform the data. Configure the delivery stream to send the transformed data to the S3 bucket.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司在同一个AWS账户中运行多个应用程序，应用程序将日志发送到Amazon CloudWatch。数据分析团队需要收集应用程序的性能指标和自定义指标，在将数据存储到Amazon S3存储桶之前需要转换指标数据，并且必须自动收集添加到CloudWatch命名空间的任何新指标。 <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 配置CloudWatch metric stream包含来自应用程序和CloudWatch命名空间的指标，配置metric stream将指标传递到Amazon Data Firehose delivery stream，配置Firehose delivery stream调用AWS Lambda函数转换数据，配置delivery stream将转换后的数据发送到S3存储桶。</div> <div class="option-analysis"><strong>B.</strong> 配置CloudWatch metrics stream包含所有指标并将指标传递到Amazon Data Firehose delivery stream，配置Firehose delivery stream调用AWS Lambda函数转换数据，配置delivery stream将转换后的数据发送到S3存储桶。</div> <div class="option-analysis"><strong>C.</strong> 为CloudWatch日志配置metric filters以创建自定义指标，配置CloudWatch metric stream将应用程序指标传递到S3存储桶。</div> <div class="option-analysis"><strong>D.</strong> 在应用程序日志组上配置subscription filters以目标Amazon Data Firehose delivery stream，配置Firehose delivery stream调用AWS Lambda函数转换数据，配置delivery stream将转换后的数据发送到S3存储桶。<div class="section-title"><strong>核心要求:</strong></div> 自动收集所有现有和新增的CloudWatch指标，进行数据转换后存储到S3，最小运维开销 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• CloudWatch Metric Stream-实时流式传输指标数据到目标服务 </div><div class="compact-content">• Amazon Data Firehose-数据传输服务，支持数据转换和批量传输到S3 </div><div class="compact-content">• <span class="key-service">AWS Lambda</span>-无服务器计算服务，用于数据转换处理 <div class="section-title"><strong>正确答案B:</strong></div> 使用CloudWatch Metric Stream包含所有指标，通过Data Firehose进行Lambda转换后存储到S3，自动覆盖所有现有和新增指标 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A-仅包含特定应用程序和命名空间的指标，无法自动收集所有新增指标 </div><div class="compact-content">• 选项C-需要手动配置metric filters，无法直接通过metric stream转换数据到S3 </div><div class="compact-content">• 选项D-基于日志而非指标，无法直接获取CloudWatch性能指标和自定义指标 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-Metric Stream提供实时指标流式传输，Firehose支持批量高效传输 </div><div class="compact-content">• 成本-无服务器架构按使用量付费，避免持续运行资源成本 </div><div class="compact-content">• 可扩展性-自动包含所有指标，无需手动配置新增指标的收集规则</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: B</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-342">
            <div class="question-header">
                <div class="question-title">Question #342 ✅ ⚪ <small style="float: right;">(342/353)</small></div>
            </div>
            <div class="question-content">A company uses an HPC platform to run analysis jobs for data. The company uses <span class="key-service">AWS CodeBuild</span> to create container images and store the images on Amazon Elastic Container Registry (<span class="key-service">Amazon ECR</span>). The images are then deployed on Amazon Elastic Kubernetes Service (<span class="key-service">Amazon EKS</span>). To maintain compliance, the company needs to ensure that the images are signed before the images are deployed on <span class="key-service">Amazon EKS</span>. The signing keys must be rotated periodically and must be managed automatically. The company needs to track who generates the signatures. Which solution will meet these requirements with the LEAST operational effort?</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Use CodeBuild to retrieve the image that was previously pushed to <span class="key-service">Amazon ECR</span>. Use AWS Signer to sign the image. Use <span class="key-service">AWS CloudTrail</span> to track who generates the signatures.</div>                <div class="option"><strong>B.</strong> Use <span class="key-service">AWS Lambda</span> to retrieve the image that was previously pushed to <span class="key-service">Amazon ECR</span>. Use a Lambda function to sign the image. Use <span class="key-service">Amazon CloudWatch</span> to track who generates the signatures.</div>                <div class="option"><strong>C.</strong> Use <span class="key-service">AWS Lambda</span> to retrieve the image that was previously pushed to <span class="key-service">Amazon ECR</span>. Use AWS Signer to sign the image. Use <span class="key-service">Amazon CloudWatch</span> to track who generates the signatures.</div>                <div class="option correct-answer"><strong>D.</strong> Use CodeBuild to build the image. Sign the image by using AWS Signer before pushing the image to <span class="key-service">Amazon ECR</span>. Use <span class="key-service">AWS CloudTrail</span> to track who generates the signatures.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司使用HPC平台运行数据分析作业。公司使用AWS CodeBuild创建容器镜像并将镜像存储在Amazon ECR上。然后将镜像部署到Amazon EKS上。为了保持合规性，公司需要确保镜像在部署到Amazon EKS之前进行签名。签名密钥必须定期轮换并自动管理。公司需要跟踪谁生成了签名。哪种解决方案能以最少的运营工作量满足这些要求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 使用CodeBuild检索之前推送到Amazon ECR的镜像，使用AWS Signer对镜像进行签名，使用AWS CloudTrail跟踪谁生成了签名</div> <div class="option-analysis"><strong>B.</strong> 使用AWS Lambda检索之前推送到Amazon ECR的镜像，使用Lambda函数对镜像进行签名，使用Amazon CloudWatch跟踪谁生成了签名</div> <div class="option-analysis"><strong>C.</strong> 使用AWS Lambda检索之前推送到Amazon ECR的镜像，使用AWS Signer对镜像进行签名，使用Amazon CloudWatch跟踪谁生成了签名</div> <div class="option-analysis"><strong>D.</strong> 使用CodeBuild构建镜像，在推送镜像到Amazon ECR之前使用AWS Signer对镜像进行签名，使用AWS CloudTrail跟踪谁生成了签名<div class="section-title"><strong>核心要求:</strong></div> 实现容器镜像签名、密钥自动轮换管理和签名审计跟踪 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• AWS Signer-提供代码签名服务，支持自动密钥轮换和管理 </div><div class="compact-content">• <span class="key-service">AWS CloudTrail</span>-记录API调用和用户操作，用于审计跟踪 <div class="section-title"><strong>正确答案D:</strong></div> 在构建流程中集成签名，使用AWS Signer提供托管签名服务和自动密钥轮换，CloudTrail记录签名操作的完整审计日志 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A-需要额外步骤从ECR检索镜像再签名，增加运营复杂度 </div><div class="compact-content">• 选项B-使用Lambda自定义签名缺乏自动密钥轮换功能，CloudWatch无法提供详细的用户操作审计 </div><div class="compact-content">• 选项C-使用Lambda增加额外运营开销，CloudWatch无法提供完整的API调用审计信息 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-在构建流程中直接签名避免额外的镜像传输开销 </div><div class="compact-content">• 成本-使用托管服务AWS Signer减少自定义开发和维护成本 </div><div class="compact-content">• 可扩展性-AWS Signer和CloudTrail都是完全托管服务，自动扩展无需人工干预</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: D</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-343">
            <div class="question-header">
                <div class="question-title">Question #343 ✅ ⚪ <small style="float: right;">(343/353)</small></div>
            </div>
            <div class="question-content">A company uses an AWS CodeArtifact repository to store Python packages that the company developed internally. A DevOps engineer needs to use <span class="key-service">AWS CodeDeploy</span> to deploy an application to an <span class="key-service">Amazon EC2</span> instance. The application uses a Python package that is stored in the CodeArtifact repository. A BeforeInstall lifecycle event hook will install the package. The DevOps engineer needs to grant the EC2 instance access to the CodeArtifact repository. Which solution will meet this requirement?</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Create a service-linked role for CodeArtifact. Associate the role with the EC2 instance. Use the aws codeartifact get-authorization-token CLI command on the instance.</div>                <div class="option"><strong>B.</strong> Configure a resource-based policy for the CodeArtifact repository that allows the ReadFromRepository action for the EC2 instance principal.</div>                <div class="option"><strong>C.</strong> Configure ACLs on the CodeArtifact repository to allow the EC2 instance to access the Python package.</div>                <div class="option correct-answer"><strong>D.</strong> Create an instance profile that contains an IAM role that has access to CodeArtifact. Associate the instance profile with the EC2 instance. Use the aws codeartifact login CLI command on the instance.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司使用AWS CodeArtifact存储库来存储内部开发的Python包。DevOps工程师需要使用AWS CodeDeploy将应用程序部署到Amazon EC2实例。应用程序使用存储在CodeArtifact存储库中的Python包。BeforeInstall生命周期事件钩子将安装该包。DevOps工程师需要授予EC2实例访问CodeArtifact存储库的权限。哪种解决方案能满足这个要求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 为CodeArtifact创建服务链接角色，将角色与EC2实例关联，在实例上使用aws codeartifact get-authorization-token CLI命令</div> <div class="option-analysis"><strong>B.</strong> 为CodeArtifact存储库配置基于资源的策略，允许EC2实例主体执行ReadFromRepository操作</div> <div class="option-analysis"><strong>C.</strong> 在CodeArtifact存储库上配置ACL以允许EC2实例访问Python包</div> <div class="option-analysis"><strong>D.</strong> 创建包含具有CodeArtifact访问权限的IAM角色的实例配置文件，将实例配置文件与EC2实例关联，在实例上使用aws codeartifact login CLI命令<div class="section-title"><strong>核心要求:</strong></div> 为EC2实例配置访问CodeArtifact存储库的权限以下载Python包 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• AWS CodeArtifact-私有软件包存储库服务，需要身份验证和授权 </div><div class="compact-content">• <span class="key-service">Amazon EC2</span>-需要通过实例配置文件获得IAM权限访问其他AWS服务 <div class="section-title"><strong>正确答案D:</strong></div> 通过实例配置文件为EC2实例分配IAM角色权限，使用codeartifact login命令配置包管理器认证，这是EC2访问CodeArtifact的标准方式 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A-服务链接角色由AWS管理且不能直接与EC2实例关联，get-authorization-token命令不能直接配置包管理器 </div><div class="compact-content">• 选项B-CodeArtifact不支持基于资源的策略，只能通过IAM身份策略控制访问 </div><div class="compact-content">• 选项C-CodeArtifact不使用传统ACL机制，而是依赖IAM进行访问控制 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-实例配置文件提供无缝的权限管理，login命令自动配置认证 </div><div class="compact-content">• 成本-使用现有IAM机制无额外费用，避免复杂的权限配置 </div><div class="compact-content">• 可扩展性-实例配置文件可重用于多个实例，便于大规模部署管理</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: D</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-344">
            <div class="question-header">
                <div class="question-title">Question #344 ✅ ⚪ <small style="float: right;">(344/353)</small></div>
            </div>
            <div class="question-content">A company has a file-reading application that saves files to a database that runs on <span class="key-service">Amazon EC2</span> instances. Regulations require the company to delete files from EC2 instances every day at a specific time. The company must delete database records that are older than 60 days. The database record deletion must occur after the file deletions. The company has created scripts to delete files and database records. The company needs to receive an email notification for any failure of the deletion scripts. Which solution will meet these requirements with the LEAST development effort?</div>
            <div class="options-container">                <div class="option correct-answer"><strong>A.</strong> Use <span class="key-service">AWS Systems Manager</span> State Manager to automatically invoke a Systems Manager Automation document at the specified time each day. Configure the Automation document to use a run command to run the deletion scripts in sequential order. Create an Amazon EventBridge rule to use Amazon Simple Notification Service (<span class="key-service">Amazon SNS</span>) to send failure notifications to the company.</div>                <div class="option"><strong>B.</strong> Use <span class="key-service">AWS Systems Manager</span> State Manager to automatically invoke a Systems Manager Automation document at the specified time each day. Configure the Automation document to use a run command to run the deletion scripts in sequential order. Create a conditional statement inside the Automation document as the last step to check for errors. Use Amazon Simple Email Service (Amazon SES) to send failure notifications as email messages to the company.</div>                <div class="option"><strong>C.</strong> Create an Amazon EventBridge rule that invokes an <span class="key-service">AWS Lambda</span> function at the specified time. Add the necessary permissions for the invocation to the Lambda function's resource-based policy. Configure the Lambda function to run the deletion scripts in sequential order. Configure the Lambda function to use Amazon Simple Notification Service (<span class="key-service">Amazon SNS</span>) to send failure notifications to the company.</div>                <div class="option"><strong>D.</strong> Create an Amazon EventBridge rule that invokes an <span class="key-service">AWS Lambda</span> function at the specified time. Add the necessary permissions for the invocation to the Lambda function's resource-based policy. Configure the Lambda function to run the deletion scripts in sequential order. Configure the Lambda function to use Amazon Simple Email Service (Amazon SES) to send failure notifications as email messages to the company.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司有一个文件读取应用程序，将文件保存到运行在Amazon EC2实例上的数据库中。法规要求公司每天在特定时间从EC2实例删除文件。公司必须删除超过60天的数据库记录。数据库记录删除必须在文件删除之后进行。公司已创建了删除文件和数据库记录的脚本。公司需要在删除脚本失败时收到电子邮件通知。哪种解决方案能以最少的开发工作量满足这些要求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 使用AWS Systems Manager State Manager每天在指定时间自动调用Systems Manager Automation文档。配置Automation文档使用运行命令按顺序运行删除脚本。创建Amazon EventBridge规则使用Amazon Simple Notification Service (<span class="key-service">Amazon SNS</span>)向公司发送失败通知。</div> <div class="option-analysis"><strong>B.</strong> 使用AWS Systems Manager State Manager每天在指定时间自动调用Systems Manager Automation文档。配置Automation文档使用运行命令按顺序运行删除脚本。在Automation文档中创建条件语句作为最后一步检查错误。使用Amazon Simple Email Service (Amazon SES)向公司发送失败通知邮件。</div> <div class="option-analysis"><strong>C.</strong> 创建Amazon EventBridge规则在指定时间调用AWS Lambda函数。为Lambda函数的基于资源的策略添加调用的必要权限。配置Lambda函数按顺序运行删除脚本。配置Lambda函数使用Amazon Simple Notification Service (<span class="key-service">Amazon SNS</span>)向公司发送失败通知。</div> <div class="option-analysis"><strong>D.</strong> 创建Amazon EventBridge规则在指定时间调用AWS Lambda函数。为Lambda函数的基于资源的策略添加调用的必要权限。配置Lambda函数按顺序运行删除脚本。配置Lambda函数使用Amazon Simple Email Service (Amazon SES)向公司发送失败通知邮件。<div class="section-title"><strong>核心要求:</strong></div> 定时执行删除脚本、确保执行顺序、失败通知，最少开发工作量 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• <span class="key-service">AWS Systems Manager</span> State Manager-自动化运维任务调度和执行 </div><div class="compact-content">• Amazon EventBridge-事件驱动的服务集成和通知 <div class="section-title"><strong>正确答案A:</strong></div> Systems Manager State Manager提供原生的定时任务调度和脚本执行能力，Automation文档支持顺序执行，EventBridge与SNS集成提供自动化失败通知机制 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项B-需要在Automation文档中手动编写条件语句检查错误，增加开发复杂度 </div><div class="compact-content">• 选项C-需要编写Lambda函数代码来执行脚本和处理错误，开发工作量大 </div><div class="compact-content">• 选项D-需要编写Lambda函数代码来执行脚本和处理错误，开发工作量大 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-Systems Manager原生支持EC2实例脚本执行 </div><div class="compact-content">• 成本-使用托管服务减少运维成本 </div><div class="compact-content">• 可扩展性-State Manager提供企业级自动化运维能力</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: A</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-345">
            <div class="question-header">
                <div class="question-title">Question #345 ✅ ⚪ <small style="float: right;">(345/353)</small></div>
            </div>
            <div class="question-content">A company uses an organization in <span class="key-service">AWS Organizations</span> that has all features enabled to manage its AWS accounts. <span class="key-service">Amazon EC2</span> instances run in the AWS accounts. The company requires that all current EC2 instances must use Instance Metadata Service Version 2 (IMDSv2). The company needs to block AWS API calls that originate from EC2 instances that do not use IMDSv2. Which solution will meet these requirements?</div>
            <div class="options-container">                <div class="option correct-answer"><strong>A.</strong> Create a new <span class="key-service">SCP</span> statement that denies the ec2:RunInstances action when the ec2:MetadataHttpTokens condition key is not equal to the value of required. Attach the <span class="key-service">SCP</span> to the root of the organization.</div>                <div class="option"><strong>B.</strong> Create a new <span class="key-service">SCP</span> statement that denies the ec2:RunInstances action when the ec2:MetadataHttpPutResponseHopLimit condition key value is greater than two. Attach the <span class="key-service">SCP</span> to the root of the organization.</div>                <div class="option"><strong>C.</strong> Create a new <span class="key-service">SCP</span> statement that denies "*" when the ec2:RoleDelivery condition key value is less than two. Attach the <span class="key-service">SCP</span> to the root of the organization.</div>                <div class="option"><strong>D.</strong> Create a new <span class="key-service">SCP</span> statement that denies "*" when the ec2:MetadataHttpTokens condition key value is not equal to required. Attach the <span class="key-service">SCP</span> to the root of the organization.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司使用启用了所有功能的AWS Organizations来管理其AWS账户，EC2实例运行在这些账户中。公司要求所有当前EC2实例必须使用Instance Metadata Service Version 2 (IMDSv2)，需要阻止来自未使用IMDSv2的EC2实例的AWS API调用。 <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 创建新的SCP语句，当ec2:MetadataHttpTokens条件键不等于required值时拒绝ec2:RunInstances操作，将SCP附加到组织根部</div> <div class="option-analysis"><strong>B.</strong> 创建新的SCP语句，当ec2:MetadataHttpPutResponseHopLimit条件键值大于2时拒绝ec2:RunInstances操作，将SCP附加到组织根部</div> <div class="option-analysis"><strong>C.</strong> 创建新的SCP语句，当ec2:RoleDelivery条件键值小于2时拒绝"*"操作，将SCP附加到组织根部</div> <div class="option-analysis"><strong>D.</strong> 创建新的SCP语句，当ec2:MetadataHttpTokens条件键值不等于required时拒绝"*"操作，将SCP附加到组织根部<div class="section-title"><strong>核心要求:</strong></div> 强制所有EC2实例使用IMDSv2并阻止未使用IMDSv2实例的API调用 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• <span class="key-service">AWS Organizations</span> - 集中管理多个AWS账户的服务 </div><div class="compact-content">• <span class="key-service">SCP</span> (Service Control Policy) - 控制组织内账户可执行操作的策略 </div><div class="compact-content">• IMDSv2 - EC2实例元数据服务第二版，提供更强的安全性 <div class="section-title"><strong>正确答案A:</strong></div> 使用ec2:MetadataHttpTokens条件键检查是否启用IMDSv2，通过限制ec2:RunInstances操作防止创建不合规实例，从源头解决问题 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项B - ec2:MetadataHttpPutResponseHopLimit是跳数限制条件，与IMDSv2令牌要求无关 </div><div class="compact-content">• 选项C - ec2:RoleDelivery不是有效的IMDSv2相关条件键，且条件逻辑错误 </div><div class="compact-content">• 选项D - 虽然条件键正确但拒绝所有操作过于宽泛，会影响正常的AWS服务功能 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能 - 在实例创建时进行控制，避免运行时检查开销 </div><div class="compact-content">• 成本 - 通过SCP实现零额外成本的合规性控制 </div><div class="compact-content">• 可扩展性 - 组织级别策略自动应用于所有账户和未来创建的账户</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: A</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-346">
            <div class="question-header">
                <div class="question-title">Question #346 ✅ 📝 <small style="float: right;">(346/353)</small></div>
            </div>
            <div class="question-content">A DevOps team supports an application that runs on a large number of <span class="key-service">Amazon EC2</span> instances in an Auto Scaling group. The DevOps team uses <span class="key-service">AWS CloudFormation</span> to deploy the EC2 instances. The application recently experienced an issue. A single instance returned errors to a large percentage of requests. The EC2 instance responded as healthy to both <span class="key-service">Amazon EC2</span> and Elastic Load Balancing health checks. The DevOps team collects application logs in <span class="key-service">Amazon CloudWatch</span> by using the embedded metric format. The DevOps team needs to receive an alert if any EC2 instance is responsible for more than half of all errors. Which combination of steps will meet these requirements with the LEAST operational overhead? (Choose two.)</div>
            <div class="options-container">                <div class="option correct-answer"><strong>A.</strong> Create a CloudWatch Contributor Insights rule that groups logs from the CloudWatch application logs based on instance ID and errors.</div>                <div class="option"><strong>B.</strong> Create a resource group in AWS Resource Groups. Use the CloudFormation stack to group the resources for the application. Add the application to CloudWatch Application Insights. Use the resource group to identify the application.</div>                <div class="option"><strong>C.</strong> Create a metric filter for the application logs to count the occurrence of the term "Error." Create a CloudWatch alarm that uses the METRIC_COUNT function to determine whether errors have occurred. Configure the CloudWatch alarm to send a notification to an Amazon Simple Notification Service (<span class="key-service">Amazon SNS</span>) topic to notify the DevOps team.</div>                <div class="option correct-answer"><strong>D.</strong> Create a CloudWatch alarm that uses the INSIGHT_RULE_METRIC function to determine whether a specific instance is responsible for more than half of all errors reported by EC2 instances. Configure the CloudWatch alarm to send a notification to an Amazon Simple Notification Service (<span class="key-service">Amazon SNS</span>) topic to notify the DevOps team.</div>                <div class="option"><strong>E.</strong> Create a CloudWatch subscription filter for the application logs that filters for errors and invokes an <span class="key-service">AWS Lambda</span> function. Configure the Lambda function to send the instance ID and error in a notification to an Amazon Simple Notification Service (<span class="key-service">Amazon SNS</span>) topic to notify the DevOps team.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一个DevOps团队支持运行在Auto Scaling组中大量Amazon EC2实例上的应用程序。DevOps团队使用AWS CloudFormation部署EC2实例。应用程序最近遇到问题，单个实例对大部分请求返回错误。该EC2实例对Amazon EC2和Elastic Load Balancing健康检查都响应正常。DevOps团队使用嵌入式指标格式在Amazon CloudWatch中收集应用程序日志。DevOps团队需要在任何EC2实例负责超过一半错误时收到警报。哪种步骤组合能以最少运营开销满足这些要求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 创建CloudWatch Contributor Insights规则，基于实例ID和错误对CloudWatch应用程序日志进行分组</div> <div class="option-analysis"><strong>B.</strong> 在AWS Resource Groups中创建资源组，使用CloudFormation堆栈对应用程序资源进行分组，将应用程序添加到CloudWatch Application Insights，使用资源组识别应用程序</div> <div class="option-analysis"><strong>C.</strong> 为应用程序日志创建指标过滤器来计算"Error"术语的出现次数，创建使用METRIC_COUNT函数确定是否发生错误的CloudWatch警报，配置CloudWatch警报向Amazon SNS主题发送通知给DevOps团队</div> <div class="option-analysis"><strong>D.</strong> 创建使用INSIGHT_RULE_METRIC函数确定特定实例是否负责超过一半EC2实例报告错误的CloudWatch警报，配置CloudWatch警报向Amazon SNS主题发送通知给DevOps团队</div> <div class="option-analysis"><strong>E.</strong> 为应用程序日志创建CloudWatch订阅过滤器来过滤错误并调用AWS Lambda函数，配置Lambda函数将实例ID和错误通过通知发送到Amazon SNS主题给DevOps团队<div class="section-title"><strong>核心要求:</strong></div> 识别单个EC2实例是否负责超过一半的应用程序错误并发送警报 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• CloudWatch Contributor Insights-分析日志数据并识别顶级贡献者 </div><div class="compact-content">• CloudWatch Alarms-基于指标阈值触发通知 <div class="section-title"><strong>正确答案AD:</strong></div> Contributor Insights规则按实例ID分组错误日志，INSIGHT_RULE_METRIC函数在警报中使用该规则指标检测单实例错误占比超过50% <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项B-Application Insights用于应用程序性能监控，不专门用于错误分布分析 </div><div class="compact-content">• 选项C-METRIC_COUNT只计算总错误数，无法识别特定实例的错误占比 </div><div class="compact-content">• 选项E-Lambda函数需要自定义逻辑处理错误分布计算，增加运营复杂性 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-Contributor Insights提供实时日志分析和实例级错误分布 </div><div class="compact-content">• 成本-使用托管服务避免自定义Lambda函数的开发和维护成本 </div><div class="compact-content">• 可扩展性-原生CloudWatch功能自动处理大规模EC2实例的日志分析</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: AD (A、D)</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-347">
            <div class="question-header">
                <div class="question-title">Question #347 ✅ ⚪ <small style="float: right;">(347/353)</small></div>
            </div>
            <div class="question-content">A company is using <span class="key-service">AWS CloudFormation</span> to perform deployments of its application environment. A deployment failed during a recent update to the existing CloudFormation stack. A DevOps engineer discovered that some resources in the stack were manually modified. The DevOps engineer needs a solution that detects manual modification of resources and sends an alert to the DevOps lead. Which solution will meet these requirements with the LEAST operational effort?</div>
            <div class="options-container">                <div class="option correct-answer"><strong>A.</strong> Create an Amazon Simple Notification Service (<span class="key-service">Amazon SNS</span>) topic. Subscribe the DevOps lead to the topic by using an email address. Create an <span class="key-service">AWS Config</span> managed rule that has the CLOUDFORMATION_STACK_DRIFT_DETECTION_CHECK identifier. Create an Amazon EventBridge rule that is invoked on the NON_COMPLIANT resources status. Set the SNS topic as the rule target.</div>                <div class="option"><strong>B.</strong> Tag all CloudFormation resources with a specific tag. Create an <span class="key-service">AWS Config</span> custom rule by using the <span class="key-service">AWS Config</span> Rules Development Kit Library (RDKlib) that checks all resource changes that have the specific tag. Configure the custom rule to mark all the tagged resource changes as NON_COMPLIANT when the change is not performed by CloudFormation. Create an Amazon EventBridge rule that is invoked on the NON_COMPLIANT resources status. Create an <span class="key-service">AWS Lambda</span> function that sends an email message to the DevOps lead. Set the Lambda function as the rule target.</div>                <div class="option"><strong>C.</strong> Create an Amazon Simple Notification Service (<span class="key-service">Amazon SNS</span>) topic. Subscribe the DevOps lead to the topic by using an email address. Create an <span class="key-service">AWS Config</span> managed rule that has the CLOUDFORMATION_STACK_DRIFT_DETECTION_CHECK identifier. Create an Amazon EventBridge rule that is invoked on the COMPLIANT resources status. Set the SNS topic as the rule target.</div>                <div class="option"><strong>D.</strong> Create an <span class="key-service">AWS Config</span> managed rule that has the CLOUDFORMATION_STACK_DRIFT_DETECTION_CHECK identifier. Create an Amazon EventBridge rule that is invoked on the NON_COMPLIANT resources status. Create an <span class="key-service">AWS Lambda</span> function that sends an email message to the DevOps lead. Set the Lambda function as the rule target.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司使用AWS CloudFormation部署应用环境。最近更新现有CloudFormation堆栈时部署失败。DevOps工程师发现堆栈中的一些资源被手动修改了。DevOps工程师需要一个解决方案来检测资源的手动修改并向DevOps负责人发送警报。哪个解决方案能以最少的运营工作量满足这些要求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 创建Amazon Simple Notification Service (<span class="key-service">Amazon SNS</span>)主题。使用邮箱地址让DevOps负责人订阅该主题。创建一个使用CLOUDFORMATION_STACK_DRIFT_DETECTION_CHECK标识符的AWS Config托管规则。创建一个Amazon EventBridge规则，当资源状态为NON_COMPLIANT时触发。将SNS主题设置为规则目标。</div> <div class="option-analysis"><strong>B.</strong> 为所有CloudFormation资源打上特定标签。使用AWS Config Rules Development Kit Library (RDKlib)创建AWS Config自定义规则，检查所有带有特定标签的资源变更。配置自定义规则将所有非CloudFormation执行的标签资源变更标记为NON_COMPLIANT。创建Amazon EventBridge规则在NON_COMPLIANT资源状态时触发。创建AWS Lambda函数向DevOps负责人发送邮件。将Lambda函数设置为规则目标。</div> <div class="option-analysis"><strong>C.</strong> 创建Amazon Simple Notification Service (<span class="key-service">Amazon SNS</span>)主题。使用邮箱地址让DevOps负责人订阅该主题。创建一个使用CLOUDFORMATION_STACK_DRIFT_DETECTION_CHECK标识符的AWS Config托管规则。创建一个Amazon EventBridge规则，当资源状态为COMPLIANT时触发。将SNS主题设置为规则目标。</div> <div class="option-analysis"><strong>D.</strong> 创建一个使用CLOUDFORMATION_STACK_DRIFT_DETECTION_CHECK标识符的AWS Config托管规则。创建Amazon EventBridge规则在NON_COMPLIANT资源状态时触发。创建AWS Lambda函数向DevOps负责人发送邮件。将Lambda函数设置为规则目标。<div class="section-title"><strong>核心要求:</strong></div> 检测CloudFormation堆栈资源的手动修改并发送警报通知 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• <span class="key-service">AWS Config</span> - 监控资源配置变更和合规性检查 </div><div class="compact-content">• EventBridge - 基于事件触发自动化响应 </div><div class="compact-content">• SNS - 简化的消息通知服务 <div class="section-title"><strong>正确答案A:</strong></div> 使用AWS Config托管规则检测堆栈漂移，通过EventBridge监听NON_COMPLIANT状态，直接使用SNS发送邮件通知，架构简单运营工作量最少 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项B - 需要开发自定义规则和Lambda函数，运营复杂度高 </div><div class="compact-content">• 选项C - 监听COMPLIANT状态而非NON_COMPLIANT状态，逻辑错误 </div><div class="compact-content">• 选项D - 需要开发和维护Lambda函数，比直接使用SNS复杂 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能 - 托管规则比自定义规则响应更快更可靠 </div><div class="compact-content">• 成本 - SNS直接通知比Lambda函数成本更低 </div><div class="compact-content">• 可扩展性 - 托管服务减少运营负担，易于扩展和维护</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: A</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-348">
            <div class="question-header">
                <div class="question-title">Question #348 ✅ ⚪ <small style="float: right;">(348/353)</small></div>
            </div>
            <div class="question-content">A DevOps engineer deployed multiple AWS accounts by using AWS Control Tower to support different business, technical, and administrative units in a company. A security team needs the DevOps engineer to automate AWS Control Tower guardrails for the company. The guardrails must be applied to all accounts in an OU of the company's organization in <span class="key-service">AWS Organizations</span>. The security team needs a solution that has version control and can be reviewed and rolled back if necessary. The security team will maintain the management of the solution in its OU. The security team wants to limit the type of guardrails that are allowed and allow only new guardrails that are approved by the security team. Which solution will meet these requirements with the MOST operational efficiency?</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Create individual <span class="key-service">AWS CloudFormation</span> templates that align to a guardrail. Store the templates in an <span class="key-service">AWS CodeCommit</span> repository. Create an AWS::ControlTower::EnableControl logical resource in the template for each OU in the organization. Configure an <span class="key-service">AWS CodeBuild</span> project that an Amazon EventBridge rule will invoke for the security team's <span class="key-service">AWS CodeCommit</span> changes.</div>                <div class="option"><strong>B.</strong> Create individual <span class="key-service">AWS CloudFormation</span> templates that align to a guardrail. Store the templates in an <span class="key-service">AWS CodeCommit</span> repository. Create an AWS::ControlTower::EnableControl logical resource in the template for each account in the organization. Configure an <span class="key-service">AWS CodePipeline</span> pipeline in the security team's account. Advise the security team to invoke the pipeline and provide these parameters when starting the pipeline.</div>                <div class="option correct-answer"><strong>C.</strong> Create individual <span class="key-service">AWS CloudFormation</span> templates that align to a guardrail. Store the templates in an <span class="key-service">AWS CodeCommit</span> repository. Create an AWS::ControlTower::EnableControl logical resource in the template for each OU in the organization. Configure an <span class="key-service">AWS CodePipeline</span> pipeline in the security team's account that an Amazon EventBridge rule will invoke for the security team's CodeCommit changes.</div>                <div class="option"><strong>D.</strong> Configure an <span class="key-service">AWS CodePipeline</span> pipeline in the security team's account that an Amazon EventBridge rule will invoke for PutObject events to an <span class="key-service">Amazon S3</span> bucket. Create individual <span class="key-service">AWS CloudFormation</span> templates that align to a guardrail. Store the templates in the S3 bucket. Create an AWS::ControlTower::EnableControl logical resource in the template for each OU in the organization.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一名DevOps工程师使用AWS Control Tower部署了多个AWS账户来支持公司不同的业务、技术和管理单元。安全团队需要DevOps工程师为公司自动化AWS Control Tower guardrails。这些guardrails必须应用到AWS Organizations组织中某个OU的所有账户。安全团队需要一个具有版本控制、可审查和必要时可回滚的解决方案。安全团队将在其OU中维护解决方案的管理。安全团队希望限制允许的guardrails类型，只允许经安全团队批准的新guardrails。哪个解决方案能以最高运营效率满足这些要求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 创建与guardrail对应的单独AWS CloudFormation模板，将模板存储在AWS CodeCommit存储库中，在模板中为组织中的每个OU创建AWS::ControlTower::EnableControl逻辑资源，配置AWS CodeBuild项目，由Amazon EventBridge规则为安全团队的AWS CodeCommit更改调用该项目。</div> <div class="option-analysis"><strong>B.</strong> 创建与guardrail对应的单独AWS CloudFormation模板，将模板存储在AWS CodeCommit存储库中，在模板中为组织中的每个账户创建AWS::ControlTower::EnableControl逻辑资源，在安全团队账户中配置AWS CodePipeline管道，建议安全团队在启动管道时调用管道并提供这些参数。</div> <div class="option-analysis"><strong>C.</strong> 创建与guardrail对应的单独AWS CloudFormation模板，将模板存储在AWS CodeCommit存储库中，在模板中为组织中的每个OU创建AWS::ControlTower::EnableControl逻辑资源，在安全团队账户中配置AWS CodePipeline管道，由Amazon EventBridge规则为安全团队的CodeCommit更改调用该管道。</div> <div class="option-analysis"><strong>D.</strong> 在安全团队账户中配置AWS CodePipeline管道，由Amazon EventBridge规则为Amazon S3存储桶的PutObject事件调用该管道，创建与guardrail对应的单独AWS CloudFormation模板，将模板存储在S3存储桶中，在模板中为组织中的每个OU创建AWS::ControlTower::EnableControl逻辑资源。<div class="section-title"><strong>核心要求:</strong></div> 自动化Control Tower guardrails管理，支持版本控制、审查回滚，限制guardrails类型并需安全团队批准 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• AWS Control Tower - 多账户治理和guardrails管理 </div><div class="compact-content">• <span class="key-service">AWS CodeCommit</span> - 版本控制和代码存储 </div><div class="compact-content">• <span class="key-service">AWS CodePipeline</span> - 自动化部署管道 </div><div class="compact-content">• Amazon EventBridge - 事件驱动的自动化触发 <div class="section-title"><strong>正确答案C:</strong></div> 使用CodeCommit提供版本控制，CloudFormation模板针对OU级别部署guardrails，CodePipeline提供完整的CI/CD流程，EventBridge实现自动化触发，满足所有运营效率要求 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A - 使用CodeBuild而非CodePipeline，缺乏完整的CI/CD流程和部署管道功能 </div><div class="compact-content">• 选项B - 需要手动调用管道，缺乏自动化触发机制，运营效率低 </div><div class="compact-content">• 选项D - 使用S3存储模板而非CodeCommit，缺乏专业的版本控制功能 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能 - CodePipeline提供完整CI/CD流程，EventBridge实现事件驱动自动化 </div><div class="compact-content">• 成本 - OU级别部署比账户级别更高效，减少资源消耗 </div><div class="compact-content">• 可扩展性 - CodeCommit版本控制支持团队协作，管道化部署易于扩展</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: C</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-349">
            <div class="question-header">
                <div class="question-title">Question #349 ✅ ⚪ <small style="float: right;">(349/353)</small></div>
            </div>
            <div class="question-content">A company runs a web application on Amazon Elastic Kubernetes Service (<span class="key-service">Amazon EKS</span>). The company uses Amazon CloudFront to distribute the application. The company recently enabled AWS WAF. The company set up <span class="key-service">Amazon CloudWatch</span> Logs to send logs to an aws-waf-logs log group. The company wants a DevOps engineer to receive alerts if there are sudden changes in blocked traffic. The company does not want to receive alerts for other changes in AWS WAF log behavior. The company will tune AWS WAF rules over time. The DevOps engineer is currently subscribed to an Amazon Simple Notification Service (<span class="key-service">Amazon SNS</span>) topic in the environment. Which solution will meet these requirements?</div>
            <div class="options-container">                <div class="option correct-answer"><strong>A.</strong> Create a CloudWatch Logs metrics filter for blocked requests on the AWS WAF log group to create a custom metric. Create a CloudWatch alarm by using CloudWatch anomaly detection and the published custom metric. Configure the alarm to notify the SNS topic to alert the DevOps engineer.</div>                <div class="option"><strong>B.</strong> Create a CloudWatch anomaly detector for the log group. Create a CloudWatch alarm by using metrics that the CloudWatch anomaly detector publishes. Use the high setting for the LogAnomalyPriority metric. Configure the alarm to go into alarm state if a static threshold of one anomaly is detected. Configure the alarm to notify the SNS topic to alert the DevOps engineer.</div>                <div class="option"><strong>C.</strong> Create a CloudWatch metrics filter for counted requests on the AWS WAF log group to create a custom metric. Create a CloudWatch alarm that activates when the sum of blocked requests in the custom metric during a period of 1 hour is greater than a static estimate for the acceptable number of blocked requests in 1 hour. Configure the alarm to notify the SNS topic to alert the DevOps engineer.</div>                <div class="option"><strong>D.</strong> Create a CloudWatch anomaly detector for the log group. Create a CloudWatch alarm by using metrics that the CloudWatch anomaly detector publishes. Use the medium setting for the LogAnomalyPriority metric. Configure the alarm to go into alarm state if a sum of anomalies over 1 hour is greater than an expected value. Configure the alarm to notify the SNS topic to alert the DevOps engineer.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司在Amazon EKS上运行Web应用程序，使用Amazon CloudFront分发应用程序。公司最近启用了AWS WAF，设置Amazon CloudWatch Logs将日志发送到aws-waf-logs日志组。公司希望DevOps工程师在被阻止流量突然变化时收到警报，但不希望收到AWS WAF日志行为其他变化的警报。公司将随时间调整AWS WAF规则。DevOps工程师当前已订阅环境中的Amazon SNS主题。 <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 在AWS WAF日志组上为被阻止的请求创建CloudWatch Logs指标过滤器以创建自定义指标，使用CloudWatch异常检测和发布的自定义指标创建CloudWatch警报，配置警报通知SNS主题以提醒DevOps工程师。</div> <div class="option-analysis"><strong>B.</strong> 为日志组创建CloudWatch异常检测器，使用CloudWatch异常检测器发布的指标创建CloudWatch警报，为LogAnomalyPriority指标使用高设置，配置警报在检测到一个异常的静态阈值时进入警报状态，配置警报通知SNS主题以提醒DevOps工程师。</div> <div class="option-analysis"><strong>C.</strong> 在AWS WAF日志组上为计数请求创建CloudWatch指标过滤器以创建自定义指标，创建CloudWatch警报当自定义指标中1小时内被阻止请求的总和大于1小时内可接受被阻止请求数量的静态估计时激活，配置警报通知SNS主题以提醒DevOps工程师。</div> <div class="option-analysis"><strong>D.</strong> 为日志组创建CloudWatch异常检测器，使用CloudWatch异常检测器发布的指标创建CloudWatch警报，为LogAnomalyPriority指标使用中等设置，配置警报在1小时内异常总和大于预期值时进入警报状态，配置警报通知SNS主题以提醒DevOps工程师。<div class="section-title"><strong>核心要求:</strong></div> 检测AWS WAF被阻止流量的突然变化并发送警报，避免其他日志行为变化的误报 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• CloudWatch Logs - 存储AWS WAF日志并提供指标过滤功能 </div><div class="compact-content">• CloudWatch异常检测 - 基于机器学习检测指标异常模式 </div><div class="compact-content">• <span class="key-service">Amazon SNS</span> - 发送警报通知给DevOps工程师 <div class="section-title"><strong>正确答案A:</strong></div> 创建专门针对被阻止请求的自定义指标，结合异常检测算法智能识别突然变化，避免WAF规则调整时的误报 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项B - 直接对整个日志组进行异常检测会包含所有日志行为变化，不符合只监控被阻止流量的要求 </div><div class="compact-content">• 选项C - 使用静态阈值无法适应WAF规则调整后的正常流量变化，会产生误报 </div><div class="compact-content">• 选项D - 同样对整个日志组检测且使用复杂的异常总和计算，不够精确且可能产生误报 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能 - 自定义指标过滤器精确定位被阻止请求，异常检测自动适应基线变化 </div><div class="compact-content">• 成本 - 只监控特定指标类型，避免不必要的全量日志分析成本 </div><div class="compact-content">• 可扩展性 - 异常检测算法可随WAF规则调整自动学习新的正常模式</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: A</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-350">
            <div class="question-header">
                <div class="question-title">Question #350 ✅ ⚪ <small style="float: right;">(350/353)</small></div>
            </div>
            <div class="question-content">A video platform company is migrating its video catalog to AWS. The company will host MP4 video files in an <span class="key-service">Amazon S3</span> bucket. The company will use Amazon CloudFront and <span class="key-service">Amazon EC2</span> instances to serve the video files. Users first connect to a frontend application that redirects to a video URL. The video URL contains an authorization token in CloudFront. The cache is activated on the CloudFront distribution. Authorization token check activity needs to be logged in <span class="key-service">Amazon CloudWatch</span>. The company wants to prevent direct access to video files on CloudFront and <span class="key-service">Amazon S3</span> and wants to implement checks of the authorization token that the frontend application provides. The company also wants to perform regular rolling updates of the code that checks the authorization token signature. Which solution will meet these requirements with the LEAST operational effort?</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Implement an authorization token check in Lambda@Edge as a trigger on the CloudFront distribution. Enable CloudWatch logging for the Lambda@Edge function. Attach the Lambda@Edge function to the CloudFront distribution. Implement CloudFront continuous deployment to perform updates.</div>                <div class="option correct-answer"><strong>B.</strong> Implement an authorization token check in CloudFront Functions. Enable CloudWatch logging for the CloudFront function. Attach the CloudFront function to the CloudFront distribution. Implement CloudFront continuous deployment to perform updates.</div>                <div class="option"><strong>C.</strong> Implement an authorization token check in the application code that is installed on the EC2 instances. Install the CloudWatch agent on the EC2 instances. Configure the application to log to the CloudWatch agent. Implement a second CloudFront distribution. Migrate the traffic from the first CloudFront distribution by using <span class="key-service">Amazon Route 53</span> weighted routing.</div>                <div class="option"><strong>D.</strong> Implement an authorization token check in CloudFront Functions. Enable CloudWatch logging for the CloudFront function. Attach the CloudFront function to the CloudFront distribution. Implement a second CloudFront distribution. Migrate the traffic from the first CloudFront distribution by using <span class="key-service">Amazon Route 53</span> weighted routing.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家视频平台公司正在将其视频目录迁移到AWS。公司将在Amazon S3存储桶中托管MP4视频文件，使用Amazon CloudFront和Amazon EC2实例提供视频文件服务。用户首先连接到前端应用程序，该应用程序重定向到包含CloudFront授权令牌的视频URL。CloudFront分发上启用了缓存。授权令牌检查活动需要记录在Amazon CloudWatch中。公司希望防止直接访问CloudFront和Amazon S3上的视频文件，并实现对前端应用程序提供的授权令牌的检查。公司还希望对检查授权令牌签名的代码执行定期滚动更新。哪种解决方案能以最少的运营工作量满足这些要求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 在Lambda@Edge中实现授权令牌检查作为CloudFront分发的触发器，为Lambda@Edge函数启用CloudWatch日志记录，将Lambda@Edge函数附加到CloudFront分发，实施CloudFront持续部署来执行更新。</div> <div class="option-analysis"><strong>B.</strong> 在CloudFront Functions中实现授权令牌检查，为CloudFront函数启用CloudWatch日志记录，将CloudFront函数附加到CloudFront分发，实施CloudFront持续部署来执行更新。</div> <div class="option-analysis"><strong>C.</strong> 在安装在EC2实例上的应用程序代码中实现授权令牌检查，在EC2实例上安装CloudWatch代理，配置应用程序记录到CloudWatch代理，实施第二个CloudFront分发，使用Amazon Route 53加权路由从第一个CloudFront分发迁移流量。</div> <div class="option-analysis"><strong>D.</strong> 在CloudFront Functions中实现授权令牌检查，为CloudFront函数启用CloudWatch日志记录，将CloudFront函数附加到CloudFront分发，实施第二个CloudFront分发，使用Amazon Route 53加权路由从第一个CloudFront分发迁移流量。<div class="section-title"><strong>核心要求:</strong></div> 实现CloudFront边缘授权令牌验证，防止直接访问，支持滚动更新，最小运营开销 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• CloudFront Functions-轻量级边缘计算，适合简单授权检查 </div><div class="compact-content">• CloudFront持续部署-原生滚动更新机制，零停机时间 <div class="section-title"><strong>正确答案B:</strong></div> CloudFront Functions提供低延迟边缘授权检查，CloudFront持续部署实现无缝代码更新，运营开销最小 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A-Lambda@Edge比CloudFront Functions更重量级，启动时间更长，成本更高 </div><div class="compact-content">• 选项C-EC2实例检查增加复杂性和成本，Route 53加权路由更新方式复杂 </div><div class="compact-content">• 选项D-使用两个CloudFront分发和Route 53迁移增加不必要的复杂性和成本 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-CloudFront Functions边缘执行延迟最低 </div><div class="compact-content">• 成本-Functions比Lambda@Edge成本更低，避免额外基础设施 </div><div class="compact-content">• 可扩展性-持续部署提供原生滚动更新能力</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: B</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-351">
            <div class="question-header">
                <div class="question-title">Question #351 ✅ 📝 <small style="float: right;">(351/353)</small></div>
            </div>
            <div class="question-content">A company uses an organization in <span class="key-service">AWS Organizations</span> to manage multiple AWS accounts in a hierarchical structure. An <span class="key-service">SCP</span> that is associated with the organization root allows IAM users to be created. A DevOps team must be able to create IAM users with any level of permissions. Developers must also be able to create IAM users. However, developers must not be able to grant new IAM users excessive permissions. The developers have the CreateAndManageUsers role in each account. The DevOps team must be able to prevent other users from creating IAM users. Which combination of steps will meet these requirements? (Choose two.)</div>
            <div class="options-container">                <div class="option correct-answer"><strong>A.</strong> Create an <span class="key-service">SCP</span> in the organization to deny users the ability to create and modify IAM users. Attach the <span class="key-service">SCP</span> to the root of the organization. Attach the CreateAndManageUsers role to developers.</div>                <div class="option"><strong>B.</strong> Create an <span class="key-service">SCP</span> in the organization to grant users that have the DeveloperBoundary policy attached the ability to create new IAM users and to modify IAM users. Configure the <span class="key-service">SCP</span> to require users to attach the PermissionBoundaries policy to any new IAM user. Attach the <span class="key-service">SCP</span> to the root of the organization.</div>                <div class="option correct-answer"><strong>C.</strong> Create an IAM permissions policy named PermissionBoundaries within each account. Configure the PermissionBoundaries policy to specify the maximum permissions that a developer can grant to a new IAM user.</div>                <div class="option"><strong>D.</strong> Create an IAM permissions policy named PermissionBoundaries within each account. Configure PermissionBoundaries to allow users who have the PermissionBoundaries policy to create new IAM users.</div>                <div class="option"><strong>E.</strong> Create an IAM permissions policy named DeveloperBoundary within each account. Configure the DeveloperBoundary policy to allow developers to create IAM users and to assign policies to IAM users only if the developer includes the PermissionBoundaries policy as the permissions boundary. Attach the DeveloperBoundary policy to the CreateAndManageUsers role within each account.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司使用AWS Organizations中的组织来管理分层结构中的多个AWS账户。与组织根关联的SCP允许创建IAM用户。DevOps团队必须能够创建具有任何级别权限的IAM用户。开发人员也必须能够创建IAM用户，但不能授予新IAM用户过多权限。开发人员在每个账户中都有CreateAndManageUsers角色。DevOps团队必须能够阻止其他用户创建IAM用户。哪种步骤组合将满足这些要求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 在组织中创建SCP以拒绝用户创建和修改IAM用户的能力，将SCP附加到组织根，将CreateAndManageUsers角色附加给开发人员</div> <div class="option-analysis"><strong>B.</strong> 在组织中创建SCP以授予附加了DeveloperBoundary策略的用户创建和修改IAM用户的能力，配置SCP要求用户将PermissionBoundaries策略附加到任何新IAM用户，将SCP附加到组织根</div> <div class="option-analysis"><strong>C.</strong> 在每个账户中创建名为PermissionBoundaries的IAM权限策略，配置PermissionBoundaries策略以指定开发人员可以授予新IAM用户的最大权限</div> <div class="option-analysis"><strong>D.</strong> 在每个账户中创建名为PermissionBoundaries的IAM权限策略，配置PermissionBoundaries以允许具有PermissionBoundaries策略的用户创建新IAM用户</div> <div class="option-analysis"><strong>E.</strong> 在每个账户中创建名为DeveloperBoundary的IAM权限策略，配置DeveloperBoundary策略以允许开发人员创建IAM用户并仅在开发人员包含PermissionBoundaries策略作为权限边界时向IAM用户分配策略，将DeveloperBoundary策略附加到每个账户中的CreateAndManageUsers角色<div class="section-title"><strong>核心要求:</strong></div> 实现分层权限控制，DevOps团队拥有完全IAM权限，开发人员创建IAM用户时受权限边界限制 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• <span class="key-service">SCP</span> - 组织级权限控制，可以拒绝或允许特定操作 </div><div class="compact-content">• IAM Permission Boundaries - 定义用户或角色可获得的最大权限范围 <div class="section-title"><strong>正确答案AC:</strong></div> 选项A通过SCP在组织根级别拒绝IAM用户创建，然后通过特定角色例外允许；选项C创建权限边界策略限制开发人员授予新用户的最大权限，实现了分层控制 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项B - SCP语法错误，SCP不能基于策略附加情况进行条件授权 </div><div class="compact-content">• 选项D - PermissionBoundaries策略用途错误，应该定义权限上限而非授权创建用户 </div><div class="compact-content">• 选项E - 过于复杂且未解决DevOps团队需要阻止其他用户创建IAM用户的核心需求 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 安全性 - SCP提供组织级强制控制，权限边界防止权限升级 </div><div class="compact-content">• 管理性 - 分层权限模型便于不同团队角色管理 </div><div class="compact-content">• <span class="key-point">合规性</span> - 确保开发人员无法绕过权限限制创建高权限用户</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: AC (A、C)</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-352">
            <div class="question-header">
                <div class="question-title">Question #352 ✅ ⚪ <small style="float: right;">(352/353)</small></div>
            </div>
            <div class="question-content">A company has deployed a landing zone that has a well-defined <span class="key-service">AWS Organizations</span> structure and an <span class="key-service">SCP</span>. The company's development team can create their AWS resources only by using <span class="key-service">AWS CloudFormation</span> and the AWS Cloud Development Kit (AWS CDK). A DevOps engineer notices that Amazon Simple Queue Service (<span class="key-service">Amazon SQS</span>) queues that are deployed in different CloudFormation stacks have different configurations. The DevOps engineer also notices that the application cost allocation tag is not always set. The DevOps engineer needs a solution that will enforce tagging and promote the reuse of code. The DevOps engineer needs to avoid different configurations for the deployed SQS queues. What should the DevOps engineer do to meet these requirements?</div>
            <div class="options-container">                <div class="option"><strong>A.</strong> Create an Organizations tag policy to enforce the cost allocation tag in CloudFormation stacks. Instruct the development team to use CloudFormation to define SQS queues. Instruct the development team to deploy the SQS queues by using CloudFormation StackSets.</div>                <div class="option"><strong>B.</strong> Update the <span class="key-service">SCP</span> to enforce the cost allocation tag in CloudFormation stacks. Instruct the development team to use CloudFormation modules to define SQS queues. Instruct the development team to deploy the SQS queues by using CloudFormation stacks.</div>                <div class="option correct-answer"><strong>C.</strong> Use AWS CDK tagging to enforce the cost allocation tag in CloudFormation StackSets. Instruct the development team to use the AWS CDK to define SQS queues. Instruct the development team to deploy the SQS queues by using CDK stacks.</div>                <div class="option"><strong>D.</strong> Use AWS CDK tagging to enforce the cost allocation tag in CloudFormation stacks. Instruct the development team to use the AWS CDK to define SQS queues. Instruct the development team to deploy the SQS queues by using CDK feature flags.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一家公司部署了具有明确定义的AWS Organizations结构和SCP的landing zone。公司开发团队只能使用AWS CloudFormation和AWS CDK创建AWS资源。DevOps工程师注意到在不同CloudFormation堆栈中部署的Amazon SQS队列具有不同配置，且应用成本分配标签并不总是设置。DevOps工程师需要一个解决方案来强制执行标签并促进代码重用，避免已部署SQS队列的不同配置。 <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 创建Organizations标签策略在CloudFormation堆栈中强制执行成本分配标签，指导开发团队使用CloudFormation定义SQS队列，使用CloudFormation StackSets部署SQS队列。</div> <div class="option-analysis"><strong>B.</strong> 更新SCP在CloudFormation堆栈中强制执行成本分配标签，指导开发团队使用CloudFormation模块定义SQS队列，使用CloudFormation堆栈部署SQS队列。</div> <div class="option-analysis"><strong>C.</strong> 使用AWS CDK标签在CloudFormation StackSets中强制执行成本分配标签，指导开发团队使用AWS CDK定义SQS队列，使用CDK堆栈部署SQS队列。</div> <div class="option-analysis"><strong>D.</strong> 使用AWS CDK标签在CloudFormation堆栈中强制执行成本分配标签，指导开发团队使用AWS CDK定义SQS队列，使用CDK功能标志部署SQS队列。<div class="section-title"><strong>核心要求:</strong></div> 强制执行标签并促进代码重用，统一SQS队列配置 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• AWS CDK-提供高级抽象和标签管理功能 </div><div class="compact-content">• CloudFormation StackSets-支持跨账户和区域的统一部署 </div><div class="compact-content">• Organizations标签策略-组织级别的标签治理 <div class="section-title"><strong>正确答案C:</strong></div> AWS CDK提供内置标签功能和代码重用能力，CloudFormation StackSets确保跨多个账户和区域的统一配置部署 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项A-Organizations标签策略无法在CloudFormation堆栈级别强制执行标签，且普通CloudFormation缺乏代码重用抽象 </div><div class="compact-content">• 选项B-SCP主要用于权限控制而非标签强制执行，CloudFormation模块不如CDK提供更好的抽象 </div><div class="compact-content">• 选项D-CDK功能标志用于控制CDK行为而非部署机制，无法解决跨账户统一配置问题 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能-CDK提供更高级的抽象和更好的开发体验 </div><div class="compact-content">• 成本-统一的标签策略确保准确的成本分配和追踪 </div><div class="compact-content">• 可扩展性-StackSets支持大规模跨账户和区域部署</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: C</strong>
                </div>
            </div>
        </div>
        <div class="question-block completed" id="question-353">
            <div class="question-header">
                <div class="question-title">Question #353 ✅ ⚪ <small style="float: right;">(353/353)</small></div>
            </div>
            <div class="question-content">A DevOps team manages a company's AWS account. The company wants to ensure that specific AWS resource configuration changes are automatically reverted. Which solution will meet this requirement? Unlock free, top-quality video courses on ExamTopics with a simple registration. Elevate your learning journey with our expertly curated content. Register now to access a diverse range of educational resources designed for learners and professionals.</div>
            <div class="options-container">                <div class="option correct-answer"><strong>A.</strong> Use <span class="key-service">AWS Config</span> rules to detect changes in resource configurations. Configure remediation action that uses <span class="key-service">AWS Systems Manager</span> Automation documents to revert the configuration changes.</div>                <div class="option"><strong>B.</strong> Use <span class="key-service">Amazon CloudWatch</span> alarms to monitor resource metrics. When an alarm is activated, use an Amazon Simple Notification Service (<span class="key-service">Amazon SNS</span>) topic to notify an administrator to manually revert the configuration changes.</div>                <div class="option"><strong>C.</strong> Use <span class="key-service">AWS CloudFormation</span> to create a stack that deploys the necessary configuration changes. Update the stack when configuration changes need to be reverted.</div>                <div class="option"><strong>D.</strong> Use AWS Trusted Advisor to check for noncompliant configurations. Manually apply necessary changes based on Trusted Advisor recommendations.</div>            </div>
            <div class="analysis-container">
                <div class="translation-section">
                    <div class="compact-content"><div class="section-title"><strong>题目翻译:</strong></div> 一个DevOps团队管理公司的AWS账户。公司希望确保特定的AWS资源配置更改能够自动回滚。哪个解决方案能满足这个要求？ <div class="section-title"><strong>选项翻译:</strong></div> <div class="option-analysis"><strong>A.</strong> 使用AWS Config规则检测资源配置变更，配置使用AWS Systems Manager自动化文档的修复操作来回滚配置更改</div> <div class="option-analysis"><strong>B.</strong> 使用Amazon CloudWatch告警监控资源指标，当告警激活时使用Amazon SNS主题通知管理员手动回滚配置更改</div> <div class="option-analysis"><strong>C.</strong> 使用AWS CloudFormation创建堆栈来部署必要的配置更改，当需要回滚配置更改时更新堆栈</div> <div class="option-analysis"><strong>D.</strong> 使用AWS Trusted Advisor检查不合规配置，根据Trusted Advisor建议手动应用必要更改<div class="section-title"><strong>核心要求:</strong></div> 实现AWS资源配置更改的自动回滚机制 <div class="section-title"><strong>关键服务:</strong></div> <div class="compact-content">• <span class="key-service">AWS Config</span> - 监控和评估AWS资源配置合规性 </div><div class="compact-content">• <span class="key-service">AWS Systems Manager</span> Automation - 执行自动化运维任务和修复操作 <div class="section-title"><strong>正确答案A:</strong></div> AWS Config规则可检测配置偏差并触发Systems Manager自动化文档执行自动修复，实现完全自动化的配置回滚 <div class="section-title"><strong>错误选项:</strong></div> </div><div class="compact-content">• 选项B - CloudWatch监控指标而非配置变更，且需要人工干预无法自动回滚 </div><div class="compact-content">• 选项C - CloudFormation用于基础设施部署，不是配置变更检测和自动修复工具 </div><div class="compact-content">• 选项D - Trusted Advisor提供建议但需要手动操作，无法实现自动回滚 <div class="section-title"><strong>决策标准:</strong></div> </div><div class="compact-content">• 性能 - Config规则实时检测配置变更并立即触发自动修复 </div><div class="compact-content">• 成本 - 自动化减少人工运维成本和响应时间 </div><div class="compact-content">• 可扩展性 - 可应用于多种资源类型和大规模环境的配置管理</div></div></div>
                </div>
                <div class="detailed-analysis">
                    <strong>✅ Correct Answer: A</strong>
                </div>
            </div>
        </div>
        </div>
        
        <div class="stats">
            <div class="stats-item">
                <div class="stats-number">353</div>
                <div class="stats-label">Total Questions</div>
            </div>
            <div class="stats-item">
                <div class="stats-number success">350</div>
                <div class="stats-label">Successfully Analyzed (99.2%)</div>
            </div>
            <div class="stats-item">
                <div class="stats-number failure">3</div>
                <div class="stats-label">Failed (0.8%)</div>
            </div>
        </div>
        
        <div class="header">
            <p><strong>Completed:</strong> 2025-09-23 21:49:33</p>
            <p><strong>Analysis Quality:</strong> 350/353 questions processed successfully</p>
        </div>
    </div>
    
    <script>
        // 简单的统计更新
        document.getElementById('totalQuestions').textContent = '353';
        document.getElementById('successCount').textContent = '350';
        document.getElementById('failureCount').textContent = '3';
        document.title = 'AWS Questions Analysis - 350/353 (99.2%)';
    </script>
</body>
</html>
